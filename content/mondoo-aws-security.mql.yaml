# Copyright (c) Mondoo, Inc.
# SPDX-License-Identifier: BUSL-1.1
policies:
  - uid: mondoo-aws-security
    name: Mondoo AWS Security
    version: 6.0.0
    license: BUSL-1.1
    tags:
      mondoo.com/category: security
      mondoo.com/platform: aws,cloud
    require:
      - provider: aws
      - provider: terraform
    authors:
      - name: Mondoo, Inc.
        email: hello@mondoo.com
    docs:
      desc: |
        The Mondoo AWS Security policy is designed to identify critical misconfigurations that could leave your AWS infrastructure vulnerable to attackers. This policy helps organizations detect and remediate security risks before they can be exploited, reducing the likelihood of unauthorized access, data breaches, privilege escalation, and operational disruptions.

        This policy provides security checks across key AWS services, uncovering misconfigurations that could put critical resources at risk, particularly those exposed to the public internet:

        - API Gateway
        - AWS Backup
        - AWS CodeBuild
        - AWS Config
        - CloudFront
        - CloudTrail
        - CloudWatch
        - DynamoDB
        - Elastic Compute Cloud (EC2) instances & storage
        - Elastic Container Registry (ECR)
        - Elastic Container Service (ECS)
        - ElastiCache (Redis & Memcached)
        - Elastic File System (EFS)
        - Elastic Kubernetes Service (EKS)
        - Elastic Load Balancers (ELBs)
        - Elasticsearch (OpenSearch Service)
        - FSx
        - GuardDuty
        - IAM Access Analyzer
        - Identity and Access Management (IAM)
        - Key Management Service (KMS)
        - Lambda
        - Neptune
        - OpenSearch
        - Relational Database Service (RDS) & Redshift
        - SageMaker
        - Secrets Manager
        - Security Hub
        - Simple Notification Service (SNS)
        - Simple Queue Service (SQS)
        - Simple Storage Service (S3)
        - Virtual Private Cloud (VPCs)

        Have suggestions for new checks in this policy? Visit our [cnspec repository](https://github.com/mondoohq/cnspec).
    groups:
      - title: AWS General
        checks:
          - uid: mondoo-aws-security-no-static-credentials-in-providers
      - title: Amazon API Gateway
        checks:
          - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted
          - uid: mondoo-aws-security-api-gw-execution-logging-enabled
          - uid: mondoo-aws-security-api-gw-require-authentication
          - uid: mondoo-aws-security-api-gw-tls
          - uid: mondoo-aws-security-api-gw-xray-enabled
      - title: AWS IAM
        checks:
          - uid: mondoo-aws-security-access-keys-rotated
          - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
          - uid: mondoo-aws-security-root-account-mfa-enabled
          - uid: mondoo-aws-security-iam-password-policy
          - uid: mondoo-aws-security-iam-root-access-key-check
          - uid: mondoo-aws-security-iam-users-only-one-access-key
          - uid: mondoo-aws-security-iam-group-has-users-check
          - uid: mondoo-aws-security-iam-user-no-inline-policies-check
          - uid: mondoo-aws-security-iam-no-wildcards-policies
      - title: AWS Lambda Function
        checks:
          - uid: mondoo-aws-security-lambda-concurrency-check
          - uid: mondoo-aws-security-lambda-function-public-access-prohibited
      - title: Amazon S3 Bucket
        checks:
          - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
          - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
          - uid: mondoo-aws-security-s3-bucket-versioning-enabled
          - uid: mondoo-aws-security-s3-bucket-logging-enabled
          - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled
          - uid: mondoo-aws-security-s3-bucket-public-read-prohibited
          - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled
      - title: AWS Security Group
        checks:
          - uid: mondoo-aws-security-secgroup-restricted-ssh
          - uid: mondoo-aws-security-secgroup-restricted-vnc
          - uid: mondoo-aws-security-secgroup-restricted-rdp
          - uid: mondoo-aws-security-secgroup-restrict-traffic
      - title: AWS VPC
        checks:
          - uid: mondoo-aws-security-vpc-default-security-group-closed
          - uid: mondoo-aws-security-vpc-flow-logs-enabled
          - uid: mondoo-aws-security-vpc-bpa-enabled
      - title: Amazon DynamoDB Table
        checks:
          - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
      - title: Amazon RDS DB Instance
        checks:
          - uid: mondoo-aws-security-rds-instance-public-access-check
          - uid: mondoo-aws-security-rds-instance-encryption-at-rest
          - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades
          - uid: mondoo-aws-security-rds-snapshot-encrypted
      - title: Amazon RDS DB Cluster
        checks:
          - uid: mondoo-aws-security-rds-cluster-public-access-check
          - uid: mondoo-aws-security-rds-cluster-encryption-at-rest
          - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades
          - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl
      - title: Amazon Redshift Cluster
        checks:
          - uid: mondoo-aws-security-redshift-cluster-public-access-check
          - uid: mondoo-aws-security-redshift-cluster-encrypted
          - uid: mondoo-aws-security-redshift-cluster-audit-logging
          - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing
          - uid: mondoo-aws-security-redshift-cluster-require-ssl
      - title: Amazon EC2
        checks:
          - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
          - uid: mondoo-aws-security-ec2-imdsv2-check
          - uid: mondoo-aws-security-ec2-instance-no-public-ip
          - uid: mondoo-aws-security-ec2-volume-inuse-check
          - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
          - uid: mondoo-aws-security-ebs-snapshot-encrypted
          - uid: mondoo-aws-security-ec2-encrypted-volumes
          - uid: mondoo-aws-security-ec2-user-data-no-secrets
          - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited
      - title: Amazon ECR
        checks:
          - uid: mondoo-aws-security-ecr-image-scan-on-push
          - uid: mondoo-aws-security-ecr-tag-immutability
      - title: Amazon ECS
        checks:
          - uid: mondoo-aws-security-ecs-no-privileged-containers
          - uid: mondoo-aws-security-ecs-readonly-root-filesystem
          - uid: mondoo-aws-security-ecs-logging-enabled
          - uid: mondoo-aws-security-ecs-container-non-root-user
          - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption
      - title: Amazon EFS Filesystem
        checks:
          - uid: mondoo-aws-security-efs-encrypted-check
          - uid: mondoo-aws-security-efs-backup-enabled
      - title: AWS CloudWatch
        checks:
          - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
          - uid: mondoo-aws-security-cloudwatch-log-group-retention-set
      - title: AWS ELB Load Balancer
        checks:
          - uid: mondoo-aws-security-elb-deletion-protection-enabled
          - uid: mondoo-aws-security-elb-logging-enabled
          - uid: mondoo-aws-security-elb-security-policy-enabled
          - uid: mondoo-aws-security-elb-ssl-listener
          - uid: mondoo-aws-security-elb-drop-invalid-headers
      - title: AWS Elasticsearch Domain
        checks:
          - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
      - title: Amazon OpenSearch
        checks:
          - uid: mondoo-aws-security-opensearch-enforce-https
          - uid: mondoo-aws-security-opensearch-node-to-node-encryption
          - uid: mondoo-aws-security-opensearch-tls-policy
          - uid: mondoo-aws-security-opensearch-fine-grained-access-control
          - uid: mondoo-aws-security-opensearch-audit-logging
          - uid: mondoo-aws-security-opensearch-in-vpc
          - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled
      - title: AWS KMS Key
        checks:
          - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
      - title: Amazon SageMaker Notebook Instance
        checks:
          - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
          - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet
      - title: Amazon CloudFront
        checks:
          - uid: mondoo-aws-security-cloudfront-viewer-policy-https
          - uid: mondoo-aws-security-cloudfront-minimum-tls-version
          - uid: mondoo-aws-security-cloudfront-waf-enabled
      - title: AWS CloudTrail Trail
        checks:
          - uid: mondoo-aws-security-cloud-trail-encryption-enabled
          - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled
          - uid: mondoo-aws-security-cloud-trail-multi-region-enabled
      - title: Amazon EKS Cluster
        checks:
          - uid: mondoo-aws-security-eks-cluster-cmks-in-kms
          - uid: mondoo-aws-security-eks-cluster-private-controlplane
          - uid: mondoo-aws-security-eks-cluster-logging-enabled
          - uid: mondoo-aws-security-eks-cluster-restrict-public-access
          - uid: mondoo-aws-security-eks-cluster-deletion-protection
      - title: Amazon GuardDuty
        checks:
          - uid: mondoo-aws-security-guardduty-enabled
          - uid: mondoo-aws-security-guardduty-findings-publishing-frequency
      - title: AWS Security Hub
        checks:
          - uid: mondoo-aws-security-securityhub-enabled
      - title: AWS Config
        checks:
          - uid: mondoo-aws-security-config-recorder-enabled
          - uid: mondoo-aws-security-config-recorder-all-resources
      - title: AWS Secrets Manager
        checks:
          - uid: mondoo-aws-security-secretsmanager-rotation-enabled
          - uid: mondoo-aws-security-secretsmanager-cmk-encryption
      - title: IAM Access Analyzer
        checks:
          - uid: mondoo-aws-security-iam-access-analyzer-enabled
      - title: Amazon SNS
        checks:
          - uid: mondoo-aws-security-sns-topic-encrypted
          - uid: mondoo-aws-security-sns-topic-signature-version
      - title: Amazon SQS
        checks:
          - uid: mondoo-aws-security-sqs-queue-encrypted
          - uid: mondoo-aws-security-sqs-queue-dead-letter-queue
      - title: Amazon ElastiCache
        checks:
          - uid: mondoo-aws-security-elasticache-encryption-at-rest
          - uid: mondoo-aws-security-elasticache-encryption-in-transit
          - uid: mondoo-aws-security-elasticache-redis-auth-enabled
      - title: AWS Backup
        checks:
          - uid: mondoo-aws-security-backup-vault-encrypted
      - title: Amazon FSx
        checks:
          - uid: mondoo-aws-security-fsx-filesystem-encrypted
      - title: AWS CodeBuild
        checks:
          - uid: mondoo-aws-security-codebuild-no-privileged-mode
          - uid: mondoo-aws-security-codebuild-no-plaintext-credentials
      - title: Amazon Neptune
        checks:
          - uid: mondoo-aws-security-neptune-cluster-encrypted
    scoring_system: highest impact
queries:
  - uid: mondoo-aws-security-eks-cluster-cmks-in-kms
    title: Ensure Amazon EKS clusters are configured to use AWS Key Management Service (KMS) for encryption of Kubernetes secrets
    impact: 70
    variants:
      - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-hcl
      - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-plan
      - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EKS clusters are configured to use AWS Key Management Service (KMS) for encryption of Kubernetes secrets. By default, EKS uses a default KMS key for encryption, but organizations can create and manage their own customer-managed keys (CMKs) for enhanced security and compliance.

        **Why this matters**

        Using KMS for encryption provides several benefits:

        - **Data protection:** Secrets are encrypted at rest using strong encryption algorithms.
        - **Access control:** Organizations can manage access to the KMS key using IAM policies.
        - **Auditability:** AWS CloudTrail logs all KMS key usage, providing a detailed audit trail.

        **Risk mitigation:**

        - **Prevents unauthorized access:** Only authorized users and services can decrypt secrets.
        - **Ensures compliance:** Meets regulatory requirements for data protection and encryption.
        - **Enhances security posture:** Reduces the risk of data breaches and unauthorized access to sensitive information.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EKS Console.
            2. Select the EKS cluster you want to configure.
            3. In the Configuration tab, select Secrets Encryption.
            4. Choose the option to use a custom KMS key.
            5. Select or create a new KMS key for encryption.
            6. Save the changes to apply the new configuration.
        - id: cli
          desc: |
            **Using AWS CLI**

            To check if your EKS cluster is using a custom KMS key:

            ```bash
            aws eks describe-cluster --name <cluster_name> --query "cluster.encryptionConfig"
            ```

            If no custom KMS key is listed, you can update the cluster configuration:

            ```bash
            aws eks update-cluster-config --name <cluster_name> --resources-vpc-config <vpc_config> --encryption-config <kms_key_arn>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Define an EKS cluster with a custom KMS key in your Terraform configuration:

            ```hcl
            resource "aws_eks_cluster" "example" {
              name     = "example-cluster"
              role_arn = aws_iam_role.eks_role.arn

              vpc_config {
                subnet_ids = [aws_subnet.eks_subnet.id]
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Create an EKS cluster with a custom KMS key in your CloudFormation template:

            ```yaml
            Resources:
              MyEKSCluster:
                Type: AWS::EKS::Cluster
                Properties:
                  Name: example-cluster
                  RoleArn: !GetAtt eksRole.Arn
                  VpcConfig:
                    SubnetIds:
                      - !Ref eksSubnet
                  EncryptionConfig:
                    - Provider:
                        KeyArn: !Ref myKmsKey
                      Resources:
                        - "*"
            ```
    refs:
      - url: https://docs.aws.amazon.com/eks/latest/best-practices/security.html
        title: Amazon EKS Security Best Practices
      - url: https://docs.aws.amazon.com/kms/latest/developerguide/best-practices.html
        title: AWS KMS Best Practices
  - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-api
    filters: asset.platform == "aws-eks-cluster"
    mql: |
      aws.eks.cluster.encryptionConfig != empty
  - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_eks_cluster")
    mql: |
      terraform.resources.where( nameLabel == "aws_eks_cluster" ).all(
        blocks.where( type == "encryption_config" ) != empty &&
        blocks.where( type == "encryption_config" ).all(
          blocks.where( type == "provider" ) != empty &&
          blocks.where( type == "provider" ).all( arguments.key_arn != empty )
        )
      )
  - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_eks_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_eks_cluster").all(
        change.after.encryption_config != empty &&
        change.after.encryption_config.all(
          _['provider'] != empty &&
          _['provider'].all( _['key_arn'] != empty )
        )
      )
  - uid: mondoo-aws-security-eks-cluster-cmks-in-kms-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_eks_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_eks_cluster").all(
        values.encryption_config != empty &&
        values.encryption_config.all(
          _['provider'] != empty &&
          _['provider'].all( _['key_arn'] != empty )
        )
      )
  - uid: mondoo-aws-security-eks-cluster-private-controlplane
    title: Ensure Amazon EKS clusters are configured with private endpoint access only
    impact: 90
    variants:
      - uid: mondoo-aws-security-eks-cluster-private-controlplane-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-hcl
      - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-plan
      - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-state
    docs:
      refs:
        - url: https://docs.aws.amazon.com/eks/latest/userguide/pod-networking.html
          title: Amazon EKS - Pod networking
        - url: https://docs.aws.amazon.com/eks/latest/userguide/networking-vpc.html
          title: Amazon EKS - Networking in Amazon VPC
      desc: |
        This check ensures that Amazon EKS clusters are configured with private endpoint access. By default, EKS clusters are accessible over the public internet, which can expose them to potential attacks. Configuring private endpoint access restricts access to the cluster's API server to resources within the VPC.

        **Why this matters**

        - **Security:** Reduces the attack surface by preventing public access to the EKS control plane.
        - **Compliance:** Meets security standards and best practices for cloud-native applications.
        - **Network isolation:** Enhances network security by limiting access to trusted networks.

        **Risk mitigation:**

        - **Prevents unauthorized access:** Only resources within the VPC can communicate with the EKS control plane.
        - **Enhances security posture:** Reduces the risk of data breaches and unauthorized access to sensitive information.
        - **Improves compliance:** Aligns with security frameworks and regulations that require network isolation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EKS Console.
            2. Select the EKS cluster you want to configure.
            3. In the Configuration tab, select Networking.
            4. Under Cluster Endpoint Access, select Private and ensure Public access is disabled (unchecked).
            5. Save the changes to apply the new configuration.
        - id: cli
          desc: |
            **Using AWS CLI**

            To check if your EKS cluster is using private endpoint access and not public endpoint access:

            ```bash
            aws eks describe-cluster --name <cluster_name> --query "cluster.resourcesVpcConfig.{Private:endpointPrivateAccess, Public:endpointPublicAccess}"
            ```

            The output should show `"Private": true` and `"Public": false`.

            If the output does not match, you can update the cluster configuration:

            ```bash
            aws eks update-cluster-config --name <cluster_name> --resources-vpc-config endpointPrivateAccess=true,endpointPublicAccess=false
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Define an EKS cluster with private endpoint access and public endpoint access disabled in your Terraform configuration:

            ```hcl
            resource "aws_eks_cluster" "example" {
              name     = "example-cluster"
              role_arn = aws_iam_role.eks_role.arn

              vpc_config {
                subnet_ids               = [aws_subnet.eks_subnet.id]
                endpoint_private_access  = true
                endpoint_public_access   = false
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Create an EKS cluster with private endpoint access in your CloudFormation template:

            ```yaml
            Resources:
              MyEKSCluster:
                Type: AWS::EKS::Cluster
                Properties:
                  Name: example-cluster
                  RoleArn: !GetAtt eksRole.Arn
                  VpcConfig:
                    SubnetIds:
                      - !Ref eksSubnet
                    EndpointPrivateAccess: true
                    EndpointPublicAccess: false
            ```
    refs:
      - url: https://docs.aws.amazon.com/eks/latest/best-practices/security.html
        title: Amazon EKS Security Best Practices
  - uid: mondoo-aws-security-eks-cluster-private-controlplane-api
    filters: asset.platform == "aws-eks-cluster"
    mql: |
      aws.eks.cluster.resourcesVpcConfig.endpointPrivateAccess == true
      aws.eks.cluster.resourcesVpcConfig.endpointPublicAccess == false
  - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_eks_cluster")
    mql: |
      terraform.resources.where( nameLabel == "aws_eks_cluster" ).all(
        blocks.where( type == "vpc_config" ) != empty &&
        blocks.where( type == "vpc_config" ).all(
          arguments.endpoint_private_access == true &&
          arguments.endpoint_public_access == false
        )
      )
  - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_eks_cluster")
    mql: |
      eksPlan = terraform.plan.resourceChanges.where(type == "aws_eks_cluster").map(change.after.vpc_config).flat
      eksPlan.all(_['endpoint_private_access'] == true)
      eksPlan.all(_['endpoint_public_access'] == false)
  - uid: mondoo-aws-security-eks-cluster-private-controlplane-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      eksState = terraform.state.resources.where(type == "aws_eks_cluster").map(values.vpc_config).flat
      eksState.all(_['endpoint_private_access'] == true)
      eksState.all(_['endpoint_public_access'] == false)
  - uid: mondoo-aws-security-iam-root-access-key-check
    title: Ensure no root user account access key exists
    impact: 85
    variants:
      - uid: mondoo-aws-security-iam-root-access-key-check-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-hcl
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-plan
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-state
    docs:
      desc: |
        This check ensures that the AWS root user account does not have an active access key. The AWS root user has full administrative privileges over the AWS account, making it the most powerful identity in AWS. AWS best practices recommend that root user credentials should never be used for everyday operations, and instead, AWS Identity and Access Management (IAM) users or roles should be utilized for all administrative tasks.

        **Why this matters**

        Root user access keys pose a high security risk if compromised, as they provide unrestricted access to all AWS resources. If an attacker gains access to a root user's credentials, they can:

        - Delete or modify critical resources.
        - Access sensitive data across all AWS services.
        - Disable security controls, logging, and monitoring.

        By ensuring that no root user access keys exist, organizations can enforce security best practices and reduce the risk of unauthorized access.

        **Risk mitigation:**

        - **Prevents root key compromise:** Eliminates a major attack vector for AWS account takeovers.
        - **Ensures compliance:** Aligns with security frameworks like CIS AWS Foundations Benchmark, SOC 2, PCI DSS, and ISO 27001.
        - **Encourages least privilege:** Promotes the use of IAM users and roles for secure access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users → Root User.
            3.  Under Access Keys, verify that no access keys are listed.
            4.  If an access key exists, delete it immediately:
                - Select the Access Key ID.
                - Select Delete and confirm the action.
            5.  Ensure that MFA is enabled for the root user for additional security.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if the root user has an access key:

            ```bash
            aws iam get-account-summary --query "SummaryMap.RootAccessKeysPresent"
            ```

            If the output is greater than 0, a root access key exists.

            Delete the root access key (replace ACCESS_KEY_ID with the actual key ID):

            ```bash
            aws iam delete-access-key --access-key-id ACCESS_KEY_ID --user-name root
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not allow direct management of the root user's access key via Terraform. However, you should enforce IAM policies that prevent the creation of root access keys:

            ```hcl
            resource "aws_iam_policy" "deny_root_access_keys" {
              name        = "DenyRootAccessKeys"
              description = "Prevents creation of root user access keys"

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect   = "Deny"
                    Action   = "iam:CreateAccessKey"
                    Resource = "arn:aws:iam::123456789012:root"
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            AWS does not allow direct management of the root user's access keys via CloudFormation. However, you can create a stack that implements preventative controls:

            ```yaml
            Resources:
              DenyRootAccessKeysPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: DenyRootAccessKeys
                  Description: Prevents creation of root user access keys
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action: 'iam:CreateAccessKey'
                        Resource: 'arn:aws:iam::123456789012:root'

            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html
        title: AWS Documentation - AWS account root user
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user_manage_delete-key.html
        title: AWS Documentation - Delete access keys for the root user
  - uid: mondoo-aws-security-iam-root-access-key-check-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(properties.user == "<root_account>").all(accessKey1Active == false)
      aws.iam.credentialReport.where(properties.user == "<root_account>").all(accessKey2Active == false)
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-hcl
    filters: asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(arguments.policy.any(Statement {Effect == "Deny" && Action == "iam:CreateAccessKey"} ) )
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-plan
    filters: asset.platform == "terraform-plan"
    mql: |
      policyPlan = terraform.plan.resourceChanges.where(type == "aws_iam_policy").map(change.after.policy).first
      policyPlan.contains('Action') && policyPlan.contains('iam:CreateAccessKey')
      policyPlan.contains('Effect') && policyPlan.contains('Deny')
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      policyState = terraform.state.resources.where(type == "aws_iam_policy").map(values.policy).first
      policyState.contains('Action') && policyState.contains('iam:CreateAccessKey')
      policyState.contains('Effect') && policyState.contains('Deny')
  - uid: mondoo-aws-security-root-account-mfa-enabled
    title: Ensure MFA is enabled for the "root user" account
    impact: 95
    variants:
      - uid: mondoo-aws-security-root-account-mfa-enabled-aws
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-hcl
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-plan
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Multi-Factor Authentication (MFA) is enabled for the AWS root user account. The root user has full administrative privileges over an AWS account, making it the most critical identity. Enabling MFA significantly enhances security by requiring an additional authentication factor beyond just the password.

        **Why this matters**

        The root user account is the most powerful account in AWS, and if compromised, an attacker can gain full control over all AWS resources. Without MFA, an attacker who obtains the root password (via phishing, credential leaks, or brute-force attacks) can:

        - Delete or modify critical resources.
        - Disable security controls, logging, and monitoring.
        - Access and exfiltrate sensitive data.

        By enabling Multi-Factor Authentication (MFA), organizations prevent unauthorized access, even if root credentials are compromised. AWS supports hardware MFA tokens and virtual MFA devices (such as Authy or Google Authenticator) for added security.

        **Risk mitigation:**

        - **Prevents account takeovers:** Even if the root password is stolen, MFA blocks unauthorized logins.
        - **Ensures compliance:** Meets security standards such as CIS AWS Foundations Benchmark, SOC 2, ISO 27001, and PCI DSS.
        - **Strengthens account security:** Adds an extra layer of authentication beyond the password.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users → Root User.
            3.  Under Multi-Factor Authentication (MFA), check if an MFA device is assigned.
            4.  If no MFA is enabled, select Enable MFA and choose one of the following options:
              - Virtual MFA device: Use a mobile authenticator app (e.g., Google Authenticator, Authy).
              - Hardware MFA device: Use a FIDO2 security key or an AWS-supported MFA token.
            5.  Follow the on-screen steps to scan the QR code (for virtual MFA) or register a hardware MFA device.
            6.  Enter the two consecutive MFA codes generated by the device and select Enable MFA.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if MFA is enabled for the root user:

            ```bash
            aws iam get-account-summary --query "SummaryMap.AccountMFAEnabled"
            ```

            If the output is 0, MFA is not enabled.

            To enable MFA, first list existing MFA devices:

            ```bash
            aws iam list-mfa-devices --user-name root
            ```

            If no device is listed, assign a new MFA device (replace arn-of-mfa-device with the correct ARN):

            ```bash
            aws iam enable-mfa-device --user-name root --serial-number arn-of-mfa-device --authentication-code-1 123456 --authentication-code-2 654321
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not allow managing root MFA directly through Terraform. However, you can enforce a security policy that blocks root logins unless MFA is enabled:

            ```hcl
            resource "aws_iam_policy" "require_root_mfa" {
              name        = "RequireRootMFA"
              description = "Blocks root logins without MFA"

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect   = "Deny"
                    Action   = "sts:AssumeRole"
                    Resource = "*"
                    Condition = {
                      BoolIfExists = {
                        "aws:MultiFactorAuthPresent": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RequireRootMFAPolicy:
                Type: "AWS::IAM::ManagedPolicy"
                Properties:
                  Description: "Blocks root logins without MFA"
                  ManagedPolicyName: "RequireRootMFA"
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Deny"
                        Action: "*"
                        Resource: "*"
                        Condition:
                          Bool:
                            "aws:MultiFactorAuthPresent": "false"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/enable-virt-mfa-for-root.html
        title: Enable a virtual MFA device for the root user (console)
  - uid: mondoo-aws-security-root-account-mfa-enabled-aws
    filters: asset.platform == "aws"
    mql: aws.iam.credentialReport.where(properties.user == "<root_account>").all(mfaActive == true)
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy") {
        arguments.policy {
          Statement {
            Effect == "Deny"
            Action == "sts:AssumeRole"
            Resource == "*"
            Condition {BoolIfExists {_["aws:MultiFactorAuthPresent"] == false}}
          }
        }
      }
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_xxx" )
    mql: |
      policyPlan = terraform.plan.resourceChanges.where(type == "aws_iam_policy").map(change.after.policy).first
      policyPlan.contains('Action') && policyPlan.contains('sts:AssumeRole')
      policyPlan.contains('Effect') && policyPlan.contains('Deny')
      policyPlan.contains('Resource') && policyPlan.contains('"*"')
      policyPlan.contains('aws:MultiFactorAuthPresent') && policyPlan.contains('false')
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_xxx" )
    mql: |
      policyState = terraform.state.resources.where(type == "aws_iam_policy").map(values.policy).first
      policyState.contains('Action') && policyState.contains('sts:AssumeRole')
      policyState.contains('Effect') && policyState.contains('Deny')
      policyState.contains('Resource') && policyState.contains('"*"')
      policyState.contains('aws:MultiFactorAuthPresent') && policyState.contains('false')
  - uid: mondoo-aws-security-iam-password-policy
    title: Ensure strong account password policy requirements are used
    impact: 60
    props:
      - uid: mondooAWSSecurityIamPasswordPolicyMaxPasswordAge
        title: Define the maximum number of days a password is allowed to exist before being rotated
        mql: "90"
      - uid: mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength
        title: Minimum password length
        mql: "14"
      - uid: mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention
        title: Number of passwords before allowing reuse
        mql: "24"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireLowercaseCharacters
        title: Denotes whether lowercase characters are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireNumbers
        title: Denotes whether numbers are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireSymbols
        title: Denotes whether symbols are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireUppercaseCharacters
        title: Denotes whether uppercase characters are required for passwords
        mql: "true"
    variants:
      - uid: mondoo-aws-security-iam-password-policy-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-password-policy-terraform-hcl
      - uid: mondoo-aws-security-iam-password-policy-terraform-plan
      - uid: mondoo-aws-security-iam-password-policy-terraform-state
    docs:
      desc: |
        This check ensures that AWS accounts enforce a strong IAM password policy to enhance security by preventing weak or easily guessable passwords. A well-defined password policy helps protect against brute-force attacks, credential stuffing, and unauthorized access.

        **Why this matters**

        Without a strong password policy, IAM users may use weak passwords, increasing the risk of compromised credentials. Implementing a strict password policy ensures that AWS accounts comply with security best practices and regulatory standards such as CIS AWS Foundations Benchmark, NIST, ISO 27001, PCI DSS, and SOC 2.

        A secure IAM password policy should enforce the following requirements:

        - At least one uppercase character
        - At least one lowercase character
        - At least one number
        - At least one symbol (e.g., !@#$%^&*)
        - A minimum password length of 14 characters
        - Prevention of password reuse for at least the last 24 passwords
        - Password expiration after 90 days

        **Risk mitigation:**

        - **Prevents brute-force attacks:** Ensures passwords are complex and difficult to guess.
        - **Reduces credential stuffing risks:** Enforces frequent password changes and prevents password reuse.
        - **Ensures compliance:** Meets security requirements for regulated industries.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Account settings in the left panel.
            3.  In the Password Policy section, ensure the following settings are enabled:
              - Require at least one uppercase letter
              - Require at least one lowercase letter
              - Require at least one number
              - Require at least one symbol
              - Require a minimum password length of 14 characters
              - Prevent password reuse for the last 24 passwords
              - Require password expiration every 90 days
            4.  Select Apply Password Policy to enforce these settings.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the current password policy settings:

            ```bash
            aws iam get-account-password-policy
            ```

            If no password policy exists, apply a strong password policy:

            ```bash
            aws iam update-account-password-policy \
            --minimum-password-length 14 \
            --require-symbols true \
            --require-numbers true \
            --require-uppercase-characters true \
            --require-lowercase-characters true \
            --max-password-age 90 \
            --password-reuse-prevention 24 \
            --allow-users-to-change-password true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Define a strict password policy using Terraform:

            ```hcl
            resource "aws_iam_account_password_policy" "strong_policy" {
              minimum_password_length        = 14
              require_uppercase_characters   = true
              require_lowercase_characters   = true
              require_numbers                = true
              require_symbols                = true
              max_password_age               = 90
              password_reuse_prevention      = 24
              allow_users_to_change_password = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can enforce a strong IAM password policy by creating an AWS::IAM::AccountPasswordPolicy resource with the necessary complexity requirements:

            ```yaml
            Resources:
              StrongIAMPasswordPolicy:
                Type: "AWS::IAM::AccountPasswordPolicy"
                Properties:
                  MinimumPasswordLength: 14
                  RequireUppercaseCharacters: true
                  RequireLowercaseCharacters: true
                  RequireNumbers: true
                  RequireSymbols: true
                  MaxPasswordAge: 90
                  PasswordReusePrevention: 24
                  AllowUsersToChangePassword: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords.html
        title: User passwords in AWS
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html
        title: Set an account password policy for IAM users
  - uid: mondoo-aws-security-iam-password-policy-api
    filters: asset.platform == "aws"
    mql: |
      // Ensure properties do exist.
      aws.iam.accountPasswordPolicy.RequireUppercaseCharacters != empty
      aws.iam.accountPasswordPolicy.RequireLowercaseCharacters != empty
      aws.iam.accountPasswordPolicy.RequireSymbols != empty
      aws.iam.accountPasswordPolicy.RequireNumbers != empty
      aws.iam.accountPasswordPolicy.MinimumPasswordLength != empty
      aws.iam.accountPasswordPolicy.PasswordReusePrevention != empty
      aws.iam.accountPasswordPolicy.MaxPasswordAge != empty
      // Validate each policy setting against props
      aws.iam.accountPasswordPolicy.where(RequireUppercaseCharacters != empty).all(RequireUppercaseCharacters == props.mondooAWSSecurityIamPasswordPolicyRequireUppercaseCharacters)
      aws.iam.accountPasswordPolicy.where(RequireLowercaseCharacters != empty).all(RequireLowercaseCharacters == props.mondooAWSSecurityIamPasswordPolicyRequireLowercaseCharacters)
      aws.iam.accountPasswordPolicy.where(RequireSymbols != empty).all(RequireSymbols == props.mondooAWSSecurityIamPasswordPolicyRequireSymbols)
      aws.iam.accountPasswordPolicy.where(RequireNumbers != empty).all(RequireNumbers == props.mondooAWSSecurityIamPasswordPolicyRequireNumbers)
      aws.iam.accountPasswordPolicy.where(MinimumPasswordLength != empty).all(MinimumPasswordLength >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength)
      aws.iam.accountPasswordPolicy.where(PasswordReusePrevention != empty).all(PasswordReusePrevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention)
      aws.iam.accountPasswordPolicy.where(MaxPasswordAge != empty).all(MaxPasswordAge <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge)
  - uid: mondoo-aws-security-iam-password-policy-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_account_password_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_account_password_policy").all(
        arguments.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength &&
        arguments.require_uppercase_characters == true &&
        arguments.require_lowercase_characters == true &&
        arguments.require_numbers == true &&
        arguments.require_symbols == true &&
        arguments.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge &&
        arguments.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention &&
        arguments.allow_users_to_change_password == true
      )
  - uid: mondoo-aws-security-iam-password-policy-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_account_password_policy")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_account_password_policy").all(
        change.after.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength &&
        change.after.require_uppercase_characters == true &&
        change.after.require_lowercase_characters == true &&
        change.after.require_numbers == true &&
        change.after.require_symbols == true &&
        change.after.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge &&
        change.after.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention &&
        change.after.allow_users_to_change_password == true
      )
  - uid: mondoo-aws-security-iam-password-policy-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_account_password_policy")
    mql: |
      terraform.state.resources.where(type == "aws_iam_account_password_policy").all(
        values.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength &&
        values.require_uppercase_characters == true &&
        values.require_lowercase_characters == true &&
        values.require_numbers == true &&
        values.require_symbols == true &&
        values.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge &&
        values.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention &&
        values.allow_users_to_change_password == true
      )
  - uid: mondoo-aws-security-access-keys-rotated
    title: Ensure IAM user access keys are rotated
    impact: 70
    props:
      - uid: mondooAWSSecurityMaxAccessKeyAge
        title: Define the maximum number of days an IAM key is allowed to exist before rotation
        mql: "90"
    variants:
      - uid: mondoo-aws-security-access-keys-rotated-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-access-keys-rotated-state
    docs:
      desc: |
        This check ensures that AWS IAM user access keys are regularly rotated to reduce the risk of credential compromise. Access keys should be changed periodically to prevent long-term exposure and limit the impact of potential key leaks. AWS best practices recommend rotating IAM access keys every 90 days or less.

        **Why this matters**

        IAM access keys provide programmatic access to AWS services. If an access key is compromised, an attacker could gain unauthorized access to AWS resources. Regularly rotating access keys limits the window of opportunity for an attacker to use stolen credentials.

        A strong key rotation policy helps organizations comply with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2.

        **Risk mitigation:**

        - Reduces the risk of long-term key exposure
        - Ensures compliance with security and regulatory standards
        - Limits the impact of potential credential leaks
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users in the left panel.
            3.  Select an IAM user and go to the Security Credentials tab.
            4.  Under Access Keys, check the Last Used and Created Date columns.
            5.  If a key is older than 90 days, create a new access key:
              - Select Create access key
              - Update AWS applications and scripts to use the new key
              - Deactivate and delete the old access key
            6.  Repeat this process for all IAM users with access keys.
        - id: cli
          desc: |
            **Using AWS CLI**

            List all IAM users with active access keys:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check the age of access keys for each user:

            ```bash
            aws iam list-access-keys --user-name <username> --query "AccessKeyMetadata[*].{AccessKeyId:AccessKeyId, CreateDate:CreateDate}"
            ```

            If a key is older than 90 days, create a new key and delete the old one:

            ```bash
            aws iam create-access-key --user-name <username>
            aws iam delete-access-key --access-key-id <old-access-key-id> --user-name <username>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not support automatic access key rotation in Terraform, but you can enforce IAM policies to require regular key rotation:

            ```hcl
            resource "aws_iam_policy" "enforce_key_rotation" {
              name        = "EnforceKeyRotation"
              description = "Requires IAM users to rotate access keys every 90 days"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = "iam:UpdateAccessKey",
                    Resource = "*",
                    Condition = {
                      NumericGreaterThan = {
                        "aws:MultiFactorAuthAge": 7776000  # 90 days in seconds
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              # IAM policy to enforce key rotation
              EnforceKeyRotationPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: EnforceKeyRotation
                  Description: Requires IAM users to rotate access keys every 90 days
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action: 'iam:UpdateAccessKey'
                        Resource: '*'
                        Condition:
                          NumericGreaterThan:
                            'aws:MultiFactorAuthAge': 7776000  # 90 days in seconds
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
        title: AWS Documentation - Manage access keys for IAM users
  - uid: mondoo-aws-security-access-keys-rotated-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(accessKey1Active == true && time.now - createdAt > props.mondooAWSSecurityMaxAccessKeyAge * time.day).all(time.now - accessKey1LastRotated < props.mondooAWSSecurityMaxAccessKeyAge * time.day)
      aws.iam.credentialReport.where(accessKey2Active == true && time.now - createdAt > props.mondooAWSSecurityMaxAccessKeyAge * time.day).all(time.now - accessKey2LastRotated < props.mondooAWSSecurityMaxAccessKeyAge * time.day)
  - uid: mondoo-aws-security-access-keys-rotated-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_access_key")
    mql: |
      creationDate = parse.date(terraform.state.resources.where(type == "aws_iam_access_key").map(values.create_date).first)
      time.now - creationDate
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
    title: Ensure multi-factor authentication is enabled for all IAM users with console access
    impact: 90
    variants:
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-hcl
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-plan
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-state
    docs:
      desc: |
        This check ensures that all AWS IAM users with console access have Multi-Factor Authentication (MFA) enabled. MFA provides an additional layer of security beyond just a username and password, reducing the risk of unauthorized account access in case credentials are compromised.

        **Why this matters**

        IAM users with console access rely on password-based authentication, which is vulnerable to phishing, credential leaks, and brute-force attacks. Without MFA, an attacker who obtains an IAM user's password can gain unauthorized access to AWS resources. Enforcing MFA helps mitigate this risk by requiring a second factor, such as a one-time code from a mobile authenticator app or a hardware security key.

        AWS best practices and security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2 require MFA for all users with administrative or privileged access.

        **Risk mitigation:**

        - Prevents unauthorized access due to stolen or weak passwords
        - Enhances security posture by enforcing multi-layer authentication
        - Aligns with compliance and security best practices
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users in the left panel.
            3.  Identify users with Console Access enabled.
            4.  Select a user and go to the Security Credentials tab.
            5.  Under Multi-Factor Authentication (MFA), check if MFA is enabled.
            6.  If MFA is not enabled:
              - Select Assign MFA Device
              - Choose a method (Virtual MFA Device, FIDO Security Key, or Hardware MFA Token)
              - Follow the setup process and enter the required MFA codes
            7.  Repeat this process for all IAM users with console access.
        - id: cli
          desc: |
            **Using AWS CLI**

            List IAM users with console access and check their MFA status:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            For each user, check if MFA is enabled:

            ```bash
            aws iam list-mfa-devices --user-name <username>
            ```

            If no MFA device is listed, enforce MFA by setting up a virtual MFA device:

            ```bash
            aws iam enable-mfa-device --user-name <username> --serial-number "arn-of-mfa-device" --authentication-code-1 123456 --authentication-code-2 654321
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not allow enforcing MFA directly via Terraform, but you can create an IAM policy that denies access unless MFA is enabled:

            ```hcl
            resource "aws_iam_policy" "enforce_mfa" {
              name        = "EnforceMFA"
              description = "Require MFA for all IAM users with console access"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = [
                      "ec2:*",
                      "s3:*",
                      "iam:*",
                      "lambda:*"
                    ],
                    Resource  = "*",
                    Condition = {
                      Bool = {
                        "aws:MultiFactorAuthPresent": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              EnforceMFAPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: EnforceMFA
                  Description: Require MFA for all IAM users with console access
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action:
                          - 'ec2:*'
                          - 's3:*'
                          - 'iam:*'
                          - 'lambda:*'
                        Resource: '*'
                        Condition:
                          Bool:
                            'aws:MultiFactorAuthPresent': 'false'

            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html
        title: AWS Multi-factor authentication in IAM
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html
        title: Assign a virtual MFA device in the AWS Management Console
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(passwordEnabled == true).all(mfaActive == true)
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(
        arguments.policy.any(
          _['Statement'].any(
            _['Condition']['Bool']['aws:MultiFactorAuthPresent'] == false
              && _['Effect'] == "Deny"
              && _['Resource'] == "*"
          )
        )
      )
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-plan
    filters: asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_policy").any(
        change.after.policy.contains('Deny') &&
        change.after.policy.contains('aws:MultiFactorAuthPresent') &&
        change.after.policy.contains('false')
      )
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "aws_iam_policy").any(
        values.policy.contains('Deny') &&
        values.policy.contains('aws:MultiFactorAuthPresent') &&
        values.policy.contains('false')
      )
  - uid: mondoo-aws-security-iam-group-has-users-check
    title: Ensure IAM groups are utilized by assigning at least one user
    impact: 30
    variants:
      - uid: mondoo-aws-security-iam-group-has-users-check-single
        tags:
          mondoo.com/filter-title: "AWS IAM Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-hcl
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-plan
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-state
    docs:
      desc: |
        This check ensures that IAM groups in AWS have at least one assigned user. IAM groups help manage permissions efficiently by allowing administrators to assign policies at the group level instead of managing permissions for individual IAM users. If IAM groups exist without any users, it indicates potential misconfigurations or unused access controls.

        **Why this matters**

        IAM groups simplify access management by allowing permissions to be applied collectively to users rather than individually. This reduces administrative overhead, enforces consistency, and minimizes the risk of misconfigured permissions. If IAM groups exist but have no users assigned, it may indicate:

        - Poor permission management practices.
        - Orphaned groups that should be removed or repurposed.
        - A failure to follow the principle of least privilege, leading to excessive permissions being granted to individual users.

        By ensuring that IAM groups are properly utilized, organizations can improve security, maintain structured access controls, and reduce human errors in permission assignments.

        **Risk mitigation:**

        - Reduces the risk of misconfigured permissions by enforcing structured access control.
        - Simplifies permission management by grouping users with similar roles.
        - Aligns with security best practices and compliance frameworks such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and SOC 2.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Groups in the left panel.
            3.  Review IAM groups and check if they have at least one assigned user.
            4.  If a group has no users:
              - Select the group name.
              - Go to the Users tab and select Add Users to Group.
              - Select the appropriate users and select Add Users.
            5.  If an IAM group is not needed, consider deleting it to reduce clutter.
        - id: cli
          desc: |
            **Using AWS CLI**

            List all IAM groups:

            ```bash
            aws iam list-groups --query "Groups[*].GroupName"
            ```

            Check if an IAM group has users assigned:

            ```bash
            aws iam get-group --group-name <group-name> --query "Users[*].UserName"
            ```

            If a group has no users, add a user to the group:

            ```bash
            aws iam add-user-to-group --group-name <group-name> --user-name <user-name>
            ```

            If a group is unused and unnecessary, delete it:

            ```bash
            aws iam delete-group --group-name <group-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure IAM users are assigned to groups in Terraform:

            ```hcl
            resource "aws_iam_group" "admins" {
              name = "Admins"
            }

            resource "aws_iam_user" "user1" {
              name = "user1"
            }

            resource "aws_iam_group_membership" "admin_membership" {
              name  = "admin-membership"
              group = aws_iam_group.admins.name
              users = [aws_iam_user.user1.name]
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can manage IAM groups and group memberships. To ensure IAM groups have at least one user:

            ```yaml
            Resources:
              # Create an IAM group
              AdminGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "Administrators"
                  Path: "/"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/AdministratorAccess"

              # Create an IAM user
              AdminUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "admin-user"
                  Path: "/"

              # Add user to the group
              GroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref AdminGroup
                  Users:
                    - !Ref AdminUser
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage.html
        title: AWS Documentation - IAM user groups
  - uid: mondoo-aws-security-iam-group-has-users-check-single
    filters: asset.platform == "aws-iam-group"
    mql: aws.iam.group.usernames != empty
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_group_membership")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_group_membership").all(
        arguments.users != empty
      )
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_group_membership")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_group_membership").all(
        change.after.users != empty
      )
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_group_membership")
    mql: |
      terraform.state.resources.where(type == "aws_iam_group_membership").all(
        values.users != empty
      )
  - uid: mondoo-aws-security-iam-users-only-one-access-key
    title: Ensure there is only one active access key available for any single IAM user
    impact: 70
    variants:
      - uid: mondoo-aws-security-iam-users-only-one-access-key-single
        tags:
          mondoo.com/filter-title: "AWS IAM User"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-hcl
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-plan
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-state
    docs:
      desc: |
        This check ensures that each AWS IAM user has no more than one active access key. IAM users can have up to two access keys, but maintaining multiple active keys increases the risk of credential leakage and unauthorized access if one of the keys is compromised. Best practices dictate that only one active key should exist per IAM user to reduce attack surfaces and ensure proper key management.

        **Why this matters**

        Access keys provide programmatic access to AWS services. If multiple active keys exist for a user:

        - The risk of credential exposure increases.
        - It becomes harder to track and rotate access keys securely.
        - Unused keys may remain active longer than necessary, violating least privilege principles.

        AWS best practices and security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2 recommend that IAM users should have at most one active access key at any time.

        **Risk mitigation:**

        - Reduces exposure to key compromise by minimizing unused or unnecessary credentials.
        - Simplifies access key rotation by ensuring only one key is active at any given time.
        - Enhances security posture by enforcing least privilege access for IAM users.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users in the left panel.
            3.  Select a user and go to the Security Credentials tab.
            4.  Under Access Keys, check how many active keys exist.
            5.  If more than one active access key is present:

              - Determine which key is in use.
              - Disable and delete the extra key(s).
              - If a key is needed for rotation, create a new key before deleting the old one.
        - id: cli
          desc: |
            **Using AWS CLI**

            List all IAM users:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check access keys for a specific user:

            ```bash
            aws iam list-access-keys --user-name <username> --query "AccessKeyMetadata[*].{AccessKeyId:AccessKeyId, Status:Status}"
            ```

            If more than one Active (Status: Active) key exists, deactivate and delete extra keys:

            ```bash
            aws iam update-access-key --user-name <username> --access-key-id <access-key-id> --status Inactive
            aws iam delete-access-key --user-name <username> --access-key-id <access-key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not support direct enforcement of single active access keys in Terraform, but you can enforce a security policy to limit IAM users to one active key:

            ```hcl
            resource "aws_iam_policy" "limit_access_keys" {
              name        = "LimitAccessKeys"
              description = "Ensure IAM users have at most one active access key"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = "iam:CreateAccessKey",
                    Resource = "*",
                    Condition = {
                      NumericGreaterThan = {
                        "iam:AccessKeysCount": 1
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              # Policy to deny creation of more than one access key per user
              LimitAccessKeysPolicy:
                Type: "AWS::IAM::ManagedPolicy"
                Properties:
                  ManagedPolicyName: "LimitAccessKeys"
                  Description: "Ensure IAM users have at most one active access key"
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Deny"
                        Action: "iam:CreateAccessKey"
                        Resource: "*"
                        Condition:
                          NumericGreaterThanEquals:
                            "iam:ActiveAccessKeys": "1"
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html
        title: AWS IAM Best Practices
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
        title: AWS Documentation - Manage access keys for IAM users
  - uid: mondoo-aws-security-iam-users-only-one-access-key-single
    filters: asset.platform == "aws-iam-user"
    mql: |
      aws.iam.user.accessKeys.flat.where(Status == "Active").length <= 1
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(
        arguments.policy.any(
          _['Statement'].any(
            _['Effect'] == "Deny" &&
            _['Action'] == "iam:CreateAccessKey" &&
            _['Condition']['NumericGreaterThan']['iam:AccessKeysCount'] >= 1
          )
        )
      )
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_policy")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_policy").any(
        change.after.policy.contains('iam:CreateAccessKey') &&
        change.after.policy.contains('Deny') &&
        change.after.policy.contains('NumericGreaterThan') &&
        change.after.policy.contains('iam:AccessKeysCount')
      )
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_policy")
    mql: |
      terraform.state.resources.where(type == "aws_iam_policy").any(
        values.policy.contains('iam:CreateAccessKey') &&
        values.policy.contains('Deny') &&
        values.policy.contains('NumericGreaterThan') &&
        values.policy.contains('iam:AccessKeysCount')
      )
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check
    title: Ensure IAM users receive permissions only through groups
    impact: 70
    variants:
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single
        tags:
          mondoo.com/filter-title: "AWS IAM User"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-hcl
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-plan
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-state
    docs:
      desc: |
        This check ensures that AWS IAM users do not have directly attached policies and instead receive permissions exclusively through IAM groups. Assigning permissions via groups simplifies access management, enforces least privilege principles, and reduces the risk of misconfigured permissions at the individual user level.

        **Why this matters**

        IAM users should not have inline or managed policies attached directly to their accounts. Instead, permissions should be granted via IAM groups to:

        - Ensure consistent and scalable permission management
        - Reduce the risk of excessive privileges assigned to individual users
        - Improve auditability and compliance with security frameworks such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and SOC 2

        By enforcing group-based access control, administrators can efficiently manage role-based permissions and prevent overly permissive access for individual IAM users.

        **Risk mitigation:**

        - Reduces administrative overhead by managing permissions collectively
        - Prevents privilege creep by enforcing structured access control
        - Enhances security posture by ensuring users inherit only necessary permissions
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS IAM Console.
            2.  Select Users in the left panel.
            3.  Select a user and go to the Permissions tab.
            4.  Identify users with directly attached policies (either managed or inline policies).
            5.  If direct policies exist:
              - Detach managed policies from the user.
              - Delete inline policies assigned to the user.
              - Assign the user to an IAM group that grants the necessary permissions.
        - id: cli
          desc: |
            **Using AWS CLI**

            List all IAM users and check if they have directly attached policies:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check managed policies attached to a user:

            ```bash
            aws iam list-attached-user-policies --user-name <username>
            ```

            Detach any managed policies:

            ```bash
            aws iam detach-user-policy --user-name <username> --policy-arn <policy-arn>
            ```

            Check inline policies assigned to a user:

            ```bash
            aws iam list-user-policies --user-name <username>
            ```

            Delete any inline policies:

            ```bash
            aws iam delete-user-policy --user-name <username> --policy-name <policy-name>
            ```

            Assign the user to an IAM group instead:

            ```bash
            aws iam add-user-to-group --group-name <group-name> --user-name <username>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enforce group-based permissions and prevent direct policy assignments:

            ```hcl
            resource "aws_iam_group" "developers" {
              name = "Developers"
            }

            resource "aws_iam_user" "user1" {
              name = "user1"
            }

            resource "aws_iam_group_membership" "dev_group_membership" {
              name  = "dev-membership"
              group = aws_iam_group.developers.name
              users = [aws_iam_user.user1.name]
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can enforce that IAM users receive permissions through groups only:

            ```yaml
            Resources:
              # Create IAM groups with appropriate permissions
              ReadOnlyGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "ReadOnlyUsers"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/ReadOnlyAccess"

              AdminGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "Administrators"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/AdministratorAccess"

              # Create IAM users without direct policies
              ReadOnlyUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "readonly-user"
                  Path: "/"
                  # No inline policies or managed policies attached directly

              AdminUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "admin-user"
                  Path: "/"
                  # No inline policies or managed policies attached directly

              # Add users to the appropriate groups
              ReadOnlyUserGroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref ReadOnlyGroup
                  Users:
                    - !Ref ReadOnlyUser

              AdminUserGroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref AdminGroup
                  Users:
                    - !Ref AdminUser
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html
        title: Managed policies and inline policies
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single
    filters: asset.platform == "aws-iam-user"
    mql: |
      aws.iam.user.policies == empty
      aws.iam.user.attachedPolicies == empty
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_user")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_user_policy_attachment" || nameLabel == "aws_iam_user_policy") == empty
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_user")
    mql: |
      terraform.plan.resourceChanges.none(type == "aws_iam_user_policy" || type == "aws_iam_user_policy_attachment")
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_user")
    mql: |
      terraform.state.resources.none(type == "aws_iam_user_policy" || type == "aws_iam_user_policy_attachment")
  - uid: mondoo-aws-security-vpc-default-security-group-closed
    title: Ensure the default security group of every VPC restricts all traffic
    impact: 80
    variants:
      - uid: mondoo-aws-security-vpc-default-security-group-closed-single
        tags:
          mondoo.com/filter-title: "AWS EC2 Security Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-hcl
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-plan
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-state
    docs:
      desc: |
        This check ensures that the default security group (SG) for every AWS Virtual Private Cloud (VPC) is configured to restrict all inbound and outbound traffic. By default, AWS creates a default security group for each VPC, which allows unrestricted communication between instances associated with the group. This can pose a significant security risk if not properly restricted.

        **Why this matters**

        The default security group in a VPC automatically allows all inbound and outbound traffic between instances using the same security group, which can:

        - Allow unintended access between instances, increasing the risk of lateral movement.
        - Expose resources to potential unauthorized access if assigned inadvertently.
        - Violate security best practices and compliance standards such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and PCI DSS.

        To mitigate this risk, the default security group should be modified to restrict all traffic by removing all inbound and outbound rules.

        **Risk mitigation:**

        - Prevents unintended access by eliminating unrestricted communication between instances.
        - Enforces least privilege by requiring explicit security group assignments.
        - Improves network security posture by reducing exposure to internal threats.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS VPC Console.
            2.  Select Security Groups from the left panel.
            3.  Filter by “default” security groups under the VPC ID column.
            4.  For each default security group:
              - Remove all inbound rules by selecting Edit inbound rules and deleting all existing entries.
              - Remove all outbound rules by selecting Edit outbound rules and deleting all existing entries.
            5.  Save the changes to ensure that the default security group does not allow any traffic.
        - id: cli
          desc: |
            **Using AWS CLI**

            List all default security groups:

            ```bash
            aws ec2 describe-security-groups --filters Name=group-name,Values=default --query "SecurityGroups[*].GroupId"
            ```

            For each default security group, remove all inbound rules:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <sg-id> --protocol all --port -1 --cidr 0.0.0.0/0
            ```

            Remove all outbound rules:

            ```bash
            aws ec2 revoke-security-group-egress --group-id <sg-id> --protocol all --port -1 --cidr 0.0.0.0/0
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the default security group restricts all traffic:

            ```hcl
            resource "aws_default_security_group" "default_sg" {
              vpc_id = aws_vpc.main.id

              ingress = []  # No inbound rules
              egress  = []  # No outbound rules

              tags = {
                Name = "Restricted Default SG"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can help you manage the default security group to ensure it has no inbound or outbound rules:

            ```yaml
            Resources:
              DefaultSecurityGroup:
                Type: AWS::EC2::SecurityGroupIngress
                Properties:
                  GroupId: !GetAtt MainVPC.DefaultSecurityGroup
                  # Empty list for no inbound rules

              DefaultSecurityGroupEgress:
                Type: AWS::EC2::SecurityGroupEgress
                Properties:
                  GroupId: !GetAtt MainVPC.DefaultSecurityGroup
                  # Empty list for no outbound rules

              DefaultSecurityGroupTagging:
                Type: AWS::EC2::Tags
                Properties:
                  ResourceId: !GetAtt MainVPC.DefaultSecurityGroup
                  Tags:
                    - Key: Name
                      Value: Restricted Default SG
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Reference - EC2
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-vpc-default-security-group-closed-single
    filters: asset.platform == "aws-security-group" && aws.ec2.securitygroup.name == "default"
    mql: |
      aws.ec2.securitygroup.ipPermissions == empty
      aws.ec2.securitygroup.ipPermissionsEgress == empty
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_default_security_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_default_security_group").all(
        arguments.ingress == empty && arguments.egress == empty
      )
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_default_security_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_default_security_group").all(
        change.after.ingress == empty && change.after.egress == empty
      )
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_default_security_group")
    mql: |
      terraform.state.resources.where(type == "aws_default_security_group").all(
        values.ingress == empty && values.egress == empty
      )
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
    title: Ensure EBS volume encryption is enabled by default
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-hcl
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-plan
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volume encryption is enabled by default in an AWS account. Enabling default encryption ensures that all newly created EBS volumes are encrypted automatically using AWS Key Management Service (KMS) keys. This eliminates the risk of unencrypted volumes being created inadvertently.

        **Why this matters**

        By default, EBS volumes are not encrypted unless specified during creation. Without default encryption, users may create unencrypted EBS volumes, exposing sensitive data to unauthorized access if the volume is compromised. Enabling default EBS encryption ensures:

        - Consistent enforcement of encryption across all new volumes.
        - Improved security by protecting data at rest.
        - Simplified compliance with regulations such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        **Risk mitigation:**

        - Prevents accidental creation of unencrypted volumes by enforcing encryption automatically.
        - Ensures compliance with data protection standards that require encryption at rest.
        - Reduces the risk of data breaches by protecting data stored on AWS-managed disks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select EC2 Dashboard > EBS > Settings.
            3.  Locate the Always encrypt new EBS volumes option.
            4.  If encryption is disabled, select Edit and check Enable encryption by default.
            5.  Select the KMS key to use (either the default AWS-managed key or a customer-managed key).
            6.  Select Save changes to enforce encryption by default.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if EBS encryption is enabled by default:

            ```bash
            aws ec2 get-ebs-encryption-by-default
            ```

            If the output is false, enable default encryption:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```

            To specify a custom KMS key for encryption:

            ```bash
            aws ec2 modify-ebs-default-kms-key-id --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure EBS encryption is enabled by default:

            ```hcl
            resource "aws_ebs_encryption_by_default" "default_encryption" {}
            ```

            To use a specific KMS key for encryption:

            ```hcl
            resource "aws_ebs_default_kms_key" "default" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can enable EBS encryption by default for your AWS account:

            ```yaml
            Resources:
              DefaultEBSEncryption:
                Type: AWS::EC2::EBSEncryptionByDefault
                Properties:
                  Enabled: true

              DefaultEBSKMSKey:
                Type: AWS::EC2::EBSDefaultKMSKey
                Properties:
                  KmsKeyId: !GetAtt EBSEncryptionKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default
        title: AWS Documentation - Encryption by default
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-api
    filters: asset.platform == "aws"
    mql: aws.ec2.ebsEncryptionByDefault.values.all(_ == true)
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_encryption_by_default")
    mql: |
      terraform.resources.where(nameLabel == "aws_ebs_encryption_by_default").all(
        arguments.enabled == true
      )
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_encryption_by_default")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_encryption_by_default").all(
        change.after.enabled == true
      )
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_encryption_by_default")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_encryption_by_default").all(
        values.enabled == true
      )
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
    title: Ensure public access to S3 buckets is blocked at the account level
    impact: 95
    variants:
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-aws
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-hcl
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-plan
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 Public Access Block settings are enabled at the account level to prevent accidental or intentional exposure of data stored in S3 buckets. Enforcing this setting at the account level ensures that no S3 bucket or object can be made public, even if bucket policies or ACLs attempt to allow public access.

        **Why this matters**

        By default, S3 allows granular control over access policies, but misconfigurations in bucket policies, access control lists (ACLs), or object permissions can lead to data leaks. Enforcing S3 Public Access Block settings at the account level ensures that:

        - All buckets are protected from accidental public exposure.
        - Individual users cannot override security policies by changing bucket-level settings.
        - Compliance requirements for data protection and privacy regulations (such as CIS AWS Foundations Benchmark, GDPR, PCI DSS, and ISO 27001) are met.

        **Risk mitigation:**

        - Prevents accidental public data exposure by blocking public access to all S3 resources.
        - Enhances security posture by enforcing organization-wide security policies.
        - Ensures compliance with regulatory frameworks that require strict data access controls.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS S3 Console.
            2.  Select Block Public Access Settings for this Account.
            3.  Ensure the following options are enabled:
              - Block public access to buckets and objects granted through new access control lists (ACLs)
              - Block public access to buckets and objects granted through any access control lists (ACLs)
              - Block public access to buckets and objects granted through new public bucket policies
              - Block public and cross-account access to buckets that have public policies
            4.  Select Save Changes to enforce these settings at the account level.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if public access is blocked at the account level:

            ```bash
            aws s3control get-public-access-block --account-id <account-id>
            ```

            If any of the settings are missing or set to false, enable full public access block:

            ```bash
            aws s3control put-public-access-block \
            --account-id <account-id> \
            --public-access-block-configuration '{
                "BlockPublicAcls": true,
                "IgnorePublicAcls": true,
                "BlockPublicPolicy": true,
                "RestrictPublicBuckets": true
            }'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure account-level S3 public access block settings are enforced:

            ```hcl
            resource "aws_s3_account_public_access_block" "account_block" {
              block_public_acls       = true
              ignore_public_acls      = true
              block_public_policy     = true
              restrict_public_buckets = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            CloudFormation can enable S3 Block Public Access at the account level:

            ```yaml
            Resources:
              # Enable S3 Block Public Access at the account level
                S3AccountPublicAccessBlock:
                Type: AWS::S3::AccountPublicAccessBlock
                Properties:
                  BlockPublicAcls: true
                  IgnorePublicAcls: true
                  BlockPublicPolicy: true
                  RestrictPublicBuckets: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/configuring-block-public-access-account.html
        title: Configuring block public access settings for your account
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-aws
    filters: asset.platform == "aws"
    mql: |
      aws.s3control.accountPublicAccessBlock != empty &&
      aws.s3control.accountPublicAccessBlock.values.all(_ == true)
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_account_public_access_block")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_account_public_access_block").all(
        arguments.block_public_acls == true &&
        arguments.ignore_public_acls == true &&
        arguments.block_public_policy == true &&
        arguments.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_account_public_access_block")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_account_public_access_block").all(
        change.after.block_public_acls == true &&
        change.after.ignore_public_acls == true &&
        change.after.block_public_policy == true &&
        change.after.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_account_public_access_block")
    mql: |
      terraform.state.resources.where(type == "aws_s3_account_public_access_block").all(
        values.block_public_acls == true &&
        values.ignore_public_acls == true &&
        values.block_public_policy == true &&
        values.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
    title: Ensure Amazon S3 buckets have public access restrictions enforced
    impact: 100
    variants:
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-bucket
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that each Amazon S3 bucket has public access restrictions enforced to prevent unauthorized exposure of sensitive data. While account-level public access block settings provide a broad safeguard, bucket-level controls ensure that no individual bucket is unintentionally exposed due to misconfigurations in bucket policies, ACLs, or object permissions.

        **Why this matters**

        Amazon S3 buckets can be made publicly accessible through:

        - Bucket policies that allow public s3:GetObject or s3:ListBucket permissions.
        - Access Control Lists (ACLs) that grant READ or WRITE permissions to AllUsers or AuthenticatedUsers.
        - Cross-account access where a bucket is unintentionally exposed via an overly permissive policy.

        Unrestricted public access to S3 buckets can result in:

        - Data breaches exposing sensitive files to unauthorized users.
        - Compliance violations under frameworks such as CIS AWS Foundations Benchmark, GDPR, PCI DSS, and ISO 27001.
        - Malicious exploitation, including data theft, ransomware attacks, or unauthorized data modifications.

        By enforcing bucket-level public access restrictions, organizations can prevent unintended data exposure while maintaining granular control over access permissions.

        **Risk mitigation:**

        - Prevents accidental or intentional data leaks due to misconfigured bucket policies or ACLs.
        - Strengthens security posture by enforcing explicit access control at the bucket level.
        - Ensures regulatory compliance with industry data protection standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS S3 Console.
            2.  Select a bucket and go to the Permissions tab.
            3.  Under Block public access (bucket settings), ensure the following options are enabled:
              - Block public access to buckets and objects granted through new access control lists (ACLs)
              - Block public access to buckets and objects granted through any access control lists (ACLs)
              - Block public access to buckets and objects granted through new public bucket policies
              - Block public and cross-account access to buckets that have public policies
            4.  Under Bucket policy, review the policy and ensure it does not allow `Principal: "*"` or overly permissive access rules.
            5.  Under Access Control List (ACLs), verify that no objects or buckets have `READ` or `WRITE` permissions assigned to Everyone `(public)` or `Authenticated Users`.
            6.  Save changes and confirm that public access is fully restricted.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the public access block settings for a specific bucket:

            ```bash
            aws s3api get-public-access-block --bucket <bucket-name>
            ```

            If public access is not fully blocked, apply the following settings:

            ```bash
            aws s3api put-public-access-block --bucket <bucket-name> --public-access-block-configuration '{
                "BlockPublicAcls": true,
                "IgnorePublicAcls": true,
                "BlockPublicPolicy": true,
                "RestrictPublicBuckets": true
            }'
            ```

            Check if the bucket policy allows public access:

            ```bash
            aws s3api get-bucket-policy --bucket <bucket-name> --query "Policy"
            ```

            If a policy allows public access (Principal: "*", "Effect": "Allow", and "Action": "s3:*"), remove or modify it:

            ```bash
            aws s3api delete-bucket-policy --bucket <bucket-name>
            ```

            Check if ACLs allow public or cross-account access:

            ```bash
            aws s3api get-bucket-acl --bucket <bucket-name>
            ```

            If ACLs allow public access ("Grantee": { "URI": "http://acs.amazonaws.com/groups/global/AllUsers" }), remove the ACL:

            ```bash
            aws s3api put-bucket-acl --bucket <bucket-name> --acl private
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure S3 public access block settings are enforced at the bucket level:

            ```hcl
            resource "aws_s3_bucket_public_access_block" "secure_bucket" {
              bucket = aws_s3_bucket.my_bucket.id

              block_public_acls       = true
              ignore_public_acls      = true
              block_public_policy     = true
              restrict_public_buckets = true
            }
            ```

            Ensure S3 bucket policies do not allow public access:

            ```hcl
            resource "aws_s3_bucket_policy" "secure_policy" {
              bucket = aws_s3_bucket.my_bucket.id
              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect    = "Deny",
                    Principal = "*",
                    Action    = "s3:*",
                    Resource  = [
                      "arn:aws:s3:::${aws_s3_bucket.my_bucket.id}",
                      "arn:aws:s3:::${aws_s3_bucket.my_bucket.id}/*"
                    ],
                    Condition = {
                      Bool = {
                        "aws:SecureTransport": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureBucketPublicAccessBlock:
                Type: AWS::S3::BucketPublicAccessBlock
                Properties:
                  Bucket: !Ref MyBucket
                  BlockPublicAcls: true
                  IgnorePublicAcls: true
                  BlockPublicPolicy: true
                  RestrictPublicBuckets: true

              SecureBucketPolicy:
                Type: AWS::S3::BucketPolicy
                Properties:
                  Bucket: !Ref MyBucket
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Principal: '*'
                        Action: 's3:*'
                        Resource:
                          - !Sub 'arn:aws:s3:::${MyBucket}'
                          - !Sub 'arn:aws:s3:::${MyBucket}/*'
                        Condition:
                          Bool:
                            'aws:SecureTransport': 'false'
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS Documentation - Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS CLI Command Reference - aws s3api put-public-access-block
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block
        title: Terraform Documentation - AWS Provider - aws_s3_bucket_public_access_block
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-bucket
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.publicAccessBlock != empty
      aws.s3.bucket.publicAccessBlock.BlockPublicAcls == true
      aws.s3.bucket.publicAccessBlock.BlockPublicPolicy == true
      aws.s3.bucket.publicAccessBlock.IgnorePublicAcls == true
      aws.s3.bucket.publicAccessBlock.RestrictPublicBuckets == true
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_s3_bucket_public_access_block" )
    mql: |
      terraform.resources.where( nameLabel == "aws_s3_bucket_public_access_block" ).all(
        arguments.block_public_acls == true &&
        arguments.block_public_policy == true &&
        arguments.ignore_public_acls == true &&
        arguments.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_s3_bucket_public_access_block" )
    mql: |
      terraform.plan.resourceChanges.where( type == "aws_s3_bucket_public_access_block" ).all(
        change.after.block_public_acls == true &&
        change.after.block_public_policy == true &&
        change.after.ignore_public_acls == true &&
        change.after.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_s3_bucket_public_access_block" )
    mql: |
      terraform.state.resources.where( type == "aws_s3_bucket_public_access_block" ).all(
        values.block_public_acls == true &&
        values.block_public_policy == true &&
        values.ignore_public_acls == true &&
        values.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-ec2-instance-no-public-ip
    title: Ensure no public IPs are associated with EC2 instances
    impact: 80
    variants:
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-hcl
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-plan
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EC2 instances do not have public IP addresses to prevent unintended exposure of cloud resources to the internet. Instances with public IPs can be directly accessed from the internet, increasing the risk of security breaches, unauthorized access, and potential data exfiltration.

        **Why this matters**

        By default, EC2 instances launched in a public subnet may receive an auto-assigned public IP unless explicitly disabled. Additionally, Elastic IPs (EIPs) can be manually associated with instances. Direct public access to EC2 instances poses serious security risks, including:

        - Increased attack surface for brute-force, DDoS, or credential stuffing attacks.
        - Unauthorized access if security groups, ACLs, or instance configurations are misconfigured.
        - Regulatory non-compliance with standards such as CIS AWS Foundations Benchmark, PCI DSS, and ISO 27001.

        To mitigate these risks, EC2 instances should be placed in private subnets and accessed securely using bastion hosts, AWS Systems Manager Session Manager, or VPNs instead of exposing them directly to the internet.

        **Risk mitigation:**

        - Reduces exposure to external threats by eliminating direct public access.
        - Improves security posture by enforcing network segmentation best practices.
        - Ensures compliance with cloud security frameworks and industry standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select Instances in the left panel.
            3.  Check the Public IPv4 Address column for any assigned public IPs.
            4.  If an instance has a public IP:
              - Select the instance and select Networking > Manage IP Addresses.
              - If using an Elastic IP (EIP), disassociate it from the instance.
              - Modify the instance's subnet settings to disable auto-assign public IPs.
            5.  If public access is necessary, use a bastion host, VPN, or AWS Systems Manager Session Manager instead of directly exposing the instance.
        - id: cli
          desc: |
            **Using AWS CLI**

            List EC2 instances with public IP addresses:

            ```bash
            aws ec2 describe-instances --query "Reservations[*].Instances[*].[InstanceId, PublicIpAddress]" --output table
            ```

            If any instances have a Public IP, remove manually assigned Elastic IPs:

            ```bash
            aws ec2 disassociate-address --public-ip <public-ip-address>
            ```

            Modify an instance's network interface to remove the public IP (requires instance stop/start):

            ```bash
            aws ec2 modify-instance-attribute --instance-id <instance-id> --no-associate-public-ip-address
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure that EC2 instances are launched without public IPs:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami             = "ami-12345678"
              instance_type   = "t3.micro"
              subnet_id       = aws_subnet.private_subnet.id
              associate_public_ip_address = false  # Ensure no public IP is assigned

              tags = {
                Name = "PrivateInstance"
              }
            }
            ```

            Ensure that default VPC subnets do not auto-assign public IPs:

            ```hcl
            resource "aws_subnet" "private_subnet" {
              vpc_id            = aws_vpc.main.id
              cidr_block        = "10.0.1.0/24"
              map_public_ip_on_launch = false  # Disable auto-assigned public IPs
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure that EC2 instances do not receive public IPs in CloudFormation templates:

            ```yaml
            Resources:
              PrivateInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  SubnetId: !Ref PrivateSubnet
                  NetworkInterfaces:
                    - AssociatePublicIpAddress: false
                      DeviceIndex: 0
              PrivateSubnet:
                Type: "AWS::EC2::Subnet"
                Properties:
                  VpcId: !Ref VPC
                  CidrBlock: "10.0.1.0/24"
                  MapPublicIpOnLaunch: false
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-ip-addressing.html
        title: AWS Documentation - IP addressing for your VPCs and subnets
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance
        title: Terraform Registry - aws_instance
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-api
    filters: asset.platform == "aws"
    mql: aws.ec2.instances.all(publicIp == empty)
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_instance" )
    mql: terraform.resources.where( nameLabel == "aws_instance" ).none( arguments.associate_public_ip_address == true )
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_instance" )
    mql: terraform.plan.resourceChanges.where( type == "aws_instance" ).none( change.after.associate_public_ip_address == true )
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_instance" )
    mql: terraform.state.resources.where( type == "aws_instance" ).none( values.associate_public_ip_address == true )
  - uid: mondoo-aws-security-ec2-imdsv2-check
    title: Ensure EC2 instances use IMDSv2 for metadata access
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-imdsv2-check-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-hcl
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-plan
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EC2 instances are configured to use Instance Metadata Service Version 2 (IMDSv2) instead of IMDSv1. IMDSv2 provides enhanced security by requiring session-based authentication using a token, reducing the risk of metadata theft and credential exposure.

        **Why this matters**

        IMDSv1 allows unauthenticated HTTP requests to retrieve instance metadata, making it vulnerable to server-side request forgery (SSRF) attacks, credential theft, and container breakout scenarios. IMDSv2 mitigates these risks by:

        - Requiring session-based authentication with a limited-time token.
        - Protecting against open WAF bypasses and SSRF exploitation.
        - Enforcing request headers to prevent unauthorized access.

        AWS security best practices, as well as CIS AWS Foundations Benchmark, PCI DSS, ISO 27001, and NIST, recommend enforcing IMDSv2-only for all EC2 instances.

        **Risk mitigation:**

        - Prevents unauthorized metadata access by enforcing authenticated API requests.
        - Mitigates SSRF vulnerabilities that could expose instance credentials.
        - Aligns with compliance requirements for secure cloud environments.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select Instances in the left panel.
            3.  Select an instance and go to the Details tab.
            4.  Under Metadata version, check if it is set to V2 only.
            5.  If IMDSv1 is allowed, update the settings:

              - Select Actions > Modify instance metadata options.
              - Set Metadata version to IMDSv2 only.
              - Set Hop limit to at least 1 (for containerized workloads).
              - Select Save to apply the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the IMDS version for all EC2 instances:

            ```bash
            aws ec2 describe-instances --query "Reservations[*].Instances[*].{Instance:InstanceId, MetadataOptions:MetadataOptions}" --output table
            ```

            Update an instance to enforce IMDSv2 only:

            ```bash
            aws ec2 modify-instance-metadata-options --instance-id <instance-id> --http-tokens required --http-put-response-hop-limit 1
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure IMDSv2-only is enforced in Terraform:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              metadata_options {
                http_tokens                 = "required"  # Enforce IMDSv2
                http_put_response_hop_limit = 1
                http_endpoint               = "enabled"
              }

              tags = {
                Name = "SecureInstance"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Configure IMDSv2-only in a CloudFormation template:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  MetadataOptions:
                    HttpTokens: "required"
                    HttpPutResponseHopLimit: 1
                    HttpEndpoint: "enabled"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security.html
        title: Amazon EC2 Security
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html
        title: Configure the Instance Metadata Service
  - uid: mondoo-aws-security-ec2-imdsv2-check-api
    filters: |
      asset.platform == "aws"
    mql: |
      aws.ec2.instances.where(
        state != /terminated|shutting-down/
          && httpEndpoint == "enabled"
        ).all(
          httpTokens == "required"
        )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_instance")
    mql: |
      terraform.resources.where( nameLabel == "aws_instance" ).all(
        blocks.where( type == "metadata_options" ) != empty &&
        blocks.where( type == "metadata_options" ).all(
          arguments.http_endpoint == "disabled" || arguments.http_tokens == "required"
        )
      )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_instance")
    mql: terraform.plan.resourceChanges.where( type == "aws_instance" ).all( change.after.metadata_options[0].http_endpoint == "disabled" || change.after.metadata_options[0].http_tokens == "required" )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_instance")
    mql: terraform.state.resources.where( type == "aws_instance" ).all( values.metadata_options[0].http_endpoint == "disabled" || values.metadata_options[0].http_tokens == "required" )
  - uid: mondoo-aws-security-vpc-bpa-enabled
    title: Ensure VPC Block Public Access (BPA) is enabled
    impact: 90
    variants:
      - uid: mondoo-aws-security-vpc-bpa-enabled-single
        tags:
          mondoo.com/filter-title: "AWS EC2 VPC"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-hcl
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-plan
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Virtual Private Cloud (VPC) Block Public Access (BPA) is enabled on all VPCs to prevent accidental exposure of resources to the internet. VPC BPA provides a centralized control to block the creation of Internet Gateways, public route table entries, and public security group rules, thereby preventing resources within the VPC from becoming publicly accessible.

        **Why this matters**

        Without VPC Block Public Access enabled:

        - Resources may be inadvertently exposed to the internet through misconfigured network settings.
        - Human error during configuration changes could lead to unintended public access to sensitive workloads.
        - Compliance frameworks such as CIS AWS Foundations Benchmark, PCI DSS, and SOC 2 recommendations for network isolation may be compromised.

        VPC Block Public Access serves as a guardrail that prevents accidental exposure while still allowing for intentional public-facing workloads when properly configured.

        **Risk mitigation:**

        - **Defense Against Misconfiguration:** Prevents accidental public exposure of resources through configuration errors.
        - **Consistent Security Posture:** Maintains network isolation across the organization even during rapid development.
        - **Reduced Attack Surface:** Minimizes the risk of resources being unintentionally exposed to internet-based threats.

        **Important caveats:**

        - VPC BPA will block all new public access, which may disrupt legitimate public-facing workloads like web applications unless exceptions are properly configured.
        - Enabling BPA does not retroactively remove existing public access; existing Internet Gateways and public routes remain functional.
        - Service-linked resources managed by AWS (such as those for ELB or NAT Gateways) require explicit exemptions to continue functioning properly.
        - There may be organizational impacts requiring coordination across teams before implementation to avoid disrupting business operations.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS VPC Console.
            2. Select Your VPCs from the left panel.
            3. Select the target VPC.
            4. Under Actions, select Edit VPC settings.
            5. In the Block Public Access settings section, select Enable block public access.
            6. Configure appropriate exclusions for resources that need public access, if needed.
            7. Select Save changes to apply the settings.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable VPC Block Public Access for a specific VPC:

            ```bash
            aws ec2 enable-vpc-block-public-access-v2 --vpc-ids vpc-12345678
            ```

            Create an exclusion for specific resources (if necessary):

            ```bash
            aws ec2 create-vpc-block-public-access-exclusion --vpc-id vpc-12345678 --internet-gateway-exclusion-mode "allow-egress" --subnet-id subnet-12345678
            ```

            Verify the status of VPC BPA:

            ```bash
            aws ec2 describe-vpc-block-public-access --vpc-ids vpc-12345678
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_vpc" "main" {
              cidr_block = "10.0.0.0/16"
              tags = {
                Name = "main-vpc"
              }
            }

            resource "aws_vpc_block_public_access" "example" {
              vpc_id = aws_vpc.main.id
            }

            # Optional: If you need exclusions for specific resources
            resource "aws_vpc_block_public_access_exclusion" "example" {
              vpc_id                         = aws_vpc.main.id
              subnet_id                      = aws_subnet.public.id
              internet_gateway_exclusion_mode = "allow-egress"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              MainVPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  Tags:
                    - Key: "Name"
                      Value: "main-vpc"

              VPCBlockPublicAccess:
                Type: "AWS::EC2::VPCBlockPublicAccess"
                Properties:
                  VpcId: !Ref MainVPC

              # Optional: If you need exclusions for specific resources
              VPCBlockPublicAccessExclusion:
                Type: "AWS::EC2::VPCBlockPublicAccessExclusion"
                Properties:
                  VpcId: !Ref MainVPC
                  SubnetId: !Ref PublicSubnet
                  InternetGatewayExclusionMode: "allow-egress"
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html
        title: Amazon VPC Security Best Practices
  - uid: mondoo-aws-security-vpc-bpa-enabled-single
    filters: asset.platform == "aws-vpc"
    mql: aws.vpc.internetGatewayBlockMode != "off"
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_vpc_block_public_access_exclusion")
    mql: |
      terraform.resources.where( nameLabel == "aws_vpc_block_public_access_exclusion" ).all(
        arguments.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/
      )
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_vpc_block_public_access_exclusion")
    mql: |
      terraform.plan.resourceChanges.where( type == "aws_vpc_block_public_access_exclusion" ).all(
        change.after.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/
      )
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_vpc_block_public_access_exclusion")
    mql: |
      terraform.state.resources.where( type == "aws_vpc_block_public_access_exclusion" ).all(
        values.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled
    title: Ensure VPC flow logging is enabled in all VPCs
    impact: 70
    variants:
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-single
        tags:
          mondoo.com/filter-title: "AWS EC2 VPC"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-hcl
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-plan
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Virtual Private Cloud (VPC) flow logs are enabled for all VPCs to capture network traffic metadata. VPC Flow Logs provide visibility into network traffic patterns, allowing security teams to monitor, detect anomalies, and investigate incidents such as unauthorized access, data exfiltration, and security breaches.

        **Why this matters**

        Without VPC Flow Logs, organizations lack visibility into ingress and egress network traffic within their AWS environment. This can lead to:

        - Difficulty in detecting security incidents, such as unauthorized connections or data leaks.
        - Lack of compliance with industry standards (e.g., CIS AWS Foundations Benchmark, NIST, PCI DSS, ISO 27001).
        - Inability to audit network activity, which is crucial for forensic investigations.

        Enabling VPC Flow Logs ensures that network traffic metadata is continuously collected, aiding in threat detection, security analytics, and compliance reporting.

        **Risk mitigation:**

        - Enhances network visibility by capturing VPC-level traffic metadata.
        - Improves threat detection by monitoring suspicious or unauthorized traffic.
        - Supports compliance requirements for security monitoring and audit logging.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS VPC Console.
            2.  Select Your VPCs from the left panel.
            3.  For each VPC:
              - Select the VPC name.
              - Go to the Flow Logs tab.
              - Select Create Flow Log and configure:
              - Filter: Choose All Traffic to capture both accepted and rejected packets.
              - Destination: Select Amazon CloudWatch Logs or Amazon S3.
              - IAM Role: Ensure an IAM role with appropriate permissions is used.
              - Log Format: Use default or a custom log format if required.
              - Select Create to enable flow logging.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if VPC Flow Logs are enabled for all VPCs:

            ```bash
            aws ec2 describe-flow-logs --query "FlowLogs[*].{VPC:ResourceId,LogGroup:LogGroupName}"
            ```

            If a VPC does not have flow logs enabled, create one:

            ```bash
            aws ec2 create-flow-logs \
            --resource-type VPC \
            --resource-ids <vpc-id> \
            --traffic-type ALL \
            --log-destination-type cloud-watch-logs \
            --log-group-name vpc-flow-logs \
            --deliver-logs-permission-arn arn:aws:iam::<account-id>:role/vpc-flow-logs-role
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure that VPC Flow Logs are enabled in Terraform:

            ```hcl
            resource "aws_flow_log" "vpc_flow_log" {
              vpc_id          = aws_vpc.main.id
              traffic_type    = "ALL"
              log_destination = aws_cloudwatch_log_group.vpc_logs.arn
            }

            resource "aws_cloudwatch_log_group" "vpc_logs" {
              name = "vpc-flow-logs"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable VPC Flow Logs in CloudFormation:

            ```yaml
            Resources:
              VPCFlowLog:
                Type: "AWS::EC2::FlowLog"
                Properties:
                  ResourceType: "VPC"
                  ResourceId: !Ref MyVPC
                  TrafficType: "ALL"
                  LogDestinationType: "cloud-watch-logs"
                  LogGroupName: "/aws/vpc/flow-logs"
                  DeliverLogsPermissionArn: !Sub "arn:aws:iam::${AWS::AccountId}:role/vpc-flow-logs-role"
              MyVPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/index.html
        title: AWS Documentation - AWS CLI Command Reference - logs
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Command Reference - ec2
      - url: https://registry.terraform.io/providers/cloudposse/awsutils/latest/docs
        title: Terraform registry - Cloud Posse AWS Utils Provider
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-single
    filters: asset.platform == "aws-vpc"
    mql: |
      aws.vpc.flowLogs.any(
        status == "ACTIVE" &&
        destination != empty &&
        destinationType == "cloud-watch-logs" &&
        deliverLogsStatus == "SUCCESS" &&
        trafficType == "REJECT" || trafficType == "ALL"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_flow_log")
    mql: |
      terraform.resources.where(nameLabel == "aws_flow_log").all(
        arguments.traffic_type.in(["ALL", "REJECT"]) &&
        arguments.log_destination_type == "cloud-watch-logs"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_flow_log")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_flow_log").all(
        change.after.traffic_type.in(["ALL", "REJECT"]) &&
        change.after.log_destination_type == "cloud-watch-logs"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_flow_log")
    mql: |
      terraform.state.resources.where(type == "aws_flow_log").all(
        values.traffic_type.in(["ALL", "REJECT"]) &&
        values.log_destination_type == "cloud-watch-logs"
      )
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
    title: Ensure DynamoDB tables are encrypted with AWS Key Management Service (KMS)
    impact: 30
    variants:
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-single
        tags:
          mondoo.com/filter-title: "AWS DynamoDB Table"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-hcl
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-plan
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-state
    docs:
      desc: |
        This check ensures that Amazon DynamoDB tables are encrypted using AWS Key Management Service (KMS) to protect sensitive data at rest. DynamoDB encryption at rest ensures that data is automatically encrypted before being written to disk and decrypted when read, preventing unauthorized access to stored information.

        **Why this matters**

        By default, AWS encrypts DynamoDB tables using an AWS-owned key, but customer-managed keys (CMKs) provide additional security benefits such as:

        - Access control via AWS Identity and Access Management (IAM) policies.
        - Key rotation for enhanced security and compliance.
        - Auditability with CloudTrail logging of key usage.

        Encrypting DynamoDB tables using AWS KMS CMKs aligns with security best practices and compliance standards such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.

        **Risk mitigation:**

        - Prevents unauthorized access to sensitive data by enforcing encryption at rest.
        - Enhances security by leveraging customer-managed KMS keys (CMKs) instead of default AWS-managed keys.
        - Ensures compliance with industry security and regulatory requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS DynamoDB Console.
            2.  Select Tables from the left panel.
            3.  Select a table name and navigate to the Encryption section under Table Details.
            4.  Verify the KMS key type:
              - If it is AWS-owned key, change it to a Customer-managed KMS key (CMK).
              - Note that this requires creating a new table and migrating data, as encryption settings cannot be modified after table creation.
            5.  Create a new table with KMS encryption:
              - Select Create Table.
              - Under Encryption at rest, select AWS KMS and choose a Customer-Managed Key (CMK).
              - Migrate data from the old table and delete the unencrypted table.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a DynamoDB table is encrypted with AWS KMS CMKs:

            ```bash
            aws dynamodb describe-table --table-name <table-name> --query "Table.SSEDescription"
            ```

            If KMSMasterKeyArn is missing or the SSEType is not "KMS", you need to create a new encrypted table and migrate data:

            ```bash
            aws dynamodb create-table \
            --table-name <new-table-name> \
            --attribute-definitions AttributeName=Id,AttributeType=S \
            --key-schema AttributeName=Id,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST \
            --sse-specification Enabled=true,SSEType=KMS,KMSMasterKeyId="arn:aws:kms:region:account-id:key/key-id"
            ```

            Migrate data from the old table and delete the unencrypted table:

            ```bash
            aws dynamodb delete-table --table-name <old-table-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure DynamoDB tables use KMS CMKs for encryption:

            ```hcl
            resource "aws_kms_key" "dynamodb_encryption" {
              description = "KMS key for DynamoDB encryption"
            }

            resource "aws_dynamodb_table" "secure_dynamodb" {
              name           = "secure-table"
              billing_mode   = "PAY_PER_REQUEST"
              hash_key       = "id"

              attribute {
                name = "id"
                type = "S"
              }

              server_side_encryption {
                enabled     = true
                kms_key_arn = aws_kms_key.dynamodb_encryption.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable KMS encryption for DynamoDB tables in CloudFormation:

            ```yaml
            Resources:
              SecureDynamoDBTable:
                Type: "AWS::DynamoDB::Table"
                Properties:
                  TableName: "secure-table"
                  BillingMode: "PAY_PER_REQUEST"
                  AttributeDefinitions:
                    - AttributeName: "Id"
                      AttributeType: "S"
                  KeySchema:
                    - AttributeName: "Id"
                      KeyType: "HASH"
                  SSESpecification:
                    SSEEnabled: true
                    SSEType: "KMS"
                    KMSMasterKeyId: !Ref DynamoDBKMSKey

              DynamoDBKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for DynamoDB encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: "*"
                        Action: "kms:*"
                        Resource: "*"
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/index.html
        title: AWS Documentation - AWS CLI Command Reference - DynamoDB
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
      - url: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html
        title: AWS Documentation - DynamoDB encryption at rest
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-single
    filters: asset.platform == "aws-dynamodb-table"
    mql: |
      aws.dynamodb.table.sseDescription.SSEType == "KMS"
      aws.dynamodb.table.sseDescription.Status == "ENABLED"
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_dynamodb_table")
    mql: |
      terraform.resources.where(nameLabel == "aws_dynamodb_table").all(
        blocks.where(type == "server_side_encryption") != empty &&
        blocks.where(type == "server_side_encryption").all(
          arguments.enabled == true && arguments.kms_key_arn != empty
        )
      )
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_dynamodb_table")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_dynamodb_table").all(
        change.after.server_side_encryption != empty &&
        change.after.server_side_encryption.all(enabled == true)
      )
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_dynamodb_table")
    mql: |
      terraform.state.resources.where(type == "aws_dynamodb_table").all(
        values.server_side_encryption != empty &&
        values.server_side_encryption.all(enabled == true && kms_key_arn != empty)
      )
  - uid: mondoo-aws-security-lambda-concurrency-check
    title: Ensure Lambda functions are configured with function-level concurrent execution limits
    impact: 60
    variants:
      - uid: mondoo-aws-security-lambda-concurrency-check-single
        tags:
          mondoo.com/filter-title: "AWS Lambda Function"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-hcl
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-plan
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-state
    docs:
      desc: |
        This check ensures that AWS Lambda functions are configured with function-level concurrent execution limits to prevent excessive resource consumption and throttle protection at the account level. By default, Lambda functions share the account-level concurrency limit, which can lead to resource exhaustion, affecting other critical workloads if a single function consumes too many concurrent executions.

        **Why this matters**

        Without function-level concurrency limits:

        - A single function with high invocation rates can consume all available concurrency for an AWS account, causing throttling for other functions.
        - Unintentional denial-of-service (DoS) scenarios may occur due to unbounded parallel executions.
        - Compliance frameworks such as CIS AWS Foundations Benchmark, PCI DSS, and ISO 27001 recommend enforcing concurrency controls to mitigate resource exhaustion risks.

        Enforcing function-level concurrency limits ensures fair resource distribution and prevents overuse of compute resources by a single Lambda function.

        **Risk mitigation:**

        - Prevents resource starvation by limiting the number of concurrent executions per function.
        - Improves application stability by preventing accidental or intentional excessive execution.
        - Enhances security and compliance by enforcing workload isolation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS Lambda Console.
            2.  Select Functions from the left panel.
            3.  Select a Lambda function and go to the Configuration tab.
            4.  Under Concurrency, select Edit.
            5.  Enable Reserved Concurrency and set an appropriate concurrent execution limit.
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the current concurrency setting for a Lambda function:

            ```bash
            aws lambda get-function-concurrency --function-name <function-name>
            ```

            If no reserved concurrency is set, configure a limit:

            ```bash
            aws lambda put-function-concurrency --function-name <function-name> --reserved-concurrent-executions <limit>
            ```

            To remove a concurrency limit if needed:

            ```bash
            aws lambda delete-function-concurrency --function-name <function-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure Lambda functions have a reserved concurrency limit:

            ```hcl
            resource "aws_lambda_function" "secure_lambda" {
              function_name    = "SecureLambda"
              role            = aws_iam_role.lambda_role.arn
              handler         = "index.handler"
              runtime         = "python3.8"
              filename        = "lambda.zip"

              reserved_concurrent_executions = 10  # Set function-level concurrency limit
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Define reserved concurrency settings for a Lambda function in CloudFormation:

            ```yaml
            Resources:
              SecureLambdaFunction:
                Type: AWS::Lambda::Function
                Properties:
                  FunctionName: SecureLambda
                  Description: Example Lambda function with reserved concurrency.
                  Role: arn:aws:iam::123456789012:role/YourLambdaExecutionRole
                  Handler: index.handler
                  Runtime: python3.8
                  Code:
                    S3Bucket: your-s3-bucket-name
                    S3Key: lambda.zip
                  ReservedConcurrentExecutions: 10
            ```
    refs:
      - url: https://docs.aws.amazon.com/lambda/latest/dg/lambda-security.html
        title: AWS Lambda Security
      - url: https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html
        title: AWS Lambda Reserved Concurrency
  - uid: mondoo-aws-security-lambda-concurrency-check-single
    filters: asset.platform == "aws-lambda-function"
    mql: |
      aws.lambda.function.concurrency > 0
      aws.lambda.function.concurrency <= 100
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lambda_function")
    mql: |
      terraform.resources.where(nameLabel == "aws_lambda_function").all(
        arguments.reserved_concurrent_executions > 0 &&
        arguments.reserved_concurrent_executions <= 100
      )
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lambda_function")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lambda_function").all(
        change.after.reserved_concurrent_executions > 0 &&
        change.after.reserved_concurrent_executions <= 100
      )
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lambda_function")
    mql: |
      terraform.state.resources.where(type == "aws_lambda_function").all(
        values.reserved_concurrent_executions > 0 &&
        values.reserved_concurrent_executions <= 100
      )
  - uid: mondoo-aws-security-lambda-function-public-access-prohibited
    title: Ensure the policy attached to the lambda function prohibits public access
    impact: 95
    variants:
      - uid: mondoo-aws-lambda-function-public-access-prohibited-single
        tags:
          mondoo.com/filter-title: "AWS Lambda Function"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-hcl
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-plan
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that AWS Lambda functions have resource-based policies that explicitly prohibit public access. Resource-based policies control who can invoke or access Lambda functions, and improperly configured policies may inadvertently allow unauthorized users to trigger functions or access sensitive functionality and data.

        **Why this matters**

        Without proper access controls on Lambda functions:

        - Unauthorized users may be able to invoke functions that process sensitive data or perform privileged operations.
        - Malicious actors could potentially trigger resource-intensive functions as part of a denial-of-service attack.
        - Public exposure of Lambda functions may violate compliance requirements such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and SOC 2, which mandate strict access controls for compute resources.

        Lambda functions should follow the principle of least privilege, ensuring that only explicitly authorized identities can invoke or access the function.

        **Risk mitigation:**

        - Prevents unauthorized invocation of Lambda functions by restricting access to trusted entities only.
        - Reduces the attack surface by eliminating public exposure of serverless compute resources.
        - Ensures compliance with security frameworks that require controlled access to computing resources.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Lambda Console.
            2. Select Functions in the left panel.
            3. Select the Lambda function that has public access.
            4. Go to the Configuration tab and select Permissions.
            5. Under Resource-based policy, check for any policy statements with "Principal": "*" or "Principal": {"AWS": "*"}.
            6. Select Edit to modify the resource-based policy.
            7. Remove or update any policy statements that allow public access, restricting access to specific AWS accounts or services.
            8. Select Save to apply the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Get the current policy for a Lambda function:

            ```bash
            aws lambda get-policy --function-name <function-name>
            ```

            Remove the existing policy if it contains public access:

            ```bash
            aws lambda remove-permission --function-name <function-name> --statement-id <sid>
            ```

            Add a more restrictive policy:

            ```bash
            aws lambda add-permission \
              --function-name <function-name> \
              --statement-id AllowExecutionFromSpecificAccount \
              --action lambda:InvokeFunction \
              --principal <trusted-aws-account-id> \
              --source-account <source-account-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_lambda_function" "secure_function" {
              function_name = "secure-function"
              role          = aws_iam_role.lambda_role.arn
              handler       = "index.handler"
              runtime       = "nodejs18.x"
              filename      = "lambda.zip"
            }

            # Use a proper permission policy without public access
            resource "aws_lambda_permission" "secure_permission" {
              statement_id  = "AllowExecutionFromSpecificAccount"
              action        = "lambda:InvokeFunction"
              function_name = aws_lambda_function.secure_function.function_name
              principal     = "123456789012" # Specific AWS account ID, not "*"

              # Optional: Add additional restrictions
              source_account = "123456789012"
              source_arn     = "arn:aws:s3:::example-bucket"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureFunction:
                Type: AWS::Lambda::Function
                Properties:
                  FunctionName: secure-function
                  Role: !GetAtt LambdaRole.Arn
                  Handler: index.handler
                  Runtime: nodejs18.x
                  Code:
                    ZipFile: !Ref LambdaZipFile  # Or use S3Bucket/S3Key if stored in S3

              SecureFunctionPermission:
                Type: AWS::Lambda::Permission
                Properties:
                  FunctionName: !Ref SecureFunction
                  Action: lambda:InvokeFunction
                  Principal: '123456789012'  # Specific AWS account ID, not "*"
                  SourceAccount: '123456789012'
                  SourceArn: 'arn:aws:s3:::example-bucket'
                  StatementId: AllowExecutionFromSpecificAccount
            ```
    refs:
      - url: https://docs.aws.amazon.com/lambda/latest/dg/lambda-security.html
        title: AWS Lambda Security
      - url: https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html
        title: AWS Lambda Resource-Based Policies
  - uid: mondoo-aws-lambda-function-public-access-prohibited-single
    filters: |
      asset.platform == "aws-lambda-function"
    mql: |
      aws.lambda.function.policy.Statement.where(Effect == "Allow").all(Principal {AWS {_ != "*"}})
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lambda_permission")
    mql: |
      terraform.resources.where(nameLabel == "aws_lambda_permission").none(
        arguments.principal == "*"
      )
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lambda_permission")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lambda_permission").none(
        change.after.principal == "*"
      )
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lambda_permission")
    mql: |
      terraform.state.resources.where(type == "aws_lambda_permission").none(
        values.principal == "*"
      )
  - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades
    title: Ensure no pending OS upgrades are available for RDS instances
    impact: 90
    filters: asset.platform == "aws-rds-dbinstance"
    mql: aws.rds.dbinstance.pendingMaintenanceActions == empty
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) instances have the latest operating system patches applied and no pending OS upgrades are available. Operating system patches include critical security updates, bug fixes, and performance improvements that help maintain the security posture and stability of database instances.

        **Why this matters**

        Without regular application of OS patches on RDS instances:

        - Known vulnerabilities in the underlying operating system may remain unaddressed, potentially allowing attackers to exploit these weaknesses.
        - Database instances may miss important performance improvements and stability fixes that could impact application reliability.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for timely security patch management may not be satisfied.

        While AWS manages the underlying infrastructure, customers are responsible for scheduling and applying OS patches to their RDS instances during defined maintenance windows. Postponing these upgrades increases the risk exposure window for known vulnerabilities.

        **Risk mitigation:**

        - **Security Posture:** Reduces vulnerability exposure by ensuring the latest security patches are applied.
        - **Operational Stability:** Incorporates bug fixes and performance improvements that enhance database reliability.
        - **Compliance Management:** Helps meet regulatory requirements for timely security patch management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Select the RDS instance with pending OS upgrades.
            4. Under Maintenance & backups tab, check for pending maintenance.
            5. If maintenance is pending, select Actions, then Upgrade operating system.
            6. Choose whether to apply immediately or during the next maintenance window.
            7. Select Upgrade operating system to apply the pending patches.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for RDS instances with pending OS upgrades:

            ```bash
            aws rds describe-pending-maintenance-actions
            ```

            Apply pending upgrades immediately:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:db:instance-id \
              --apply-action system-update \
              --opt-in-type immediate
            ```

            Or schedule for next maintenance window:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:db:instance-id \
              --apply-action system-update \
              --opt-in-type next-maintenance
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # You can use auto minor version upgrades to reduce manual management
            resource "aws_db_instance" "secure_rds" {
              identifier                  = "secure-rds-instance"
              engine                      = "mysql"
              engine_version              = "8.0"
              auto_minor_version_upgrade  = true
              maintenance_window          = "Mon:03:00-Mon:04:00"

              # Other configuration parameters
              instance_class              = "db.t3.micro"
              allocated_storage           = 20
              storage_type                = "gp2"
              username                    = "admin"
              password                    = "YourSecurePassword123"
              skip_final_snapshot         = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "secure-rds-instance"
                  Engine: "mysql"
                  EngineVersion: "8.0"
                  AutoMinorVersionUpgrade: true
                  PreferredMaintenanceWindow: "Mon:03:00-Mon:04:00"

                  # Other configuration parameters
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  StorageType: "gp2"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  SkipFinalSnapshot: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html
        title: Amazon RDS Security
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest
    title: Ensure all RDS instances are enabled for encryption-at-rest
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-single
        tags:
          mondoo.com/filter-title: "AWS RDS DB Instance"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-hcl
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-plan
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-state
    docs:
      desc: |
        Amazon RDS utilizes the widely adopted AES-256 encryption algorithm, a standard in the industry, to safeguard the data stored within your DB instances. This encryption secures your information directly on the server infrastructure where your Amazon RDS DB instance resides. After encryption is enabled, Amazon RDS automatically manages access authentication and data decryption without requiring manual intervention, ensuring a minimal effect on database performance.

        **Why this matters**

        Since databases frequently contain confidential and essential data, enabling encryption is a crucial security measure. It acts as a vital layer of defense against unauthorized access or exposure of sensitive information. By activating RDS encryption, you ensure comprehensive protection, as the encryption covers the data on the instance's underlying storage, along with its automated backups, any read replicas, and all created snapshots.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Note: Encryption cannot be enabled on an existing unencrypted DB instance. Instead, create a new encrypted instance:
               - Select Create database.
               - Configure the database with the same settings as the unencrypted instance.
               - Under Encryption, enable "Turn on encryption".
               - Choose an AWS KMS key (default or custom).
               - Complete the database creation.
            4. Migrate data from the unencrypted instance to the encrypted one.
               - For MySQL/MariaDB: Use mysqldump or AWS Database Migration Service.
               - For PostgreSQL: Use pg_dump/pg_restore or AWS DMS.
               - For Oracle: Use Oracle Data Pump or AWS DMS.
               - For SQL Server: Use native backup/restore or AWS DMS.
            5. Once migration is complete, decommission the unencrypted instance.
        - id: cli
          desc: |
            **Using AWS CLI**

            Create a snapshot of the unencrypted instance:

            ```bash
            aws rds create-db-snapshot \
              --db-instance-identifier unencrypted-instance \
              --db-snapshot-identifier unencrypted-snapshot
            ```

            Create an encrypted copy of the snapshot:

            ```bash
            aws rds copy-db-snapshot \
              --source-db-snapshot-identifier unencrypted-snapshot \
              --target-db-snapshot-identifier encrypted-snapshot \
              --kms-key-id arn:aws:kms:region:account-id:key/key-id
            ```

            Restore a new instance from the encrypted snapshot:

            ```bash
            aws rds restore-db-instance-from-db-snapshot \
              --db-instance-identifier new-encrypted-instance \
              --db-snapshot-identifier encrypted-snapshot
            ```

            After verification, delete the unencrypted instance:

            ```bash
            aws rds delete-db-instance \
              --db-instance-identifier unencrypted-instance \
              --skip-final-snapshot
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Create a KMS key for RDS encryption
            resource "aws_kms_key" "rds_encryption_key" {
              description         = "KMS key for RDS encryption"
              enable_key_rotation = true
            }

            # Create an encrypted RDS instance
            resource "aws_db_instance" "encrypted_instance" {
              identifier           = "encrypted-rds-instance"
              engine               = "mysql"
              engine_version       = "8.0"
              instance_class       = "db.t3.micro"
              allocated_storage    = 20
              storage_type         = "gp2"
              username             = "admin"
              password             = "YourSecurePassword123"

              # Enable encryption
              storage_encrypted    = true
              kms_key_id           = aws_kms_key.rds_encryption_key.arn

              # Other configuration
              multi_az             = true
              skip_final_snapshot  = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RDSEncryptionKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for RDS encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"

              EncryptedRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "encrypted-rds-instance"
                  Engine: "mysql"
                  EngineVersion: "8.0"
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  StorageType: "gp2"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"

                  # Enable encryption
                  StorageEncrypted: true
                  KmsKeyId: !Ref RDSEncryptionKey

                  # Other configuration
                  MultiAZ: true
                  SkipFinalSnapshot: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html
        title: Amazon RDS Security
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html
        title: Amazon RDS Encryption
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-single
    filters: asset.platform == "aws-rds-dbinstance"
    mql: aws.rds.dbinstance.storageEncrypted == true
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_db_instance")
    mql: terraform.resources.where(nameLabel == "aws_db_instance").all(arguments['storage_encrypted'] == true)
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_db_instance")
    mql: terraform.plan.resourceChanges.where(type == "aws_db_instance").all( change.after.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_db_instance" )
    mql: terraform.state.resources.where( type == "aws_db_instance" ).all( values.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl
    title: Ensure that encryption in transit is enabled for all RDS Clusters via cluster parameter groups
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-single
        tags:
          mondoo.com/filter-title: "AWS RDS DB Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-hcl
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-plan
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-state
    docs:
      desc: |
        This check ensures that Amazon RDS database clusters have encryption in transit enforced through the appropriate cluster parameter group settings. Specifically, this verifies that the parameter `ssl` is set to "1" which mandates TLS/SSL connections for all database communications, preventing any unencrypted connections to the instances of the cluster.

        **Why this matters**

        Without proper parameter group configuration enforcing encryption in transit:

        - Database administrators or applications may be able to establish unencrypted connections to the cluster, even if TLS is available.
        - There is no uniform enforcement of secure connections across all instances in the cluster, potentially creating security inconsistencies.
        - Compliance frameworks such as PCI DSS, HIPAA, GDPR, and SOC 2 requirements for mandatory encryption of data in transit may not be satisfied.

        Using cluster parameter groups to enforce encryption provides a centralized and consistent approach to securing all instances within the cluster. Unlike instance-level or application-level settings, parameter groups ensure that secure connection requirements cannot be bypassed or misconfigured on individual instances.

        **Risk mitigation:**

        - **Consistent Security Policy:** Ensures uniform encryption requirements across all instances in the cluster.
        - **Prevent Configuration Drift:** Eliminates the risk of individual instances having different security settings.
        - **Compliance Enforcement:** Provides an auditable mechanism to demonstrate mandatory encryption for all database connections.

        **Note:**

        In general, cluster parameter groups can be overridden by instance parameter groups, but there is no equivalent setting at the instance group level for `ssl`.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS RDS Console.
            2. In the left navigation panel, select Parameter groups.
            3. Identify the cluster parameter group associated with your RDS cluster.
            4. Select the parameter group and choose Edit parameters.
            5. In the parameter search field, search for "ssl".
            6. Change the value of the ssl parameter from "0" to "1" to enforce SSL connections.
            7. Select Save changes to apply the modified parameter.
            8. If this is a new parameter group, you need to associate it with your RDS cluster:
               - Navigate to Databases in the left panel.
               - Select your RDS cluster.
               - Select Modify.
               - Under Additional configuration, select the parameter group with SSL enabled.
               - Select Continue and Apply immediately to apply the changes.
            9. After applying the changes, monitor the cluster status until it shows "Available" again.
            10. Note that the cluster may require a reboot to apply the parameter change.
        - id: cli
          desc: |
            **Using AWS CLI**

            First, check if the cluster parameter group has SSL enabled:

            ```bash
            aws rds describe-db-cluster-parameters \
              --db-cluster-parameter-group-name <parameter-group-name> \
              --query "Parameters[?ParameterName=='ssl']"
            ```

            If SSL is not enabled (value is "0"), create a modified parameter group:

            ```bash
            # First, create a new parameter group (if needed)
            aws rds create-db-cluster-parameter-group \
              --db-cluster-parameter-group-name secure-cluster-params \
              --db-parameter-group-family aurora-mysql5.7 \
              --description "Cluster parameter group with SSL enabled"

            # Modify the SSL parameter to enforce SSL connections
            aws rds modify-db-cluster-parameter-group \
              --db-cluster-parameter-group-name secure-cluster-params \
              --parameters "ParameterName=ssl,ParameterValue=1,ApplyMethod=immediate"
            ```

            Apply the parameter group to your RDS cluster:

            ```bash
            aws rds modify-db-cluster \
              --db-cluster-identifier <cluster-identifier> \
              --db-cluster-parameter-group-name secure-cluster-params \
              --apply-immediately
            ```

            Verify the parameter group is associated and the SSL parameter is set correctly:

            ```bash
            aws rds describe-db-clusters \
              --db-cluster-identifier <cluster-identifier> \
              --query "DBClusters[*].DBClusterParameterGroup"

            aws rds describe-db-cluster-parameters \
              --db-cluster-parameter-group-name secure-cluster-params \
              --query "Parameters[?ParameterName=='ssl']"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Create a MySQL cluster parameter group with SSL enabled
            resource "aws_rds_cluster_parameter_group" "secure_cluster_params" {
              name        = "secure-cluster-params-mysql5.7"
              family      = "aurora-mysql5.7"
              description = "Cluster parameter group with SSL enabled"

              parameter {
                name  = "require_secure_transport"
                value = "ON"
              }
            }

            # Create a Postgresql cluster parameter group with SSL enabled
            resource "aws_rds_cluster_parameter_group" "secure_cluster_params" {
              name        = "secure-cluster-params-pg10"
              family      = "aurora-postgresql10"
              description = "Cluster parameter group with SSL enabled"

              parameter {
                name  = "ssl"
                value = "1"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              # Create a cluster parameter group with SSL enabled
              SecureClusterParameterGroupMysql57:
                Type: "AWS::RDS::DBClusterParameterGroup"
                Properties:
                  Description: "Cluster parameter group with SSL enabled"
                  Family: "aurora-mysql5.7"
                  Parameters:
                    require_secure_transport: "ON"
                  Tags:
                    - Key: "Name"
                      Value: "secure-cluster-params"

              # Create a cluster parameter group with SSL enabled
              SecureClusterParameterGroupPG10:
                Type: "AWS::RDS::DBClusterParameterGroup"
                Properties:
                  Description: "Cluster parameter group with SSL enabled"
                  Family: "aurora-postgresql10"
                  Parameters:
                    ssl: 1
                  Tags:
                    - Key: "Name"
                      Value: "secure-cluster-params-pg10"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html
        title: Amazon RDS Security
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.SSL.html
        title: Using SSL/TLS with Aurora
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-single
    filters: asset.platform == "aws-rds-dbcluster"
    mql: |
      clusterParameterGroup = aws.rds.dbcluster.parameterGroupName
      aws.rds.clusterParameterGroups.where(name == clusterParameterGroup)
        .all(
          parameters.where(name == 'ssl').any(value == 1)
            || parameters.where(name == 'require_secure_transport').any(value == "ON")
        )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_rds_cluster_parameter_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_rds_cluster_parameter_group" && arguments.family == /mysql/).all(
        blocks.any(
          attributes.name.value =='require_secure_transport'
            && attributes.value.value == "ON"
        )
      )

      terraform.resources.where(nameLabel == "aws_rds_cluster_parameter_group" && arguments.family == /postgres/).all(
        blocks.any(
          attributes.name.value =='ssl'
            && attributes.value.value == 1
        )
      )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_rds_cluster_parameter_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_rds_cluster_parameter_group" && change.after.family == /mysql/).all(
        change.after.parameter.where(name == "require_secure_transport").map(value).first == "ON"
      )
      terraform.plan.resourceChanges.where(type == "aws_rds_cluster_parameter_group" && change.after.family == /postgres/).all(
        change.after.parameter.where(name == "ssl").map(value).first == 1
      )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_rds_cluster_parameter_group")
    mql: |
      terraform.state.resources.where(type == "aws_rds_cluster_parameter_group" && values.family == /mysql/).all(
        values.parameter.where(name == 'require_secure_transport').map(value).first == "OFF"
      )
      terraform.state.resources.where(type == "aws_rds_cluster_parameter_group" && values.family == /postgres/).all(
        values.parameter.where(name == 'ssl').map(value).first == 0
      )
  - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades
    title: Ensure no pending OS upgrades are available for RDS clusters
    impact: 90
    filters: asset.platform == "aws-rds-dbcluster"
    mql: |
      rdsArn = asset.ids.where(_ == /^arn/).first
      aws.rds.allPendingMaintenanceActions.where(resourceArn == rdsArn) == empty
    docs:
      desc: |
        This check ensures that Amazon RDS database clusters, including Aurora clusters, have the latest operating system patches applied and no pending OS upgrades are available. Operating system patches include critical security updates, bug fixes, and performance improvements that help maintain the security posture and stability of database clusters.

        **Why this matters**

        Without regular application of OS patches on RDS clusters:

        - Known vulnerabilities in the underlying operating system may remain unaddressed, potentially allowing attackers to exploit these weaknesses across multiple database instances.
        - Database clusters may miss important performance improvements and stability fixes that could impact application reliability and high availability.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for timely security patch management may not be satisfied.

        While AWS manages the underlying infrastructure, customers are responsible for scheduling and applying OS patches to their RDS clusters during defined maintenance windows. Postponing these upgrades increases the risk exposure window for known vulnerabilities.

        **Risk mitigation:**

        - **Security Posture:** Reduces vulnerability exposure by ensuring the latest security patches are applied across all instances in the cluster.
        - **Operational Stability:** Incorporates bug fixes and performance improvements that enhance database reliability and consistency.
        - **Compliance Management:** Helps meet regulatory requirements for timely security patch management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Look for the RDS cluster (such as an Aurora cluster) with pending OS upgrades.
            4. Under Maintenance & backups tab, check for pending maintenance.
            5. If maintenance is pending, select Actions, then Upgrade operating system.
            6. Choose whether to apply immediately or during the next maintenance window.
            7. If there are multiple instances in the cluster, you can choose to apply to all or specific instances.
            8. Select Upgrade operating system to apply the pending patches.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for pending maintenance actions on RDS clusters:

            ```bash
            aws rds describe-pending-maintenance-actions
            ```

            Apply pending OS upgrades immediately to a cluster:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:cluster:cluster-id \
              --apply-action system-update \
              --opt-in-type immediate
            ```

            Schedule the upgrade for the next maintenance window:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:cluster:cluster-id \
              --apply-action system-update \
              --opt-in-type next-maintenance
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Ensure auto minor version upgrades are enabled to reduce manual management of OS patches
            resource "aws_rds_cluster" "secure_cluster" {
              cluster_identifier      = "secure-aurora-cluster"
              engine                  = "aurora-mysql"
              engine_version          = "5.7.mysql_aurora.2.10.2"
              availability_zones      = ["us-west-2a", "us-west-2b", "us-west-2c"]
              database_name           = "production"
              master_username         = "admin"
              master_password         = "YourSecurePassword123"
              backup_retention_period = 7
              preferred_maintenance_window = "sun:05:00-sun:06:00"
              skip_final_snapshot     = true
            }

            resource "aws_rds_cluster_instance" "cluster_instances" {
              count               = 2
              identifier          = "secure-aurora-cluster-${count.index}"
              cluster_identifier  = aws_rds_cluster.secure_cluster.id
              instance_class      = "db.r5.large"
              engine              = aws_rds_cluster.secure_cluster.engine
              engine_version      = aws_rds_cluster.secure_cluster.engine_version
              auto_minor_version_upgrade = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureAuroraCluster:
                Type: "AWS::RDS::DBCluster"
                Properties:
                  DBClusterIdentifier: "secure-aurora-cluster"
                  Engine: "aurora-mysql"
                  EngineVersion: "5.7.mysql_aurora.2.10.2"
                  AvailabilityZones:
                    - !Select [0, !GetAZs ""]
                    - !Select [1, !GetAZs ""]
                    - !Select [2, !GetAZs ""]
                  DatabaseName: "production"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  BackupRetentionPeriod: 7
                  PreferredMaintenanceWindow: "sun:05:00-sun:06:00"
                  DeletionProtection: true

              InstanceOne:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref SecureAuroraCluster
                  DBInstanceIdentifier: "secure-aurora-cluster-0"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
                  AutoMinorVersionUpgrade: true

              InstanceTwo:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref SecureAuroraCluster
                  DBInstanceIdentifier: "secure-aurora-cluster-1"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
                  AutoMinorVersionUpgrade: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html
        title: Amazon RDS Security
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest
    title: Ensure all RDS clusters are set to be encrypted-at-rest
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-single
        tags:
          mondoo.com/filter-title: "AWS RDS DB Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-hcl
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-plan
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-state
    docs:
      desc: |
        Amazon RDS utilizes the industry-standard AES-256 encryption algorithm to safeguard the data stored within your DB clusters. This encryption secures your information directly across the cluster's underlying storage volume. Once encryption is enabled for the cluster, Amazon RDS automatically manages access authentication and data decryption transparently, designed to ensure a minimal impact on overall cluster performance.

        **Why this matters**

        Database clusters often consolidate significant amounts of sensitive or critical data. Implementing encryption is therefore a highly recommended security practice to protect this data against unauthorized access or potential disclosure. By activating RDS encryption on your cluster, you ensure comprehensive data-at-rest protection, covering the data within the shared cluster storage, as well as associated components like automated backups, cluster snapshots, and any read replicas within the cluster environment.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Note: Encryption cannot be enabled on an existing unencrypted DB cluster. Instead, create a new encrypted cluster:
               - Select Create database.
               - Choose Amazon Aurora.
               - Configure the cluster with the same settings as the unencrypted cluster.
               - Under Encryption, enable "Turn on encryption".
               - Choose an AWS KMS key (default or custom).
               - Complete the cluster creation.
            4. Migrate data from the unencrypted cluster to the encrypted one using one of these methods:
               - For Aurora MySQL: Use mysqldump, AWS Database Migration Service, or native Aurora backup/restore.
               - For Aurora PostgreSQL: Use pg_dump/pg_restore, logical replication, or AWS DMS.
            5. Once migration is complete, decommission the unencrypted cluster.
        - id: cli
          desc: |
            **Using AWS CLI**

            Export data from unencrypted cluster (for MySQL):

            ```bash
            # Use the RDS export feature to S3
            aws rds start-export-task \
              --export-task-identifier "export-unencrypted-cluster" \
              --source-arn "arn:aws:rds:region:account-id:cluster:unencrypted-cluster" \
              --s3-bucket-name "your-export-bucket" \
              --iam-role-arn "arn:aws:iam::account-id:role/rds-s3-export-role" \
              --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```

            Create a new encrypted cluster:

            ```bash
            aws rds create-db-cluster \
              --db-cluster-identifier encrypted-cluster \
              --engine aurora-mysql \
              --engine-version 5.7.mysql_aurora.2.10.2 \
              --master-username admin \
              --master-user-password YourSecurePassword123 \
              --storage-encrypted \
              --kms-key-id arn:aws:kms:region:account-id:key/key-id
            ```

            Create DB instances for the new cluster:

            ```bash
            aws rds create-db-instance \
              --db-instance-identifier encrypted-instance-1 \
              --db-cluster-identifier encrypted-cluster \
              --engine aurora-mysql \
              --db-instance-class db.r5.large
            ```

            After migration and verification, delete the unencrypted cluster:

            ```bash
            aws rds delete-db-cluster \
              --db-cluster-identifier unencrypted-cluster \
              --skip-final-snapshot
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Create a KMS key for RDS cluster encryption
            resource "aws_kms_key" "aurora_encryption_key" {
              description         = "KMS key for Aurora cluster encryption"
              enable_key_rotation = true
            }

            # Create an encrypted Aurora cluster
            resource "aws_rds_cluster" "encrypted_cluster" {
              cluster_identifier      = "encrypted-aurora-cluster"
              engine                  = "aurora-mysql"
              engine_version          = "5.7.mysql_aurora.2.10.2"
              availability_zones      = ["us-west-2a", "us-west-2b", "us-west-2c"]
              database_name           = "production"
              master_username         = "admin"
              master_password         = "YourSecurePassword123"
              backup_retention_period = 7
              preferred_backup_window = "07:00-09:00"

              # Enable encryption
              storage_encrypted       = true
              kms_key_id              = aws_kms_key.aurora_encryption_key.arn

              skip_final_snapshot     = true
            }

            # Create cluster instances
            resource "aws_rds_cluster_instance" "cluster_instances" {
              count               = 2
              identifier          = "encrypted-aurora-cluster-${count.index}"
              cluster_identifier  = aws_rds_cluster.encrypted_cluster.id
              instance_class      = "db.r5.large"
              engine              = aws_rds_cluster.encrypted_cluster.engine
              engine_version      = aws_rds_cluster.encrypted_cluster.engine_version
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              AuroraEncryptionKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for Aurora cluster encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"

              EncryptedAuroraCluster:
                Type: "AWS::RDS::DBCluster"
                Properties:
                  DBClusterIdentifier: "encrypted-aurora-cluster"
                  Engine: "aurora-mysql"
                  EngineVersion: "5.7.mysql_aurora.2.10.2"
                  AvailabilityZones:
                    - !Select [0, !GetAZs ""]
                    - !Select [1, !GetAZs ""]
                    - !Select [2, !GetAZs ""]
                  DatabaseName: "production"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  BackupRetentionPeriod: 7
                  PreferredBackupWindow: "07:00-09:00"

                  # Enable encryption
                  StorageEncrypted: true
                  KmsKeyId: !Ref AuroraEncryptionKey

                  DeletionProtection: true

              InstanceOne:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref EncryptedAuroraCluster
                  DBInstanceIdentifier: "encrypted-aurora-cluster-0"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"

              InstanceTwo:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref EncryptedAuroraCluster
                  DBInstanceIdentifier: "encrypted-aurora-cluster-1"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html
        title: Amazon RDS Security
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Overview.Encryption.html
        title: Amazon Aurora Encryption
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-single
    filters: |
      asset.platform == "aws-rds-dbcluster"
    mql: |
      aws.rds.dbcluster.storageEncrypted == true
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_rds_cluster")
    mql: terraform.resources.where(nameLabel == "aws_rds_cluster").all(arguments['storage_encrypted'] == true)
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_rds_cluster")
    mql: terraform.plan.resourceChanges.where(type == "aws_rds_cluster").all( change.after.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_rds_cluster" )
    mql: terraform.state.resources.where( type == "aws_rds_cluster" ).all( values.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-cluster-public-access-check
    title: Ensure all RDS clusters are not publicly accessible
    impact: 100
    filters: |
      asset.platform == "aws-rds-dbcluster"
    mql: |
      aws.rds.dbcluster.securityGroups.none(
        vpc.routeTables.where(
          routes.any(GatewayId == /igw-/ && DestinationCidrBlock == "0.0.0.0/0")
        )
      )
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) clusters and cluster instances are not publicly accessible to prevent unauthorized access to sensitive databases. By default, RDS instances can be configured to allow public access, which exposes them to the internet, increasing the risk of security breaches, unauthorized data access, and potential data exfiltration.

        **Why this matters**

        Publicly accessible RDS clusters pose significant security risks, including:

        - Unauthorized access if credentials or security configurations are weak.
        - Brute-force attacks on database authentication.
        - Non-compliance with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        To mitigate these risks, RDS clusters should be deployed in private subnets and accessible only through bastion hosts, VPNs, or AWS PrivateLink instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting direct exposure to the internet.
        - Enhances database security by enforcing private networking best practices.
        - Ensures compliance with regulatory and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS RDS Console.
            2.  In the left panel, select Databases.
            3.  Locate and select the RDS Cluster (e.g., Aurora) you want to update.
            4.  Under the Connectivity & security tab, check the Publicly accessible setting for both:
              - The cluster itself
              - Each DB instance in the cluster (shown below the cluster details)
            5.  If the cluster or any of its instances are publicly accessible:
              - For the cluster:
              - Choose Modify cluster.
              - Under Connectivity, set Public access to No.
              - Select Continue, then choose Apply immediately or schedule for the next maintenance window.
              - For each instance:
              - Choose the instance name to open its details.
              - Select Modify.
              - Under Connectivity, set Public access to No.
              - Select Continue, then Apply immediately or schedule as needed.
            6.  Ensure the DB subnet group used by the cluster points to private subnets (i.e., subnets with MapPublicIpOnLaunch set to false).
            7.  Confirm the security group allows access only from trusted sources—e.g., your app servers, bastion hosts, or VPN.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an RDS Cluster is publicly accessible:

            ```bash
            aws rds describe-db-clusters --query "DBClusters[*].{DBClusterIdentifier:DBClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
              ```

            Check if RDS Cluster instances are publicly accessible:

            ```bash
              aws rds describe-db-instances --query "DBInstances[*].{DBInstanceIdentifier:DBInstanceIdentifier, DBClusterIdentifier:DBClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If the cluster or any of its instances are public, modify them:

            ```bash
            aws rds modify-db-cluster --db-cluster-identifier <db-cluster-id> --publicly-accessible false --apply-immediately
            ```

            ```bash
            aws rds modify-db-instance --db-instance-identifier <db-instance-id> --publicly-accessible false --apply-immediately
            ```

            Ensure your RDS cluster is deployed in private subnets:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].{SubnetId:SubnetId, MapPublicIpOnLaunch:MapPublicIpOnLaunch}"
            ```

            If any subnet used by the DB subnet group has MapPublicIpOnLaunch: true, consider moving the cluster to a private subnet group.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure RDS clusters are not publicly accessible:

            ```hcl
              resource "aws_rds_cluster" "secure_cluster" {
                cluster_identifier      = "secure-rds-cluster"
                engine                  = "aurora-mysql"
                master_username         = "admin"
                master_password         = "yourpassword"
                vpc_security_group_ids  = [aws_security_group.private_sg.id]
                db_subnet_group_name    = aws_db_subnet_group.private_db_subnet.name
              }

              resource "aws_rds_cluster_instance" "secure_cluster_instances" {
                count                   = 2
                identifier              = "secure-rds-cluster-instance-${count.index}"
                cluster_identifier      = aws_rds_cluster.secure_cluster.id
                instance_class          = "db.r5.large"
                publicly_accessible     = false  # Can only be set on individual instances
                db_subnet_group_name    = aws_db_subnet_group.private_db_subnet.name
                engine                  = aws_rds_cluster.secure_cluster.engine
              }

              resource "aws_db_subnet_group" "private_db_subnet" {
                name       = "private-db-subnet"
                subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
              }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure RDS clusters are not publicly accessible:

            ```yaml
              Resources:
                SecureRDSCluster:
                  Type: "AWS::RDS::DBCluster"
                  Properties:
                    Engine: "aurora-mysql"
                    DBClusterIdentifier: "secure-rds-cluster"
                    MasterUsername: "admin"
                    MasterUserPassword: "YourSecurePassword123"
                    VpcSecurityGroupIds:
                      - !Ref PrivateSecurityGroup
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                SecureRDSClusterInstance1:
                  Type: "AWS::RDS::DBInstance"
                  Properties:
                    DBInstanceIdentifier: "secure-rds-cluster-instance-1"
                    DBClusterIdentifier: !Ref SecureRDSCluster
                    Engine: "aurora-mysql"
                    DBInstanceClass: "db.r5.large"
                    PubliclyAccessible: false  # Ensure the instance is private
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                SecureRDSClusterInstance2:
                  Type: "AWS::RDS::DBInstance"
                  Properties:
                    DBInstanceIdentifier: "secure-rds-cluster-instance-2"
                    DBClusterIdentifier: !Ref SecureRDSCluster
                    Engine: "aurora-mysql"
                    DBInstanceClass: "db.r5.large"
                    PubliclyAccessible: false
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                PrivateDBSubnetGroup:
                  Type: "AWS::RDS::DBSubnetGroup"
                  Properties:
                    DBSubnetGroupName: "private-db-subnet"
                    SubnetIds:
                      - !Ref PrivateSubnet1
                      - !Ref PrivateSubnet2
                    DBSubnetGroupDescription: "Private subnets for RDS cluster"
            ```
    refs:
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-cluster.html
        title: AWS CLI Command Reference - create-db-cluster
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-cluster.html
        title: AWS CLI Command Reference - modify-db-cluster
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster_instance#publicly_accessible-1
        title: Terraform Registry - rds_cluster_instance
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-rds-instance-public-access-check
    title: Ensure all RDS instances are not publicly accessible
    impact: 100
    variants:
      - uid: mondoo-aws-security-rds-instance-public-access-check-single
        tags:
          mondoo.com/filter-title: "AWS RDS DB Instance"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-hcl
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-plan
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) instances are not publicly accessible to prevent unauthorized access to sensitive databases. By default, RDS instances can be configured to allow public access, which exposes them to the internet, increasing the risk of security breaches, unauthorized data access, and potential data exfiltration.

        **Why this matters**

        Publicly accessible RDS instances pose significant security risks, including:

        - Unauthorized access if credentials or security configurations are weak.
        - Brute-force attacks on database authentication.
        - Non-compliance with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        To mitigate these risks, RDS instances should be deployed in private subnets and accessible only through bastion hosts, VPNs, or AWS PrivateLink instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting direct exposure to the internet.
        - Enhances database security by enforcing private networking best practices.
        - Ensures compliance with regulatory and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

              1.  Navigate to the AWS RDS Console.
              2.  Select Databases in the left panel.
              3.  Select an RDS instance and go to the Connectivity & security tab.
              4.  Check the Publicly accessible setting.
              5.  If the instance is publicly accessible, modify it:
                - Select Modify.
                - Under Connectivity, set Public access to No.
                - Select Continue, and then Apply immediately or schedule the change during the next maintenance window.
              6.  Ensure the instance is placed in a private subnet with security group rules allowing access only from authorized sources.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an RDS instance is publicly accessible:

            ```bash
            aws rds describe-db-instances --query "DBInstances[*].{DBInstanceIdentifier:DBInstanceIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If an instance is publicly accessible, modify it:

            ```bash
            aws rds modify-db-instance --db-instance-identifier <db-instance-id> --publicly-accessible false --apply-immediately
            ```

            Ensure that RDS is in a private subnet:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].MapPublicIpOnLaunch"
            ```

            If `MapPublicIpOnLaunch` is `true`, move the RDS instance to a private subnet.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure RDS instances are not publicly accessible:

            ```hcl
            resource "aws_db_instance" "secure_rds" {
              identifier              = "secure-rds-instance"
              engine                 = "mysql"
              instance_class         = "db.t3.micro"
              allocated_storage      = 20
              publicly_accessible    = false  # Ensure RDS is private
              vpc_security_group_ids = [aws_security_group.private_sg.id]
              db_subnet_group_name   = aws_db_subnet_group.private_db_subnet.name
            }

            resource "aws_db_subnet_group" "private_db_subnet" {
              name       = "private-db-subnet"
              subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure RDS instances are not publicly accessible:

            ```yaml
            Resources:
              SecureRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "secure-rds-instance"
                  Engine: "mysql"
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  PubliclyAccessible: false
                  DBSubnetGroupName: !Ref PrivateDBSubnetGroup

              PrivateDBSubnetGroup:
                Type: "AWS::RDS::DBSubnetGroup"
                Properties:
                  DBSubnetGroupName: "private-db-subnet"
                  SubnetIds:
                    - !Ref PrivateSubnet1
                    - !Ref PrivateSubnet2
            ```
    refs:
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-instance.html
        title: AWS CLI Command Reference - create-db-instance
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html
        title: AWS CLI Command Reference - modify-db-instance
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#publicly_accessible-1
        title: Terraform Registry - aws_db_instance
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-rds-instance-public-access-check-single
    filters: |
      asset.platform == "aws-rds-dbinstance"
    mql: |
      aws.rds.dbinstance.publiclyAccessible == false
      aws.rds.dbinstance.securityGroups.none(
        vpc.routeTables.where(
          routes.any(GatewayId == /igw-/ && DestinationCidrBlock == "0.0.0.0/0")
        )
      )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_db_instance" )
    mql: terraform.resources.where( nameLabel == "aws_db_instance" ).all( arguments.publicly_accessible != true )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_db_instance" )
    mql: terraform.plan.resourceChanges.where( type == "aws_db_instance" ).all( change.after.publicly_accessible != true )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_db_instance" )
    mql: terraform.state.resources.where( type == "aws_db_instance" ).all( values.publicly_accessible != true )
  - uid: mondoo-aws-security-redshift-cluster-public-access-check
    title: Ensure Redshift clusters are not publicly accessible
    impact: 95
    variants:
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-single
        tags:
          mondoo.com/filter-title: "AWS Redshift Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters are not publicly accessible to prevent unauthorized access and potential data breaches. A publicly accessible Redshift cluster can be reached from the internet, exposing it to security threats, including brute-force attacks and data exfiltration.

        **Why this matters**

        Amazon Redshift is used for data warehousing and analytics, often storing sensitive business intelligence and customer data. If a Redshift cluster is publicly accessible:

        - Anyone on the internet could attempt to access it if misconfigured.
        - Brute-force attacks could compromise database credentials.
        - Compliance violations may occur under frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and SOC 2.

        To mitigate these risks, Redshift clusters should be placed in private subnets and accessed securely using VPNs, VPC peering, AWS PrivateLink, or AWS IAM authentication instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting internet exposure.
        - Enhances security by ensuring database traffic remains private.
        - Ensures compliance with industry security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS Redshift Console.
            2.  Select Clusters in the left panel.
            3.  Select the cluster and go to the Properties tab.
            4.  Under Network and security, check Publicly accessible.
            5.  If the cluster is publicly accessible, modify the settings:
              - Select Edit publicly accessible setting.
              - Set Publicly accessible to No.
              - Select Save changes.
            6.  Ensure that the cluster is placed in a private subnet and that security groups restrict access to trusted sources only.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a Redshift cluster is publicly accessible:

            ```bash
            aws redshift describe-clusters --query "Clusters[*].{Cluster:ClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If a cluster is publicly accessible, modify it:

            ```bash
            aws redshift modify-cluster --cluster-identifier <cluster-id> --publicly-accessible false
            ```

            Ensure the cluster is placed in a private subnet:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].MapPublicIpOnLaunch"
            ```

            If `MapPublicIpOnLaunch` is `true`, move the Redshift cluster to a private subnet.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure Redshift clusters are not publicly accessible:

            ```hcl
            resource "aws_redshift_cluster" "secure_redshift" {
              cluster_identifier  = "secure-redshift-cluster"
              node_type           = "dc2.large"
              master_username     = "admin"
              master_password     = "securepassword"
              publicly_accessible = false  # Ensure Redshift is private
              cluster_subnet_group_name = aws_redshift_subnet_group.private_redshift_subnet.name
            }

            resource "aws_redshift_subnet_group" "private_redshift_subnet" {
              name       = "private-redshift-subnet"
              subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure Redshift clusters are not publicly accessible:

            ```yaml
            Resources:
              SecureRedshiftCluster:
                Type: "AWS::Redshift::Cluster"
                Properties:
                  ClusterIdentifier: "secure-redshift-cluster"
                  NodeType: "dc2.large"
                  MasterUsername: "admin"
                  MasterUserPassword: "securepassword"
                  PubliclyAccessible: false
                  ClusterSubnetGroupName: !Ref PrivateRedshiftSubnetGroup

              PrivateRedshiftSubnetGroup:
                Type: "AWS::Redshift::ClusterSubnetGroup"
                Properties:
                  Description: "Private Redshift Subnet Group"
                  SubnetIds:
                    - !Ref PrivateSubnet1
                    - !Ref PrivateSubnet2
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/redshift/index.html
        title: AWS Documentation - AWS CLI Command Reference - Redshift
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-single
    filters: asset.platform == "aws-redshift-cluster"
    mql: aws.redshift.cluster.publiclyAccessible == false
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_redshift_cluster" )
    mql: terraform.resources.where( nameLabel == "aws_redshift_cluster" ).all( arguments.publicly_accessible != true )
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_redshift_cluster" )
    mql: terraform.plan.resourceChanges.where( type == "aws_redshift_cluster" ).all( change.after.publicly_accessible != true )
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_redshift_cluster" )
    mql: terraform.state.resources.where( type == "aws_redshift_cluster" ).all( values.publicly_accessible != true )
  - uid: mondoo-aws-security-ec2-volume-inuse-check
    title: Ensure EBS volumes attached to EC2 instances are configured for deletion on instance termination
    impact: 60
    props:
      - uid: mondooAWSSecurityEbsVolumeDeleteOnTermination
        title: Defines whether instances should be configured to delete volumes on termination
        mql: "true"
    variants:
      - uid: mondoo-aws-security-ec2-volume-inuse-check-single
        tags:
          mondoo.com/filter-title: "AWS EBS Volume"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-hcl
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-plan
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volumes attached to EC2 instances are configured to be automatically deleted when the instance is terminated. When an EBS volume is created and attached to an instance, the `DeleteOnTermination` attribute determines whether the volume persists after instance termination.

        **Why this matters**

        By default, EBS volumes persist even after the associated EC2 instance is terminated, which can lead to orphaned volumes accumulating over time. These orphaned volumes not only increase storage costs but can also pose a security risk if they contain sensitive data and are left unmonitored.

        Setting the `DeleteOnTermination` flag ensures that unused EBS volumes do not persist beyond the lifecycle of the EC2 instance, reducing the risk of unauthorized access, data leaks, and unnecessary storage costs. This is particularly important in dynamic cloud environments where instances are frequently created and terminated.

        **Risk Mitigation**

        - **Cost Optimization:** Prevents unnecessary storage costs by ensuring that unused volumes do not persist.
        - **Security and Compliance:** Reduces the risk of orphaned volumes containing sensitive data.
        - **Operational Efficiency:** Prevents clutter and improves resource management in AWS environments.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select Instances in the left panel.
            3.  Select an instance and go to the Storage tab.
            4.  Check if the Delete on Termination flag is enabled for all EBS volumes.
            5.  If not enabled:
              - Select Modify Instance (for root volumes) or Detach Volume and reattach with Delete on Termination enabled.
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an EBS volume is set to delete on termination:

            ```bash
            aws ec2 describe-instances --query "Reservations[].Instances[].BlockDeviceMappings[?Ebs.DeleteOnTermination==`false`]" --output table
            ```

            Enable delete on termination for a specific volume:

            ```bash
            aws ec2 modify-instance-attribute --instance-id <instance-id> --block-device-mappings "[{\"DeviceName\":\"/dev/sdf\",\"Ebs\":{\"DeleteOnTermination\":true}}]"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure EBS volumes delete on termination:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              root_block_device {
                delete_on_termination = true
              }

              ebs_block_device {
                device_name           = "/dev/sdf"
                volume_size           = 20
                delete_on_termination = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure EBS volumes are deleted on termination:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  BlockDeviceMappings:
                    - DeviceName: "/dev/sda1"
                      Ebs:
                        VolumeSize: 20
                        DeleteOnTermination: true
                    - DeviceName: "/dev/sdf"
                      Ebs:
                        VolumeSize: 50
                        DeleteOnTermination: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html
        title: AWS Documentation - Delete an Amazon EBS volume
  - uid: mondoo-aws-security-ec2-volume-inuse-check-single
    filters: asset.platform == "aws-ebs-volume" && aws.ec2.volume.attachments != empty
    mql: |
      aws.ec2.volume.attachments.any(DeleteOnTermination == true)
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_instance").all(
        blocks.none(type == "root_block_device" && arguments.delete_on_termination != true) &&
        blocks.none(type == "ebs_block_device" && arguments.delete_on_termination != true)
      )
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_instance").all(
        change.after.root_block_device.none(delete_on_termination != true) &&
        change.after.ebs_block_device.none(delete_on_termination != true)
      )
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_instance")
    mql: |
      terraform.state.resources.where(type == "aws_instance").all(
        values.root_block_device.none(delete_on_termination != true) &&
        values.ebs_block_device.none(delete_on_termination != true)
      )
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
    title: Ensure EBS snapshots are not publicly restorable
    impact: 80
    variants:
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-single
        tags:
          mondoo.com/filter-title: "AWS EBS Snapshot"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-hcl
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-plan
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) snapshots are not configured to be publicly restorable. A public snapshot can be accessed by anyone, potentially exposing sensitive data. AWS provides fine-grained access controls for EBS snapshots, and by default, snapshots are private unless explicitly shared.

        **Why this matters**

        Publicly accessible EBS snapshots pose a significant security risk, as they can contain sensitive data such as personally identifiable information (PII), credentials, or proprietary application data. If a snapshot is mistakenly made public, it can be accessed by unauthorized parties, leading to data breaches, regulatory compliance violations, and reputational damage.

        Ensuring that snapshots remain private unless intentionally shared with specific AWS accounts mitigates the risk of data exposure while allowing controlled data sharing when necessary.

        **Risk mitigation:**

        - **Data Security:** Prevents unauthorized access to potentially sensitive EBS snapshot data.
        - **Compliance:** Helps maintain compliance with security frameworks such as GDPR, HIPAA, and SOC 2.
        - **Operational Control:** Ensures that data is shared only with intended AWS accounts or users.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select Snapshots in the left panel.
            3.  Check the Permissions column for any snapshots listed as Public.
            4.  If a snapshot is public, update its permissions:
              - Select the snapshot.
              - Go to Modify Permissions under the Actions menu.
              - Ensure that Public access is not selected.
              - If needed, specify the AWS account IDs that require access.
              - Select Save Changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if any snapshots are publicly accessible:

            ```bash
            aws ec2 describe-snapshots --owner-id <account-id> --query "Snapshots[?Public].SnapshotId"
            ```

            Modify a snapshot to remove public access:

            ```bash
            aws ec2 modify-snapshot-attribute --snapshot-id <snapshot-id> --attribute createVolumePermission --operation-type remove --group-names all
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Note: It's not possible to set this on snapshot level via terraform, but you can use a global setting:

            ```hcl
            resource "aws_ebs_snapshot_block_public_access" "secure_snapshot" {
              state = "block-all-sharing"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure that EBS snapshots are private in CloudFormation:

            ```yaml
            Resources:
              SecureSnapshot:
                Type: AWS::EC2::SnapshotBlockPublicAccess
                Properties:
                  State: block-all-sharing
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security.html
        title: Amazon EC2 Security
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html
        title: Share an Amazon EBS Snapshot
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-single
    filters: asset.platform == "aws-ebs-snapshot"
    mql: |
      aws.ec2.snapshot.createVolumePermission.none(Group == "all")
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_snapshot")
    mql: |
      terraform.resources.any(nameLabel == "aws_ebs_snapshot_block_public_access" && arguments.state == "block-all-sharing")
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.plan.resourceChanges.any(
        type == "aws_ebs_snapshot_block_public_access"
          && change.after.state == "block-all-sharing"
      )
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.state.resources.any(
        type == "aws_ebs_snapshot_block_public_access"
          && values.state == "block-all-sharing"
      )
  - uid: mondoo-aws-security-ebs-snapshot-encrypted
    title: Ensure EBS Snapshots are configured to be encrypted at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-single
        tags:
          mondoo.com/filter-title: "AWS EBS Snapshot"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-hcl
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-plan
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) snapshots are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that snapshot contents are stored securely. AWS KMS provides centralized key management and integrates with EBS snapshots to automatically encrypt and decrypt data transparently.

        **Why this matters**

        EBS snapshots inherit the encryption status of their source volumes. If a snapshot is created from an encrypted volume, the snapshot will be encrypted automatically using the same KMS key. However, snapshots from unencrypted volumes will remain unencrypted unless explicitly configured for encryption during the copy operation. Organizations should verify that all snapshots, including those shared or copied across accounts, maintain proper encryption settings.

        AWS KMS encryption ensures that snapshot data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects backup data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Snapshots under the Elastic Block Store section.
            3. For unencrypted snapshots, you can create an encrypted copy:
               - Select the unencrypted snapshot.
               - Select Actions, then Copy.
               - In the Copy Snapshot dialog, check Encrypt this snapshot.
               - Choose a KMS key (AWS managed or customer managed).
               - Provide a description and click Copy Snapshot.
            4. After verifying the encrypted copy, consider deleting the unencrypted original.

            To ensure future snapshots are encrypted:
            1. Navigate to EC2 Dashboard > EBS settings.
            2. Enable EBS encryption by default.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for unencrypted snapshots:

            ```bash
            aws ec2 describe-snapshots --owner-ids self --query "Snapshots[?Encrypted==`false`].SnapshotId"
            ```

            Create an encrypted copy of an unencrypted snapshot:

            ```bash
            aws ec2 copy-snapshot \
              --source-region us-east-1 \
              --source-snapshot-id snap-1234567890abcdef0 \
              --description "Encrypted copy of snapshot" \
              --encrypted \
              --kms-key-id arn:aws:kms:us-east-1:account-id:key/key-id
            ```

            Enable EBS encryption by default for all future volumes and snapshots:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Enable default EBS encryption for the account
            resource "aws_ebs_encryption_by_default" "example" {
              enabled = true
            }

            # Create a KMS key for EBS encryption
            resource "aws_kms_key" "ebs_encryption" {
              description             = "KMS key for EBS encryption"
              deletion_window_in_days = 10
              enable_key_rotation     = true
            }

            # Set the default KMS key for EBS encryption
            resource "aws_ebs_default_kms_key" "example" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }

            # Create an encrypted snapshot
            resource "aws_ebs_snapshot" "example" {
              volume_id   = aws_ebs_volume.example.id
              description = "Encrypted snapshot"

              # Snapshots will be encrypted if the volume is encrypted
              # or if encryption by default is enabled
            }

            # Create an encrypted volume
            resource "aws_ebs_volume" "example" {
              availability_zone = "us-west-2a"
              size              = 50
              encrypted         = true
              kms_key_id        = aws_kms_key.ebs_encryption.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure that EBS snapshots are encrypted in CloudFormation:

            ```yaml
            Resources:
              SecureEBSVolume:
                Type: "AWS::EC2::Volume"
                Properties:
                  Size: 20
                  AvailabilityZone: "us-east-1a"
                  Encrypted: true
                  KmsKeyId: !Ref MyKMSKey  # Optional - references a KMS key you define
                  Tags:
                    - Key: "Name"
                      Value: "Secure Volume"

              SecureEBSSnapshot:
                Type: "AWS::EC2::Snapshot"
                Properties:
                  VolumeId: !Ref SecureEBSVolume
                  Description: "Encrypted EBS snapshot"
                  Tags:
                    - Key: "Name"
                      Value: "Secure Snapshot"

              # Optional: Define your own KMS key for encryption
              MyKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for EBS volume encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security.html
        title: Amazon EC2 Security
      - url: https://docs.aws.amazon.com/ebs/latest/userguide/ebs-encryption.html
        title: Amazon EBS Encryption
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-single
    filters: asset.platform == "aws-ebs-snapshot"
    mql: |
      aws.ec2.snapshot.encrypted == true
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_snapshot" || nameLabel == "aws_ebs_snapshot_copy")
    mql: |
      terraform.resources.where(nameLabel == "aws_ebs_snapshot_copy").all(
        arguments['encrypted'] == true
      )
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_snapshot").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_snapshot").all(
        values.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-encrypted-volumes
    title: Ensure attached EBS volumes are configured to be encrypted at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-ec2-encrypted-volumes-single
        tags:
          mondoo.com/filter-title: "AWS EBS Volume"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-hcl
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-plan
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volumes are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that volume contents are stored securely. AWS KMS provides centralized key management and integrates with EBS to automatically encrypt and decrypt data transparently.

        **Why this matters**

        As of May 2019, AWS enables encryption by default for newly created EBS volumes in supported regions. However, organizations should still verify this setting, as encryption settings can be modified and older volumes created before this change may remain unencrypted. Additionally, organizations may want to use specific KMS keys rather than the default AWS-managed keys.

        AWS KMS encryption ensures that volume data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Volumes under the Elastic Block Store section.
            3. For unencrypted volumes, create encrypted replacements:
               a. First, create a snapshot of the unencrypted volume:
                  - Select the unencrypted volume.
                  - Choose Actions > Create Snapshot.
                  - Add a description and tags, then click Create Snapshot.
               b. Create an encrypted copy of the snapshot:
                  - Go to Snapshots, select the newly created snapshot.
                  - Choose Actions > Copy.
                  - Check Encrypt this snapshot.
                  - Select a KMS key.
                  - Click Copy Snapshot.
               c. Create a new encrypted volume from the encrypted snapshot:
                  - Select the encrypted snapshot.
                  - Choose Actions > Create Volume.
                  - Configure the volume size and type.
                  - Verify Encryption is enabled.
                  - Click Create Volume.
               d. Attach the new encrypted volume:
                  - Stop the EC2 instance.
                  - Detach the original unencrypted volume.
                  - Attach the new encrypted volume.
                  - Start the instance.

            4. For future volumes, enable EBS encryption by default:
               - Go to EC2 Dashboard > EBS settings.
               - Select Manage under EBS encryption.
               - Check Always encrypt new EBS volumes.
               - Click Update.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for unencrypted volumes:

            ```bash
            aws ec2 describe-volumes --query "Volumes[?Encrypted==`false`].VolumeId"
            ```

            Create a snapshot of an unencrypted volume:

            ```bash
            aws ec2 create-snapshot \
              --volume-id vol-1234567890abcdef0 \
              --description "Snapshot of unencrypted volume"
            ```

            Create an encrypted copy of the snapshot:

            ```bash
            aws ec2 copy-snapshot \
              --source-region us-east-1 \
              --source-snapshot-id snap-1234567890abcdef0 \
              --description "Encrypted copy of snapshot" \
              --encrypted \
              --kms-key-id arn:aws:kms:us-east-1:account-id:key/key-id
            ```

            Create a new encrypted volume from the encrypted snapshot:

            ```bash
            aws ec2 create-volume \
              --availability-zone us-east-1a \
              --snapshot-id snap-0abcdef1234567890 \
              --volume-type gp3
            ```

            Stop the instance, detach the old volume, and attach the new volume:

            ```bash
            aws ec2 stop-instances --instance-ids i-1234567890abcdef0

            aws ec2 detach-volume --volume-id vol-1234567890abcdef0

            aws ec2 attach-volume \
              --volume-id vol-0abcdef1234567890 \
              --instance-id i-1234567890abcdef0 \
              --device /dev/sda1

            aws ec2 start-instances --instance-ids i-1234567890abcdef0
            ```

            Enable EBS encryption by default:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Enable default EBS encryption for the account
            resource "aws_ebs_encryption_by_default" "example" {
              enabled = true
            }

            # Create a KMS key for EBS encryption
            resource "aws_kms_key" "ebs_encryption" {
              description             = "KMS key for EBS encryption"
              deletion_window_in_days = 10
              enable_key_rotation     = true
            }

            # Set the default KMS key for EBS encryption
            resource "aws_ebs_default_kms_key" "example" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }

            # Create an encrypted volume
            resource "aws_ebs_volume" "encrypted_volume" {
              availability_zone = "us-west-2a"
              size              = 50
              encrypted         = true
              kms_key_id        = aws_kms_key.ebs_encryption.arn

              tags = {
                Name = "encrypted-volume"
              }
            }

            # EC2 instance with encrypted root and additional volumes
            resource "aws_instance" "example" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              root_block_device {
                volume_size = 20
                volume_type = "gp3"
                encrypted   = true
                kms_key_id  = aws_kms_key.ebs_encryption.arn
              }

              ebs_block_device {
                device_name = "/dev/sdf"
                volume_size = 50
                volume_type = "gp3"
                encrypted   = true
                kms_key_id  = aws_kms_key.ebs_encryption.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure EBS volumes are deleted on termination:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  BlockDeviceMappings:
                    - DeviceName: "/dev/sda1"
                      Ebs:
                        VolumeSize: 20
                        Encrypted: true
                        KmsKeyId: !Ref "AWS::NoValue"  # Uses AWS-managed key by default
                    - DeviceName: "/dev/sdf"
                      Ebs:
                        VolumeSize: 50
                        Encrypted: true
                        KmsKeyId: !Ref "AWS::NoValue"  # Uses AWS-managed key by default
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security.html
        title: Amazon EC2 Security
      - url: https://docs.aws.amazon.com/ebs/latest/userguide/ebs-encryption.html
        title: Amazon EBS Encryption
  - uid: mondoo-aws-security-ec2-encrypted-volumes-single
    filters: |
      asset.platform == "aws-ebs-volume" &&
      aws.ec2.volume.state != /deleting|deleted|error/
    mql: aws.ec2.volume.encrypted == true
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_volume")
    mql: |
      terraform.resources.where(nameLabel == "aws_ebs_volume").all(
        arguments.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_volume")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_volume").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_volume")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_volume").all(
        values.encrypted == true
      )
  - uid: mondoo-aws-security-efs-encrypted-check
    title: Ensure EFS is configured to encrypt file data using KMS
    impact: 75
    variants:
      - uid: mondoo-aws-security-efs-encrypted-check-single
        tags:
          mondoo.com/filter-title: "AWS EFS File System"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-hcl
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-plan
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic File System (EFS) is configured to encrypt file data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that files are stored securely. AWS KMS provides centralized key management and integrates with EFS to automatically encrypt and decrypt data transparently.

        **Why this matters**

        By default, EFS does not enable encryption unless explicitly configured. Without encryption, data stored in EFS volumes remains in plaintext, making it vulnerable to unauthorized access if an attacker gains access to the storage system.
        AWS KMS encryption ensures that file data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EFS Console.
            2.  Select File Systems from the left panel.
            3.  Identify file systems that do not have encryption enabled.
            4.  If an EFS file system is not encrypted, encryption cannot be enabled on an existing file system. You must:
              - Create a new EFS file system with encryption enabled.
              - Migrate data from the old unencrypted file system to the new encrypted one.
            5.  While creating a new file system:
              - Under General settings, check Enable encryption.
              - Select AWS KMS as the encryption provider.
              - Choose a customer-managed KMS key (CMK) if required.
            6.  Once data migration is complete, delete the old unencrypted file system.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an EFS file system is encrypted:

            ```bash
            aws efs describe-file-systems --query "FileSystems[*].{FileSystemId:FileSystemId, Encrypted:Encrypted}"
            ```

            Create an encrypted EFS file system using a KMS key:

            ```bash
            aws efs create-file-system --creation-token "secure-efs" --encrypted --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure EFS encryption is enabled with an AWS KMS key:

            ```hcl
            resource "aws_kms_key" "efs_encryption_key" {
              description             = "KMS key for EFS encryption"
              enable_key_rotation     = true
            }

            resource "aws_efs_file_system" "secure_efs" {
              encrypted  = true
              kms_key_id = aws_kms_key.efs_encryption_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure EFS file systems are encrypted using AWS KMS:

            ```yaml
            Resources:
              SecureEFS:
                Type: "AWS::EFS::FileSystem"
                Properties:
                  Encrypted: true
                  KmsKeyId: !Ref EFSKMSKey

              EFSKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for EFS encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html
        title: AWS Documentation - Security in Amazon EFS
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system
        title: Terraform Registry - aws_efs_file_system resource
      - url: https://docs.aws.amazon.com/efs/latest/ug/creating-using-create-fs.html#creating-using-fs-part1-cli
        title: AWS Documentation - Creating a file system using the AWS CLI
  - uid: mondoo-aws-security-efs-encrypted-check-single
    filters: asset.platform == "aws-efs-filesystem"
    mql: |
      aws.efs.filesystem.encrypted == true
      aws.efs.filesystem.kmsKey != empty
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_efs_file_system")
    mql: |
      terraform.resources.where(nameLabel == "aws_efs_file_system").all(
        arguments.encrypted == true
          && arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_efs_file_system")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_efs_file_system").all(
        change.after.encrypted == true
      )
      terraform.plan.resourceChanges.where(type == "aws_efs_file_system").all(
        change.after.kms_key_id != empty || change.afterUnknown.kms_key_id == true
      )
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_efs_file_system")
    mql: |
      terraform.state.resources.where(type == "aws_efs_file_system").all(
        values.encrypted == true &&
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
    title: Ensure CloudWatch Logs are encrypted at rest using KMS CMKs
    impact: 70
    variants:
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS CloudWatch Log Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-hcl
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-plan
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudWatch log groups are configured to encrypt log data at rest using AWS Key Management Service (KMS) Customer-Managed Keys (CMKs). CloudWatch Logs store critical operational and security data, and encrypting them using CMKs enhances security by providing better control over key management and access policies.

        **Why this matters**

        CloudWatch Logs often store critical system logs, security logs, and application logs, which may contain sensitive data. Without KMS CMK encryption:

        - Logs are encrypted using default AWS-managed keys, which lack fine-grained access control.
        - Compliance requirements under CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001 may not be met.
        - Security risks increase, as logs could be exposed to unauthorized access.

        Using customer-managed KMS CMKs allows organizations to control key permissions, enable key rotation, and track encryption events via AWS CloudTrail.

        **Risk mitigation:**

        - **Data Security:** Ensures sensitive log data is encrypted at rest.
        - **Regulatory Compliance:** Helps meet security and compliance standards (e.g., GDPR, HIPAA, PCI DSS, SOC 2).
        - **Access Control:** Provides better control over encryption keys, including key rotation and access permissions.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS CloudWatch Console.
            2.  Select Log Groups from the left panel.
            3.  Select a log group and go to the Log Group Settings.
            4.  Under Data Protection, check if KMS encryption is enabled.
            5.  If KMS is not configured:
              - Select Edit and enable Use a KMS key to encrypt log data.
              - Choose a Customer-Managed KMS Key (CMK) instead of the AWS-managed key.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a CloudWatch log group is encrypted with a KMS CMK:

            ```bash
            aws logs describe-log-groups --query "logGroups[*].{LogGroupName:logGroupName, KmsKeyId:kmsKeyId}"
            ```

            If a log group does not have a KMS key, assign one:

            ```bash
            aws logs associate-kms-key --log-group-name <log-group-name> --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure CloudWatch Logs use KMS encryption:

            ```hcl
            resource "aws_kms_key" "cloudwatch_kms_key" {
              description         = "KMS key for CloudWatch Log encryption"
              enable_key_rotation = true
            }

            resource "aws_cloudwatch_log_group" "secure_log_group" {
              name       = "secure-log-group"
              kms_key_id = aws_kms_key.cloudwatch_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure CloudWatch Logs are encrypted using AWS KMS:

            ```yaml
            Resources:
              SecureCloudWatchLogs:
                Type: "AWS::Logs::LogGroup"
                Properties:
                  LogGroupName: "secure-log-group"
                  KmsKeyId: !Ref CloudWatchKMSKey

              CloudWatchKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for CloudWatch Log encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/security.html
        title: Amazon CloudWatch Security
      - url: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/encrypt-log-data-kms.html
        title: Encrypt Log Data in CloudWatch Logs Using AWS KMS
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-api
    filters: asset.platform == "aws-cloudwatch-loggroup"
    mql: |
      aws.cloudwatch.loggroup.kmsKey != empty
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudwatch_log_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudwatch_log_group").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudwatch_log_group").all(
        change.after.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.state.resources.where(type == "aws_cloudwatch_log_group").all(
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled
    title: Ensure Application Load Balancers are configured with a secure TLS security policy
    impact: 70
    props:
      - uid: allowedTlsPoliciesAlb
        title: Defines a list of allowed TLS policies that can be used with ALBs
        mql: |
          return [
            "ELBSecurityPolicy-TLS13-1-2-2021-06",
            "ELBSecurityPolicy-TLS13-1-3-2021-06",
            "ELBSecurityPolicy-TLS13-1-2-Res-2021-06",
            "ELBSecurityPolicy-FS-1-2-Res-2020-10"
          ]
    variants:
      - uid: mondoo-aws-security-elb-security-policy-enabled-single
        tags:
          mondoo.com/filter-title: "AWS Application Load Balancer"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with secure Transport Layer Security (TLS) policies that enforce strong encryption protocols and cipher suites. TLS security policies define which protocols and ciphers are supported when establishing secure connections between clients and the load balancer, protecting data in transit from interception and tampering.

        **Why this matters**

        Without secure TLS policies on Application Load Balancers:

        - Outdated or vulnerable cryptographic protocols (such as TLS 1.0, TLS 1.1, or SSL 3.0) may be used, exposing communications to known security vulnerabilities.
        - Weak cipher suites might be enabled, reducing the strength of encryption and potentially allowing attackers to decrypt intercepted traffic.
        - Compliance requirements for data protection in transit, including PCI DSS, HIPAA, GDPR, and SOC 2, may not be satisfied.

        Modern TLS security policies (such as ELBSecurityPolicy-TLS-1-2-2017-01 or newer) ensure that only strong encryption methods are used, protecting sensitive information transmitted between clients and your applications.

        **Risk mitigation:**

        - **Data Protection:** Ensures sensitive data is properly encrypted in transit using strong protocols and ciphers.
        - **Security Posture:** Prevents exploitation of known vulnerabilities in outdated TLS versions and weak cipher suites.
        - **Regulatory Compliance:** Helps meet requirements for secure data transmission in various compliance frameworks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer you want to update.
            4. Select the Listeners tab.
            5. For the HTTPS listener, select Edit.
            6. Under Security policy, select a more secure policy:
               - ELBSecurityPolicy-TLS13-1-2-2021-06 (recommended)
               - ELBSecurityPolicy-TLS13-1-3-2021-06 (if you need TLS 1.3 only)
               - ELBSecurityPolicy-FS-1-2-Res-2020-10 (for FIPS compliance)
            7. Select Save changes to apply the updated security policy.
        - id: cli
          desc: |
            **Using AWS CLI**

            Identify listeners for your load balancer:

            ```bash
            aws elbv2 describe-listeners --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef
            ```

            Update the security policy for an HTTPS listener:

            ```bash
            aws elbv2 modify-listener \
              --listener-arn arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06
            ```

            Verify the updated security policy:

            ```bash
            aws elbv2 describe-listeners \
              --listener-arns arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --query "Listeners[0].SslPolicy"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]
            }

            resource "aws_lb_listener" "https" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "443"
              protocol          = "HTTPS"
              ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06" # Secure TLS policy
              certificate_arn   = aws_acm_certificate.cert.arn

              default_action {
                type             = "forward"
                target_group_arn = aws_lb_target_group.app.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB

              SecureHttpsListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 443
                  Protocol: "HTTPS"
                  SslPolicy: "ELBSecurityPolicy-TLS13-1-2-2021-06"
                  Certificates:
                    - CertificateArn: !Ref SSLCertificate
                  DefaultActions:
                    - Type: "forward"
                      TargetGroupArn: !Ref DefaultTargetGroup

              DefaultTargetGroup:
                Type: "AWS::ElasticLoadBalancingV2::TargetGroup"
                Properties:
                  VpcId: !Ref VPC
                  Port: 80
                  Protocol: "HTTP"
            ```
    refs:
      - url: https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/security.html
        title: Elastic Load Balancing Security
  - uid: mondoo-aws-security-elb-security-policy-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.listenerDescriptions.all(
        SslPolicy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb_listener")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb_listener").all(
        arguments.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb_listener")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb_listener").all(
        change.after.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb_listener")
    mql: |
      terraform.state.resources.where(type == "aws_lb_listener").all(
        values.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-ssl-listener
    title: Ensure Application Load Balancers are configured with HTTPS listeners
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-ssl-listener-single
        tags:
          mondoo.com/filter-title: "AWS Application Load Balancer"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-hcl
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-plan
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with HTTPS listeners to encrypt traffic between clients and the load balancer. HTTPS listeners use TLS/SSL certificates to establish secure encrypted connections, protecting sensitive data transmitted over the network from eavesdropping and man-in-the-middle attacks.

        **Why this matters**

        Without HTTPS listeners on Application Load Balancers:

        - Data transmitted between clients and applications remains unencrypted and vulnerable to interception by malicious actors.
        - Authentication credentials, session tokens, personal information, and other sensitive data could be exposed in plaintext.
        - Organizations may fail to meet compliance requirements such as PCI DSS, HIPAA, GDPR, and SOC 2, which mandate encryption for data in transit.

        Using HTTP-only listeners poses significant security risks, especially when transmitting sensitive information. Modern security best practices require encryption for all web traffic, regardless of the sensitivity level.

        **Risk mitigation:**

        - **Data Confidentiality:** Encrypts communications to prevent unauthorized access to sensitive information.
        - **Authentication Protection:** Secures user credentials and session information from being intercepted.
        - **Trust and Compliance:** Builds user trust and satisfies regulatory requirements for protecting data in transit.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer that needs HTTPS configuration.
            4. Select the Listeners tab.
            5. If there isn't an HTTPS listener (port 443):
               - Select Add listener.
               - Set Protocol:Port to HTTPS:443.
               - Under Security policy, select a secure policy like ELBSecurityPolicy-TLS13-1-2-2021-06.
               - Under Default SSL certificate, choose one of:
                 * Choose from ACM (recommended)
                 * Choose from IAM
                 * Import a certificate
               - Configure the default action (typically forwarding to a target group).
            6. Select Add to create the HTTPS listener.

            7. For existing HTTP listeners, consider implementing a redirect to HTTPS:
               - Select the HTTP listener and choose Edit.
               - Change the default action to Redirect.
               - Set Protocol to HTTPS, Port to 443, and Status code to 301 (Permanently moved).
            8. Select Save changes to apply the updated configuration.
        - id: cli
          desc: |
            **Using AWS CLI**

            Create an HTTPS listener:

            ```bash
            aws elbv2 create-listener \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --protocol HTTPS \
              --port 443 \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06 \
              --certificates CertificateArn=arn:aws:acm:region:account-id:certificate/certificate-id \
              --default-actions Type=forward,TargetGroupArn=arn:aws:elasticloadbalancing:region:account-id:targetgroup/my-target-group/1234567890abcdef
            ```

            Update an existing HTTP listener to redirect to HTTPS:

            ```bash
            aws elbv2 modify-listener \
              --listener-arn arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --port 80 \
              --protocol HTTP \
              --default-actions Type=redirect,RedirectConfig="{Protocol=HTTPS,Port=443,StatusCode=HTTP_301}"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]
            }

            # HTTPS listener
            resource "aws_lb_listener" "https" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "443"
              protocol          = "HTTPS"
              ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06"
              certificate_arn   = aws_acm_certificate.cert.arn

              default_action {
                type             = "forward"
                target_group_arn = aws_lb_target_group.app.arn
              }
            }

            # HTTP listener redirecting to HTTPS
            resource "aws_lb_listener" "http" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "80"
              protocol          = "HTTP"

              default_action {
                type = "redirect"

                redirect {
                  port        = "443"
                  protocol    = "HTTPS"
                  status_code = "HTTP_301"
                }
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB

              # HTTPS Listener
              HttpsListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 443
                  Protocol: "HTTPS"
                  SslPolicy: "ELBSecurityPolicy-TLS13-1-2-2021-06"
                  Certificates:
                    - CertificateArn: !Ref SSLCertificate
                  DefaultActions:
                    - Type: "forward"
                      TargetGroupArn: !Ref DefaultTargetGroup

              # HTTP Listener with redirect to HTTPS
              HttpListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 80
                  Protocol: "HTTP"
                  DefaultActions:
                    - Type: "redirect"
                      RedirectConfig:
                        Protocol: "HTTPS"
                        Port: "443"
                        StatusCode: "HTTP_301"
            ```
    refs:
      - url: https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/security.html
        title: Elastic Load Balancing Security
  - uid: mondoo-aws-security-elb-ssl-listener-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.listenerDescriptions.all(Protocol == "HTTPS" || Protocol == "HTTP" && DefaultActions.any(Type == "redirect" && RedirectConfig["Protocol"] == "HTTPS"))
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb_listener")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb_listener").all(
        arguments.protocol == "HTTPS"
      )
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb_listener")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb_listener").all(
        change.after.protocol == "HTTPS"
      )
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb_listener")
    mql: |
      terraform.state.resources.where(type == "aws_lb_listener").all(
        values.protocol == "HTTPS"
      )
  - uid: mondoo-aws-security-elb-logging-enabled
    title: Ensure Application Load Balancers have logging enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-logging-enabled-single
        tags:
          mondoo.com/filter-title: "AWS Application Load Balancer"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with access logging enabled to capture detailed information about requests sent to the load balancer. Access logs provide comprehensive data including client IP addresses, request paths, latencies, response codes, and more, which are delivered to an Amazon S3 bucket for storage and analysis.

        **Why this matters**

        Without access logging enabled on Application Load Balancers:

        - Security teams lack visibility into traffic patterns and potential security incidents targeting web applications.
        - Troubleshooting application issues becomes more difficult without historical request data.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for maintaining audit trails of system access may not be satisfied.

        Access logs are critical for security monitoring, compliance auditing, operational troubleshooting, and traffic analysis. These logs help identify suspicious patterns that may indicate security threats or application issues.

        **Risk mitigation:**

        - **Security Monitoring:** Provides visibility into potential attacks, such as SQL injection attempts or cross-site scripting.
        - **Compliance Documentation:** Helps meet regulatory requirements for maintaining audit trails of system access.
        - **Operational Intelligence:** Allows analysis of traffic patterns, error rates, and client behaviors to improve application performance.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer you want to enable logging for.
            4. Select the Attributes tab.
            5. Select Edit.
            6. Under Access logs, check Enable.
            7. Specify an existing S3 bucket or create a new one.
            8. Optionally, specify a prefix to organize the logs within the bucket.
            9. Select Save changes to enable access logging.

            Note: Ensure the S3 bucket has the appropriate permissions to allow the ELB to write logs.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable access logs for a load balancer:

            ```bash
            aws elbv2 modify-load-balancer-attributes \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --attributes Key=access_logs.s3.enabled,Value=true Key=access_logs.s3.bucket,Value=my-log-bucket Key=access_logs.s3.prefix,Value=my-app-logs
            ```

            Verify that logging is enabled:

            ```bash
            aws elbv2 describe-load-balancer-attributes \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --query "Attributes[?Key=='access_logs.s3.enabled' || Key=='access_logs.s3.bucket']"
            ```

            Create an S3 bucket policy to allow ELB to write logs:

            ```bash
            aws s3api put-bucket-policy \
              --bucket my-log-bucket \
              --policy '{
                "Version": "2012-10-17",
                "Statement": [
                  {
                    "Effect": "Allow",
                    "Principal": {
                      "AWS": "arn:aws:iam::elb-account-id:root"
                    },
                    "Action": "s3:PutObject",
                    "Resource": "arn:aws:s3:::my-log-bucket/my-app-logs/AWSLogs/account-id/*"
                  }
                ]
              }'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # S3 bucket for ALB access logs
            resource "aws_s3_bucket" "alb_logs" {
              bucket = "my-alb-logs-bucket"
              force_destroy = true
            }

            # S3 bucket policy to allow ALB to write logs
            resource "aws_s3_bucket_policy" "alb_logs_policy" {
              bucket = aws_s3_bucket.alb_logs.id

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect = "Allow"
                    Principal = {
                      AWS = "arn:aws:iam::${data.aws_elb_service_account.main.id}:root"
                    }
                    Action = "s3:PutObject"
                    Resource = "${aws_s3_bucket.alb_logs.arn}/alb-logs/AWSLogs/${data.aws_caller_identity.current.account_id}/*"
                  }
                ]
              })
            }

            # Get AWS ELB service account ID
            data "aws_elb_service_account" "main" {}

            # Get current AWS account ID
            data "aws_caller_identity" "current" {}

            # Create ALB with logging enabled
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]

              access_logs {
                bucket  = aws_s3_bucket.alb_logs.id
                prefix  = "alb-logs"
                enabled = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              LogBucket:
                Type: "AWS::S3::Bucket"
                Properties:
                  BucketName: "my-alb-logs-bucket"

              LogBucketPolicy:
                Type: "AWS::S3::BucketPolicy"
                Properties:
                  Bucket: !Ref LogBucket
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "s3:PutObject"
                        Resource: !Sub "${LogBucket.Arn}/alb-logs/AWSLogs/${AWS::AccountId}/*"

              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB
                  LoadBalancerAttributes:
                    - Key: "access_logs.s3.enabled"
                      Value: "true"
                    - Key: "access_logs.s3.bucket"
                      Value: !Ref LogBucket
                    - Key: "access_logs.s3.prefix"
                      Value: "alb-logs"
            ```
    refs:
      - url: https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/security.html
        title: Elastic Load Balancing Security
  - uid: mondoo-aws-security-elb-logging-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.attributes.any(Key == "access_logs.s3.enabled")
      aws.elb.loadbalancer.attributes.where(Key == "access_logs.s3.enabled").all(Value == true)
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb").all(
        blocks.where(type == "access_logs") != empty &&
        blocks.where(type == "access_logs").all(arguments.enabled == true)
      )
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb").all(
        change.after.access_logs != empty &&
        change.after.access_logs.all(enabled == true)
      )
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb")
    mql: |
      terraform.state.resources.where(type == "aws_lb").all(
        values.access_logs != empty &&
        values.access_logs.all(enabled == true)
      )
  - uid: mondoo-aws-security-elb-deletion-protection-enabled
    title: Ensure Application Load Balancers are configured with deletion protection enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-single
        tags:
          mondoo.com/filter-title: "AWS Application Load Balancer"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) have deletion protection enabled to prevent accidental or unauthorized deletion. Deleting a load balancer without proper authorization or by mistake can result in application downtime, traffic disruption, and loss of critical configurations.

        **Why this matters**

        By default, deletion protection is disabled for Application Load Balancers, making them susceptible to accidental removal. If an ALB is deleted:

        - All traffic routing is disrupted, causing application downtime.
        - Reconfiguration is required, leading to potential misconfigurations or longer recovery times.
        - Security policies and access control settings are lost, which may expose applications to threats.

        Enabling deletion protection ensures that ALBs cannot be deleted without explicitly disabling this setting first, providing an additional layer of protection against human errors and misconfigurations.

        **Risk mitigation:**

        - Prevents accidental deletions that could cause service outages.
        - Ensures operational stability by enforcing change control processes.
        - Reduces misconfigurations and security risks associated with unintended deletions.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select an Application Load Balancer (ALB).
            4. Select the Description tab.
            5. Under Deletion Protection, check if it is enabled.
            6. If it is disabled, modify the setting:
              - Select Edit attributes.
              - Enable Deletion protection.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an ALB has deletion protection enabled:

            ```bash
            aws elbv2 describe-load-balancers --query "LoadBalancers[*].{Name:LoadBalancerName, DeletionProtectionEnabled:Attributes[?Key=='deletion_protection.enabled'].Value | [0]}"
            ```

            Enable deletion protection for a specific ALB:

            ```bash
            aws elbv2 modify-load-balancer-attributes \
            --load-balancer-arn <load-balancer-arn> \
            --attributes Key=deletion_protection.enabled,Value=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure ALBs have deletion protection enabled:

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-application-lb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.alb_sg.id]
              subnets            = [aws_subnet.public1.id, aws_subnet.public2.id]

              enable_deletion_protection = true  # Ensures deletion protection is enabled
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable deletion protection for ALBs:

            ```yaml
            Resources:
              SecureApplicationLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-application-lb"
                  Type: "application"
                  Scheme: "internet-facing"
                  Subnets:
                    - !Ref PublicSubnet1
                    - !Ref PublicSubnet2
                  SecurityGroups:
                    - !Ref ALBSecurityGroup
                  LoadBalancerAttributes:
                    - Key: "deletion_protection.enabled"
                      Value: "true"
            ```
    refs:
      - url: https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/security.html
        title: Elastic Load Balancing Security
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.attributes.any(Key == "deletion_protection.enabled")
      aws.elb.loadbalancer.attributes.where(Key == "deletion_protection.enabled").all(Value == true)
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb").all(
        arguments.enable_deletion_protection == true
      )
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb").all(
        change.after.enable_deletion_protection == true
      )
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb")
    mql: |
      terraform.state.resources.where(type == "aws_lb").all(
        values.enable_deletion_protection == true
      )
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
    title: Ensure Amazon OpenSearch Service domains are configured with encryption-at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-api
        tags:
          mondoo.com/filter-title: "AWS Amazon OpenSearch Service"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-hcl
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-plan
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption at rest protects sensitive search and analytics data from unauthorized access, ensuring that stored data is automatically encrypted before being written to disk.

        **Why this matters**

        By default, OpenSearch Service does not encrypt data at rest unless explicitly enabled. Without encryption:

        - Sensitive data remains in plaintext, making it vulnerable to unauthorized access.
        - Security and compliance risks increase under regulations such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.
        - Data exposure risks exist if an OpenSearch domain is compromised.

        To mitigate these risks, OpenSearch domains should be encrypted using AWS KMS, which provides centralized key management, access control, and audit logging.

        **Risk mitigation:**

        - Prevents unauthorized access by ensuring all stored data is encrypted.
        - Enhances compliance with industry security frameworks requiring encryption at rest.
        - Improves security posture by integrating AWS KMS for key management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS OpenSearch Service Console.
            2.  Select Domains in the left panel.
            3.  Select an OpenSearch domain and go to the Security tab.
            4.  Under Encryption at rest, check if encryption is enabled.
            5.  If encryption is not enabled, create a new OpenSearch domain with encryption:
              - Select Create domain.
              - Under Encryption at rest, enable encrypt data at rest.
              - Choose a customer-managed KMS key (CMK) if required.
              - Complete the domain creation process.
            6.  Migrate data from the unencrypted domain to the new encrypted domain, then delete the unencrypted domain.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if an OpenSearch domain is encrypted:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> --query "DomainStatus.EncryptionAtRestOptions"
            ```

            If encryption is not enabled, create a new encrypted OpenSearch domain:

            ```bash
            aws opensearch create-domain \
            --domain-name "secure-opensearch-domain" \
            --encryption-at-rest-options Enabled=true,KmsKeyId="arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure OpenSearch Service encryption is enabled using AWS KMS:

            ```hcl
            resource "aws_kms_key" "opensearch_kms_key" {
              description         = "KMS key for OpenSearch encryption"
              enable_key_rotation = true
            }

            resource "aws_opensearch_domain" "secure_opensearch" {
              domain_name = "secure-opensearch-domain"

              encrypt_at_rest {
                enabled    = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable encryption at rest for OpenSearch domains:

            ```yaml
            Resources:
              SecureOpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "secure-opensearch-domain"
                  EncryptionAtRestOptions:
                    Enabled: true
                    KmsKeyId: !Ref OpenSearchKMSKey

              OpenSearchKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for OpenSearch encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/encryption-at-rest.html
        title: Encryption of Data at Rest for Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/welcome.html
        title: AWS Well-Architected Security Pillar
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-api
    filters: asset.platform == "aws"
    mql: aws.es.domains.all(encryptionAtRestEnabled == true)
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "encrypt_at_rest") != empty &&
        blocks.where(type == "encrypt_at_rest").all(arguments.enabled == true)
      )
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.encrypt_at_rest != empty &&
        change.after.encrypt_at_rest.all(enabled == true)
      )
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.encrypt_at_rest != empty &&
        values.encrypt_at_rest.all(enabled == true)
      )
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
    title: Ensure rotation for customer-managed keys (CMKs) is enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-single
        tags:
          mondoo.com/filter-title: "AWS KMS Key"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-hcl
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-plan
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Key Management Service (KMS) customer-managed keys (CMKs) have automatic key rotation enabled. Enabling key rotation ensures that cryptographic keys are periodically refreshed, reducing the risk of long-term key compromise and enhancing overall security.

        **Why this matters**

        By default, AWS does not enable automatic rotation for CMKs, leaving encryption keys unchanged unless manually rotated. Without key rotation:

        - Keys remain in use indefinitely, increasing the impact of potential key compromise.
        - Compliance issues may arise under security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.
        - Security best practices require periodic key changes to limit exposure.

        AWS allows automatic key rotation for symmetric CMKs every 365 days, ensuring that keys remain secure over time.

        **Risk mitigation:**

        - Reduces key compromise risk by ensuring keys are periodically refreshed.
        - Ensures compliance with security frameworks that mandate key rotation.
        - Improves cryptographic security by limiting key lifespan.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS KMS Console.
            2.  Select Customer managed keys in the left panel.
            3.  Select a CMK to review its settings.
            4.  Under Key rotation, check if Automatic rotation is enabled.
            5.  If rotation is disabled, select Edit key settings:
              - Enable Automatic key rotation.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if key rotation is enabled for all customer-managed CMKs:

            ```bash
            aws kms list-keys --query "Keys[*].KeyId" | while read -r key_id; do
                aws kms get-key-rotation-status --key-id "$key_id" --query "KeyRotationEnabled"
            done
            ```

            If rotation is not enabled, activate it:

            ```bash
            aws kms enable-key-rotation --key-id <key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure KMS key rotation is enabled:

            ```hcl
            resource "aws_kms_key" "secure_kms_key" {
              description         = "Customer-managed KMS key with automatic rotation"
              enable_key_rotation = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable KMS key rotation for CMKs:

            ```yaml
            Resources:
              SecureKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "Customer-managed KMS key with automatic rotation"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/kms/latest/developerguide/best-practices.html
        title: AWS KMS Best Practices
      - url: https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html
        title: Rotating AWS KMS Keys
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-single
    filters: asset.platform == "aws-kms-key" && aws.kms.key.metadata.KeyState == "Enabled" && aws.kms.key.metadata.KeySpec == "SYMMETRIC_DEFAULT" && aws.kms.key.metadata.KeyManager == "CUSTOMER"
    mql: |
      aws.kms.key.keyRotationEnabled == true
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_kms_key")
    mql: |
      terraform.resources.where(nameLabel == "aws_kms_key").all(
        arguments.enable_key_rotation == true
      )
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_kms_key")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_kms_key").all(
        change.after.enable_key_rotation == true
      )
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_kms_key")
    mql: |
      terraform.state.resources.where(type == "aws_kms_key").all(
        values.enable_key_rotation == true
      )
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
    title: Ensure SageMaker notebook instances are configured to use KMS
    impact: 50
    variants:
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-single
        tags:
          mondoo.com/filter-title: "AWS SageMaker Notebook Instance"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-hcl
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-plan
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SageMaker notebook instances are configured to encrypt data at rest using AWS Key Management Service (KMS). Enabling KMS encryption enhances security by protecting sensitive machine learning (ML) data stored in SageMaker notebook instances from unauthorized access.

        **Why this matters**

        By default, SageMaker notebook instances may store training datasets, model artifacts, and proprietary code in Amazon EBS volumes. Without KMS encryption:

        - Data is stored in plaintext, making it vulnerable to unauthorized access.
        - Security and compliance risks increase, especially for organizations under PCI DSS, HIPAA, ISO 27001, and CIS AWS Foundations Benchmark.
        - No centralized control over encryption keys, preventing fine-grained access control and auditing.

        To mitigate these risks, SageMaker notebook instances should be encrypted using AWS KMS, allowing secure key management, key rotation, and logging of key usage.

        **Risk mitigation:**

        - Prevents unauthorized access to sensitive machine learning data.
        - Ensures compliance with security frameworks that mandate encryption.
        - Improves security posture by leveraging AWS KMS for centralized key management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS SageMaker Console.
            2.  Select Notebook instances in the left panel.
            3.  Select a notebook instance and go to the Storage volume settings.
            4.  Check if the Encryption key is set to an AWS KMS key.
            5.  If no KMS key is assigned, update the instance by creating a new SageMaker notebook instance with encryption enabled:
              - Select Create Notebook Instance.
              - Under Encryption key, select a customer-managed KMS key (CMK).
              - Launch the new instance and migrate existing data.
            6.  Delete the unencrypted notebook instance once migration is complete.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if SageMaker notebook instances are encrypted with KMS:

            ```bash
            aws sagemaker list-notebook-instances --query "NotebookInstances[*].{Name:NotebookInstanceName, KmsKeyId:KmsKeyId}"
            ```

            If an instance does not have a KMS key, create a new encrypted notebook instance:

            ```bash
            aws sagemaker create-notebook-instance \
            --notebook-instance-name "secure-sagemaker-instance" \
            --instance-type "ml.t3.medium" \
            --role-arn "arn:aws:iam::<account-id>:role/SageMakerRole" \
            --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure SageMaker notebook instances are encrypted using a KMS key:

            ```hcl
            resource "aws_kms_key" "sagemaker_kms_key" {
              description         = "KMS key for SageMaker notebook encryption"
              enable_key_rotation = true
            }

            resource "aws_sagemaker_notebook_instance" "secure_notebook" {
              name               = "secure-sagemaker-instance"
              instance_type      = "ml.t3.medium"
              role_arn          = aws_iam_role.sagemaker_role.arn
              kms_key_id        = aws_kms_key.sagemaker_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureSageMakerNotebook:
                Type: "AWS::SageMaker::NotebookInstance"
                Properties:
                  NotebookInstanceName: "secure-sagemaker-instance"
                  InstanceType: "ml.t3.medium"
                  RoleArn: !GetAtt SageMakerRole.Arn
                  KmsKeyId: !Ref SageMakerKMSKey

              SageMakerKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for SageMaker encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/sagemaker/latest/dg/security.html
        title: Amazon SageMaker Security
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-single
    filters: asset.platform == "aws-sagemaker-notebookinstance"
    mql: |
      aws.sagemaker.notebookinstance.details.kmsKey != empty
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_sagemaker_notebook_instance").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sagemaker_notebook_instance").all(
        change.after.kms_key_id != empty ||
        change.afterUnknown.kms_key_id == true
      )
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.state.resources.where(type == "aws_sagemaker_notebook_instance").all(
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled
    title: Ensure CloudTrail log file validation is enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-single
        tags:
          mondoo.com/filter-title: "AWS CloudTrail Trail"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-plan
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS CloudTrail has log file validation enabled to verify the integrity of logged events. Log file validation generates a digitally signed digest file containing a hash of each log that CloudTrail delivers, allowing you to determine whether a log file was modified, deleted, or unchanged after CloudTrail delivered it.

        **Why this matters**

        Without log file validation enabled in CloudTrail:

        - Unauthorized modifications to log files may go undetected, compromising the reliability of audit trails.
        - Attackers could potentially alter or delete log records to cover their tracks after gaining unauthorized access.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for maintaining tamper-proof audit logs may not be satisfied.

        Log file validation is crucial for maintaining the chain of custody for security events and ensuring the authenticity of CloudTrail logs during security investigations, compliance audits, and forensic analysis of security incidents.

        **Risk mitigation:**

        - **Log Integrity:** Provides cryptographic assurance that logs have not been modified since they were delivered by CloudTrail.
        - **Forensic Readiness:** Ensures reliable evidence for security incident investigations and dispute resolution.
        - **Compliance Validation:** Helps meet regulatory requirements for tamper-evident logging mechanisms.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS CloudTrail Console.
            2. Select Trails in the left panel.
            3. Select the CloudTrail trail you want to update.
            4. Select Edit.
            5. Scroll down to the Additional settings section.
            6. Check the Enable log file validation checkbox.
            7. Select Save changes to update the trail.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if log file validation is enabled for a specific trail:

            ```bash
            aws cloudtrail describe-trails \
              --trail-name-list my-trail \
              --query "trailList[*].{Name:Name,LogFileValidation:LogFileValidationEnabled}"
            ```

            Enable log file validation for a trail:

            ```bash
            aws cloudtrail update-trail \
              --name my-trail \
              --enable-log-file-validation
            ```

            Verify that log file validation is now enabled:

            ```bash
            aws cloudtrail describe-trails \
              --trail-name-list my-trail \
              --query "trailList[*].{Name:Name,LogFileValidation:LogFileValidationEnabled}"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Create a secure CloudTrail trail with log file validation enabled
            resource "aws_cloudtrail" "secure_trail" {
              name                          = "secure-cloudtrail"
              s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
              is_multi_region_trail         = true
              include_global_service_events = true
              enable_logging                = true
              enable_log_file_validation    = true  # Ensure log file validation is enabled
            }

            # S3 bucket for CloudTrail logs
            resource "aws_s3_bucket" "cloudtrail_logs" {
              bucket        = "cloudtrail-logs-bucket"
              force_destroy = true
            }

            # S3 bucket policy for CloudTrail
            resource "aws_s3_bucket_policy" "cloudtrail" {
              bucket = aws_s3_bucket.cloudtrail_logs.id
              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Sid    = "AWSCloudTrailAclCheck"
                    Effect = "Allow"
                    Principal = {
                      Service = "cloudtrail.amazonaws.com"
                    }
                    Action   = "s3:GetBucketAcl"
                    Resource = aws_s3_bucket.cloudtrail_logs.arn
                  },
                  {
                    Sid    = "AWSCloudTrailWrite"
                    Effect = "Allow"
                    Principal = {
                      Service = "cloudtrail.amazonaws.com"
                    }
                    Action   = "s3:PutObject"
                    Resource = "${aws_s3_bucket.cloudtrail_logs.arn}/AWSLogs/*"
                    Condition = {
                      StringEquals = {
                        "s3:x-amz-acl" = "bucket-owner-full-control"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              CloudTrailLogsBucket:
                Type: "AWS::S3::Bucket"
                Properties:
                  BucketName: !Sub "cloudtrail-logs-${AWS::AccountId}"
                  VersioningConfiguration:
                    Status: Enabled

              CloudTrailBucketPolicy:
                Type: "AWS::S3::BucketPolicy"
                Properties:
                  Bucket: !Ref CloudTrailLogsBucket
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Sid: "AWSCloudTrailAclCheck"
                        Effect: "Allow"
                        Principal:
                          Service: "cloudtrail.amazonaws.com"
                        Action: "s3:GetBucketAcl"
                        Resource: !GetAtt CloudTrailLogsBucket.Arn
                      - Sid: "AWSCloudTrailWrite"
                        Effect: "Allow"
                        Principal:
                          Service: "cloudtrail.amazonaws.com"
                        Action: "s3:PutObject"
                        Resource: !Sub "${CloudTrailLogsBucket.Arn}/AWSLogs/${AWS::AccountId}/*"
                        Condition:
                          StringEquals:
                            "s3:x-amz-acl": "bucket-owner-full-control"

              SecureCloudTrail:
                Type: "AWS::CloudTrail::Trail"
                DependsOn:
                  - CloudTrailBucketPolicy
                Properties:
                  TrailName: "secure-cloudtrail"
                  S3BucketName: !Ref CloudTrailLogsBucket
                  IsMultiRegionTrail: true
                  EnableLogFileValidation: true  # Enable log file validation
                  IncludeGlobalServiceEvents: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/best-practices-security.html
        title: AWS CloudTrail Security Best Practices
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-single
    filters: asset.platform == "aws-cloudtrail-trail"
    mql: aws.cloudtrail.trail.logFileValidationEnabled == true
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudtrail")
    mql: terraform.resources.where(nameLabel == "aws_cloudtrail").all(arguments.enable_log_file_validation == true)
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudtrail")
    mql: terraform.plan.resourceChanges.where(type == "aws_cloudtrail").all(change.after.enable_log_file_validation == true)
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudtrail")
    mql: terraform.state.resources.where(type == "aws_cloudtrail").all(values.enable_log_file_validation == true)
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled
    title: Ensure CloudTrail trails are configured to use the server-side encryption KMS
    impact: 70
    variants:
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-single
        tags:
          mondoo.com/filter-title: "AWS CloudTrail Trail"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-plan
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS CloudTrail trails are configured to use AWS Key Management Service (KMS) for server-side encryption (SSE). Using KMS encryption protects log data from unauthorized access and enhances the security of audit logs.

        **Why this matters**

        By default, CloudTrail logs are not encrypted using a customer-managed KMS key (CMK) unless explicitly configured. Without KMS encryption:

        - CloudTrail logs may be accessed or modified if security policies are misconfigured.
        - Sensitive log data is stored in plaintext, increasing security risks.
        - Compliance requirements under CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST may not be met.

        Using KMS CMKs provides fine-grained access control, automatic key rotation, and detailed audit logging via AWS CloudTrail.

        **Risk mitigation:**

        - Prevents unauthorized access to audit logs by enforcing encryption.
        - Enhances security posture by integrating AWS KMS for key management.
        - Ensures compliance with industry security frameworks requiring encryption at rest.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS CloudTrail Console.
            2.  Select Trails in the left panel.
            3.  Select a CloudTrail trail and go to the Storage Location section.
            4.  Under Log file SSE-KMS encryption, check if encryption is enabled.
            5.  If KMS encryption is not enabled, modify the trail:
              - Select Edit.
              - Under Log file encryption, select Use a custom AWS KMS key.
              - Choose an existing Customer-Managed KMS Key (CMK) or create a new one.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a CloudTrail trail is using KMS encryption:

            ```bash
            aws cloudtrail describe-trails --query "trailList[*].{TrailName:Name, KmsKeyId:KmsKeyId}"
            ```

            If KMS encryption is not configured, update the trail:

            ```bash
            aws cloudtrail update-trail --name <trail-name> --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure CloudTrail is encrypted with KMS:

            ```hcl
            resource "aws_kms_key" "cloudtrail_kms_key" {
              description         = "KMS key for CloudTrail encryption"
              enable_key_rotation = true
            }

            resource "aws_cloudtrail" "secure_trail" {
              name                          = "secure-cloudtrail"
              s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
              is_multi_region_trail         = true
              kms_key_id                    = aws_kms_key.cloudtrail_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Enable CloudTrail encryption using KMS:

            ```yaml
            Resources:
              SecureCloudTrail:
                Type: "AWS::CloudTrail::Trail"
                Properties:
                  TrailName: "secure-cloudtrail"
                  S3BucketName: !Ref CloudTrailLogsBucket
                  IsMultiRegionTrail: true
                  KMSKeyId: !Ref CloudTrailKMSKey

              CloudTrailKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for CloudTrail encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/best-practices-security.html
        title: AWS CloudTrail Security Best Practices
      - url: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html
        title: Encrypting CloudTrail Log Files with AWS KMS
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-single
    filters: asset.platform == "aws-cloudtrail-trail"
    mql: |
      aws.cloudtrail.trail.kmsKey != empty
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudtrail")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudtrail").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudtrail")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudtrail").all(
        change.after.kms_key_id != empty ||
        change.afterUnknown.kms_key_id == true
      )
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudtrail")
    mql: |
      terraform.state.resources.where(type == "aws_cloudtrail").all(
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-secgroup-restricted-ssh
    title: Ensure security groups restrict incoming SSH traffic
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-ssh-single
        tags:
          mondoo.com/filter-title: "AWS Security Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups are configured to restrict incoming SSH (port 22) traffic. Allowing unrestricted SSH access (0.0.0.0/0 or ::/0) poses a significant security risk by exposing instances to unauthorized access attempts, brute-force attacks, and potential exploitation by malicious actors.

        **Why this matters**

        By default, AWS allows full control over inbound and outbound traffic through security groups. However, allowing unrestricted SSH access increases the risk of unauthorized logins, credential theft, and automated attacks. Instead, SSH access should be restricted to specific IP addresses, such as known administrative networks, bastion hosts, or VPN subnets.

        **Restricting SSH access helps mitigate:**

        - **Brute-force attacks:** Reduces exposure to automated SSH login attempts.
        - **Unauthorized access:** Limits access to only trusted networks.
        - **Compliance risks:** Aligns with best practices in security frameworks like PCI DSS, NIST, and CIS benchmarks.

        **Risk mitigation:**

        - **Minimize attack surface:** Reduces the number of exposed SSH endpoints.
        - **Ensure least privilege access:** Restricts access to only authorized IP ranges.
        - **Improve network security:** Protects EC2 instances from unauthorized access.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon EC2 Console.
            2.  Select Security Groups from the left navigation panel.
            3.  Identify security groups that have inbound rules allowing port 22 (SSH) from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.  Edit the security group's inbound rules and replace 0.0.0.0/0 with a trusted IP range (e.g., your office network or VPN).
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check security groups with unrestricted SSH access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?FromPort==`22` && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0')]].GroupId"
            ```

            Revoke unrestricted SSH access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 22 --cidr 0.0.0.0/0
            ```

            Add a more restrictive SSH rule (replace x.x.x.x/x with a trusted IP range):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 22 --cidr x.x.x.x/x
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure SSH access is restricted to a specific IP range:

            ```hcl
            resource "aws_security_group" "secure_sg" {
              name        = "secure-sg"
              description = "Restricts SSH access"

              ingress {
                from_port   = 22
                to_port     = 22
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with trusted IP range
              }
              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            This template ensures that SSH access (port 22) is only allowed from a specific IP range (e.g., a corporate VPN or a bastion host):

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted SSH access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 22
                      ToPort: 22
                      CidrIp: "192.168.1.0/24"  # Replace with your trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedSSHSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html
        title: Amazon VPC Security Best Practices
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html
        title: Security Group Rules Reference
  - uid: mondoo-aws-security-secgroup-restricted-ssh-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 22 && toPort >= 22 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == 22 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == 22 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == 22 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-vnc
    title: Ensure security groups restrict incoming VNC traffic
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-vnc-single
        tags:
          mondoo.com/filter-title: "AWS Security Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups do not allow unrestricted incoming Virtual Network Computing (VNC) traffic, which operates on ports 5900-5903. Allowing unrestricted VNC access (0.0.0.0/0 or ::/0) exposes instances to unauthorized access attempts, brute-force attacks, and remote exploitation.

        **Why this matters**

        VNC is a widely used remote desktop protocol that, if exposed to the internet, can be exploited by attackers for unauthorized access, credential theft, or lateral movement within the network. Attackers frequently scan for open VNC ports, and leaving them unrestricted significantly increases the risk of compromise.

        To mitigate risks, VNC access should be restricted to trusted IP addresses, such as an internal corporate network, a VPN, or a bastion host.

        **Risks of unrestricted VNC access:**

        - **Brute-force attacks:** Attackers can repeatedly attempt to guess VNC passwords.
        - **Unencrypted connections:** Many VNC implementations do not encrypt traffic by default.
        - **Unauthorized remote access:** Unrestricted access allows attackers to control the remote system.

        **Risk mitigation:**

        - **Limit exposure:** Restrict VNC access to known IP addresses (e.g., office VPN or bastion host).
        - **Use encrypted alternatives:** Consider replacing VNC with more secure alternatives like SSH tunneling or AWS Session Manager.
        - **Enhance authentication:** Use strong passwords, multi-factor authentication (MFA), and network segmentation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon EC2 Console.
            2.  Select Security Groups from the left navigation panel.
            3.  Identify security groups that have inbound rules allowing traffic on ports 5900-5903 from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.  Edit the security group's inbound rules and remove any rule that allows unrestricted VNC access.
            5.  If necessary, replace 0.0.0.0/0 with a trusted IP range (e.g., your office VPN or bastion host).
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check security groups with unrestricted VNC access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?((FromPort==`5900` || FromPort==`5901` || FromPort==`5902` || FromPort==`5903`) && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0'))]].GroupId"
            ```

            Revoke unrestricted VNC access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 5900-5903 --cidr 0.0.0.0/0
            ```

            Allow VNC access only from a trusted IP range (replace x.x.x.x/x with your specific IP range):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 5900-5903 --cidr x.x.x.x/x
            ```
        - id: terraform
          desc: |
            **Ensure security groups restrict VNC access to a specific IP range:**

            ```hcl
            resource "aws_security_group" "restricted_vnc" {
              name        = "restricted-vnc"
              description = "Restricts VNC access"

              ingress {
                from_port   = 5900
                to_port     = 5903
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with trusted IP range
              }

              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
              }
            }
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure security groups restrict VNC access to a specific IP range:

            ```yaml
            Resources:
              RestrictedVNC:
                Type: AWS::EC2::SecurityGroup
                Properties:
                  GroupName: restricted-vnc
                  GroupDescription: Restricts VNC access
                  SecurityGroupIngress:
                    - IpProtocol: tcp
                      FromPort: 5900
                      ToPort: 5903
                      CidrIp: 203.0.113.0/24  # Replace with trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: -1
                      FromPort: 0
                      ToPort: 0
                      CidrIp: 0.0.0.0/0  # Allow all outbound traffic
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html
        title: Amazon VPC Security Best Practices
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html
        title: Security Group Rules Reference
  - uid: mondoo-aws-security-secgroup-restricted-vnc-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 5900 && toPort >= 5903 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
        )
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_security_group")
    mql: |
      terraform.resources.where(
        nameLabel == "aws_security_group" && blocks.where(type == "ingress").contains(
          arguments.from_port <= 5903 && arguments.to_port >= 5903 && arguments.to_port != 0)
        ).none(
          blocks.where(type == "ingress") {
            arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0")
          }
        )
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_security_group")
    mql: |
      terraform.plan.resourceChanges.where(
        type == "aws_security_group" && change.after.ingress.contains(
          from_port <= 5900 && to_port >= 5903 && to_port != 0
        )
      ).none(
        change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0")
      )
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_security_group")
    mql: |
      terraform.state.resources.where(
        type == "aws_security_group" && values.ingress.contains(
          from_port <= 5900 && to_port >= 5903 && to_port != 0
        )
      ).none(
        values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0")
      )
  - uid: mondoo-aws-security-secgroup-restricted-rdp
    title: Ensure security groups restrict incoming RDP traffic
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-rdp-single
        tags:
          mondoo.com/filter-title: "AWS Security Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups are not configured to allow unrestricted inbound Remote Desktop Protocol (RDP) traffic, which operates on port 3389. Allowing unrestricted RDP access (0.0.0.0/0 or ::/0) significantly increases the risk of brute-force attacks, unauthorized remote access, and exploitation by malicious actors.

        **Why this matters**

        RDP is a widely used protocol for remote administration of Windows-based instances in AWS. However, exposing port 3389 to the internet without restrictions creates a high-security risk. Attackers continuously scan for open RDP ports and attempt brute-force login attacks using credential stuffing or password spraying techniques.

        Instead of allowing open RDP access, organizations should:

        - Restrict RDP access to trusted IP addresses (e.g., corporate networks, VPNs, or bastion hosts).
        - Use AWS Systems Manager Session Manager as a secure alternative to direct RDP access.
        - Enable multi-factor authentication (MFA) and strong authentication mechanisms.

        **Risk mitigation:**

        - **Prevent brute-force attacks:** Limits exposure to automated credential-guessing attacks.
        - **Ensure least privilege access:** Only trusted IPs can establish RDP sessions.
        - **Improve security posture:** Protects Windows servers from unauthorized access and exploits.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon EC2 Console.
            2.  Select Security Groups from the left navigation panel.
            3.  Identify security groups that allow inbound rules on port 3389 (RDP) from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.  Select Edit inbound rules and remove any rule that allows unrestricted RDP access.
            5.  If necessary, replace 0.0.0.0/0 with a trusted IP range (e.g., a VPN or bastion host).
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for security groups with unrestricted RDP access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?FromPort==`3389` && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0')]].GroupId"
            ```

            Revoke unrestricted RDP access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 3389 --cidr 0.0.0.0/0
            ```

            Allow RDP access only from a trusted IP range (replace x.x.x.x/x with your corporate/VPN subnet):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 3389 --cidr x.x.x.x/x
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure security groups restrict RDP access to a specific IP range:

            ```hcl
            resource "aws_security_group" "restricted_rdp" {
              name        = "restricted-rdp"
              description = "Restricts RDP access"

              ingress {
                from_port   = 3389
                to_port     = 3389
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with a trusted IP range
              }

              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure security groups do not allow unrestricted RDP access:

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted RDP access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 3389
                      ToPort: 3389
                      CidrIp: "192.168.1.0/24"  # Restrict to a trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedRDPSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html
        title: Amazon VPC Security Best Practices
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html
        title: Security Group Rules Reference
  - uid: mondoo-aws-security-secgroup-restricted-rdp-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 3389 && toPort >= 3389 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == 3389 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == 3389 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == 3389 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restrict-traffic
    title: Ensure security groups restrict access to specific IPs and ports
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restrict-traffic-single
        tags:
          mondoo.com/filter-title: "AWS Security Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-plan
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups do not allow unrestricted access to all IPs (0.0.0.0/0 or ::/0) on any port. Allowing open access to security groups exposes AWS resources to unauthorized access, increasing the risk of security breaches, brute-force attacks, and data exfiltration.

        **Why this matters**

        AWS security groups act as virtual firewalls that control inbound and outbound traffic. When a security group allows access from all IPs (0.0.0.0/0 for IPv4 or ::/0 for IPv6) on all ports, it poses significant risks:

        - Unrestricted access to sensitive services (e.g., SSH on port 22, RDP on port 3389, or databases like MySQL on port 3306).
        - Increased exposure to brute-force attacks, credential stuffing, and other cyber threats.
        - Compliance violations under security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.

        To mitigate these risks, security groups should be configured with the principle of least privilege, allowing access only to specific IP ranges and necessary ports.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting inbound and outbound traffic.
        - Reduces exposure to external attacks (e.g., brute force, malware injections).
        - Ensures compliance with industry best practices and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the AWS EC2 Console.
            2.  Select Security Groups in the left panel.
            3.  Identify security groups with inbound rules allowing 0.0.0.0/0 or ::/0.
            4.  If a rule allows unrestricted access, modify it:
              - Select Edit inbound rules.
              - Restrict the source IP range to trusted networks (e.g., corporate VPN, private subnets, specific IPs).
              - Select Save changes.
            5.  Repeat for outbound rules, ensuring traffic is limited to necessary destinations.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check security groups for unrestricted inbound rules:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[*].{ID:GroupId, Name:GroupName, Ingress:IpPermissions[*]}"
            ```

            Revoke a rule that allows open access:

            ```bash
            aws ec2 revoke-security-group-ingress \
            --group-id <security-group-id> \
            --protocol tcp \
            --port 22 \
            --cidr 0.0.0.0/0
            ```

            Add a restricted rule (e.g., allow SSH only from a trusted IP range):

            ```bash
            aws ec2 authorize-security-group-ingress \
            --group-id <security-group-id> \
            --protocol tcp \
            --port 22 \
            --cidr 192.168.1.0/24
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure security groups do not allow open access:

            ```hcl
            resource "aws_security_group" "restricted_sg" {
              name        = "restricted-security-group"
              description = "Security group with restricted access"
              vpc_id      = aws_vpc.main.id

              ingress {
                description = "Allow SSH from a trusted IP range"
                from_port   = 22
                to_port     = 22
                protocol    = "tcp"
                cidr_blocks = ["192.168.1.0/24"]  # Restrict to a known IP range
              }

              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow all outbound traffic (if necessary)
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            Ensure security groups do not allow unrestricted access:

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 22
                      ToPort: 22
                      CidrIp: "192.168.1.0/24"  # Restrict to a trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html
        title: Amazon VPC Security Best Practices
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html
        title: Security Group Rules Reference
  - uid: mondoo-aws-security-secgroup-restrict-traffic-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort == -1 && toPort == -1).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == -1 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == -1 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == -1 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-no-static-credentials-in-providers
    title: Ensure Terraform AWS providers do not contain hard-coded credentials
    impact: 95
    variants:
      - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-hcl
      - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-plan
      - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-state
    docs:
      desc: |
        This check ensures that AWS provider configurations in Terraform do not contain hard-coded access keys or secret keys. Hard-coded credentials pose a significant security risk, especially if the Terraform configuration is committed to version control systems.

        **Why this matters**

        Hard-coded credentials in Terraform configurations can lead to:

        - **Credential exposure:** If the code is committed to a public or shared repository, attackers can discover and exploit the credentials.
        - **Unauthorized access:** Compromised credentials can provide full access to AWS resources, leading to data breaches, resource abuse, or financial loss.
        - **Compliance violations:** Many security frameworks (CIS, SOC 2, PCI DSS, ISO 27001) prohibit storing credentials in code.

        **Risk mitigation:**

        - Prevents credential leakage by enforcing secure authentication methods.
        - Ensures compliance with security best practices for infrastructure as code.
        - Reduces the attack surface by eliminating static credentials from codebases.
      remediation:
        - id: terraform
          desc: |
            **Using Environment Variables**

            Configure AWS credentials using environment variables instead of hard-coding them:

            ```bash
            export AWS_ACCESS_KEY_ID="your-access-key"
            export AWS_SECRET_ACCESS_KEY="your-secret-key"
            export AWS_DEFAULT_REGION="us-west-2"
            terraform plan
            ```

            ```hcl
            provider "aws" {}
            ```

            **Using Assumed Role**

            Use IAM roles for authentication:

            ```hcl
            provider "aws" {
              assume_role {
                role_arn     = "arn:aws:iam::ACCOUNT_ID:role/ROLE_NAME"
                session_name = "SESSION_NAME"
                external_id  = "EXTERNAL_ID"
              }
            }
            ```

            **Using AWS Profiles**

            Configure AWS CLI profiles and reference them in Terraform:

            ```hcl
            provider "aws" {
              profile = "my-aws-profile"
              region  = "us-west-2"
            }
            ```
    refs:
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs#authentication-and-configuration
        title: Terraform AWS Provider - Authentication and Configuration
      - url: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html
        title: AWS CLI - Environment Variables
  - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.providers.any(nameLabel == "aws")
    mql: |
      terraform.providers.where( nameLabel == "aws" ) {
        arguments["access_key"] == null || arguments["access_key"].find(/(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}/).all("AKIAIOSFODNN7EXAMPLE")
        arguments["secret_key"] == null || arguments["secret_key"].find(/([A-Za-z0-9\\\/+\\]{40})/).all( "wJalrXUtnFEMI/A1AAAAA/bPxRfiCYAAAAAAAKEY")
      }
  - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.configuration.providerConfig.any(_['name'] == "aws")
    mql: |
      terraform.plan.configuration.providerConfig.where(_['name'] == "aws") {
        _['expressions']['access_key'] == null
        _['expressions']['secret_key'] == null
      }
  - uid: mondoo-aws-security-no-static-credentials-in-providers-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      # Terraform state does not store provider credentials, so this check passes if no credentials are found in configuration
      true
  - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted
    title: Ensure API Gateway cache is enabled and encrypted
    impact: 70
    variants:
      - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-hcl
      - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-plan
      - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon API Gateway method settings have caching enabled and that cached data is encrypted. Caching improves performance by reducing the load on backend services, while encryption protects sensitive data stored in the cache.

        **Why this matters**

        API Gateway caching stores responses from backend integrations to reduce latency and backend load. Without encryption:

        - **Data exposure:** Cached responses may contain sensitive information that could be accessed if the cache is compromised.
        - **Compliance violations:** Security frameworks such as PCI DSS, HIPAA, and SOC 2 require encryption of data at rest.
        - **Security risks:** Unencrypted caches are vulnerable to unauthorized access.

        **Risk mitigation:**

        - Protects sensitive API response data by encrypting cached content.
        - Ensures compliance with data protection regulations.
        - Reduces the risk of data breaches from compromised cache storage.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon API Gateway Console.
            2.  Select the desired API and stage.
            3.  Go to the "Method Settings" section.
            4.  For each method, ensure that caching is enabled and "Cache Data Encrypted" is checked.
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**
            Enable cache encryption for a specific method:

            ```bash
            aws apigateway update-method-settings \
              --rest-api-id <rest-api-id> \
              --stage-name <stage-name> \
              --method-settings <method-path>={"cachingEnabled":true,"cacheDataEncrypted":true}
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable cache encryption in API Gateway method settings:

            ```hcl
            resource "aws_api_gateway_method_settings" "example" {
              rest_api_id = aws_api_gateway_rest_api.example.id
              stage_name  = aws_api_gateway_stage.example.stage_name
              method_path = "path1/GET"

              settings {
                metrics_enabled      = true
                logging_level        = "INFO"
                caching_enabled      = true
                cache_data_encrypted = true
              }
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html
        title: AWS Documentation - Enable API caching
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method_settings
        title: Terraform Documentation - api_gateway_method_settings Resource
  - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-api
    filters: asset.platform == "aws"
    mql: |
      aws.apigateway.restApis.all(
        stages.all(
          methodSettings['*/*']['CacheDataEncrypted'] == true || methodSettings == empty
        )
      )
  - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_api_gateway_method_settings")
    mql: |
      terraform.resources.where( nameLabel == "aws_api_gateway_method_settings").all(
        blocks.one(type == "settings" && arguments["cache_data_encrypted"] == true)
      )
  - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_api_gateway_method_settings")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_api_gateway_method_settings").all(
        change.after.settings[0].cache_data_encrypted == true
      )
  - uid: mondoo-aws-security-api-gw-cache-enabled-and-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_api_gateway_method_settings")
    mql: |
      terraform.state.resources.where(type == "aws_api_gateway_method_settings").all(
        values.settings[0].cache_data_encrypted == true
      )
  - uid: mondoo-aws-security-api-gw-execution-logging-enabled
    title: Ensure API Gateway stages have execution logging enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-api-gw-execution-logging-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon API Gateway stages have access logging enabled. Access logs capture detailed information about API requests, which is essential for monitoring, troubleshooting, and security analysis.

        **Why this matters**

        Without access logging enabled:

        - **Limited visibility:** Inability to track API usage patterns, errors, and performance issues.
        - **Security blind spots:** Difficulty in detecting and investigating suspicious activities or attacks.
        - **Compliance gaps:** Many security frameworks (CIS, SOC 2, PCI DSS) require logging of API access for audit purposes.

        **Risk mitigation:**

        - Enables monitoring and alerting on API activity.
        - Supports incident response and forensic investigations.
        - Ensures compliance with audit and logging requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon API Gateway Console.
            2.  Select the desired API and stage.
            3.  Go to the "Logs/Tracing" tab.
            4.  Enable "Access Logging" and specify a CloudWatch Log Group for storing logs.
            5.  Define a log format (e.g., JSON format with relevant context variables).
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable access logging for an API Gateway stage:

            ```bash
            aws apigateway update-stage \
              --rest-api-id <rest-api-id> \
              --stage-name <stage-name> \
              --patch-operations op=replace,path=/accessLogSettings/destinationArn,value=<log-group-arn> \
              op=replace,path=/accessLogSettings/format,value='<log-format>'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable access logging for API Gateway stages:

            ```hcl
            resource "aws_api_gateway_stage" "example" {
              deployment_id = aws_api_gateway_deployment.example.id
              rest_api_id   = aws_api_gateway_rest_api.example.id
              stage_name    = "prod"

              access_log_settings {
                destination_arn = aws_cloudwatch_log_group.api_gw.arn
                format          = jsonencode({
                  requestId      = "$context.requestId"
                  ip             = "$context.identity.sourceIp"
                  caller         = "$context.identity.caller"
                  user           = "$context.identity.user"
                  requestTime    = "$context.requestTime"
                  httpMethod     = "$context.httpMethod"
                  resourcePath   = "$context.resourcePath"
                  status         = "$context.status"
                  protocol       = "$context.protocol"
                  responseLength = "$context.responseLength"
                })
              }
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/api-gw-execution-logging-enabled.html
        title: AWS Config Managed Rules
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_stage
        title: Terraform Documentation - api_gateway_stage Resource
  - uid: mondoo-aws-security-api-gw-execution-logging-enabled-api
    filters: asset.platform == "aws"
    mql: |
      aws.apigateway.restApis.all(
        stages.all(
          methodSettings['*/*'] != empty &&
          methodSettings['*/*']['LoggingLevel'] != "" &&
          methodSettings['*/*']['LoggingLevel'] != "OFF"
        )
      )
  - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_api_gateway_stage" || nameLabel == "aws_apigatewayv2_stage")
    mql: |
      terraform.resources.where( nameLabel == "aws_api_gateway_stage").all(
        blocks.one(type == "access_log_settings" && arguments["destination_arn"] != "" )
      )
      terraform.resources.where( nameLabel == "aws_apigatewayv2_stage").all(
        blocks.one(type == "access_log_settings" && arguments["destination_arn"] != "" )
      )
  - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_api_gateway_stage" || type == "aws_apigatewayv2_stage")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_api_gateway_stage").all(
        change.after.access_log_settings != empty && change.after.access_log_settings[0].destination_arn != ""
      )
      terraform.plan.resourceChanges.where(type == "aws_apigatewayv2_stage").all(
        change.after.access_log_settings != empty && change.after.access_log_settings[0].destination_arn != ""
      )
  - uid: mondoo-aws-security-api-gw-execution-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_api_gateway_stage" || type == "aws_apigatewayv2_stage")
    mql: |
      terraform.state.resources.where(type == "aws_api_gateway_stage").all(
        values.access_log_settings != empty && values.access_log_settings[0].destination_arn != ""
      )
      terraform.state.resources.where(type == "aws_apigatewayv2_stage").all(
        values.access_log_settings != empty && values.access_log_settings[0].destination_arn != ""
      )
  - uid: mondoo-aws-security-api-gw-require-authentication
    title: Ensure API Gateway methods require authentication
    impact: 80
    variants:
      - uid: mondoo-aws-security-api-gw-require-authentication-terraform-hcl
      - uid: mondoo-aws-security-api-gw-require-authentication-terraform-plan
      - uid: mondoo-aws-security-api-gw-require-authentication-terraform-state
    docs:
      desc: |
        This check ensures that Amazon API Gateway methods have authentication enabled. Methods without authentication (authorization set to NONE) should at minimum require an API key to prevent unauthorized access.

        **Why this matters**

        Unauthenticated API endpoints can lead to:

        - **Unauthorized access:** Anyone can invoke the API, potentially accessing sensitive data or functionality.
        - **Abuse and misuse:** Open endpoints are vulnerable to automated attacks, scraping, and resource abuse.
        - **Data breaches:** Exposed APIs without authentication can leak sensitive information.

        **Risk mitigation:**

        - Prevents unauthorized access to API resources.
        - Reduces the risk of API abuse and denial of service attacks.
        - Ensures compliance with security best practices for API protection.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon API Gateway Console.
            2.  Select the desired API and resource/method.
            3.  Go to the "Method Request" section.
            4.  Set "Authorization" to a valid method (e.g., AWS_IAM, COGNITO_USER_POOLS, CUSTOM).
            5.  If "Authorization" must be NONE, enable "API Key Required".
            6.  Save the changes.

        - id: cli
          desc: |
            **Using AWS CLI**

            Update method authorization for an API Gateway method:

            ```bash
            aws apigateway update-method \
              --rest-api-id <rest-api-id> \
              --resource-id <resource-id> \
              --http-method <http-method> \
              --patch-operations op=replace,path=/authorizationType,value=AWS_IAM
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Configure authentication for API Gateway methods:

            ```hcl
            resource "aws_api_gateway_method" "example" {
              rest_api_id   = aws_api_gateway_rest_api.example.id
              resource_id   = aws_api_gateway_resource.example.id
              http_method   = "GET"
              authorization = "AWS_IAM"  # Or use "COGNITO_USER_POOLS", "CUSTOM"
            }
            ```

            If authorization must be NONE, require an API key:

            ```hcl
            resource "aws_api_gateway_method" "example" {
              rest_api_id      = aws_api_gateway_rest_api.example.id
              resource_id      = aws_api_gateway_resource.example.id
              http_method      = "GET"
              authorization    = "NONE"
              api_key_required = true
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-to-api.html
        title: AWS Documentation - Controlling access to API Gateway APIs
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method
        title: Terraform Documentation - api_gateway_method Resource
  - uid: mondoo-aws-security-api-gw-require-authentication-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_api_gateway_method")
    mql: |
      terraform.resources
        .where( nameLabel == "aws_api_gateway_method" && arguments["authorization"].upcase == "NONE" && arguments["http_method"].upcase != "OPTIONS" )
        .all(arguments["api_key_required"] == true )
  - uid: mondoo-aws-security-api-gw-require-authentication-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_api_gateway_method")
    mql: |
      terraform.plan.resourceChanges
        .where(type == "aws_api_gateway_method" && change.after.authorization.upcase == "NONE" && change.after.http_method.upcase != "OPTIONS")
        .all(change.after.api_key_required == true)
  - uid: mondoo-aws-security-api-gw-require-authentication-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_api_gateway_method")
    mql: |
      terraform.state.resources
        .where(type == "aws_api_gateway_method" && values.authorization.upcase == "NONE" && values.http_method.upcase != "OPTIONS")
        .all(values.api_key_required == true)
  - uid: mondoo-aws-security-api-gw-tls
    title: Ensure API Gateway uses TLS 1.2 or higher
    impact: 80
    variants:
      - uid: mondoo-aws-security-api-gw-tls-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-api-gw-tls-terraform-hcl
      - uid: mondoo-aws-security-api-gw-tls-terraform-plan
      - uid: mondoo-aws-security-api-gw-tls-terraform-state
    docs:
      desc: |
        This check ensures that Amazon API Gateway custom domain names are configured with TLS 1.2 security policy. Older TLS versions (1.0 and 1.1) have known vulnerabilities and should not be used.

        **Why this matters**

        Using outdated TLS versions exposes APIs to:

        - **Known vulnerabilities:** TLS 1.0 and 1.1 have security weaknesses that can be exploited by attackers.
        - **Man-in-the-middle attacks:** Weak encryption can be broken, allowing attackers to intercept and modify traffic.
        - **Compliance violations:** PCI DSS, HIPAA, and other standards require TLS 1.2 or higher.

        **Risk mitigation:**

        - Protects API traffic with strong encryption.
        - Ensures compliance with industry security standards.
        - Prevents exploitation of known TLS vulnerabilities.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon API Gateway Console.
            2.  Select "Custom Domain Names" from the left panel.
            3.  Choose the custom domain name to update.
            4.  Edit the "Security Policy" to select "TLS 1.2".
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Update the security policy for an API Gateway custom domain name:

            ```bash
            aws apigateway update-domain-name \
              --domain-name <domain-name> \
              --patch-operations op=replace,path=/securityPolicy,value=TLS_1_2
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Configure TLS 1.2 for API Gateway custom domain names:

            ```hcl
            resource "aws_api_gateway_domain_name" "example" {
              domain_name              = "api.example.com"
              regional_certificate_arn = aws_acm_certificate.example.arn
              security_policy          = "TLS_1_2"

              endpoint_configuration {
                types = ["REGIONAL"]
              }
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-custom-domain-tls-version.html
        title: AWS Documentation - Choosing a minimum TLS version
      - url: https://docs.aws.amazon.com/config/latest/developerguide/api-gw-ssl-enabled.html
        title: AWS Config Managed Rules
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_domain_name
        title: Terraform Documentation - api_gateway_domain_name Resource
  - uid: mondoo-aws-security-api-gw-tls-api
    filters: asset.platform == "aws"
    mql: |
      aws.apigateway.restApis.all(
        securityPolicy == "TLS_1_2"
      )
  - uid: mondoo-aws-security-api-gw-tls-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_api_gateway_domain_name")
    mql: |
      terraform.resources.where( nameLabel == "aws_api_gateway_domain_name").all(
        arguments["security_policy"] == "TLS_1_2"
      )
  - uid: mondoo-aws-security-api-gw-tls-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_api_gateway_domain_name")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_api_gateway_domain_name").all(
        change.after.security_policy == "TLS_1_2"
      )
  - uid: mondoo-aws-security-api-gw-tls-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_api_gateway_domain_name")
    mql: |
      terraform.state.resources.where(type == "aws_api_gateway_domain_name").all(
        values.security_policy == "TLS_1_2"
      )
  - uid: mondoo-aws-security-api-gw-xray-enabled
    title: Ensure API Gateway X-Ray tracing is enabled
    impact: 50
    variants:
      - uid: mondoo-aws-security-api-gw-xray-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-hcl
      - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-plan
      - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS X-Ray tracing is enabled on Amazon API Gateway REST APIs. X-Ray provides end-to-end visibility into requests as they travel through your API, helping with debugging, performance optimization, and security analysis.

        **Why this matters**

        Without X-Ray tracing:

        - **Limited observability:** Difficulty in understanding request flows and identifying bottlenecks.
        - **Slower troubleshooting:** Increased time to diagnose and resolve issues.
        - **Security blind spots:** Reduced ability to detect and investigate anomalous behavior.

        **Risk mitigation:**

        - Provides detailed insights into API request processing.
        - Enables faster identification and resolution of performance issues.
        - Supports security monitoring and anomaly detection.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon API Gateway Console.
            2.  Select the desired API and stage.
            3.  Go to the "Logs/Tracing" tab.
            4.  Enable "X-Ray Tracing".
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable X-Ray tracing for an API Gateway stage:

            ```bash
            aws apigateway update-stage \
              --rest-api-id <rest-api-id> \
              --stage-name <stage-name> \
              --patch-operations op=replace,path=/tracingEnabled,value=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable X-Ray tracing for API Gateway stages:

            ```hcl
            resource "aws_api_gateway_stage" "example" {
              deployment_id        = aws_api_gateway_deployment.example.id
              rest_api_id          = aws_api_gateway_rest_api.example.id
              stage_name           = "prod"
              xray_tracing_enabled = true
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/api-gw-xray-enabled.html
        title: AWS Config Managed Rules
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_stage
        title: Terraform Documentation - api_gateway_stage Resource
  - uid: mondoo-aws-security-api-gw-xray-enabled-api
    filters: asset.platform == "aws"
    mql: |
      aws.apigateway.restApis.all(
        stages.all(tracingEnabled == true)
      )
  - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_api_gateway_stage")
    mql: |
      terraform.resources.where( nameLabel == "aws_api_gateway_stage").all(
        arguments["xray_tracing_enabled"] == true
      )
  - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_api_gateway_stage")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_api_gateway_stage").all(
        change.after.xray_tracing_enabled == true
      )
  - uid: mondoo-aws-security-api-gw-xray-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_api_gateway_stage")
    mql: |
      terraform.state.resources.where(type == "aws_api_gateway_stage").all(
        values.xray_tracing_enabled == true
      )
  - uid: mondoo-aws-security-ec2-user-data-no-secrets
    title: Ensure EC2 instance user data does not contain secrets
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-hcl
      - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-plan
      - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-state
    docs:
      desc: |
        This check ensures that EC2 instance user data does not contain hard-coded secrets such as AWS access keys or secret keys. User data is often logged and can be accessed by anyone with permissions to describe instances, making it an insecure location for sensitive credentials.

        **Why this matters**

        Storing secrets in EC2 user data poses significant risks:

        - **Credential exposure:** User data is visible to anyone with EC2 describe permissions and is often logged to CloudWatch.
        - **Persistence:** Unlike environment variables, user data persists and can be retrieved at any time.
        - **Compliance violations:** Security frameworks prohibit storing credentials in plain text.

        **Risk mitigation:**

        - Prevents credential leakage through user data exposure.
        - Ensures compliance with security best practices for secret management.
        - Encourages use of secure alternatives like IAM roles, Secrets Manager, or Parameter Store.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the EC2 Console.
            2.  Select the instance and go to the "Actions" menu.
            3.  Choose "Instance Settings" > "View/Change User Data".
            4.  Remove any hard-coded secrets from the user data script.
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Update the user data for an EC2 instance to remove hard-coded secrets:

            ```bash
            aws ec2 modify-instance-attribute \
              --instance-id <instance-id> \
              --user-data '{"Value": "#!/bin/bash\n# Updated user data without secrets"}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Instead of embedding secrets in user data, use IAM roles or AWS Secrets Manager:

            ```hcl
            resource "aws_instance" "example" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              # Use IAM instance profile instead of hard-coded credentials
              iam_instance_profile = aws_iam_instance_profile.example.name

              user_data = <<-EOF
                #!/bin/bash
                # Retrieve secrets from Secrets Manager
                SECRET=$(aws secretsmanager get-secret-value --secret-id my-secret --query SecretString --output text)
                # Use the secret securely
              EOF
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-add-user-data.html
        title: AWS Documentation - Work with instance user data
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html
        title: AWS Documentation - Run commands on your Linux instance at launch
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance
        title: Terraform Documentation - aws_instance Resource
  - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_instance")
    mql: |
      terraform.resources.where( nameLabel == "aws_instance" && arguments["user_data"] != empty ) {
        arguments["user_data"] {
          _.find(/(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}/).all("AKIAIOSFODNN7EXAMPLE")
        }
        arguments["user_data"] {
          _.find(/([A-Za-z0-9\\\/+\\]{40})/).all( "wJalrXUtnFEMI/A1AAAAA/bPxRfiCYAAAAAAAKEY")
        }
      }
  - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_instance" && change.after.user_data != empty) {
        change.after.user_data {
          _.find(/(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}/).all("AKIAIOSFODNN7EXAMPLE")
        }
        change.after.user_data {
          _.find(/([A-Za-z0-9\\\/+\\]{40})/).all("wJalrXUtnFEMI/A1AAAAA/bPxRfiCYAAAAAAAKEY")
        }
      }
  - uid: mondoo-aws-security-ec2-user-data-no-secrets-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_instance")
    mql: |
      terraform.state.resources.where(type == "aws_instance" && values.user_data != empty) {
        values.user_data {
          _.find(/(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}/).all("AKIAIOSFODNN7EXAMPLE")
        }
        values.user_data {
          _.find(/([A-Za-z0-9\\\/+\\]{40})/).all("wJalrXUtnFEMI/A1AAAAA/bPxRfiCYAAAAAAAKEY")
        }
      }
  - uid: mondoo-aws-security-iam-no-wildcards-policies
    title: Ensure IAM policies do not use wildcards and apply least privilege
    impact: 80
    variants:
      - uid: mondoo-aws-security-iam-no-wildcards-policies-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-hcl
      - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-plan
      - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-state
    docs:
      desc: |
        This check ensures that IAM policies do not use wildcard (*) resources except in Deny statements. Using wildcards in Allow statements grants overly permissive access, violating the principle of least privilege.

        **Why this matters**

        Wildcard permissions in IAM policies can lead to:

        - **Excessive privileges:** Users or roles may have access to resources they don't need.
        - **Blast radius expansion:** If credentials are compromised, attackers have broad access.
        - **Compliance violations:** CIS, SOC 2, PCI DSS, and other frameworks require least privilege access.

        **Risk mitigation:**

        - Enforces the principle of least privilege.
        - Reduces the potential impact of credential compromise.
        - Ensures compliance with security frameworks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the IAM Console.
            2.  Select "Policies" from the left panel.
            3.  Find and select the policy to update.
            4.  Edit the policy document to replace wildcard resources with specific ARNs.
            5.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Update an IAM policy to replace wildcard resources:

            ```bash
            aws iam create-policy-version \
              --policy-arn <policy-arn> \
              --policy-document file://updated-policy.json \
              --set-as-default
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Replace wildcard resources with specific ARNs:

            ```hcl
            resource "aws_iam_policy" "example" {
              name        = "restricted-policy"
              description = "Policy with specific resource access"

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect   = "Allow"
                    Action   = ["s3:GetObject", "s3:PutObject"]
                    Resource = "arn:aws:s3:::my-bucket/*"  # Specific bucket, not *
                  },
                  {
                    Effect   = "Deny"
                    Action   = "*"
                    Resource = "*"  # Wildcards are acceptable in Deny statements
                    Condition = {
                      Bool = {
                        "aws:MultiFactorAuthPresent" = "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html
        title: AWS Documentation - Security best practices in IAM
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy
        title: Terraform Documentation - iam_policy Resource
  - uid: mondoo-aws-security-iam-no-wildcards-policies-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.policies.where(isAttachable == true) {
        defaultVersion.document.where(_['Statement'] != empty) {
          _['Statement'].all(
            _['Resource'] != "*" || _['Effect'].upcase == "DENY"
          )
        }
      }
  - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_policy" || nameLabel == "aws_iam_user_policy" || nameLabel == "aws_iam_role_policy" || nameLabel == "aws_iam_group_policy")
    mql: |
      terraform.resources.where( nameLabel == "aws_iam_policy" && arguments["policy"] != empty ) {
        arguments["policy"].where( _["Statement"] != empty) {
          _["Statement"] {
            _["Resource"] != "*" || _["Effect"].upcase == "DENY"
          }
        }
      }
      terraform.resources.where( nameLabel == "aws_iam_user_policy" && arguments["policy"] != empty ) {
        arguments["policy"].where( _["Statement"] != empty) {
          _["Statement"] {
            _["Resource"] != "*" || _["Effect"].upcase == "DENY"
          }
        }
      }
      terraform.resources.where( nameLabel == "aws_iam_role_policy" && arguments["policy"] != empty ) {
        arguments["assume_role_policy"].where( _["Statement"] != empty) {
          _["Statement"] {
            _["Resource"] != "*" || _["Effect"].upcase == "DENY"
          }
        }
      }
      terraform.resources.where( nameLabel == "aws_iam_group_policy" && arguments["policy"] != empty ) {
        arguments["policy"].where( _["Statement"] != empty) {
          _["Statement"] {
            _["Resource"] != "*" || _["Effect"].upcase == "DENY"
          }
        }
      }
  - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_policy" || type == "aws_iam_user_policy" || type == "aws_iam_role_policy" || type == "aws_iam_group_policy")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_policy" && change.after.policy != empty) {
        change.after.policy {
          _.contains('"Resource": "*"') == false || _.contains('"Effect": "Deny"')
        }
      }
  - uid: mondoo-aws-security-iam-no-wildcards-policies-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_policy" || type == "aws_iam_user_policy" || type == "aws_iam_role_policy" || type == "aws_iam_group_policy")
    mql: |
      terraform.state.resources.where(type == "aws_iam_policy" && values.policy != empty) {
        values.policy {
          _.contains('"Resource": "*"') == false || _.contains('"Effect": "Deny"')
        }
      }
  - uid: mondoo-aws-security-s3-bucket-versioning-enabled
    title: Ensure S3 bucket versioning is enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-s3-bucket-versioning-enabled-api
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 buckets have versioning enabled. Versioning preserves multiple versions of objects, providing protection against accidental deletions and enabling recovery of previous versions.

        **Why this matters**

        Without versioning:

        - **Data loss:** Accidental deletions or overwrites cannot be recovered.
        - **No audit trail:** Changes to objects cannot be tracked over time.
        - **Ransomware vulnerability:** Encrypted files cannot be restored to pre-attack versions.

        **Risk mitigation:**

        - Protects against accidental data loss and overwrites.
        - Enables recovery from ransomware attacks.
        - Supports compliance with data retention requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon S3 Console.
            2.  Select the desired bucket.
            3.  Go to the "Properties" tab.
            4.  Under "Bucket Versioning", click "Edit".
            5.  Enable versioning and save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable versioning for an S3 bucket:

            ```bash
            aws s3api put-bucket-versioning \
              --bucket <bucket-name> \
              --versioning-configuration Status=Enabled
            ```
        - id: terraform
          desc: |
            **Using Terraform (AWS Provider 4.x)**

            Enable versioning for S3 buckets:

            ```hcl
            resource "aws_s3_bucket" "example" {
              bucket = "my-bucket"
            }

            resource "aws_s3_bucket_versioning" "example" {
              bucket = aws_s3_bucket.example.id
              versioning_configuration {
                status = "Enabled"
              }
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-versioning-enabled.html
        title: AWS Config Managed Rules
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_versioning
        title: Terraform Documentation - s3_bucket_versioning Resource
  - uid: mondoo-aws-security-s3-bucket-versioning-enabled-api
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.versioning['Status'] == "Enabled"
  - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_bucket_versioning")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_bucket_versioning").all(
        blocks.one(type.downcase == "versioning_configuration") &&
        blocks.where(type.downcase == "versioning_configuration").all(
          arguments['status'].downcase == 'enabled'
        )
      )
  - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_bucket_versioning")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_bucket_versioning").all(
        change.after.versioning_configuration[0].status.downcase == "enabled"
      )
  - uid: mondoo-aws-security-s3-bucket-versioning-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_bucket_versioning")
    mql: |
      terraform.state.resources.where(type == "aws_s3_bucket_versioning").all(
        values.versioning_configuration[0].status.downcase == "enabled"
      )
  - uid: mondoo-aws-security-s3-bucket-logging-enabled
    title: Ensure S3 bucket logging is enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-s3-bucket-logging-enabled-api
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 buckets have server access logging enabled. Access logs record all requests made to the bucket, providing valuable data for security analysis, auditing, and compliance.

        **Why this matters**

        Without logging:

        - **No visibility:** Unable to track who accessed what data and when.
        - **Security blind spots:** Cannot detect unauthorized access attempts.
        - **Compliance gaps:** Many regulations require access logging for audit purposes.

        **Risk mitigation:**

        - Enables detection of unauthorized access attempts.
        - Supports forensic investigations and incident response.
        - Ensures compliance with audit and logging requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon S3 Console.
            2.  Select the desired bucket.
            3.  Go to the "Properties" tab.
            4.  Under "Server access logging", click "Edit".
            5.  Enable logging, specify a target bucket and prefix, and save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable logging for an S3 bucket:

            ```bash
            aws s3api put-bucket-logging \
              --bucket <source-bucket-name> \
              --bucket-logging-status '{
                "LoggingEnabled": {
                  "TargetBucket": "<target-bucket-name>",
                  "TargetPrefix": "logs/"
                }
              }'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable logging for S3 buckets:

            ```hcl
            resource "aws_s3_bucket" "example" {
              bucket = "my-bucket"
            }

            resource "aws_s3_bucket_logging" "example" {
              bucket = aws_s3_bucket.example.id

              target_bucket = aws_s3_bucket.log_bucket.id
              target_prefix = "logs/"
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-logging-enabled.html
        title: AWS Config Managed Rules
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/ServerLogs.html
        title: AWS Documentation - Logging requests using server access logging
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_logging
        title: Terraform Documentation - s3_bucket_logging Resource
  - uid: mondoo-aws-security-s3-bucket-logging-enabled-api
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.logging['TargetBucket'] != empty
  - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_bucket_logging")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_bucket_logging").all(
        arguments['target_bucket'] != empty
      )
  - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_bucket_logging")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_bucket_logging").all(
        change.after.target_bucket != empty
      )
  - uid: mondoo-aws-security-s3-bucket-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_bucket_logging")
    mql: |
      terraform.state.resources.where(type == "aws_s3_bucket_logging").all(
        values.target_bucket != empty
      )
  - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled
    title: Ensure S3 bucket server-side encryption is enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-api
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 buckets have default server-side encryption enabled. When enabled, all new objects are automatically encrypted using either Amazon S3-managed keys (SSE-S3) or AWS KMS keys (SSE-KMS).

        **Why this matters**

        Without default encryption:

        - **Data exposure:** Unencrypted data at rest is vulnerable if storage is compromised.
        - **Compliance violations:** PCI DSS, HIPAA, and other standards require encryption at rest.
        - **Inconsistent protection:** Objects may be uploaded without encryption.

        **Risk mitigation:**

        - Protects data at rest with strong encryption.
        - Ensures all objects are automatically encrypted.
        - Supports compliance with data protection regulations.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon S3 Console.
            2.  Select the desired bucket.
            3.  Go to the "Properties" tab.
            4.  Under "Default encryption", click "Edit".
            5.  Enable default encryption using SSE-S3 or SSE-KMS and save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable default server-side encryption for an S3 bucket using SSE-KMS:

            ```bash
            aws s3api put-bucket-encryption \
              --bucket <bucket-name> \
              --server-side-encryption-configuration '{
                "Rules": [
                  {
                    "ApplyServerSideEncryptionByDefault": {
                      "SSEAlgorithm": "aws:kms",
                      "KMSMasterKeyID": "<kms-key-id>"
                    }
                  }
                ]
              }'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable server-side encryption for S3 buckets:

            ```hcl
            resource "aws_s3_bucket" "example" {
              bucket = "my-bucket"
            }

            resource "aws_s3_bucket_server_side_encryption_configuration" "example" {
              bucket = aws_s3_bucket.example.id

              rule {
                apply_server_side_encryption_by_default {
                  sse_algorithm     = "aws:kms"
                  kms_master_key_id = aws_kms_key.example.arn
                }
              }
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html
        title: AWS Documentation - Setting default server-side encryption
      - url: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-server-side-encryption-enabled.html
        title: AWS Config Managed Rules
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_server_side_encryption_configuration
        title: Terraform Documentation - s3_bucket_server_side_encryption_configuration Resource
  - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-api
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.encryption['Rules'] != empty
  - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_bucket_server_side_encryption_configuration")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_bucket_server_side_encryption_configuration").all(
        blocks.one(type == "rule") &&
        blocks.where(type == "rule").all(
          blocks.one(_.type == 'apply_server_side_encryption_by_default')
        )
      )
  - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_bucket_server_side_encryption_configuration")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_bucket_server_side_encryption_configuration").all(
        change.after.rule[0].apply_server_side_encryption_by_default != empty
      )
  - uid: mondoo-aws-security-s3-bucket-server-side-encryption-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_bucket_server_side_encryption_configuration")
    mql: |
      terraform.state.resources.where(type == "aws_s3_bucket_server_side_encryption_configuration").all(
        values.rule[0].apply_server_side_encryption_by_default != empty
      )
  - uid: mondoo-aws-security-s3-bucket-public-read-prohibited
    title: Ensure S3 buckets do not allow public read access via ACLs
    impact: 95
    variants:
      - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-api
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 buckets do not have public-read or public-read-write ACLs configured. Public ACLs expose bucket contents to the internet, risking unauthorized data access and breaches.

        **Why this matters**

        Public read ACLs can lead to:

        - **Data breaches:** Anyone on the internet can access bucket contents.
        - **Sensitive data exposure:** Confidential files may be inadvertently exposed.
        - **Compliance violations:** GDPR, PCI DSS, and HIPAA prohibit public access to sensitive data.

        **Risk mitigation:**

        - Prevents unauthorized public access to S3 data.
        - Protects against data breaches and leaks.
        - Ensures compliance with data protection regulations.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1.  Navigate to the Amazon S3 Console.
            2.  Select the desired bucket.
            3.  Go to the "Permissions" tab.
            4.  Under "Access Control List (ACL)", click "Edit".
            5.  Remove any public read or public read/write permissions.
            6.  Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Set the ACL of an S3 bucket to private:

            ```bash
            aws s3api put-bucket-acl \
              --bucket <bucket-name> \
              --acl private
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Use private ACLs for S3 buckets:

            ```hcl
            resource "aws_s3_bucket" "example" {
              bucket = "my-bucket"
            }

            resource "aws_s3_bucket_acl" "example" {
              bucket = aws_s3_bucket.example.id
              acl    = "private"
            }
            ```

            Better yet, use bucket public access blocks:

            ```hcl
            resource "aws_s3_bucket_public_access_block" "example" {
              bucket = aws_s3_bucket.example.id

              block_public_acls       = true
              block_public_policy     = true
              ignore_public_acls      = true
              restrict_public_buckets = true
            }
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-read-prohibited.html
        title: AWS Config Managed Rules - public read
      - url: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-write-prohibited.html
        title: AWS Config Managed Rules - public write
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl
        title: Terraform Documentation - s3_bucket_acl Resource
  - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-api
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.acl.none(
        permission == "READ" && grantee['URI'] == "http://acs.amazonaws.com/groups/global/AllUsers"
      )
      aws.s3.bucket.acl.none(
        permission == "FULL_CONTROL" && grantee['URI'] == "http://acs.amazonaws.com/groups/global/AllUsers"
      )
  - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_bucket_acl")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_bucket_acl").all(
        arguments['acl'].downcase != /public-read/
      )
  - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_bucket_acl")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_bucket_acl").all(
        change.after.acl.downcase != /public-read/
      )
  - uid: mondoo-aws-security-s3-bucket-public-read-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_bucket_acl")
    mql: |
      terraform.state.resources.where(type == "aws_s3_bucket_acl").all(
        values.acl.downcase != /public-read/
      )
  - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled
    title: Ensure S3 bucket static website hosting is disabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-api
        tags:
          mondoo.com/filter-title: "AWS S3 Bucket"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 buckets do not have static website hosting enabled. When static website hosting is enabled on an S3 bucket, it serves content over an unauthenticated HTTP endpoint, which can expose data to the public internet.

        **Why this matters**

        When static website hosting is enabled:

        - **Data exposure:** The bucket's contents may be accessible over the internet without authentication.
        - **Attack surface:** The publicly accessible endpoint can be exploited for phishing, malware distribution, or data exfiltration.
        - **Compliance violations:** Regulations such as PCI DSS, HIPAA, and GDPR require strict control over public-facing resources.

        **Risk mitigation:**

        - Prevents accidental exposure of sensitive data through public website endpoints.
        - Reduces the attack surface by eliminating unnecessary public-facing services.
        - Ensures compliance with data protection and access control requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon S3 Console.
            2. Select the desired bucket.
            3. Go to the "Properties" tab.
            4. Under "Static website hosting", click "Edit".
            5. Select "Disable" and save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws s3api delete-bucket-website --bucket <bucket-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Remove any `aws_s3_bucket_website_configuration` resources associated with the bucket:

            ```hcl
            # Remove or comment out website configuration resources
            # resource "aws_s3_bucket_website_configuration" "example" {
            #   bucket = aws_s3_bucket.example.id
            #   index_document {
            #     suffix = "index.html"
            #   }
            # }
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html
        title: Hosting a static website using Amazon S3
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_website_configuration
        title: Terraform Documentation - s3_bucket_website_configuration Resource
  - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-api
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.staticWebsiteHosting == empty
  - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_bucket_website_configuration")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_bucket_website_configuration").length == 0
  - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_bucket_website_configuration")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_bucket_website_configuration").length == 0
  - uid: mondoo-aws-security-s3-bucket-static-website-hosting-disabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_bucket_website_configuration")
    mql: |
      terraform.state.resources.where(type == "aws_s3_bucket_website_configuration").length == 0
  - uid: mondoo-aws-security-cloud-trail-multi-region-enabled
    title: Ensure CloudTrail is enabled in all regions with a multi-region trail
    impact: 90
    variants:
      - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-single
        tags:
          mondoo.com/filter-title: "AWS CloudTrail Trail"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-plan
      - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS CloudTrail is configured with at least one multi-region trail that captures management events across all AWS regions. A single-region trail only records API activity in the region where it was created, leaving events in other regions unmonitored and potentially allowing attackers to operate undetected in regions where CloudTrail is not active.

        **Why this matters**

        Without a multi-region trail enabled:

        - API activity in regions where CloudTrail is not active goes unrecorded, creating blind spots in the audit trail.
        - Attackers can exploit regions without active trails to perform malicious actions without detection.
        - Compliance frameworks such as CIS AWS Foundations Benchmark (control 3.1), PCI DSS, HIPAA, and SOC 2 require comprehensive logging across all regions.

        A multi-region trail ensures complete visibility into account activity regardless of which region the API call originates from, including global service events such as IAM, STS, and CloudFront.

        **Risk mitigation:**

        - **Complete audit coverage:** All API activity across every region is captured in a single trail.
        - **Threat detection:** Enables detection of unauthorized activity in regions that are not commonly used.
        - **Compliance:** Meets CIS AWS Foundations Benchmark 3.1 and other regulatory requirements for comprehensive logging.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS CloudTrail Console.
            2. Select Trails in the left panel.
            3. Select the trail you want to update, or create a new trail.
            4. Under General details, ensure the Multi-region trail option is set to Yes.
            5. Ensure Include global service events is also enabled.
            6. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if any trail is configured as a multi-region trail:

            ```bash
            aws cloudtrail describe-trails \
              --query "trailList[*].{Name:Name,IsMultiRegion:IsMultiRegionTrail,IsLogging:HomeRegion}"
            ```

            If no multi-region trail exists, update an existing trail or create a new one:

            ```bash
            aws cloudtrail update-trail \
              --name my-trail \
              --is-multi-region-trail \
              --include-global-service-events
            ```

            Verify that the trail is logging:

            ```bash
            aws cloudtrail get-trail-status --name my-trail \
              --query "{IsLogging:IsLogging}"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_cloudtrail" "multi_region_trail" {
              name                          = "multi-region-cloudtrail"
              s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
              is_multi_region_trail         = true   # Enable multi-region trail
              include_global_service_events = true   # Include global service events
              enable_logging                = true
              enable_log_file_validation    = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              MultiRegionCloudTrail:
                Type: "AWS::CloudTrail::Trail"
                Properties:
                  TrailName: "multi-region-cloudtrail"
                  S3BucketName: !Ref CloudTrailLogsBucket
                  IsMultiRegionTrail: true
                  IncludeGlobalServiceEvents: true
                  EnableLogFileValidation: true
                  IsLogging: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail.html
        title: AWS Documentation - Creating and updating a trail
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/cloudtrail-controls.html
        title: AWS Documentation - CloudTrail controls
  - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-single
    filters: asset.platform == "aws-cloudtrail-trail"
    mql: |
      aws.cloudtrail.trail.isMultiRegionTrail == true
      aws.cloudtrail.trail.status["IsLogging"] == true
  - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudtrail")
    mql: terraform.resources.where(nameLabel == "aws_cloudtrail").any(arguments.is_multi_region_trail == true)
  - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudtrail")
    mql: terraform.plan.resourceChanges.where(type == "aws_cloudtrail").any(change.after.is_multi_region_trail == true)
  - uid: mondoo-aws-security-cloud-trail-multi-region-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudtrail")
    mql: terraform.state.resources.where(type == "aws_cloudtrail").any(values.is_multi_region_trail == true)
  - uid: mondoo-aws-security-cloudfront-viewer-policy-https
    title: Ensure CloudFront distributions require HTTPS for viewer connections
    impact: 80
    variants:
      - uid: mondoo-aws-security-cloudfront-viewer-policy-https-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-hcl
      - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-plan
      - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudFront distributions are configured to require HTTPS for viewer connections, preventing content from being served over unencrypted HTTP. By default, CloudFront distributions can be configured with an "allow-all" viewer protocol policy, which permits both HTTP and HTTPS connections and exposes users to man-in-the-middle (MITM) attacks.

        **Why this matters**

        When CloudFront distributions allow HTTP connections:

        - Data transmitted between viewers and CloudFront is unencrypted and can be intercepted by attackers.
        - Sensitive information such as authentication tokens, session cookies, and user data can be exposed.
        - Users are vulnerable to man-in-the-middle attacks that can modify content in transit.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 require encryption in transit for sensitive data.

        Configuring the viewer protocol policy to "https-only" or "redirect-to-https" ensures that all communication between viewers and CloudFront is encrypted.

        **Risk mitigation:**

        - **Data protection:** Prevents eavesdropping on traffic between viewers and CloudFront edge locations.
        - **MITM prevention:** Eliminates the risk of content being modified in transit by attackers.
        - **Compliance:** Meets regulatory requirements for encryption in transit.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon CloudFront Console.
            2. Select the distribution you want to update.
            3. Select the Behaviors tab.
            4. Select the default cache behavior and choose Edit.
            5. Under Viewer Protocol Policy, select Redirect HTTP to HTTPS or HTTPS Only.
            6. Select Save changes.
            7. Repeat for any additional cache behaviors.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the viewer protocol policy for a distribution:

            ```bash
            aws cloudfront get-distribution-config --id <distribution-id> \
              --query "DistributionConfig.DefaultCacheBehavior.ViewerProtocolPolicy"
            ```

            If the output shows "allow-all", update the distribution:

            ```bash
            aws cloudfront get-distribution-config --id <distribution-id> > dist-config.json
            # Edit dist-config.json to set ViewerProtocolPolicy to "redirect-to-https"
            aws cloudfront update-distribution --id <distribution-id> \
              --if-match <etag> \
              --distribution-config file://dist-config.json
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_cloudfront_distribution" "secure_distribution" {
              enabled = true

              default_cache_behavior {
                viewer_protocol_policy = "redirect-to-https"  # Require HTTPS
                allowed_methods        = ["GET", "HEAD"]
                cached_methods         = ["GET", "HEAD"]
                target_origin_id       = "myS3Origin"

                forwarded_values {
                  query_string = false
                  cookies {
                    forward = "none"
                  }
                }
              }

              origin {
                domain_name = aws_s3_bucket.example.bucket_regional_domain_name
                origin_id   = "myS3Origin"
              }

              restrictions {
                geo_restriction {
                  restriction_type = "none"
                }
              }

              viewer_certificate {
                cloudfront_default_certificate = true
                minimum_protocol_version       = "TLSv1.2_2021"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecureCloudFrontDistribution:
                Type: "AWS::CloudFront::Distribution"
                Properties:
                  DistributionConfig:
                    Enabled: true
                    DefaultCacheBehavior:
                      ViewerProtocolPolicy: "redirect-to-https"
                      TargetOriginId: "myS3Origin"
                      ForwardedValues:
                        QueryString: false
                    Origins:
                      - Id: "myS3Origin"
                        DomainName: !GetAtt S3Bucket.DomainName
                        S3OriginConfig:
                          OriginAccessIdentity: ""
                    ViewerCertificate:
                      MinimumProtocolVersion: "TLSv1.2_2021"
                      CloudFrontDefaultCertificate: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html
        title: AWS Documentation - Requiring HTTPS for communication between viewers and CloudFront
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/cloudfront-controls.html
        title: AWS Documentation - CloudFront controls
  - uid: mondoo-aws-security-cloudfront-viewer-policy-https-api
    filters: asset.platform == "aws"
    mql: |
      aws.cloudfront.distributions.all(
        viewerProtocolPolicy != "allow-all"
      )
  - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudfront_distribution")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudfront_distribution").all(
        blocks.where(type == "default_cache_behavior").all(
          arguments.viewer_protocol_policy == "redirect-to-https" || arguments.viewer_protocol_policy == "https-only"
        )
      )
  - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudfront_distribution").all(
        change.after.default_cache_behavior.all(_['viewer_protocol_policy'] != "allow-all")
      )
  - uid: mondoo-aws-security-cloudfront-viewer-policy-https-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.state.resources.where(type == "aws_cloudfront_distribution").all(
        values.default_cache_behavior.all(_['viewer_protocol_policy'] != "allow-all")
      )
  - uid: mondoo-aws-security-eks-cluster-logging-enabled
    title: Ensure Amazon EKS control plane logging is enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-eks-cluster-logging-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EKS clusters have control plane logging enabled. EKS control plane logging provides audit and diagnostic logs directly from the Amazon EKS control plane to CloudWatch Logs. These logs include API server, audit, authenticator, controller manager, and scheduler components that are essential for security monitoring and troubleshooting.

        **Why this matters**

        Without EKS control plane logging enabled:

        - Unauthorized API calls and authentication attempts go undetected, making it difficult to identify security incidents.
        - There is no audit trail for Kubernetes API activity, hindering forensic investigations.
        - Compliance frameworks such as CIS EKS Benchmark, PCI DSS, and SOC 2 require logging of security-relevant events.
        - Operational issues with the control plane cannot be diagnosed effectively.

        At minimum, the audit log type should be enabled as it records all individual API requests for accountability. Enabling all log types (api, audit, authenticator, controllerManager, scheduler) provides comprehensive visibility.

        **Risk mitigation:**

        - **Threat detection:** Enables detection of unauthorized API calls, privilege escalation attempts, and suspicious authentication activity.
        - **Forensic capability:** Provides detailed audit trail for incident investigation and response.
        - **Compliance:** Meets CIS EKS Benchmark and regulatory requirements for logging security events.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EKS Console.
            2. Select the EKS cluster you want to configure.
            3. In the Observability tab, select Manage logging.
            4. Enable all log types: API server, Audit, Authenticator, Controller manager, and Scheduler.
            5. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the current logging configuration for an EKS cluster:

            ```bash
            aws eks describe-cluster --name <cluster_name> \
              --query "cluster.logging.clusterLogging"
            ```

            Enable all control plane log types:

            ```bash
            aws eks update-cluster-config --name <cluster_name> \
              --logging '{"clusterLogging":[{"types":["api","audit","authenticator","controllerManager","scheduler"],"enabled":true}]}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_eks_cluster" "example" {
              name     = "example-cluster"
              role_arn = aws_iam_role.eks_role.arn

              vpc_config {
                subnet_ids = [aws_subnet.eks_subnet.id]
              }

              enabled_cluster_log_types = [
                "api",
                "audit",
                "authenticator",
                "controllerManager",
                "scheduler"
              ]
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              MyEKSCluster:
                Type: AWS::EKS::Cluster
                Properties:
                  Name: example-cluster
                  RoleArn: !GetAtt eksRole.Arn
                  ResourcesVpcConfig:
                    SubnetIds:
                      - !Ref eksSubnet
                  Logging:
                    ClusterLogging:
                      EnabledTypes:
                        - Type: api
                        - Type: audit
                        - Type: authenticator
                        - Type: controllerManager
                        - Type: scheduler
            ```
    refs:
      - url: https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html
        title: AWS Documentation - Amazon EKS control plane logging
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/eks-controls.html
        title: AWS Documentation - EKS controls
  - uid: mondoo-aws-security-eks-cluster-logging-enabled-api
    filters: asset.platform == "aws-eks-cluster"
    mql: |
      aws.eks.cluster.logging['clusterLogging'] != null
      aws.eks.cluster.logging['clusterLogging'].any(_['enabled'] == true)
  - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_eks_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_eks_cluster").all(
        arguments.enabled_cluster_log_types != empty
      )
  - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_eks_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_eks_cluster").all(
        change.after.enabled_cluster_log_types != empty
      )
  - uid: mondoo-aws-security-eks-cluster-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_eks_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_eks_cluster").all(
        values.enabled_cluster_log_types != empty
      )
  - uid: mondoo-aws-security-opensearch-enforce-https
    title: Ensure Amazon OpenSearch Service domains enforce HTTPS
    impact: 90
    variants:
      - uid: mondoo-aws-security-opensearch-enforce-https-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-enforce-https-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-enforce-https-terraform-hcl
      - uid: mondoo-aws-security-opensearch-enforce-https-terraform-plan
      - uid: mondoo-aws-security-opensearch-enforce-https-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains are configured to enforce HTTPS for all connections. Without HTTPS enforcement, data transmitted between clients and the OpenSearch domain is unencrypted, exposing sensitive search queries, indexed data, and authentication credentials to potential interception.

        **Why this matters**

        - Unencrypted traffic can be intercepted by network-level attackers, exposing sensitive data and credentials.
        - OpenSearch domains often contain business-critical or personally identifiable information (PII) that must be protected in transit.
        - AWS Security Hub control OpenSearch.8 requires HTTPS enforcement on OpenSearch domains.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 require encryption of data in transit.

        **Risk mitigation:**

        - **Data protection:** Encrypts all communication between clients and the OpenSearch cluster.
        - **Credential security:** Prevents exposure of authentication tokens and API keys in transit.
        - **Compliance:** Aligns with AWS Security Hub, CIS, and regulatory requirements for encryption in transit.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select Edit security configuration.
            4. Under Domain endpoint options, enable Require HTTPS for all traffic to the domain.
            5. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if HTTPS is enforced on a domain:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.DomainEndpointOptions.EnforceHTTPS"
            ```

            Enable HTTPS enforcement:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --domain-endpoint-options '{"EnforceHTTPS": true, "TLSSecurityPolicy": "Policy-Min-TLS-1-2-2019-07"}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              domain_endpoint_options {
                enforce_https       = true
                tls_security_policy = "Policy-Min-TLS-1-2-2019-07"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  DomainEndpointOptions:
                    EnforceHTTPS: true
                    TLSSecurityPolicy: "Policy-Min-TLS-1-2-2019-07"
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/encryption-at-rest.html
        title: AWS Documentation - Encryption in Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-enforce-https-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.enforceHTTPS == true
  - uid: mondoo-aws-security-opensearch-enforce-https-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(enforceHTTPS == true)
  - uid: mondoo-aws-security-opensearch-enforce-https-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "domain_endpoint_options") != empty &&
        blocks.where(type == "domain_endpoint_options").all(arguments.enforce_https == true)
      )
  - uid: mondoo-aws-security-opensearch-enforce-https-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.domain_endpoint_options != empty &&
        change.after.domain_endpoint_options.all(enforce_https == true)
      )
  - uid: mondoo-aws-security-opensearch-enforce-https-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.domain_endpoint_options != empty &&
        values.domain_endpoint_options.all(enforce_https == true)
      )
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption
    title: Ensure Amazon OpenSearch Service domains use node-to-node encryption
    impact: 80
    variants:
      - uid: mondoo-aws-security-opensearch-node-to-node-encryption-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-node-to-node-encryption-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-hcl
      - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-plan
      - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains have node-to-node encryption enabled. Node-to-node encryption provides an additional layer of security by encrypting data as it is transferred between nodes within the OpenSearch cluster, protecting against potential internal network eavesdropping.

        **Why this matters**

        - Without node-to-node encryption, data moving between cluster nodes is transmitted in plaintext within the VPC.
        - Attackers with network access within the VPC could potentially intercept inter-node traffic containing indexed data, search results, and cluster metadata.
        - AWS Security Hub control OpenSearch.6 requires node-to-node encryption.
        - This is especially critical for domains processing sensitive or regulated data.

        **Risk mitigation:**

        - **Internal traffic protection:** Encrypts all communication between nodes within the OpenSearch cluster.
        - **Defense in depth:** Adds an encryption layer beyond VPC-level network isolation.
        - **Compliance:** Meets AWS Security Hub and regulatory requirements for comprehensive encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select Edit security configuration.
            4. Enable Node-to-node encryption.
            5. Select Save changes.

            Note: Enabling node-to-node encryption on an existing domain requires a blue/green deployment. Plan for potential downtime.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if node-to-node encryption is enabled:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.NodeToNodeEncryptionOptions.Enabled"
            ```

            Enable node-to-node encryption:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --node-to-node-encryption-options Enabled=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              node_to_node_encryption {
                enabled = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  NodeToNodeEncryptionOptions:
                    Enabled: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ntn.html
        title: AWS Documentation - Node-to-node encryption for Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.nodeToNodeEncryptionEnabled == true
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(nodeToNodeEncryptionEnabled == true)
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "node_to_node_encryption") != empty &&
        blocks.where(type == "node_to_node_encryption").all(arguments.enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.node_to_node_encryption != empty &&
        change.after.node_to_node_encryption.all(enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-node-to-node-encryption-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.node_to_node_encryption != empty &&
        values.node_to_node_encryption.all(enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-tls-policy
    title: Ensure Amazon OpenSearch Service domains use TLS 1.2 or higher
    impact: 70
    variants:
      - uid: mondoo-aws-security-opensearch-tls-policy-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-tls-policy-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-tls-policy-terraform-hcl
      - uid: mondoo-aws-security-opensearch-tls-policy-terraform-plan
      - uid: mondoo-aws-security-opensearch-tls-policy-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains are configured with a TLS security policy that enforces TLS 1.2 or higher. Older TLS versions (1.0 and 1.1) have known vulnerabilities that can be exploited by attackers to intercept or decrypt encrypted traffic.

        **Why this matters**

        - TLS 1.0 and 1.1 have known security weaknesses including susceptibility to BEAST, POODLE, and other attacks.
        - Major browsers and compliance frameworks have deprecated TLS 1.0 and 1.1.
        - PCI DSS requires TLS 1.2 or higher for all systems that handle cardholder data.
        - AWS Security Hub recommends enforcing a minimum TLS version of 1.2.

        **Risk mitigation:**

        - **Protocol security:** Eliminates use of deprecated TLS versions with known vulnerabilities.
        - **Cipher strength:** TLS 1.2+ policies enforce the use of strong cipher suites.
        - **Compliance:** Meets PCI DSS, HIPAA, and other regulatory requirements for encryption protocols.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select Edit security configuration.
            4. Under Domain endpoint options, set the TLS security policy to Policy-Min-TLS-1-2-2019-07 or a newer policy.
            5. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the TLS security policy for a domain:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.DomainEndpointOptions.TLSSecurityPolicy"
            ```

            Update the TLS security policy:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --domain-endpoint-options '{"TLSSecurityPolicy": "Policy-Min-TLS-1-2-2019-07"}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              domain_endpoint_options {
                enforce_https       = true
                tls_security_policy = "Policy-Min-TLS-1-2-2019-07"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  DomainEndpointOptions:
                    EnforceHTTPS: true
                    TLSSecurityPolicy: "Policy-Min-TLS-1-2-2019-07"
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/encryption-at-rest.html
        title: AWS Documentation - Encryption in Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-tls-policy-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.tlsSecurityPolicy == /Policy-Min-TLS-1-2/
  - uid: mondoo-aws-security-opensearch-tls-policy-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(tlsSecurityPolicy == /Policy-Min-TLS-1-2/)
  - uid: mondoo-aws-security-opensearch-tls-policy-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "domain_endpoint_options") != empty &&
        blocks.where(type == "domain_endpoint_options").all(
          arguments.tls_security_policy == /Policy-Min-TLS-1-2/
        )
      )
  - uid: mondoo-aws-security-opensearch-tls-policy-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.domain_endpoint_options != empty &&
        change.after.domain_endpoint_options.all(tls_security_policy == /Policy-Min-TLS-1-2/)
      )
  - uid: mondoo-aws-security-opensearch-tls-policy-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.domain_endpoint_options != empty &&
        values.domain_endpoint_options.all(tls_security_policy == /Policy-Min-TLS-1-2/)
      )
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control
    title: Ensure Amazon OpenSearch Service domains have fine-grained access control enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-opensearch-fine-grained-access-control-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-fine-grained-access-control-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-hcl
      - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-plan
      - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains have fine-grained access control (advanced security options) enabled. Fine-grained access control provides granular permissions for indices, documents, and fields, enabling role-based access control (RBAC) within the OpenSearch domain.

        **Why this matters**

        - Without fine-grained access control, access is managed solely through IAM and resource-based policies, which cannot restrict access at the index, document, or field level.
        - Sensitive data within specific indices or fields cannot be protected from authorized but over-privileged users.
        - AWS Security Hub control OpenSearch.7 requires fine-grained access control.
        - Fine-grained access control enables audit logging of user actions within the domain.

        **Risk mitigation:**

        - **Least privilege:** Enables restricting users to specific indices, documents, and fields.
        - **Data isolation:** Prevents unauthorized access to sensitive data within shared domains.
        - **Audit capability:** Provides detailed logging of who accessed what data and when.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select Edit security configuration.
            4. Enable Fine-grained access control.
            5. Choose either IAM ARN as master user or create a master user with a username and password.
            6. Select Save changes.

            Note: Enabling fine-grained access control requires encryption at rest, node-to-node encryption, and HTTPS enforcement to also be enabled.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if fine-grained access control is enabled:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.AdvancedSecurityOptions.Enabled"
            ```

            Enable fine-grained access control:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --advanced-security-options '{"Enabled": true, "InternalUserDatabaseEnabled": true, "MasterUserOptions": {"MasterUserName": "admin", "MasterUserPassword": "SecurePassword123!"}}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              advanced_security_options {
                enabled                        = true
                internal_user_database_enabled = true
                master_user_options {
                  master_user_name     = "admin"
                  master_user_password = var.master_user_password
                }
              }

              # Required prerequisites for fine-grained access control
              encrypt_at_rest { enabled = true }
              node_to_node_encryption { enabled = true }
              domain_endpoint_options {
                enforce_https       = true
                tls_security_policy = "Policy-Min-TLS-1-2-2019-07"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  AdvancedSecurityOptions:
                    Enabled: true
                    InternalUserDatabaseEnabled: true
                    MasterUserOptions:
                      MasterUserName: "admin"
                      MasterUserPassword: !Ref MasterPassword
                  EncryptionAtRestOptions:
                    Enabled: true
                  NodeToNodeEncryptionOptions:
                    Enabled: true
                  DomainEndpointOptions:
                    EnforceHTTPS: true
                    TLSSecurityPolicy: "Policy-Min-TLS-1-2-2019-07"
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/fgac.html
        title: AWS Documentation - Fine-grained access control in Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.advancedSecurityEnabled == true
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(advancedSecurityEnabled == true)
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "advanced_security_options") != empty &&
        blocks.where(type == "advanced_security_options").all(arguments.enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.advanced_security_options != empty &&
        change.after.advanced_security_options.all(enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-fine-grained-access-control-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.advanced_security_options != empty &&
        values.advanced_security_options.all(enabled == true)
      )
  - uid: mondoo-aws-security-opensearch-audit-logging
    title: Ensure Amazon OpenSearch Service domains have audit logging enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-opensearch-audit-logging-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-audit-logging-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-audit-logging-terraform-hcl
      - uid: mondoo-aws-security-opensearch-audit-logging-terraform-plan
      - uid: mondoo-aws-security-opensearch-audit-logging-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains have audit logging enabled. Audit logs capture authentication attempts, access to indices, queries executed, and changes to the domain configuration, providing a detailed record of activity for security monitoring and compliance.

        **Why this matters**

        - Without audit logging, unauthorized access attempts and data exfiltration go undetected.
        - Security investigations and forensic analysis require detailed access logs to reconstruct events.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 require logging of access to systems containing sensitive data.
        - AWS Security Hub control OpenSearch.4 recommends enabling audit logging.

        **Risk mitigation:**

        - **Threat detection:** Enables detection of unauthorized access attempts and anomalous query patterns.
        - **Forensic readiness:** Provides detailed audit trail for incident investigation and response.
        - **Compliance:** Meets regulatory requirements for access logging and monitoring.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select the Logs tab and then Edit.
            4. Enable Audit logs and select a CloudWatch log group as the destination.
            5. Select Save changes.

            Note: Audit logging requires fine-grained access control to be enabled.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if audit logging is enabled:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.LogPublishingOptions.AUDIT_LOGS"
            ```

            Enable audit logging:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --log-publishing-options '{"AUDIT_LOGS": {"CloudWatchLogsLogGroupArn": "arn:aws:logs:us-east-1:123456789012:log-group:/aws/opensearch/domains/example/audit-logs", "Enabled": true}}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              log_publishing_options {
                cloudwatch_log_group_arn = aws_cloudwatch_log_group.audit.arn
                log_type                = "AUDIT_LOGS"
                enabled                 = true
              }
            }

            resource "aws_cloudwatch_log_group" "audit" {
              name              = "/aws/opensearch/domains/example/audit-logs"
              retention_in_days = 365
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  LogPublishingOptions:
                    AUDIT_LOGS:
                      CloudWatchLogsLogGroupArn: !GetAtt AuditLogGroup.Arn
                      Enabled: true

              AuditLogGroup:
                Type: "AWS::Logs::LogGroup"
                Properties:
                  LogGroupName: "/aws/opensearch/domains/example/audit-logs"
                  RetentionInDays: 365
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/audit-logs.html
        title: AWS Documentation - Monitoring audit logs in Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-audit-logging-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.auditLogEnabled == true
  - uid: mondoo-aws-security-opensearch-audit-logging-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(auditLogEnabled == true)
  - uid: mondoo-aws-security-opensearch-audit-logging-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "log_publishing_options").where(arguments.log_type == "AUDIT_LOGS") != empty &&
        blocks.where(type == "log_publishing_options").where(arguments.log_type == "AUDIT_LOGS").all(arguments.enabled != false)
      )
  - uid: mondoo-aws-security-opensearch-audit-logging-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.log_publishing_options != empty &&
        change.after.log_publishing_options.any(log_type == "AUDIT_LOGS")
      )
  - uid: mondoo-aws-security-opensearch-audit-logging-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.log_publishing_options != empty &&
        values.log_publishing_options.any(log_type == "AUDIT_LOGS")
      )
  - uid: mondoo-aws-security-opensearch-in-vpc
    title: Ensure Amazon OpenSearch Service domains are deployed within a VPC
    impact: 80
    variants:
      - uid: mondoo-aws-security-opensearch-in-vpc-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-in-vpc-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-in-vpc-terraform-hcl
      - uid: mondoo-aws-security-opensearch-in-vpc-terraform-plan
      - uid: mondoo-aws-security-opensearch-in-vpc-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains are deployed within a VPC rather than using a public endpoint. Domains deployed outside a VPC are accessible from the internet, significantly increasing the attack surface and risk of unauthorized access.

        **Why this matters**

        - Public OpenSearch domains are accessible from any IP address on the internet, making them targets for brute-force attacks and exploitation of vulnerabilities.
        - Data indexed in public domains can potentially be accessed by unauthorized parties if access policies are misconfigured.
        - AWS Security Hub control OpenSearch.2 requires OpenSearch domains to be in a VPC.
        - VPC deployment enables use of security groups and network ACLs for additional access control layers.

        **Risk mitigation:**

        - **Network isolation:** Restricts access to the domain to resources within the VPC or connected networks.
        - **Defense in depth:** Enables use of security groups and NACLs as additional access control mechanisms.
        - **Reduced attack surface:** Eliminates direct internet exposure of the OpenSearch endpoint.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            Note: You cannot migrate an existing public domain into a VPC. You must create a new domain within a VPC and migrate your data.

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select Create domain.
            3. Under Network, select VPC access.
            4. Select the VPC, subnets, and security groups for the domain.
            5. Complete the remaining configuration and select Create.
            6. Migrate data from the old public domain to the new VPC domain using a snapshot or reindex operation.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a domain is in a VPC:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.VPCOptions"
            ```

            If the output is null or empty, the domain is using a public endpoint. Create a new domain within a VPC:

            ```bash
            aws opensearch create-domain --domain-name <new-domain-name> \
              --engine-version "OpenSearch_2.11" \
              --vpc-options '{"SubnetIds": ["subnet-12345"], "SecurityGroupIds": ["sg-12345"]}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              vpc_options {
                subnet_ids         = [aws_subnet.private.id]
                security_group_ids = [aws_security_group.opensearch.id]
              }
            }

            resource "aws_security_group" "opensearch" {
              name   = "opensearch-sg"
              vpc_id = aws_vpc.main.id

              ingress {
                from_port   = 443
                to_port     = 443
                protocol    = "tcp"
                cidr_blocks = [aws_vpc.main.cidr_block]
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  VPCOptions:
                    SubnetIds:
                      - !Ref PrivateSubnet
                    SecurityGroupIds:
                      - !Ref OpenSearchSecurityGroup
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/vpc.html
        title: AWS Documentation - Launching your Amazon OpenSearch Service domains within a VPC
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-in-vpc-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.vpcId != ""
  - uid: mondoo-aws-security-opensearch-in-vpc-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(vpcId != "")
  - uid: mondoo-aws-security-opensearch-in-vpc-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "vpc_options") != empty
      )
  - uid: mondoo-aws-security-opensearch-in-vpc-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.vpc_options != empty
      )
  - uid: mondoo-aws-security-opensearch-in-vpc-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.vpc_options != empty
      )
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled
    title: Ensure Amazon OpenSearch Service domains do not allow anonymous authentication
    impact: 90
    variants:
      - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-single
        tags:
          mondoo.com/filter-title: "AWS OpenSearch Domain"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-hcl
      - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-plan
      - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains do not have anonymous authentication enabled. When anonymous authentication is enabled, unauthenticated users can access the domain and its data without providing credentials, posing a severe security risk.

        **Why this matters**

        - Anonymous authentication allows anyone with network access to query, modify, or delete data in the OpenSearch domain without credentials.
        - Sensitive data indexed in the domain is exposed to unauthorized access.
        - Anonymous access bypasses fine-grained access control policies, rendering role-based permissions ineffective for unauthenticated requests.
        - This setting is sometimes enabled during development and mistakenly left active in production.

        **Risk mitigation:**

        - **Authentication enforcement:** Ensures all requests to the domain must be authenticated.
        - **Data protection:** Prevents unauthorized users from accessing indexed data.
        - **Access control integrity:** Ensures fine-grained access control policies are applied to all requests.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon OpenSearch Service Console.
            2. Select the domain you want to update.
            3. Select Edit security configuration.
            4. Under Fine-grained access control, ensure Anonymous auth is disabled (unchecked).
            5. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if anonymous authentication is enabled:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> \
              --query "DomainStatus.AdvancedSecurityOptions.AnonymousAuthEnabled"
            ```

            Disable anonymous authentication:

            ```bash
            aws opensearch update-domain-config --domain-name <domain-name> \
              --advanced-security-options '{"AnonymousAuthEnabled": false}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_opensearch_domain" "example" {
              domain_name    = "example-domain"
              engine_version = "OpenSearch_2.11"

              advanced_security_options {
                enabled                        = true
                anonymous_auth_enabled         = false  # Disable anonymous auth
                internal_user_database_enabled = true
                master_user_options {
                  master_user_name     = "admin"
                  master_user_password = var.master_user_password
                }
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              OpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "example-domain"
                  EngineVersion: "OpenSearch_2.11"
                  AdvancedSecurityOptions:
                    Enabled: true
                    AnonymousAuthEnabled: false
                    InternalUserDatabaseEnabled: true
                    MasterUserOptions:
                      MasterUserName: "admin"
                      MasterUserPassword: !Ref MasterPassword
            ```
    refs:
      - url: https://docs.aws.amazon.com/opensearch-service/latest/developerguide/fgac.html
        title: AWS Documentation - Fine-grained access control in Amazon OpenSearch Service
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/opensearch-controls.html
        title: AWS Documentation - OpenSearch controls
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-single
    filters: asset.platform == "aws-opensearch-domain"
    mql: aws.opensearch.domain.anonymousAuthEnabled != true
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-api
    filters: asset.platform == "aws"
    mql: aws.opensearch.domains.all(anonymousAuthEnabled != true)
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").all(
        blocks.where(type == "advanced_security_options").all(arguments.anonymous_auth_enabled != true)
      )
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").all(
        change.after.advanced_security_options.all(anonymous_auth_enabled != true)
      )
  - uid: mondoo-aws-security-opensearch-anonymous-auth-disabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").all(
        values.advanced_security_options.all(anonymous_auth_enabled != true)
      )
  - uid: mondoo-aws-security-ecr-image-scan-on-push
    title: Ensure ECR repositories have image scanning on push enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-ecr-image-scan-on-push-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-hcl
      - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-plan
      - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Container Registry (ECR) repositories are configured with image scanning on push. When enabled, ECR automatically scans container images for known vulnerabilities as they are pushed to the repository, providing early detection of security issues in the CI/CD pipeline.

        **Why this matters**

        Container images often contain operating system packages and application dependencies that may have known vulnerabilities. Without automated scanning:

        - Vulnerable images may be deployed to production environments undetected.
        - Security teams lack visibility into the vulnerability posture of container images.
        - Compliance frameworks such as CIS, PCI DSS, and SOC 2 require vulnerability management for container workloads.

        **Risk mitigation:**

        - **Early detection:** Identifies vulnerabilities before images are deployed to production.
        - **Automated security:** Eliminates reliance on manual scanning processes.
        - **Compliance:** Meets regulatory requirements for container image vulnerability management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECR Console.
            2. Select the repository you want to configure.
            3. Select Edit.
            4. Under Image scan settings, enable Scan on push.
            5. Select Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if image scanning on push is enabled:

            ```bash
            aws ecr describe-repositories --query "repositories[*].{Name:repositoryName, ScanOnPush:imageScanningConfiguration.scanOnPush}"
            ```

            Enable scanning on push for a repository:

            ```bash
            aws ecr put-image-scanning-configuration \
              --repository-name <repository-name> \
              --image-scanning-configuration scanOnPush=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_ecr_repository" "example" {
              name = "example-repo"

              image_scanning_configuration {
                scan_on_push = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ECRRepository:
                Type: "AWS::ECR::Repository"
                Properties:
                  RepositoryName: "example-repo"
                  ImageScanningConfiguration:
                    ScanOnPush: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html
        title: AWS Documentation - Amazon ECR image scanning
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/ecr-controls.html
        title: AWS Documentation - ECR controls
  - uid: mondoo-aws-security-ecr-image-scan-on-push-api
    filters: asset.platform == "aws"
    mql: aws.ecr.privateRepositories.all(imageScanOnPush == true)
  - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecr_repository")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecr_repository").all(
        blocks.where(type == "image_scanning_configuration") != empty &&
        blocks.where(type == "image_scanning_configuration").all(arguments.scan_on_push == true)
      )
  - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecr_repository")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecr_repository").all(
        change.after.image_scanning_configuration != empty &&
        change.after.image_scanning_configuration.all(scan_on_push == true)
      )
  - uid: mondoo-aws-security-ecr-image-scan-on-push-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecr_repository")
    mql: |
      terraform.state.resources.where(type == "aws_ecr_repository").all(
        values.image_scanning_configuration != empty &&
        values.image_scanning_configuration.all(scan_on_push == true)
      )
  - uid: mondoo-aws-security-ecr-tag-immutability
    title: Ensure ECR repositories have image tag immutability enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-ecr-tag-immutability-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecr-tag-immutability-terraform-hcl
      - uid: mondoo-aws-security-ecr-tag-immutability-terraform-plan
      - uid: mondoo-aws-security-ecr-tag-immutability-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ECR repositories are configured with image tag immutability. When tag immutability is enabled, it prevents image tags from being overwritten, ensuring that once an image is tagged, the tag always refers to the same image digest.

        **Why this matters**

        Without tag immutability, an attacker or misconfigured pipeline could overwrite a trusted image tag with a malicious or vulnerable image:

        - Deployments referencing a specific tag (e.g., `v1.2.3`) could silently pull a different image.
        - Supply chain attacks become possible by replacing known-good images with compromised ones.
        - Audit trails become unreliable when tags can point to different images over time.

        **Risk mitigation:**

        - **Supply chain security:** Prevents tag overwrites that could introduce malicious code.
        - **Deployment integrity:** Ensures tags always reference the same image content.
        - **Auditability:** Maintains a reliable history of what was deployed.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECR Console.
            2. Select the repository you want to configure.
            3. Select Edit.
            4. Under Tag immutability, select Enabled.
            5. Select Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check tag immutability settings:

            ```bash
            aws ecr describe-repositories --query "repositories[*].{Name:repositoryName, TagImmutability:imageTagMutability}"
            ```

            Enable tag immutability:

            ```bash
            aws ecr put-image-tag-mutability \
              --repository-name <repository-name> \
              --image-tag-mutability IMMUTABLE
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_ecr_repository" "example" {
              name                 = "example-repo"
              image_tag_mutability = "IMMUTABLE"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ECRRepository:
                Type: "AWS::ECR::Repository"
                Properties:
                  RepositoryName: "example-repo"
                  ImageTagMutability: "IMMUTABLE"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-tag-mutability.html
        title: AWS Documentation - Image tag mutability
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/ecr-controls.html
        title: AWS Documentation - ECR controls
  - uid: mondoo-aws-security-ecr-tag-immutability-api
    filters: asset.platform == "aws"
    mql: aws.ecr.privateRepositories.all(imageTagMutability == "IMMUTABLE")
  - uid: mondoo-aws-security-ecr-tag-immutability-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecr_repository")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecr_repository").all(
        arguments.image_tag_mutability == "IMMUTABLE"
      )
  - uid: mondoo-aws-security-ecr-tag-immutability-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecr_repository")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecr_repository").all(
        change.after.image_tag_mutability == "IMMUTABLE"
      )
  - uid: mondoo-aws-security-ecr-tag-immutability-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecr_repository")
    mql: |
      terraform.state.resources.where(type == "aws_ecr_repository").all(
        values.image_tag_mutability == "IMMUTABLE"
      )
  - uid: mondoo-aws-security-ecs-no-privileged-containers
    title: Ensure ECS task definitions do not allow privileged containers
    impact: 90
    variants:
      - uid: mondoo-aws-security-ecs-no-privileged-containers-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-hcl
      - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-plan
      - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ECS task definitions do not configure containers to run in privileged mode. A privileged container has elevated access to the host system, effectively gaining root-level capabilities on the underlying EC2 instance or Fargate host.

        **Why this matters**

        Running privileged containers poses severe security risks:

        - A privileged container can access the host's devices, file systems, and kernel, enabling container escape attacks.
        - An attacker who compromises a privileged container can escalate to full control of the host and potentially other containers running on it.
        - Privileged containers bypass most Linux security mechanisms including AppArmor, SELinux, and seccomp profiles.

        **Risk mitigation:**

        - **Container isolation:** Maintains the security boundary between the container and the host system.
        - **Blast radius reduction:** Limits the impact of a container compromise to the container itself.
        - **Compliance:** Meets CIS Docker Benchmark and container security best practices.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECS Console.
            2. Select Task definitions in the left panel.
            3. Select the task definition to review.
            4. For each container definition, check the Privileged setting under Linux parameters.
            5. Ensure Privileged is unchecked (disabled) for all containers.
            6. If a container is running as privileged, create a new revision with the setting disabled.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for privileged containers in task definitions:

            ```bash
            aws ecs list-task-definitions --status ACTIVE --query "taskDefinitionArns" | \
              xargs -I {} aws ecs describe-task-definition --task-definition {} \
              --query "taskDefinition.containerDefinitions[*].{Name:name, Privileged:privileged}"
            ```

            Register a new task definition revision without privileged mode:

            ```bash
            aws ecs register-task-definition --cli-input-json file://task-definition.json
            ```

            Ensure the container definition in your JSON file has `"privileged": false` or omits the field entirely.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure container definitions do not set privileged to true:

            ```hcl
            resource "aws_ecs_task_definition" "example" {
              family = "example"

              container_definitions = jsonencode([
                {
                  name      = "app"
                  image     = "example:latest"
                  essential = true
                  privileged = false  # Must be false or omitted
                }
              ])
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              TaskDefinition:
                Type: "AWS::ECS::TaskDefinition"
                Properties:
                  Family: "example"
                  ContainerDefinitions:
                    - Name: "app"
                      Image: "example:latest"
                      Essential: true
                      Privileged: false
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/security-runtime.html
        title: AWS Documentation - Runtime security for Amazon ECS
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/ecs-controls.html
        title: AWS Documentation - ECS controls
  - uid: mondoo-aws-security-ecs-no-privileged-containers-api
    filters: asset.platform == "aws"
    mql: |
      aws.ecs.taskDefinitions.all(
        containerDefinitions.all(privileged != true)
      )
  - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecs_task_definition")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecs_task_definition").all(
        arguments.container_definitions.all(_['privileged'] != true)
      )
  - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecs_task_definition").all(
        change.after.container_definitions.all(_['privileged'] != true)
      )
  - uid: mondoo-aws-security-ecs-no-privileged-containers-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.state.resources.where(type == "aws_ecs_task_definition").all(
        values.container_definitions.all(_['privileged'] != true)
      )
  - uid: mondoo-aws-security-ecs-readonly-root-filesystem
    title: Ensure ECS task definitions configure read-only root filesystems for containers
    impact: 70
    variants:
      - uid: mondoo-aws-security-ecs-readonly-root-filesystem-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-hcl
      - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-plan
      - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ECS task definitions configure containers with read-only root filesystems. A read-only root filesystem prevents processes inside the container from writing to the container's file system, forcing the use of explicit volume mounts for any writable data.

        **Why this matters**

        Without a read-only root filesystem:

        - An attacker who gains code execution inside a container can write malicious binaries, scripts, or configuration changes to the file system.
        - Malware can persist within the container by modifying system files.
        - Web shells and backdoors can be written to the container's file system for ongoing access.

        Enabling read-only root filesystems is a defense-in-depth measure that significantly reduces the impact of container compromises.

        **Risk mitigation:**

        - **Tamper prevention:** Prevents unauthorized modification of container binaries and configuration.
        - **Malware persistence:** Makes it harder for attackers to establish persistence within a container.
        - **Compliance:** Aligns with CIS Docker Benchmark recommendations and container hardening best practices.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECS Console.
            2. Select Task definitions in the left panel.
            3. Select the task definition to review.
            4. For each container definition, check the Storage and logging section.
            5. Enable Read only root file system.
            6. Add volume mounts for any directories that require write access (e.g., `/tmp`, `/var/log`).
            7. Create a new revision with the updated settings.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check read-only root filesystem settings:

            ```bash
            aws ecs list-task-definitions --status ACTIVE --query "taskDefinitionArns" | \
              xargs -I {} aws ecs describe-task-definition --task-definition {} \
              --query "taskDefinition.containerDefinitions[*].{Name:name, ReadonlyRootFilesystem:readonlyRootFilesystem}"
            ```

            Register a new task definition revision with read-only root filesystem:

            ```bash
            aws ecs register-task-definition --cli-input-json file://task-definition.json
            ```

            Ensure the container definition has `"readonlyRootFilesystem": true`.
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_ecs_task_definition" "example" {
              family = "example"

              container_definitions = jsonencode([
                {
                  name                   = "app"
                  image                  = "example:latest"
                  essential              = true
                  readonlyRootFilesystem = true
                  mountPoints = [
                    {
                      sourceVolume  = "tmp"
                      containerPath = "/tmp"
                    }
                  ]
                }
              ])

              volume {
                name = "tmp"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              TaskDefinition:
                Type: "AWS::ECS::TaskDefinition"
                Properties:
                  Family: "example"
                  ContainerDefinitions:
                    - Name: "app"
                      Image: "example:latest"
                      Essential: true
                      ReadonlyRootFilesystem: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/security-runtime.html
        title: AWS Documentation - Runtime security for Amazon ECS
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/ecs-controls.html
        title: AWS Documentation - ECS controls
  - uid: mondoo-aws-security-ecs-readonly-root-filesystem-api
    filters: asset.platform == "aws"
    mql: |
      aws.ecs.taskDefinitions.all(
        containerDefinitions.all(readonlyRootFilesystem == true)
      )
  - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecs_task_definition")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecs_task_definition").all(
        arguments.container_definitions.all(_['readonlyRootFilesystem'] == true)
      )
  - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecs_task_definition").all(
        change.after.container_definitions.all(_['readonlyRootFilesystem'] == true)
      )
  - uid: mondoo-aws-security-ecs-readonly-root-filesystem-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.state.resources.where(type == "aws_ecs_task_definition").all(
        values.container_definitions.all(_['readonlyRootFilesystem'] == true)
      )
  - uid: mondoo-aws-security-ecs-logging-enabled
    title: Ensure ECS task definitions have logging configured for all containers
    impact: 60
    variants:
      - uid: mondoo-aws-security-ecs-logging-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecs-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-ecs-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-ecs-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that all container definitions within Amazon ECS task definitions have a log configuration specified. Without logging, container activity goes unrecorded, making it impossible to detect security incidents, troubleshoot failures, or meet audit requirements.

        **Why this matters**

        Containers without logging configured create blind spots in your security monitoring:

        - Security incidents within containers cannot be detected or investigated.
        - No audit trail exists for container activity, hindering forensic analysis.
        - Application errors and failures go unrecorded, making troubleshooting difficult.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 require logging of application activity.

        **Risk mitigation:**

        - **Incident detection:** Enables real-time monitoring and alerting for security events in containers.
        - **Forensics:** Provides detailed logs for investigating security incidents.
        - **Compliance:** Meets regulatory requirements for logging and audit trails.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECS Console.
            2. Select Task definitions in the left panel.
            3. Select the task definition to review.
            4. For each container definition, check the Storage and logging section.
            5. Configure a log driver (e.g., `awslogs` for CloudWatch Logs).
            6. Specify the log group, region, and stream prefix.
            7. Create a new revision with the updated settings.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check logging configuration for task definitions:

            ```bash
            aws ecs list-task-definitions --status ACTIVE --query "taskDefinitionArns" | \
              xargs -I {} aws ecs describe-task-definition --task-definition {} \
              --query "taskDefinition.containerDefinitions[*].{Name:name, LogConfig:logConfiguration}"
            ```

            Register a new task definition with logging configured:

            ```bash
            aws ecs register-task-definition --cli-input-json file://task-definition.json
            ```

            Ensure the container definition includes a `logConfiguration` block:

            ```json
            {
              "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                  "awslogs-group": "/ecs/example",
                  "awslogs-region": "us-east-1",
                  "awslogs-stream-prefix": "ecs"
                }
              }
            }
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_ecs_task_definition" "example" {
              family = "example"

              container_definitions = jsonencode([
                {
                  name      = "app"
                  image     = "example:latest"
                  essential = true
                  logConfiguration = {
                    logDriver = "awslogs"
                    options = {
                      "awslogs-group"         = "/ecs/example"
                      "awslogs-region"        = "us-east-1"
                      "awslogs-stream-prefix" = "ecs"
                    }
                  }
                }
              ])
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              TaskDefinition:
                Type: "AWS::ECS::TaskDefinition"
                Properties:
                  Family: "example"
                  ContainerDefinitions:
                    - Name: "app"
                      Image: "example:latest"
                      Essential: true
                      LogConfiguration:
                        LogDriver: "awslogs"
                        Options:
                          awslogs-group: "/ecs/example"
                          awslogs-region: "us-east-1"
                          awslogs-stream-prefix: "ecs"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html
        title: AWS Documentation - Using the awslogs log driver
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/ecs-controls.html
        title: AWS Documentation - ECS controls
  - uid: mondoo-aws-security-ecs-logging-enabled-api
    filters: asset.platform == "aws"
    mql: |
      aws.ecs.taskDefinitions.all(
        containerDefinitions.all(logConfiguration != empty)
      )
  - uid: mondoo-aws-security-ecs-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecs_task_definition")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecs_task_definition").all(
        arguments.container_definitions.all(_['logConfiguration'] != empty)
      )
  - uid: mondoo-aws-security-ecs-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecs_task_definition").all(
        change.after.container_definitions.all(_['logConfiguration'] != empty)
      )
  - uid: mondoo-aws-security-ecs-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.state.resources.where(type == "aws_ecs_task_definition").all(
        values.container_definitions.all(_['logConfiguration'] != empty)
      )
  - uid: mondoo-aws-security-efs-backup-enabled
    title: Ensure EFS file systems have automatic backups enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-efs-backup-enabled-single
        tags:
          mondoo.com/filter-title: "AWS EFS File System"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-efs-backup-enabled-terraform-hcl
      - uid: mondoo-aws-security-efs-backup-enabled-terraform-plan
      - uid: mondoo-aws-security-efs-backup-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic File System (EFS) file systems have automatic backups enabled through AWS Backup. Without backups, data stored in EFS is at risk of permanent loss due to accidental deletion, corruption, or ransomware attacks.

        **Why this matters**

        EFS file systems often store critical application data, configuration files, and shared resources. Without automatic backups:

        - Data loss from accidental deletion or corruption cannot be recovered.
        - Ransomware attacks could encrypt data with no recovery option.
        - Compliance frameworks such as HIPAA, PCI DSS, and SOC 2 require data backup and recovery capabilities.

        **Risk mitigation:**

        - **Data recovery:** Enables restoration of data from backups in the event of data loss.
        - **Ransomware protection:** Provides a clean recovery point if data is encrypted by ransomware.
        - **Compliance:** Meets regulatory requirements for data protection and business continuity.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EFS Console.
            2. Select the file system you want to configure.
            3. Under the General section, check the Automatic backups setting.
            4. If disabled, select Edit, enable Automatic backups, and select Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if automatic backups are enabled:

            ```bash
            aws efs describe-backup-policy --file-system-id <file-system-id>
            ```

            Enable automatic backups:

            ```bash
            aws efs put-backup-policy --file-system-id <file-system-id> \
              --backup-policy Status=ENABLED
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_efs_file_system" "example" {
              encrypted = true
            }

            resource "aws_efs_backup_policy" "example" {
              file_system_id = aws_efs_file_system.example.id

              backup_policy {
                status = "ENABLED"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              EFSFileSystem:
                Type: "AWS::EFS::FileSystem"
                Properties:
                  Encrypted: true
                  BackupPolicy:
                    Status: "ENABLED"
            ```
    refs:
      - url: https://docs.aws.amazon.com/efs/latest/ug/awsbackup.html
        title: AWS Documentation - Using AWS Backup to back up and restore Amazon EFS file systems
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/efs-controls.html
        title: AWS Documentation - EFS controls
  - uid: mondoo-aws-security-efs-backup-enabled-single
    filters: asset.platform == "aws-efs-filesystem"
    mql: aws.efs.filesystem.backupPolicy["Status"] == "ENABLED"
  - uid: mondoo-aws-security-efs-backup-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_efs_backup_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_efs_backup_policy").all(
        blocks.where(type == "backup_policy") != empty &&
        blocks.where(type == "backup_policy").all(arguments.status == "ENABLED")
      )
  - uid: mondoo-aws-security-efs-backup-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_efs_backup_policy")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_efs_backup_policy").all(
        change.after.backup_policy.all(status == "ENABLED")
      )
  - uid: mondoo-aws-security-efs-backup-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_efs_backup_policy")
    mql: |
      terraform.state.resources.where(type == "aws_efs_backup_policy").all(
        values.backup_policy.all(status == "ENABLED")
      )
  - uid: mondoo-aws-security-elb-drop-invalid-headers
    title: Ensure Application Load Balancers are configured to drop invalid HTTP headers
    impact: 60
    variants:
      - uid: mondoo-aws-security-elb-drop-invalid-headers-single
        tags:
          mondoo.com/filter-title: "AWS Application Load Balancer"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-hcl
      - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-plan
      - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured to drop HTTP headers that are not valid. Invalid HTTP headers can be used in HTTP request smuggling attacks, which exploit discrepancies between how front-end and back-end servers parse HTTP requests to bypass security controls.

        **Why this matters**

        Without dropping invalid headers:

        - ALBs may forward malformed HTTP headers to backend applications, enabling request smuggling attacks.
        - Attackers can bypass WAF rules, authentication, and authorization controls.
        - Cache poisoning attacks become possible when invalid headers are passed through to caching layers.

        **Risk mitigation:**

        - **Request smuggling prevention:** Eliminates a common attack vector by dropping invalid headers before they reach backend services.
        - **Defense in depth:** Adds an additional security layer at the load balancer level.
        - **Compliance:** Aligns with AWS Security Hub recommendations for ALB security.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer.
            4. Select the Attributes tab.
            5. Select Edit.
            6. Enable Drop invalid header fields.
            7. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if dropping invalid headers is enabled:

            ```bash
            aws elbv2 describe-load-balancer-attributes \
              --load-balancer-arn <load-balancer-arn> \
              --query "Attributes[?Key=='routing.http.drop_invalid_header_fields.enabled']"
            ```

            Enable dropping invalid headers:

            ```bash
            aws elbv2 modify-load-balancer-attributes \
              --load-balancer-arn <load-balancer-arn> \
              --attributes Key=routing.http.drop_invalid_header_fields.enabled,Value=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_lb" "example" {
              name               = "example-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.alb_sg.id]
              subnets            = [aws_subnet.public1.id, aws_subnet.public2.id]

              drop_invalid_header_fields = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ApplicationLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "example-alb"
                  Type: "application"
                  Scheme: "internet-facing"
                  Subnets:
                    - !Ref PublicSubnet1
                    - !Ref PublicSubnet2
                  SecurityGroups:
                    - !Ref ALBSecurityGroup
                  LoadBalancerAttributes:
                    - Key: "routing.http.drop_invalid_header_fields.enabled"
                      Value: "true"
            ```
    refs:
      - url: https://docs.aws.amazon.com/elasticloadbalancing/latest/application/application-load-balancers.html
        title: AWS Documentation - Application Load Balancers
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/elb-controls.html
        title: AWS Documentation - ELB controls
  - uid: mondoo-aws-security-elb-drop-invalid-headers-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.attributes.where(Key == "routing.http.drop_invalid_header_fields.enabled").all(Value == true)
  - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb").all(
        arguments.drop_invalid_header_fields == true
      )
  - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb").all(
        change.after.drop_invalid_header_fields == true
      )
  - uid: mondoo-aws-security-elb-drop-invalid-headers-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb")
    mql: |
      terraform.state.resources.where(type == "aws_lb").all(
        values.drop_invalid_header_fields == true
      )
  - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet
    title: Ensure SageMaker notebook instances do not have direct internet access
    impact: 80
    variants:
      - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-single
        tags:
          mondoo.com/filter-title: "AWS SageMaker Notebook Instance"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-hcl
      - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-plan
      - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SageMaker notebook instances do not have direct internet access enabled. When direct internet access is enabled, the notebook instance can communicate directly with the internet, bypassing VPC network controls and potentially exposing sensitive data and models.

        **Why this matters**

        SageMaker notebook instances often contain sensitive machine learning data, proprietary models, and access to training datasets. Direct internet access:

        - Allows data exfiltration from the notebook instance to external destinations.
        - Exposes the instance to inbound attacks from the internet.
        - Bypasses VPC security controls, network ACLs, and security groups.
        - Violates the principle of least privilege for network access.

        **Risk mitigation:**

        - **Data exfiltration prevention:** Restricts outbound network access to VPC-controlled paths.
        - **Attack surface reduction:** Eliminates direct internet exposure of the notebook instance.
        - **Network control:** Ensures all traffic flows through VPC endpoints and NAT gateways where it can be monitored and controlled.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            Note: Direct internet access cannot be changed on an existing notebook instance. You must create a new instance.

            1. Navigate to the Amazon SageMaker Console.
            2. Select Notebook instances in the left panel.
            3. Select Create notebook instance.
            4. Under Network, select a VPC, subnet, and security group.
            5. Under Direct internet access, select Disable.
            6. Complete the remaining configuration and select Create notebook instance.
            7. Migrate your work from the old instance and delete it.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if direct internet access is enabled:

            ```bash
            aws sagemaker describe-notebook-instance \
              --notebook-instance-name <instance-name> \
              --query "DirectInternetAccess"
            ```

            The output should be `"Disabled"`. If it is `"Enabled"`, create a new instance without direct internet access:

            ```bash
            aws sagemaker create-notebook-instance \
              --notebook-instance-name "secure-notebook" \
              --instance-type "ml.t3.medium" \
              --role-arn "arn:aws:iam::<account-id>:role/SageMakerRole" \
              --subnet-id <subnet-id> \
              --security-group-ids <sg-id> \
              --direct-internet-access "Disabled"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_sagemaker_notebook_instance" "example" {
              name                    = "secure-notebook"
              instance_type           = "ml.t3.medium"
              role_arn                = aws_iam_role.sagemaker_role.arn
              subnet_id               = aws_subnet.private.id
              security_groups         = [aws_security_group.sagemaker_sg.id]
              direct_internet_access  = "Disabled"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SageMakerNotebook:
                Type: "AWS::SageMaker::NotebookInstance"
                Properties:
                  NotebookInstanceName: "secure-notebook"
                  InstanceType: "ml.t3.medium"
                  RoleArn: !GetAtt SageMakerRole.Arn
                  SubnetId: !Ref PrivateSubnet
                  SecurityGroupIds:
                    - !Ref SageMakerSecurityGroup
                  DirectInternetAccess: "Disabled"
            ```
    refs:
      - url: https://docs.aws.amazon.com/sagemaker/latest/dg/appendix-notebook-and-internet-access.html
        title: AWS Documentation - Notebook Instance Internet Access
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/sagemaker-controls.html
        title: AWS Documentation - SageMaker controls
  - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-single
    filters: asset.platform == "aws-sagemaker-notebookinstance"
    mql: aws.sagemaker.notebookinstance.details.directInternetAccess == "Disabled"
  - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_sagemaker_notebook_instance").all(
        arguments.direct_internet_access == "Disabled"
      )
  - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sagemaker_notebook_instance").all(
        change.after.direct_internet_access == "Disabled"
      )
  - uid: mondoo-aws-security-sagemaker-notebook-no-direct-internet-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.state.resources.where(type == "aws_sagemaker_notebook_instance").all(
        values.direct_internet_access == "Disabled"
      )
  - uid: mondoo-aws-security-eks-cluster-restrict-public-access
    title: Ensure Amazon EKS public endpoint is not accessible to 0.0.0.0/0
    impact: 80
    variants:
      - uid: mondoo-aws-security-eks-cluster-restrict-public-access-api
        tags:
          mondoo.com/filter-title: "AWS EKS Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-hcl
      - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-plan
      - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EKS clusters with public endpoint access enabled restrict the CIDR blocks that can reach the API server. By default, when public endpoint access is enabled, the API server is accessible from any IP address (0.0.0.0/0), exposing it to the entire internet.

        **Why this matters**

        An EKS API server endpoint accessible from 0.0.0.0/0:

        - Allows anyone on the internet to attempt authentication against the Kubernetes API server.
        - Increases exposure to brute-force attacks, credential stuffing, and exploitation of API server vulnerabilities.
        - Violates the principle of least privilege for network access.
        - While RBAC provides authentication, network-level restrictions add critical defense in depth.

        **Risk mitigation:**

        - **Attack surface reduction:** Limits who can even attempt to reach the API server.
        - **Defense in depth:** Adds network-level access control on top of Kubernetes RBAC.
        - **Compliance:** Meets security best practices for restricting management plane access.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EKS Console.
            2. Select the EKS cluster you want to configure.
            3. In the Networking tab, select Manage networking.
            4. Under Advanced Settings, configure the Public access CIDR restrictions.
            5. Remove 0.0.0.0/0 and add only the specific CIDR blocks that need access (e.g., your corporate network).
            6. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the current public access CIDR configuration:

            ```bash
            aws eks describe-cluster --name <cluster_name> \
              --query "cluster.resourcesVpcConfig.publicAccessCidrs"
            ```

            Restrict public access to specific CIDR blocks:

            ```bash
            aws eks update-cluster-config --name <cluster_name> \
              --resources-vpc-config publicAccessCidrs="10.0.0.0/8","172.16.0.0/12"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_eks_cluster" "example" {
              name     = "example-cluster"
              role_arn = aws_iam_role.eks_role.arn

              vpc_config {
                subnet_ids              = [aws_subnet.eks_subnet.id]
                endpoint_public_access  = true
                public_access_cidrs     = ["10.0.0.0/8"]  # Restrict to specific CIDRs
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              MyEKSCluster:
                Type: AWS::EKS::Cluster
                Properties:
                  Name: example-cluster
                  RoleArn: !GetAtt eksRole.Arn
                  ResourcesVpcConfig:
                    SubnetIds:
                      - !Ref eksSubnet
                    EndpointPublicAccess: true
                    PublicAccessCidrs:
                      - "10.0.0.0/8"
            ```
    refs:
      - url: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html
        title: AWS Documentation - Amazon EKS cluster endpoint access control
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/eks-controls.html
        title: AWS Documentation - EKS controls
  - uid: mondoo-aws-security-eks-cluster-restrict-public-access-api
    filters: asset.platform == "aws-eks-cluster"
    mql: aws.eks.cluster.publicAccessCidrs.none(_ == "0.0.0.0/0")
  - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_eks_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_eks_cluster").all(
        blocks.where(type == "vpc_config") != empty &&
        blocks.where(type == "vpc_config").all(
          arguments.public_access_cidrs != empty &&
          arguments.public_access_cidrs.none(_ == "0.0.0.0/0")
        )
      )
  - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_eks_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_eks_cluster").all(
        change.after.vpc_config != empty &&
        change.after.vpc_config.all(
          _['public_access_cidrs'] != empty &&
          _['public_access_cidrs'].none(_ == "0.0.0.0/0")
        )
      )
  - uid: mondoo-aws-security-eks-cluster-restrict-public-access-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_eks_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_eks_cluster").all(
        values.vpc_config != empty &&
        values.vpc_config.all(
          _['public_access_cidrs'] != empty &&
          _['public_access_cidrs'].none(_ == "0.0.0.0/0")
        )
      )
  - uid: mondoo-aws-security-eks-cluster-deletion-protection
    title: Ensure Amazon EKS clusters have deletion protection enabled
    impact: 50
    variants:
      - uid: mondoo-aws-security-eks-cluster-deletion-protection-api
        tags:
          mondoo.com/filter-title: "AWS EKS Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-hcl
      - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-plan
      - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EKS clusters have deletion protection enabled. Deletion protection prevents accidental or unauthorized deletion of EKS clusters, which would result in the loss of all running workloads, configurations, and associated resources.

        **Why this matters**

        Without deletion protection:

        - An EKS cluster can be deleted with a single API call or console action, destroying all running workloads.
        - Accidental deletion during infrastructure changes or automation errors can cause significant downtime.
        - Malicious actors with sufficient IAM permissions could delete clusters as part of an attack.
        - Recovery requires rebuilding the cluster and redeploying all workloads, which can take hours or days.

        **Risk mitigation:**

        - **Accidental deletion prevention:** Requires explicit disabling of the protection before a cluster can be deleted.
        - **Operational safety:** Provides a safeguard against automation errors and human mistakes.
        - **Change control:** Adds an additional step that encourages proper change management processes.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EKS Console.
            2. Select the EKS cluster you want to configure.
            3. Select Manage deletion protection.
            4. Enable deletion protection.
            5. Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if deletion protection is enabled:

            ```bash
            aws eks describe-cluster --name <cluster_name> \
              --query "cluster.deletionProtection"
            ```

            The value should be `true`. To enable deletion protection:

            ```bash
            aws eks update-cluster-config --name <cluster_name> \
              --deletion-protection
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_eks_cluster" "example" {
              name                  = "example-cluster"
              role_arn              = aws_iam_role.eks_role.arn
              deletion_protection   = true  # Enable deletion protection

              vpc_config {
                subnet_ids = [aws_subnet.eks_subnet.id]
              }

              access_config {
                authentication_mode = "API"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              MyEKSCluster:
                Type: AWS::EKS::Cluster
                Properties:
                  Name: example-cluster
                  RoleArn: !GetAtt eksRole.Arn
                  ResourcesVpcConfig:
                    SubnetIds:
                      - !Ref eksSubnet
            ```
    refs:
      - url: https://docs.aws.amazon.com/eks/latest/userguide/delete-cluster.html
        title: AWS Documentation - Deleting an Amazon EKS cluster
      - url: https://docs.aws.amazon.com/eks/latest/best-practices/security.html
        title: Amazon EKS Security Best Practices
  - uid: mondoo-aws-security-eks-cluster-deletion-protection-api
    filters: asset.platform == "aws-eks-cluster"
    mql: aws.eks.cluster.deletionProtection == true
  - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_eks_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_eks_cluster").all(
        arguments.deletion_protection == true
      )
  - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_eks_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_eks_cluster").all(
        change.after.deletion_protection == true
      )
  - uid: mondoo-aws-security-eks-cluster-deletion-protection-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_eks_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_eks_cluster").all(
        values.deletion_protection == true
      )
  - uid: mondoo-aws-security-codebuild-no-privileged-mode
    title: Ensure CodeBuild projects do not run in privileged mode
    impact: 80
    variants:
      - uid: mondoo-aws-security-codebuild-no-privileged-mode-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-hcl
      - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-plan
      - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-state
    docs:
      desc: |
        This check ensures that AWS CodeBuild projects are not configured to run in privileged mode. When privileged mode is enabled on a CodeBuild project, the Docker daemon runs inside the build container with elevated access to the underlying host, granting capabilities equivalent to root-level access on the build infrastructure.

        **Why this matters**

        - Running CodeBuild projects in privileged mode grants the build container full access to the host's kernel, devices, and file systems, enabling potential container escape attacks.
        - An attacker who compromises a privileged build container can escalate privileges to the underlying host, access secrets and environment variables from other builds, and pivot to other resources in the VPC.
        - Privileged mode bypasses Linux security mechanisms such as AppArmor, SELinux, and seccomp profiles, significantly weakening the security boundary of the build environment.
        - Privileged mode should only be enabled when building Docker images, and even then, alternatives such as kaniko or buildah should be considered.

        **Risk mitigation:**

        - **Build isolation:** Maintains the security boundary between the build container and the underlying host infrastructure.
        - **Blast radius reduction:** Limits the impact of a compromised build to the container itself, preventing lateral movement.
        - **Compliance:** Aligns with CIS AWS Foundations Benchmark and container security best practices that recommend running containers without elevated privileges.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS CodeBuild Console.
            2. Select Build projects in the left panel.
            3. Select the project to review.
            4. Choose Edit and then Environment.
            5. Under Additional configuration, ensure the Enable this flag if you want to build Docker images or want your builds to get elevated privileges checkbox is unchecked.
            6. Choose Update environment to save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if privileged mode is enabled on a CodeBuild project:

            ```bash
            aws codebuild batch-get-projects --names <project-name> \
              --query "projects[*].environment.privilegedMode"
            ```

            Update the project to disable privileged mode:

            ```bash
            aws codebuild update-project --name <project-name> \
              --environment "type=LINUX_CONTAINER,image=aws/codebuild/amazonlinux2-x86_64-standard:5.0,computeType=BUILD_GENERAL1_SMALL,privilegedMode=false"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the CodeBuild project environment does not enable privileged mode:

            ```hcl
            resource "aws_codebuild_project" "example" {
              name          = "example-project"
              service_role  = aws_iam_role.codebuild_role.arn

              environment {
                compute_type    = "BUILD_GENERAL1_SMALL"
                image           = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"
                type            = "LINUX_CONTAINER"
                privileged_mode = false  # Must be false or omitted
              }

              source {
                type     = "GITHUB"
                location = "https://github.com/example/repo.git"
              }

              artifacts {
                type = "NO_ARTIFACTS"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              CodeBuildProject:
                Type: "AWS::CodeBuild::Project"
                Properties:
                  Name: "example-project"
                  ServiceRole: !GetAtt CodeBuildRole.Arn
                  Environment:
                    ComputeType: "BUILD_GENERAL1_SMALL"
                    Image: "aws/codebuild/amazonlinux2-x86_64-standard:5.0"
                    Type: "LINUX_CONTAINER"
                    PrivilegedMode: false
                  Source:
                    Type: "GITHUB"
                    Location: "https://github.com/example/repo.git"
                  Artifacts:
                    Type: "NO_ARTIFACTS"
            ```
    refs:
      - url: https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-env-vars.html
        title: AWS Documentation - Build environment reference for CodeBuild
      - url: https://docs.aws.amazon.com/codebuild/latest/userguide/security.html
        title: AWS Documentation - Security in AWS CodeBuild
  - uid: mondoo-aws-security-codebuild-no-privileged-mode-api
    filters: asset.platform == "aws"
    mql: aws.codebuild.projects.all(environment["privilegedMode"] != true)
  - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_codebuild_project")
    mql: |
      terraform.resources.where(nameLabel == "aws_codebuild_project").all(
        blocks.where(type == "environment").all(arguments.privileged_mode != true)
      )
  - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_codebuild_project")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_codebuild_project").all(
        change.after.environment.all(_['privileged_mode'] != true)
      )
  - uid: mondoo-aws-security-codebuild-no-privileged-mode-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_codebuild_project")
    mql: |
      terraform.state.resources.where(type == "aws_codebuild_project").all(
        values.environment.all(_['privileged_mode'] != true)
      )
  - uid: mondoo-aws-security-codebuild-no-plaintext-credentials
    title: Ensure CodeBuild projects do not store plaintext credentials in environment variables
    impact: 90
    variants:
      - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-hcl
      - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-plan
      - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-state
    docs:
      desc: |
        This check ensures that AWS CodeBuild projects do not use plaintext credentials for pulling container images or storing sensitive values in environment variables. Credentials should be managed through secure mechanisms such as AWS Secrets Manager, AWS Systems Manager Parameter Store, or the CodeBuild-native credential management.

        **Why this matters**

        - Plaintext credentials in CodeBuild environment configurations are visible to anyone with access to the project settings, increasing the risk of credential exposure.
        - If a build is compromised, plaintext credentials can be exfiltrated from environment variables, allowing attackers to access container registries, databases, APIs, and other sensitive resources.
        - Plaintext credentials in build configurations may be logged in CloudWatch Logs or build output, creating additional exposure vectors.
        - Using secure credential storage such as Secrets Manager or Parameter Store provides encryption, access control, rotation capabilities, and audit logging.

        **Risk mitigation:**

        - **Credential protection:** Ensures sensitive credentials are encrypted and managed through dedicated secret management services.
        - **Least privilege access:** Leverages IAM policies to control which builds and users can access specific credentials.
        - **Audit trail:** Provides CloudTrail logging for credential access, enabling detection of unauthorized retrieval.
        - **Compliance:** Meets security framework requirements (CIS, PCI DSS, SOC 2) that mandate secure credential handling.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS CodeBuild Console.
            2. Select Build projects in the left panel.
            3. Select the project to review.
            4. Choose Edit and then Environment.
            5. Under Image pull credentials, ensure Custom credentials are configured with a Secrets Manager ARN rather than using plaintext values.
            6. Under Additional configuration, review Environment variables and ensure any sensitive values use type SECRETS_MANAGER or PARAMETER_STORE instead of PLAINTEXT.
            7. Choose Update environment to save the changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the image pull credentials type for a CodeBuild project:

            ```bash
            aws codebuild batch-get-projects --names <project-name> \
              --query "projects[*].environment.{ImagePullCredentialsType:imagePullCredentialsType,RegistryCredential:registryCredential}"
            ```

            Check for plaintext environment variables:

            ```bash
            aws codebuild batch-get-projects --names <project-name> \
              --query "projects[*].environment.environmentVariables[?type=='PLAINTEXT']"
            ```

            Update the project to use Secrets Manager for image pull credentials:

            ```bash
            aws codebuild update-project --name <project-name> \
              --environment "type=LINUX_CONTAINER,image=<registry-url>/<image>,computeType=BUILD_GENERAL1_SMALL,imagePullCredentialsType=SERVICE_ROLE,registryCredential={credential=arn:aws:secretsmanager:region:account-id:secret:secret-name,credentialProvider=SECRETS_MANAGER}"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the CodeBuild project uses secure credential storage:

            ```hcl
            resource "aws_codebuild_project" "example" {
              name          = "example-project"
              service_role  = aws_iam_role.codebuild_role.arn

              environment {
                compute_type                = "BUILD_GENERAL1_SMALL"
                image                       = "example-registry/image:latest"
                type                        = "LINUX_CONTAINER"
                image_pull_credentials_type  = "SERVICE_ROLE"

                registry_credential {
                  credential          = aws_secretsmanager_secret.registry.arn
                  credential_provider = "SECRETS_MANAGER"
                }

                # Use SECRETS_MANAGER or PARAMETER_STORE for sensitive values
                environment_variable {
                  name  = "DB_PASSWORD"
                  value = "arn:aws:secretsmanager:region:account-id:secret:db-password"
                  type  = "SECRETS_MANAGER"
                }
              }

              source {
                type     = "GITHUB"
                location = "https://github.com/example/repo.git"
              }

              artifacts {
                type = "NO_ARTIFACTS"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              CodeBuildProject:
                Type: "AWS::CodeBuild::Project"
                Properties:
                  Name: "example-project"
                  ServiceRole: !GetAtt CodeBuildRole.Arn
                  Environment:
                    ComputeType: "BUILD_GENERAL1_SMALL"
                    Image: "example-registry/image:latest"
                    Type: "LINUX_CONTAINER"
                    ImagePullCredentialsType: "SERVICE_ROLE"
                    RegistryCredential:
                      Credential: !Ref RegistrySecret
                      CredentialProvider: "SECRETS_MANAGER"
                    EnvironmentVariables:
                      - Name: "DB_PASSWORD"
                        Value: !Ref DbPasswordSecret
                        Type: "SECRETS_MANAGER"
                  Source:
                    Type: "GITHUB"
                    Location: "https://github.com/example/repo.git"
                  Artifacts:
                    Type: "NO_ARTIFACTS"
            ```
    refs:
      - url: https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html
        title: AWS Documentation - Build specification reference for CodeBuild
      - url: https://docs.aws.amazon.com/codebuild/latest/userguide/change-project-console.html
        title: AWS Documentation - Change a build project's settings in CodeBuild
      - url: https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html
        title: AWS Documentation - What is AWS Secrets Manager
  - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-api
    filters: asset.platform == "aws"
    mql: |
      aws.codebuild.projects.all(
        environment["environmentVariables"]
          .where(_["type"] == "PLAINTEXT")
          .none(_["name"] == /(?i)(PASSWORD|SECRET|KEY|TOKEN|CREDENTIAL)/)
      )
      aws.codebuild.projects.all(
        environment["imagePullCredentialsType"] == "CODEBUILD" ||
        environment["imagePullCredentialsType"] == "SERVICE_ROLE"
      )
  - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_codebuild_project")
    mql: |
      terraform.resources.where(nameLabel == "aws_codebuild_project").all(
        blocks.where(type == "environment").all(
          arguments.image_pull_credentials_type == "CODEBUILD" ||
          arguments.image_pull_credentials_type == "SERVICE_ROLE"
        )
      )
      terraform.resources.where(nameLabel == "aws_codebuild_project").all(
        blocks.where(type == "environment").all(
          blocks.where(type == "environment_variable" && arguments.type == "PLAINTEXT").none(
            arguments.name == /(?i)(PASSWORD|SECRET|KEY|TOKEN|CREDENTIAL)/
          )
        )
      )
  - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_codebuild_project")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_codebuild_project").all(
        change.after.environment.all(
          _['image_pull_credentials_type'] == "CODEBUILD" ||
          _['image_pull_credentials_type'] == "SERVICE_ROLE"
        )
      )
      terraform.plan.resourceChanges.where(type == "aws_codebuild_project").all(
        change.after.environment.all(
          _['environment_variable'].where(_['type'] == "PLAINTEXT").none(
            _['name'] == /(?i)(PASSWORD|SECRET|KEY|TOKEN|CREDENTIAL)/
          )
        )
      )
  - uid: mondoo-aws-security-codebuild-no-plaintext-credentials-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_codebuild_project")
    mql: |
      terraform.state.resources.where(type == "aws_codebuild_project").all(
        values.environment.all(
          _['image_pull_credentials_type'] == "CODEBUILD" ||
          _['image_pull_credentials_type'] == "SERVICE_ROLE"
        )
      )
      terraform.state.resources.where(type == "aws_codebuild_project").all(
        values.environment.all(
          _['environment_variable'].where(_['type'] == "PLAINTEXT").none(
            _['name'] == /(?i)(PASSWORD|SECRET|KEY|TOKEN|CREDENTIAL)/
          )
        )
      )
  - uid: mondoo-aws-security-neptune-cluster-encrypted
    title: Ensure Neptune DB clusters are encrypted at rest
    impact: 80
    variants:
      - uid: mondoo-aws-security-neptune-cluster-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-hcl
      - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-plan
      - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Neptune DB clusters are configured with encryption at rest using AWS Key Management Service (KMS). Encryption at rest protects graph database data from unauthorized access by automatically encrypting data before it is written to the underlying storage infrastructure.

        **Why this matters**

        - By default, Neptune clusters may not have encryption at rest enabled. Once a Neptune cluster is created without encryption, it cannot be modified to enable encryption; a new encrypted cluster must be created and the data migrated.
        - Without encryption at rest, sensitive graph data stored in Neptune is vulnerable to unauthorized access if the underlying storage media is compromised.
        - Encryption at rest is a requirement for compliance with security frameworks including CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and SOC 2.
        - Encrypted Neptune clusters also encrypt automated backups, snapshots, and replicas, providing comprehensive data protection across the entire data lifecycle.

        **Risk mitigation:**

        - **Data protection:** Ensures all graph data, backups, and snapshots are encrypted using AWS KMS, preventing unauthorized access to stored data.
        - **Compliance:** Meets regulatory requirements for encryption of data at rest in managed database services.
        - **Key management:** Leverages AWS KMS for centralized key management, access control policies, and automatic key rotation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon Neptune Console.
            2. Select Databases in the left panel.
            3. Select the Neptune DB cluster to review.
            4. Under the Configuration tab, check if Encryption is enabled.
            5. If encryption is not enabled, you must create a new encrypted Neptune cluster:
              - Select Create database.
              - Under Encryption-at-rest, enable encryption.
              - Choose a KMS key (AWS managed or customer-managed).
              - Complete the cluster creation process.
            6. Migrate data from the unencrypted cluster to the new encrypted cluster using Neptune export/import or snapshot-based migration.
            7. Update applications to point to the new encrypted cluster endpoint.
            8. Delete the unencrypted cluster after verifying the migration.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check if a Neptune cluster is encrypted:

            ```bash
            aws neptune describe-db-clusters --db-cluster-identifier <cluster-id> \
              --query "DBClusters[*].{ClusterId:DBClusterIdentifier,Encrypted:StorageEncrypted,KmsKeyId:KmsKeyId}"
            ```

            Create a new encrypted Neptune cluster:

            ```bash
            aws neptune create-db-cluster \
              --db-cluster-identifier secure-neptune-cluster \
              --engine neptune \
              --storage-encrypted \
              --kms-key-id arn:aws:kms:region:account-id:key/key-id
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure Neptune clusters are created with encryption at rest enabled:

            ```hcl
            resource "aws_kms_key" "neptune_kms_key" {
              description         = "KMS key for Neptune encryption"
              enable_key_rotation = true
            }

            resource "aws_neptune_cluster" "example" {
              cluster_identifier  = "secure-neptune-cluster"
              engine              = "neptune"
              storage_encrypted   = true
              kms_key_arn         = aws_kms_key.neptune_kms_key.arn

              skip_final_snapshot = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              NeptuneKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for Neptune encryption"
                  EnableKeyRotation: true

              NeptuneCluster:
                Type: "AWS::Neptune::DBCluster"
                Properties:
                  DBClusterIdentifier: "secure-neptune-cluster"
                  StorageEncrypted: true
                  KmsKeyId: !Ref NeptuneKMSKey
            ```
    refs:
      - url: https://docs.aws.amazon.com/neptune/latest/userguide/encrypt.html
        title: AWS Documentation - Encrypting Neptune resources
      - url: https://docs.aws.amazon.com/neptune/latest/userguide/security.html
        title: AWS Documentation - Security in Amazon Neptune
  - uid: mondoo-aws-security-neptune-cluster-encrypted-api
    filters: asset.platform == "aws"
    mql: aws.neptune.clusters.all(storageEncrypted == true)
  - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_neptune_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_neptune_cluster").all(
        arguments.storage_encrypted == true
      )
  - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_neptune_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_neptune_cluster").all(
        change.after.storage_encrypted == true
      )
  - uid: mondoo-aws-security-neptune-cluster-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_neptune_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_neptune_cluster").all(
        values.storage_encrypted == true
      )
  - uid: mondoo-aws-security-guardduty-enabled
    title: Ensure Amazon GuardDuty is enabled
    impact: 90
    variants:
      - uid: mondoo-aws-security-guardduty-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-guardduty-enabled-terraform-hcl
      - uid: mondoo-aws-security-guardduty-enabled-terraform-plan
      - uid: mondoo-aws-security-guardduty-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon GuardDuty is enabled in your AWS account. GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior across your AWS environment, analyzing events from AWS CloudTrail, VPC Flow Logs, and DNS logs.

        **Why this matters**

        - Without GuardDuty, malicious activity such as unauthorized API calls, cryptocurrency mining, or data exfiltration may go undetected.
        - GuardDuty uses machine learning and threat intelligence to identify suspicious behavior across your entire AWS environment.
        - AWS Security Hub control GuardDuty.1 requires GuardDuty to be enabled.
        - Compliance frameworks including CIS AWS Foundations Benchmark, PCI DSS, and SOC 2 recommend continuous threat monitoring.

        **Risk mitigation:**

        - **Threat detection:** Continuously monitors for malicious activity including reconnaissance, instance compromise, and account compromise.
        - **Automated analysis:** Uses machine learning to reduce false positives and prioritize findings.
        - **Compliance:** Meets regulatory requirements for continuous security monitoring.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon GuardDuty Console.
            2. If GuardDuty has never been enabled, choose Get Started.
            3. Choose Enable GuardDuty.
            4. Repeat in each AWS Region where you want protection.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable GuardDuty in the current region:

            ```bash
            aws guardduty create-detector --enable
            ```

            Verify GuardDuty is enabled:

            ```bash
            aws guardduty list-detectors
            aws guardduty get-detector --detector-id <detector-id> --query "Status"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_guardduty_detector" "main" {
              enable                       = true
              finding_publishing_frequency = "FIFTEEN_MINUTES"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              GuardDutyDetector:
                Type: AWS::GuardDuty::Detector
                Properties:
                  Enable: true
                  FindingPublishingFrequency: FIFTEEN_MINUTES
            ```
    refs:
      - url: https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html
        title: AWS Documentation - What is Amazon GuardDuty?
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/guardduty-controls.html
        title: AWS Documentation - GuardDuty controls
  - uid: mondoo-aws-security-guardduty-enabled-api
    filters: asset.platform == "aws"
    mql: |
      aws.guardduty.detectors.length > 0
      aws.guardduty.detectors.all(status == "ENABLED")
  - uid: mondoo-aws-security-guardduty-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_guardduty_detector")
    mql: |
      terraform.resources.where(nameLabel == "aws_guardduty_detector").all(
        arguments.enable == true
      )
  - uid: mondoo-aws-security-guardduty-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_guardduty_detector")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_guardduty_detector").all(
        change.after.enable == true
      )
  - uid: mondoo-aws-security-guardduty-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_guardduty_detector")
    mql: |
      terraform.state.resources.where(type == "aws_guardduty_detector").all(
        values.enable == true
      )
  - uid: mondoo-aws-security-guardduty-findings-publishing-frequency
    title: Ensure GuardDuty findings are published at least every 15 minutes
    impact: 60
    variants:
      - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-hcl
      - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-plan
      - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-state
    docs:
      desc: |
        This check ensures that Amazon GuardDuty detectors are configured to publish findings at least every 15 minutes. Timely publication of findings ensures security teams can respond quickly to detected threats.

        **Why this matters**

        - Delayed finding publication can increase the window of exposure to active threats.
        - The default publishing frequency may be set to one hour, delaying incident response.
        - Faster notification enables quicker containment and remediation of security incidents.

        **Risk mitigation:**

        - **Rapid response:** Ensures security findings are available for review within 15 minutes.
        - **Incident containment:** Reduces the time between threat detection and response.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon GuardDuty Console.
            2. Select Settings.
            3. Under Findings export options, set the Updated findings frequency to 15 minutes.
            4. Select Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws guardduty update-detector \
              --detector-id <detector-id> \
              --finding-publishing-frequency FIFTEEN_MINUTES
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_guardduty_detector" "main" {
              enable                       = true
              finding_publishing_frequency = "FIFTEEN_MINUTES"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              GuardDutyDetector:
                Type: AWS::GuardDuty::Detector
                Properties:
                  Enable: true
                  FindingPublishingFrequency: FIFTEEN_MINUTES
            ```
    refs:
      - url: https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_exportfindings.html
        title: AWS Documentation - Exporting GuardDuty findings
  - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-api
    filters: asset.platform == "aws"
    mql: |
      aws.guardduty.detectors.length > 0
      aws.guardduty.detectors.all(findingPublishingFrequency == "FIFTEEN_MINUTES")
  - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_guardduty_detector")
    mql: |
      terraform.resources.where(nameLabel == "aws_guardduty_detector").all(
        arguments.finding_publishing_frequency == "FIFTEEN_MINUTES"
      )
  - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_guardduty_detector")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_guardduty_detector").all(
        change.after.finding_publishing_frequency == "FIFTEEN_MINUTES"
      )
  - uid: mondoo-aws-security-guardduty-findings-publishing-frequency-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_guardduty_detector")
    mql: |
      terraform.state.resources.where(type == "aws_guardduty_detector").all(
        values.finding_publishing_frequency == "FIFTEEN_MINUTES"
      )
  - uid: mondoo-aws-security-securityhub-enabled
    title: Ensure AWS Security Hub is enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-securityhub-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-securityhub-enabled-terraform-hcl
      - uid: mondoo-aws-security-securityhub-enabled-terraform-plan
      - uid: mondoo-aws-security-securityhub-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Security Hub is enabled in your AWS account. Security Hub provides a comprehensive view of your security posture, aggregating findings from multiple AWS security services and third-party tools.

        **Why this matters**

        - Without Security Hub, security findings from services like GuardDuty, Inspector, and Macie are siloed and difficult to prioritize.
        - Security Hub provides automated compliance checks against CIS AWS Foundations Benchmark and PCI DSS.
        - Centralized visibility into security findings is essential for effective security operations.

        **Risk mitigation:**

        - **Centralized visibility:** Aggregates findings from multiple security services into a single dashboard.
        - **Automated compliance:** Continuously evaluates your environment against industry standards.
        - **Prioritization:** Normalizes findings using the AWS Security Finding Format (ASFF).
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Security Hub Console.
            2. Choose Go to Security Hub.
            3. Select the security standards you want to enable.
            4. Choose Enable Security Hub.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws securityhub enable-security-hub
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_securityhub_account" "main" {}
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecurityHub:
                Type: AWS::SecurityHub::Hub
                Properties: {}
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/what-is-securityhub.html
        title: AWS Documentation - What is AWS Security Hub?
  - uid: mondoo-aws-security-securityhub-enabled-api
    filters: asset.platform == "aws"
    mql: aws.securityhub.hubs.length > 0
  - uid: mondoo-aws-security-securityhub-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_securityhub_account")
    mql: terraform.resources.where(nameLabel == "aws_securityhub_account").length > 0
  - uid: mondoo-aws-security-securityhub-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_securityhub_account")
    mql: terraform.plan.resourceChanges.where(type == "aws_securityhub_account").length > 0
  - uid: mondoo-aws-security-securityhub-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_securityhub_account")
    mql: terraform.state.resources.where(type == "aws_securityhub_account").length > 0
  - uid: mondoo-aws-security-config-recorder-enabled
    title: Ensure AWS Config recorder is enabled and recording
    impact: 80
    variants:
      - uid: mondoo-aws-security-config-recorder-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-config-recorder-enabled-terraform-hcl
      - uid: mondoo-aws-security-config-recorder-enabled-terraform-plan
      - uid: mondoo-aws-security-config-recorder-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Config recorders are enabled and actively recording configuration changes. AWS Config provides an audit trail of resource configuration changes over time.

        **Why this matters**

        - Without AWS Config recording, you have no audit trail of configuration changes to your AWS resources.
        - Configuration drift and unauthorized changes cannot be detected without active recording.
        - AWS Config is a prerequisite for many Config Rules that evaluate resource compliance.
        - CIS AWS Foundations Benchmark 3.5 requires AWS Config to be enabled in all regions.

        **Risk mitigation:**

        - **Audit trail:** Maintains a complete history of resource configuration changes.
        - **Compliance monitoring:** Enables evaluation of resources against desired configurations.
        - **Incident investigation:** Provides historical data for forensic analysis.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Config Console.
            2. If Config has not been set up, choose Get Started or 1-click setup.
            3. Ensure the recorder is turned on.
            4. Repeat in each AWS Region.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws configservice start-configuration-recorder \
              --configuration-recorder-name default
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_config_configuration_recorder_status" "main" {
              name       = aws_config_configuration_recorder.main.name
              is_enabled = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ConfigRecorder:
                Type: AWS::Config::ConfigurationRecorder
                Properties:
                  Name: default
                  RoleARN: !GetAtt ConfigRole.Arn
                  RecordingGroup:
                    AllSupported: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/gs-console.html
        title: AWS Documentation - Setting up AWS Config
  - uid: mondoo-aws-security-config-recorder-enabled-api
    filters: asset.platform == "aws"
    mql: |
      aws.config.recorders.length > 0
      aws.config.recorders.all(recording == true)
  - uid: mondoo-aws-security-config-recorder-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_config_configuration_recorder_status")
    mql: |
      terraform.resources.where(nameLabel == "aws_config_configuration_recorder_status").all(
        arguments.is_enabled == true
      )
  - uid: mondoo-aws-security-config-recorder-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_config_configuration_recorder_status")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_config_configuration_recorder_status").all(
        change.after.is_enabled == true
      )
  - uid: mondoo-aws-security-config-recorder-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_config_configuration_recorder_status")
    mql: |
      terraform.state.resources.where(type == "aws_config_configuration_recorder_status").all(
        values.is_enabled == true
      )
  - uid: mondoo-aws-security-config-recorder-all-resources
    title: Ensure AWS Config records all supported resource types
    impact: 70
    variants:
      - uid: mondoo-aws-security-config-recorder-all-resources-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-config-recorder-all-resources-terraform-hcl
      - uid: mondoo-aws-security-config-recorder-all-resources-terraform-plan
      - uid: mondoo-aws-security-config-recorder-all-resources-terraform-state
    docs:
      desc: |
        This check ensures that AWS Config recorders are configured to record all supported resource types, including global resources like IAM.

        **Why this matters**

        - Partial recording may miss configuration changes to critical resources.
        - Global resources such as IAM policies and roles must be included for complete visibility.
        - CIS AWS Foundations Benchmark requires recording all supported resource types.

        **Risk mitigation:**

        - **Complete visibility:** Ensures all resource types are monitored for configuration changes.
        - **Global coverage:** Includes IAM and other global resources in the recording scope.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Config Console.
            2. Select Settings.
            3. Under Recording method, ensure Record all current and future resource types is selected.
            4. Ensure Include globally recorded resource types is checked.
            5. Select Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws configservice put-configuration-recorder \
              --configuration-recorder name=default,roleARN=<role-arn> \
              --recording-group allSupported=true,includeGlobalResourceTypes=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_config_configuration_recorder" "main" {
              name     = "default"
              role_arn = aws_iam_role.config.arn

              recording_group {
                all_supported                 = true
                include_global_resource_types = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ConfigRecorder:
                Type: AWS::Config::ConfigurationRecorder
                Properties:
                  Name: default
                  RoleARN: !GetAtt ConfigRole.Arn
                  RecordingGroup:
                    AllSupported: true
                    IncludeGlobalResourceTypes: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/config/latest/developerguide/select-resources.html
        title: AWS Documentation - Selecting which resources AWS Config records
  - uid: mondoo-aws-security-config-recorder-all-resources-api
    filters: asset.platform == "aws"
    mql: |
      aws.config.recorders.length > 0
      aws.config.recorders.all(allSupported == true && includeGlobalResourceTypes == true)
  - uid: mondoo-aws-security-config-recorder-all-resources-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_config_configuration_recorder")
    mql: |
      terraform.resources.where(nameLabel == "aws_config_configuration_recorder").all(
        blocks.where(type == "recording_group") != empty &&
        blocks.where(type == "recording_group").all(
          arguments.all_supported == true &&
          arguments.include_global_resource_types == true
        )
      )
  - uid: mondoo-aws-security-config-recorder-all-resources-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_config_configuration_recorder")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_config_configuration_recorder").all(
        change.after.recording_group != empty &&
        change.after.recording_group.all(all_supported == true && include_global_resource_types == true)
      )
  - uid: mondoo-aws-security-config-recorder-all-resources-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_config_configuration_recorder")
    mql: |
      terraform.state.resources.where(type == "aws_config_configuration_recorder").all(
        values.recording_group != empty &&
        values.recording_group.all(all_supported == true && include_global_resource_types == true)
      )
  - uid: mondoo-aws-security-secretsmanager-rotation-enabled
    title: Ensure Secrets Manager secrets have automatic rotation enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-secretsmanager-rotation-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Secretsmanager Secret"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-hcl
      - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-plan
      - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-state
    docs:
      desc: |
        This check ensures that all AWS Secrets Manager secrets have automatic rotation enabled. Secrets that are not rotated regularly pose a significant security risk, as compromised credentials can be used indefinitely.

        **Why this matters**

        - Static secrets increase the blast radius of credential compromise.
        - Automatic rotation limits the validity period of any compromised credential.
        - Compliance frameworks including PCI DSS, SOC 2, and NIST 800-53 require regular credential rotation.
        - AWS Security Hub control SecretsManager.1 requires rotation to be enabled.

        **Risk mitigation:**

        - **Credential hygiene:** Automatically replaces secrets on a defined schedule.
        - **Breach containment:** Limits the window of exposure for compromised credentials.
        - **Compliance:** Meets regulatory requirements for credential lifecycle management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Secrets Manager Console.
            2. Select the secret.
            3. In the Rotation configuration section, choose Edit rotation.
            4. Enable Automatic rotation.
            5. Set the rotation schedule and select a Lambda rotation function.
            6. Choose Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws secretsmanager rotate-secret \
              --secret-id <secret-name-or-arn> \
              --rotation-lambda-arn <lambda-function-arn> \
              --rotation-rules AutomaticallyAfterDays=30
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_secretsmanager_secret_rotation" "example" {
              secret_id           = aws_secretsmanager_secret.example.id
              rotation_lambda_arn = aws_lambda_function.rotation.arn

              rotation_rules {
                automatically_after_days = 30
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SecretRotation:
                Type: AWS::SecretsManager::RotationSchedule
                Properties:
                  SecretId: !Ref MySecret
                  RotationLambdaARN: !GetAtt RotationFunction.Arn
                  RotationRules:
                    AutomaticallyAfterDays: 30
            ```
    refs:
      - url: https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html
        title: AWS Documentation - Rotate Secrets Manager secrets
  - uid: mondoo-aws-security-secretsmanager-rotation-enabled-api
    filters: asset.platform == "aws-secretsmanager-secret"
    mql: aws.secretsmanager.secret.rotationEnabled == true
  - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_secretsmanager_secret_rotation")
    mql: terraform.resources.where(nameLabel == "aws_secretsmanager_secret_rotation").length > 0
  - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_secretsmanager_secret_rotation")
    mql: terraform.plan.resourceChanges.where(type == "aws_secretsmanager_secret_rotation").length > 0
  - uid: mondoo-aws-security-secretsmanager-rotation-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_secretsmanager_secret_rotation")
    mql: terraform.state.resources.where(type == "aws_secretsmanager_secret_rotation").length > 0
  - uid: mondoo-aws-security-secretsmanager-cmk-encryption
    title: Ensure Secrets Manager secrets are encrypted with a customer-managed KMS key
    impact: 70
    variants:
      - uid: mondoo-aws-security-secretsmanager-cmk-encryption-api
        tags:
          mondoo.com/filter-title: "AWS Secretsmanager Secret"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-hcl
      - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-plan
      - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Secrets Manager secrets are encrypted using a customer-managed KMS key rather than the default AWS-managed key.

        **Why this matters**

        - The default AWS-managed key does not allow fine-grained access control through key policies.
        - Customer-managed keys enable audit logging of all encryption operations via CloudTrail.
        - You can revoke access to all secrets by disabling the CMK.
        - Compliance frameworks such as PCI DSS, HIPAA, and FedRAMP often require customer-managed encryption keys.

        **Risk mitigation:**

        - **Key control:** Full control over key lifecycle including rotation and deletion.
        - **Access management:** Fine-grained access control through KMS key policies.
        - **Auditability:** All encryption operations are logged in CloudTrail.
        - **Crypto shredding:** Usage of a customer-managed key makes crypto shredding possible. Crypto shredding is a secure data destruction technique where the encryption key is deleted, making all data encrypted with that key permanently and irreversibly unrecoverable. This is required for compliance with data retention and deletion regulations.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Secrets Manager Console.
            2. Select the secret.
            3. Choose Actions, then Edit encryption key.
            4. Select a customer-managed KMS key.
            5. Choose Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws secretsmanager update-secret \
              --secret-id <secret-name-or-arn> \
              --kms-key-id <kms-key-id-or-arn>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_secretsmanager_secret" "example" {
              name       = "example-secret"
              kms_key_id = aws_kms_key.secrets.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              Secret:
                Type: AWS::SecretsManager::Secret
                Properties:
                  Name: example-secret
                  KmsKeyId: !GetAtt SecretsKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/secretsmanager/latest/userguide/security-encryption.html
        title: AWS Documentation - Secret encryption in Secrets Manager
  - uid: mondoo-aws-security-secretsmanager-cmk-encryption-api
    filters: asset.platform == "aws-secretsmanager-secret"
    mql: aws.secretsmanager.secret.kmsKey != empty
  - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_secretsmanager_secret")
    mql: |
      terraform.resources.where(nameLabel == "aws_secretsmanager_secret").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_secretsmanager_secret")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_secretsmanager_secret").all(
        change.after.kms_key_id != empty
      )
  - uid: mondoo-aws-security-secretsmanager-cmk-encryption-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_secretsmanager_secret")
    mql: |
      terraform.state.resources.where(type == "aws_secretsmanager_secret").all(
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-iam-access-analyzer-enabled
    title: Ensure IAM Access Analyzer is enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-iam-access-analyzer-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-hcl
      - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-plan
      - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-state
    docs:
      desc: |
        This check ensures that IAM Access Analyzer is enabled with at least one active analyzer. Access Analyzer identifies resources shared with external entities, detecting unintended public or cross-account access.

        **Why this matters**

        - Without Access Analyzer, unintended external access to S3 buckets, IAM roles, KMS keys, and other resources may go undetected.
        - CIS AWS Foundations Benchmark 1.20 recommends enabling IAM Access Analyzer.
        - AWS Security Hub control IAM.8 requires Access Analyzer to be configured.

        **Risk mitigation:**

        - **Access monitoring:** Continuously monitors resource policies for external access.
        - **Policy validation:** Validates IAM policies against security best practices.
        - **Compliance:** Meets CIS and Security Hub requirements for access analysis.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the IAM Console.
            2. Under Access reports, select Access Analyzer.
            3. Choose Create analyzer.
            4. Enter a name and select the zone of trust.
            5. Choose Create analyzer.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws accessanalyzer create-analyzer \
              --analyzer-name account-analyzer \
              --type ACCOUNT
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_accessanalyzer_analyzer" "account" {
              analyzer_name = "account-analyzer"
              type          = "ACCOUNT"
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              AccessAnalyzer:
                Type: AWS::AccessAnalyzer::Analyzer
                Properties:
                  AnalyzerName: account-analyzer
                  Type: ACCOUNT
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html
        title: AWS Documentation - What is IAM Access Analyzer?
  - uid: mondoo-aws-security-iam-access-analyzer-enabled-api
    filters: asset.platform == "aws"
    mql: aws.iam.accessAnalyzer.analyzers.where(status == "ACTIVE").length > 0
  - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_accessanalyzer_analyzer")
    mql: terraform.resources.where(nameLabel == "aws_accessanalyzer_analyzer").length > 0
  - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_accessanalyzer_analyzer")
    mql: terraform.plan.resourceChanges.where(type == "aws_accessanalyzer_analyzer").length > 0
  - uid: mondoo-aws-security-iam-access-analyzer-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_accessanalyzer_analyzer")
    mql: terraform.state.resources.where(type == "aws_accessanalyzer_analyzer").length > 0
  - uid: mondoo-aws-security-sns-topic-encrypted
    title: Ensure SNS topics are encrypted with KMS
    impact: 70
    variants:
      - uid: mondoo-aws-security-sns-topic-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sns-topic-encrypted-terraform-hcl
      - uid: mondoo-aws-security-sns-topic-encrypted-terraform-plan
      - uid: mondoo-aws-security-sns-topic-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SNS topics are encrypted using AWS KMS. Without encryption, messages published to SNS topics are stored in plaintext, which could expose sensitive data.

        **Why this matters**

        - SNS topics may contain sensitive notifications, alerts, or data that should be protected at rest.
        - Without KMS encryption, messages are stored unencrypted on the SNS service infrastructure.
        - AWS Security Hub control SNS.1 requires SNS topics to be encrypted at rest using KMS.
        - Compliance frameworks such as PCI DSS and HIPAA require encryption of data at rest.

        **Risk mitigation:**

        - **Data protection:** Encrypts messages at rest using KMS keys.
        - **Access control:** KMS key policies provide additional access control over who can publish and subscribe.
        - **Compliance:** Meets regulatory requirements for data-at-rest encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon SNS Console.
            2. Select the topic.
            3. Choose Edit.
            4. Under Encryption, enable encryption and select a KMS key.
            5. Choose Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws sns set-topic-attributes \
              --topic-arn <topic-arn> \
              --attribute-name KmsMasterKeyId \
              --attribute-value <kms-key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_sns_topic" "example" {
              name              = "example-topic"
              kms_master_key_id = aws_kms_key.sns.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SNSTopic:
                Type: AWS::SNS::Topic
                Properties:
                  TopicName: example-topic
                  KmsMasterKeyId: !GetAtt SNSKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html
        title: AWS Documentation - Encryption at rest for Amazon SNS
  - uid: mondoo-aws-security-sns-topic-encrypted-api
    filters: asset.platform == "aws"
    mql: |
      aws.sns.topics.all(
        attributes["KmsMasterKeyId"] != empty
      )
  - uid: mondoo-aws-security-sns-topic-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sns_topic")
    mql: |
      terraform.resources.where(nameLabel == "aws_sns_topic").all(
        arguments.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sns-topic-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sns_topic")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sns_topic").all(
        change.after.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sns-topic-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sns_topic")
    mql: |
      terraform.state.resources.where(type == "aws_sns_topic").all(
        values.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sns-topic-signature-version
    title: Ensure SNS topics use signature version 2 for message verification
    impact: 60
    variants:
      - uid: mondoo-aws-security-sns-topic-signature-version-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sns-topic-signature-version-terraform-hcl
      - uid: mondoo-aws-security-sns-topic-signature-version-terraform-plan
      - uid: mondoo-aws-security-sns-topic-signature-version-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SNS topics are configured to use signature version 2 for message verification. Signature version 2 uses SHA-256 hashing, which is more secure than the older SHA-1 based signature version 1.

        **Why this matters**

        - Signature version 1 uses SHA-1, which has known collision vulnerabilities.
        - Signature version 2 uses SHA-256, providing stronger message integrity verification.
        - Upgrading to signature version 2 prevents potential message tampering attacks.

        **Risk mitigation:**

        - **Message integrity:** SHA-256 provides stronger cryptographic guarantees for message verification.
        - **Security posture:** Eliminates reliance on the deprecated SHA-1 algorithm.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon SNS Console.
            2. Select the topic.
            3. Choose Edit.
            4. Set the Signature version to 2.
            5. Choose Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws sns set-topic-attributes \
              --topic-arn <topic-arn> \
              --attribute-name SignatureVersion \
              --attribute-value "2"
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_sns_topic" "example" {
              name              = "example-topic"
              signature_version = 2
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SNSTopic:
                Type: AWS::SNS::Topic
                Properties:
                  TopicName: example-topic
                  SignatureVersion: "2"
            ```
    refs:
      - url: https://docs.aws.amazon.com/sns/latest/dg/sns-verify-signature-of-message.html
        title: AWS Documentation - Verifying the signatures of Amazon SNS messages
  - uid: mondoo-aws-security-sns-topic-signature-version-api
    filters: asset.platform == "aws"
    mql: aws.sns.topics.all(signatureVersion == "2")
  - uid: mondoo-aws-security-sns-topic-signature-version-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sns_topic")
    mql: |
      terraform.resources.where(nameLabel == "aws_sns_topic").all(
        arguments.signature_version == 2
      )
  - uid: mondoo-aws-security-sns-topic-signature-version-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sns_topic")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sns_topic").all(
        change.after.signature_version == "2"
      )
  - uid: mondoo-aws-security-sns-topic-signature-version-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sns_topic")
    mql: |
      terraform.state.resources.where(type == "aws_sns_topic").all(
        values.signature_version == "2"
      )
  - uid: mondoo-aws-security-sqs-queue-encrypted
    title: Ensure SQS queues are encrypted
    impact: 70
    variants:
      - uid: mondoo-aws-security-sqs-queue-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-hcl
      - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-plan
      - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SQS queues are encrypted using either SQS-managed server-side encryption (SSE-SQS) or AWS KMS keys (SSE-KMS).

        **Why this matters**

        - SQS queues may contain sensitive messages that should be protected at rest.
        - Without encryption, messages are stored in plaintext on the SQS service infrastructure.
        - AWS Security Hub control SQS.1 requires SQS queues to be encrypted at rest.
        - Compliance frameworks require encryption of data at rest.

        **Risk mitigation:**

        - **Data protection:** Encrypts messages at rest in the queue.
        - **Compliance:** Meets PCI DSS, HIPAA, and SOC 2 requirements for data-at-rest encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon SQS Console.
            2. Select the queue.
            3. Choose Edit.
            4. Under Encryption, select Server-side encryption and choose SSE-SQS or SSE-KMS.
            5. Choose Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            Enable SQS-managed encryption:

            ```bash
            aws sqs set-queue-attributes \
              --queue-url <queue-url> \
              --attributes SqsManagedSseEnabled=true
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_sqs_queue" "example" {
              name                    = "example-queue"
              sqs_managed_sse_enabled = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              SQSQueue:
                Type: AWS::SQS::Queue
                Properties:
                  QueueName: example-queue
                  SqsManagedSseEnabled: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html
        title: AWS Documentation - Encryption at rest for Amazon SQS
  - uid: mondoo-aws-security-sqs-queue-encrypted-api
    filters: asset.platform == "aws"
    mql: aws.sqs.queues.all(sqsManagedSseEnabled == true || kmsKey != empty)
  - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sqs_queue")
    mql: |
      terraform.resources.where(nameLabel == "aws_sqs_queue").all(
        arguments.sqs_managed_sse_enabled == true || arguments.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sqs_queue")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sqs_queue").all(
        change.after.sqs_managed_sse_enabled == true || change.after.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sqs-queue-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sqs_queue")
    mql: |
      terraform.state.resources.where(type == "aws_sqs_queue").all(
        values.sqs_managed_sse_enabled == true || values.kms_master_key_id != empty
      )
  - uid: mondoo-aws-security-sqs-queue-dead-letter-queue
    title: Ensure SQS queues have a dead letter queue configured
    impact: 60
    variants:
      - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-hcl
      - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-plan
      - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-state
    docs:
      desc: |
        This check ensures that SQS queues have a dead letter queue (DLQ) configured. A DLQ captures messages that cannot be processed successfully, preventing message loss and enabling investigation of processing failures.

        **Why this matters**

        - Without a DLQ, failed messages are silently discarded after the maximum receive count.
        - DLQs enable forensic analysis of failed messages to identify processing issues.
        - Lost messages can lead to data inconsistency and missed security events.

        **Risk mitigation:**

        - **Message preservation:** Failed messages are retained for investigation rather than lost.
        - **Reliability:** Prevents silent data loss from processing failures.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon SQS Console.
            2. Select the queue.
            3. Choose Edit.
            4. Under Dead-letter queue, enable it and select a target queue.
            5. Set the maximum receives before sending to the DLQ.
            6. Choose Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws sqs set-queue-attributes \
              --queue-url <queue-url> \
              --attributes '{"RedrivePolicy":"{\"deadLetterTargetArn\":\"<dlq-arn>\",\"maxReceiveCount\":\"5\"}"}'
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_sqs_queue" "dlq" {
              name = "example-dlq"
            }

            resource "aws_sqs_queue" "example" {
              name = "example-queue"

              redrive_policy = jsonencode({
                deadLetterTargetArn = aws_sqs_queue.dlq.arn
                maxReceiveCount     = 5
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              DLQ:
                Type: AWS::SQS::Queue
                Properties:
                  QueueName: example-dlq
              MainQueue:
                Type: AWS::SQS::Queue
                Properties:
                  QueueName: example-queue
                  RedrivePolicy:
                    deadLetterTargetArn: !GetAtt DLQ.Arn
                    maxReceiveCount: 5
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html
        title: AWS Documentation - Amazon SQS dead-letter queues
  - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-api
    filters: asset.platform == "aws"
    mql: aws.sqs.queues.all(deadLetterQueue != empty)
  - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sqs_queue")
    mql: |
      terraform.resources.where(nameLabel == "aws_sqs_queue").all(
        arguments.redrive_policy != empty
      )
  - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sqs_queue")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sqs_queue").all(
        change.after.redrive_policy != empty
      )
  - uid: mondoo-aws-security-sqs-queue-dead-letter-queue-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sqs_queue")
    mql: |
      terraform.state.resources.where(type == "aws_sqs_queue").all(
        values.redrive_policy != empty
      )
  - uid: mondoo-aws-security-elasticache-encryption-at-rest
    title: Ensure ElastiCache clusters have encryption at rest enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-elasticache-encryption-at-rest-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-hcl
      - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-plan
      - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ElastiCache clusters have encryption at rest enabled. Without encryption at rest, cached data is stored in plaintext, which could be exposed if the underlying storage is compromised.

        **Why this matters**

        - ElastiCache clusters often store session data, authentication tokens, and other sensitive information.
        - Without encryption at rest, this data is vulnerable to unauthorized access at the storage layer.
        - AWS Security Hub control ElastiCache.3 requires encryption at rest for ElastiCache replication groups.
        - Compliance frameworks require encryption of data at rest for all data stores.

        **Risk mitigation:**

        - **Data protection:** Encrypts all data stored on disk in ElastiCache nodes.
        - **Compliance:** Meets PCI DSS, HIPAA, and SOC 2 requirements for data-at-rest encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ElastiCache Console.
            2. Note: Encryption at rest can only be enabled at creation time.
            3. Create a new replication group or cluster with Encryption at rest enabled.
            4. Migrate data from the unencrypted cluster to the new encrypted cluster.
            5. Delete the old unencrypted cluster.
        - id: cli
          desc: |
            **Using AWS CLI**

            Create a new replication group with encryption at rest:

            ```bash
            aws elasticache create-replication-group \
              --replication-group-id example-encrypted \
              --replication-group-description "Encrypted cluster" \
              --at-rest-encryption-enabled \
              --cache-node-type cache.r6g.large \
              --engine redis
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_elasticache_replication_group" "example" {
              replication_group_id = "example-encrypted"
              description          = "Encrypted ElastiCache cluster"
              node_type            = "cache.r6g.large"
              engine               = "redis"

              at_rest_encryption_enabled = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ElastiCacheReplicationGroup:
                Type: AWS::ElastiCache::ReplicationGroup
                Properties:
                  ReplicationGroupId: example-encrypted
                  ReplicationGroupDescription: Encrypted ElastiCache cluster
                  CacheNodeType: cache.r6g.large
                  Engine: redis
                  AtRestEncryptionEnabled: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/at-rest-encryption.html
        title: AWS Documentation - ElastiCache at-rest encryption
  - uid: mondoo-aws-security-elasticache-encryption-at-rest-api
    filters: asset.platform == "aws"
    mql: aws.elasticache.cacheClusters.where(engine == "redis").all(atRestEncryptionEnabled == true)
  - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_elasticache_replication_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_elasticache_replication_group").all(
        arguments.at_rest_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_elasticache_replication_group").all(
        change.after.at_rest_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-encryption-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.state.resources.where(type == "aws_elasticache_replication_group").all(
        values.at_rest_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-encryption-in-transit
    title: Ensure ElastiCache clusters have encryption in transit enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-elasticache-encryption-in-transit-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-hcl
      - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-plan
      - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ElastiCache clusters have encryption in transit enabled, protecting data as it moves between clients and cache nodes.

        **Why this matters**

        - Without in-transit encryption, data between applications and ElastiCache is transmitted in plaintext.
        - Sensitive session data, authentication tokens, and cached content can be intercepted.
        - AWS Security Hub control ElastiCache.4 requires encryption in transit.

        **Risk mitigation:**

        - **Data protection:** Encrypts all communication between clients and ElastiCache nodes using TLS.
        - **MITM prevention:** Prevents eavesdropping on cache traffic.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ElastiCache Console.
            2. Note: Encryption in transit can only be enabled at creation time.
            3. Create a new replication group with Encryption in transit enabled.
            4. Migrate data and update application connection strings to use TLS.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws elasticache create-replication-group \
              --replication-group-id example-encrypted \
              --replication-group-description "Encrypted cluster" \
              --transit-encryption-enabled \
              --cache-node-type cache.r6g.large \
              --engine redis
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_elasticache_replication_group" "example" {
              replication_group_id = "example-encrypted"
              description          = "Encrypted ElastiCache cluster"
              node_type            = "cache.r6g.large"
              engine               = "redis"

              transit_encryption_enabled = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ElastiCacheReplicationGroup:
                Type: AWS::ElastiCache::ReplicationGroup
                Properties:
                  ReplicationGroupId: example-encrypted
                  ReplicationGroupDescription: Encrypted ElastiCache cluster
                  CacheNodeType: cache.r6g.large
                  Engine: redis
                  TransitEncryptionEnabled: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/in-transit-encryption.html
        title: AWS Documentation - ElastiCache in-transit encryption
  - uid: mondoo-aws-security-elasticache-encryption-in-transit-api
    filters: asset.platform == "aws"
    mql: aws.elasticache.cacheClusters.where(engine == "redis").all(transitEncryptionEnabled == true)
  - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_elasticache_replication_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_elasticache_replication_group").all(
        arguments.transit_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_elasticache_replication_group").all(
        change.after.transit_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-encryption-in-transit-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.state.resources.where(type == "aws_elasticache_replication_group").all(
        values.transit_encryption_enabled == true
      )
  - uid: mondoo-aws-security-elasticache-redis-auth-enabled
    title: Ensure ElastiCache Redis clusters require authentication
    impact: 70
    variants:
      - uid: mondoo-aws-security-elasticache-redis-auth-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-hcl
      - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-plan
      - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-state
    docs:
      desc: |
        This check ensures that ElastiCache Redis clusters have authentication enabled via Redis AUTH tokens, preventing unauthorized access to cached data.

        **Why this matters**

        - Without authentication, anyone with network access to the Redis cluster can read and modify data.
        - Redis clusters often contain sensitive session data, tokens, and cached business data.
        - AWS Security Hub control ElastiCache.6 recommends Redis AUTH for authentication.

        **Risk mitigation:**

        - **Access control:** Requires clients to authenticate before executing commands.
        - **Unauthorized access prevention:** Prevents data access from compromised network segments.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ElastiCache Console.
            2. Create a new replication group with Auth token enabled.
            3. Specify a strong AUTH token.
            4. Update application connection strings to include the AUTH token.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws elasticache create-replication-group \
              --replication-group-id example-auth \
              --replication-group-description "Auth-enabled cluster" \
              --transit-encryption-enabled \
              --auth-token <strong-auth-token> \
              --cache-node-type cache.r6g.large \
              --engine redis
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_elasticache_replication_group" "example" {
              replication_group_id = "example-auth"
              description          = "Auth-enabled cluster"
              node_type            = "cache.r6g.large"
              engine               = "redis"

              transit_encryption_enabled = true
              auth_token                 = var.redis_auth_token
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              ElastiCacheReplicationGroup:
                Type: AWS::ElastiCache::ReplicationGroup
                Properties:
                  ReplicationGroupId: example-auth
                  ReplicationGroupDescription: Auth-enabled cluster
                  CacheNodeType: cache.r6g.large
                  Engine: redis
                  TransitEncryptionEnabled: true
                  AuthToken: !Ref RedisAuthToken
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html
        title: AWS Documentation - Authenticating with the Redis AUTH command
  - uid: mondoo-aws-security-elasticache-redis-auth-enabled-api
    filters: asset.platform == "aws"
    mql: aws.elasticache.cacheClusters.where(engine == "redis").all(authTokenEnabled == true)
  - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_elasticache_replication_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_elasticache_replication_group").all(
        arguments.auth_token != empty
      )
  - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_elasticache_replication_group").all(
        change.after.auth_token != empty
      )
  - uid: mondoo-aws-security-elasticache-redis-auth-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_elasticache_replication_group")
    mql: |
      terraform.state.resources.where(type == "aws_elasticache_replication_group").all(
        values.auth_token != empty
      )
  - uid: mondoo-aws-security-backup-vault-encrypted
    title: Ensure AWS Backup vaults are encrypted
    impact: 70
    variants:
      - uid: mondoo-aws-security-backup-vault-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-backup-vault-encrypted-terraform-hcl
      - uid: mondoo-aws-security-backup-vault-encrypted-terraform-plan
      - uid: mondoo-aws-security-backup-vault-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that AWS Backup vaults are encrypted using a KMS key. Backup vaults store recovery points that may contain sensitive data from databases, file systems, and other resources.

        **Why this matters**

        - Backup vaults contain copies of production data that may include sensitive information.
        - Without encryption, backup data is vulnerable to unauthorized access at the storage layer.
        - Compliance frameworks require encryption of backup data at rest.

        **Risk mitigation:**

        - **Data protection:** Encrypts all recovery points stored in the backup vault.
        - **Compliance:** Meets requirements for backup data encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the AWS Backup Console.
            2. Choose Backup vaults.
            3. Create a new vault with a KMS encryption key specified.
            4. Note: Encryption cannot be changed after vault creation.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws backup create-backup-vault \
              --backup-vault-name example-vault \
              --encryption-key-arn <kms-key-arn>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_backup_vault" "example" {
              name        = "example-vault"
              kms_key_arn = aws_kms_key.backup.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              BackupVault:
                Type: AWS::Backup::BackupVault
                Properties:
                  BackupVaultName: example-vault
                  EncryptionKeyArn: !GetAtt BackupKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/aws-backup/latest/devguide/encryption.html
        title: AWS Documentation - Encryption for backups in AWS Backup
  - uid: mondoo-aws-security-backup-vault-encrypted-api
    filters: asset.platform == "aws"
    mql: aws.backup.vaults.all(encryptionKeyArn != empty)
  - uid: mondoo-aws-security-backup-vault-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_backup_vault")
    mql: |
      terraform.resources.where(nameLabel == "aws_backup_vault").all(
        arguments.kms_key_arn != empty
      )
  - uid: mondoo-aws-security-backup-vault-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_backup_vault")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_backup_vault").all(
        change.after.kms_key_arn != empty
      )
  - uid: mondoo-aws-security-backup-vault-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_backup_vault")
    mql: |
      terraform.state.resources.where(type == "aws_backup_vault").all(
        values.kms_key_arn != empty
      )
  - uid: mondoo-aws-security-fsx-filesystem-encrypted
    title: Ensure FSx file systems are encrypted at rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-fsx-filesystem-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-hcl
      - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-plan
      - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon FSx file systems are encrypted at rest. FSx supports multiple file system types (Lustre, Windows File Server, ONTAP, OpenZFS) and all should be encrypted.

        **Why this matters**

        - FSx file systems may store sensitive files, application data, and shared resources.
        - Without encryption, data is stored in plaintext on the underlying storage infrastructure.
        - Compliance frameworks require encryption of data at rest for all storage services.

        **Risk mitigation:**

        - **Data protection:** Encrypts all data stored on FSx file systems.
        - **Compliance:** Meets requirements for data-at-rest encryption across file storage services.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon FSx Console.
            2. Note: Encryption can only be enabled at creation time.
            3. Create a new file system with encryption enabled.
            4. Migrate data from the unencrypted file system.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws fsx create-file-system \
              --file-system-type LUSTRE \
              --storage-capacity 1200 \
              --subnet-ids <subnet-id> \
              --lustre-configuration DeploymentType=PERSISTENT_2,PerUnitStorageThroughput=125 \
              --kms-key-id <kms-key-arn>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_fsx_lustre_file_system" "example" {
              storage_capacity = 1200
              subnet_ids       = [aws_subnet.example.id]
              kms_key_id       = aws_kms_key.fsx.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              FSxFileSystem:
                Type: AWS::FSx::FileSystem
                Properties:
                  FileSystemType: LUSTRE
                  StorageCapacity: 1200
                  SubnetIds:
                    - !Ref Subnet
                  KmsKeyId: !GetAtt FSxKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/fsx/latest/LustreGuide/encryption-at-rest.html
        title: AWS Documentation - Encrypting data at rest for Amazon FSx
  - uid: mondoo-aws-security-fsx-filesystem-encrypted-api
    filters: asset.platform == "aws"
    mql: aws.fsx.fileSystems.all(encrypted == true)
  - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_fsx_lustre_file_system")
    mql: |
      terraform.resources.where(nameLabel == "aws_fsx_lustre_file_system").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_fsx_lustre_file_system")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_fsx_lustre_file_system").all(
        change.after.kms_key_id != empty
      )
  - uid: mondoo-aws-security-fsx-filesystem-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_fsx_lustre_file_system")
    mql: |
      terraform.state.resources.where(type == "aws_fsx_lustre_file_system").all(
        values.kms_key_id != empty
      )
  - uid: mondoo-aws-security-redshift-cluster-encrypted
    title: Ensure Redshift clusters are encrypted at rest
    impact: 80
    variants:
      - uid: mondoo-aws-security-redshift-cluster-encrypted-api
        tags:
          mondoo.com/filter-title: "AWS Redshift Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters are encrypted at rest. Unencrypted Redshift clusters store data warehouse data in plaintext, exposing sensitive business data to unauthorized access at the storage layer.

        **Why this matters**

        - Redshift clusters typically contain large volumes of business-critical analytics data that may include PII, financial records, or other sensitive information.
        - Without encryption, data is stored in plaintext and can be accessed if the underlying storage is compromised.
        - AWS Security Hub control Redshift.10 requires Redshift clusters to be encrypted at rest.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 require encryption of data at rest.

        **Risk mitigation:**

        - **Data protection:** Encrypts all data blocks and system metadata in the Redshift cluster using AES-256.
        - **Compliance:** Meets regulatory requirements for data-at-rest encryption.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon Redshift Console.
            2. Note: Encryption can only be enabled at creation time or by modifying the cluster.
            3. Select the cluster, choose Actions, then Modify.
            4. Under Database configurations, enable Encryption and select a KMS key.
            5. Choose Modify cluster.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws redshift modify-cluster \
              --cluster-identifier <cluster-id> \
              --encrypted \
              --kms-key-id <kms-key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_redshift_cluster" "example" {
              cluster_identifier = "example-cluster"
              node_type          = "dc2.large"
              encrypted          = true
              kms_key_id         = aws_kms_key.redshift.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RedshiftCluster:
                Type: AWS::Redshift::Cluster
                Properties:
                  ClusterIdentifier: example-cluster
                  NodeType: dc2.large
                  Encrypted: true
                  KmsKeyId: !GetAtt RedshiftKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-db-encryption.html
        title: AWS Documentation - Amazon Redshift database encryption
  - uid: mondoo-aws-security-redshift-cluster-encrypted-api
    filters: asset.platform == "aws-redshift-cluster"
    mql: aws.redshift.cluster.encrypted == true
  - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_redshift_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_redshift_cluster").all(
        arguments.encrypted == true
      )
  - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_redshift_cluster").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-redshift-cluster-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_redshift_cluster").all(
        values.encrypted == true
      )
  - uid: mondoo-aws-security-redshift-cluster-audit-logging
    title: Ensure Redshift clusters have audit logging enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-redshift-cluster-audit-logging-api
        tags:
          mondoo.com/filter-title: "AWS Redshift Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters have audit logging enabled. Audit logging records information about connections, user activities, and queries for security analysis and compliance.

        **Why this matters**

        - Without audit logging, database activities cannot be monitored or investigated after a security incident.
        - Audit logs provide visibility into who accessed the data warehouse, what queries were run, and what data was accessed.
        - AWS Security Hub control Redshift.4 requires audit logging to be enabled.

        **Risk mitigation:**

        - **Audit trail:** Provides a record of all database activity for forensic analysis.
        - **Threat detection:** Enables detection of suspicious query patterns and unauthorized access.
        - **Compliance:** Meets regulatory requirements for database activity logging.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon Redshift Console.
            2. Select the cluster.
            3. Choose Properties, then Edit audit logging.
            4. Enable audit logging and specify an S3 bucket for log delivery.
            5. Choose Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws redshift enable-logging \
              --cluster-identifier <cluster-id> \
              --bucket-name <s3-bucket-name> \
              --s3-key-prefix redshift-audit-logs/
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_redshift_cluster" "example" {
              cluster_identifier = "example-cluster"
              node_type          = "dc2.large"

              logging {
                enable        = true
                bucket_name   = aws_s3_bucket.logs.id
                s3_key_prefix = "redshift-audit-logs/"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RedshiftCluster:
                Type: AWS::Redshift::Cluster
                Properties:
                  ClusterIdentifier: example-cluster
                  NodeType: dc2.large
                  LoggingProperties:
                    BucketName: !Ref LogBucket
                    S3KeyPrefix: redshift-audit-logs/
            ```
    refs:
      - url: https://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html
        title: AWS Documentation - Database audit logging for Amazon Redshift
  - uid: mondoo-aws-security-redshift-cluster-audit-logging-api
    filters: asset.platform == "aws-redshift-cluster"
    mql: aws.redshift.cluster.logging["LoggingEnabled"] == true
  - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_redshift_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_redshift_cluster").all(
        blocks.where(type == "logging") != empty &&
        blocks.where(type == "logging").all(arguments.enable == true)
      )
  - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_redshift_cluster").all(
        change.after.logging != empty &&
        change.after.logging.all(_['enable'] == true)
      )
  - uid: mondoo-aws-security-redshift-cluster-audit-logging-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_redshift_cluster").all(
        values.logging != empty &&
        values.logging.all(_['enable'] == true)
      )
  - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing
    title: Ensure Redshift clusters use enhanced VPC routing
    impact: 70
    variants:
      - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-api
        tags:
          mondoo.com/filter-title: "AWS Redshift Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters use enhanced VPC routing. With enhanced VPC routing, Redshift forces all COPY and UNLOAD traffic between your cluster and data repositories through your VPC, allowing you to use VPC security features such as security groups, network ACLs, and VPC endpoints.

        **Why this matters**

        - Without enhanced VPC routing, Redshift routes traffic through the internet, bypassing VPC security controls.
        - Enhanced VPC routing enables monitoring and control of data movement with VPC flow logs.
        - AWS Security Hub control Redshift.2 requires enhanced VPC routing.

        **Risk mitigation:**

        - **Network control:** Forces data transfer traffic through VPC for security group and NACL enforcement.
        - **Visibility:** Enables VPC flow log monitoring of data movement.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon Redshift Console.
            2. Select the cluster.
            3. Choose Actions, then Modify.
            4. Enable Enhanced VPC routing.
            5. Choose Modify cluster.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws redshift modify-cluster \
              --cluster-identifier <cluster-id> \
              --enhanced-vpc-routing
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_redshift_cluster" "example" {
              cluster_identifier  = "example-cluster"
              node_type           = "dc2.large"
              enhanced_vpc_routing = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RedshiftCluster:
                Type: AWS::Redshift::Cluster
                Properties:
                  ClusterIdentifier: example-cluster
                  NodeType: dc2.large
                  EnhancedVpcRouting: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/redshift/latest/mgmt/enhanced-vpc-routing.html
        title: AWS Documentation - Amazon Redshift enhanced VPC routing
  - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-api
    filters: asset.platform == "aws-redshift-cluster"
    mql: aws.redshift.cluster.enhancedVpcRouting == true
  - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_redshift_cluster")
    mql: |
      terraform.resources.where(nameLabel == "aws_redshift_cluster").all(
        arguments.enhanced_vpc_routing == true
      )
  - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_redshift_cluster").all(
        change.after.enhanced_vpc_routing == true
      )
  - uid: mondoo-aws-security-redshift-cluster-enhanced-vpc-routing-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_redshift_cluster")
    mql: |
      terraform.state.resources.where(type == "aws_redshift_cluster").all(
        values.enhanced_vpc_routing == true
      )
  - uid: mondoo-aws-security-cloudfront-minimum-tls-version
    title: Ensure CloudFront distributions use TLS 1.2 or higher
    impact: 80
    variants:
      - uid: mondoo-aws-security-cloudfront-minimum-tls-version-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-hcl
      - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-plan
      - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudFront distributions are configured with a minimum TLS protocol version of 1.2 or higher. Older TLS versions (1.0 and 1.1) have known vulnerabilities and should not be used.

        **Why this matters**

        - TLS 1.0 and 1.1 have known vulnerabilities including POODLE and BEAST attacks.
        - Modern browsers and security standards require TLS 1.2 as the minimum version.
        - AWS Security Hub control CloudFront.10 requires TLS 1.2 or higher.
        - PCI DSS requires TLS 1.2 or higher for all connections handling cardholder data.

        **Risk mitigation:**

        - **Protocol security:** Eliminates known vulnerabilities in older TLS versions.
        - **Compliance:** Meets PCI DSS, HIPAA, and industry requirements for modern encryption protocols.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon CloudFront Console.
            2. Select the distribution.
            3. Choose the General tab, then Edit.
            4. Under Custom SSL certificate, set the Minimum SSL/TLS protocol to TLSv1.2_2021.
            5. Choose Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws cloudfront get-distribution-config --id <distribution-id> > dist-config.json
            # Edit to set MinimumProtocolVersion to "TLSv1.2_2021"
            aws cloudfront update-distribution --id <distribution-id> \
              --if-match <etag> --distribution-config file://dist-config.json
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_cloudfront_distribution" "example" {
              viewer_certificate {
                minimum_protocol_version = "TLSv1.2_2021"
                ssl_support_method       = "sni-only"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              Distribution:
                Type: AWS::CloudFront::Distribution
                Properties:
                  DistributionConfig:
                    ViewerCertificate:
                      MinimumProtocolVersion: TLSv1.2_2021
                      SslSupportMethod: sni-only
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/secure-connections-supported-viewer-protocols-ciphers.html
        title: AWS Documentation - Supported protocols and ciphers between viewers and CloudFront
  - uid: mondoo-aws-security-cloudfront-minimum-tls-version-api
    filters: asset.platform == "aws"
    mql: aws.cloudfront.distributions.all(minimumProtocolVersion == /TLSv1.2/)
  - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudfront_distribution")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudfront_distribution").all(
        blocks.where(type == "viewer_certificate").all(
          arguments.minimum_protocol_version == /TLSv1.2/
        )
      )
  - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudfront_distribution").all(
        change.after.viewer_certificate != empty &&
        change.after.viewer_certificate.all(minimum_protocol_version == /TLSv1.2/)
      )
  - uid: mondoo-aws-security-cloudfront-minimum-tls-version-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.state.resources.where(type == "aws_cloudfront_distribution").all(
        values.viewer_certificate != empty &&
        values.viewer_certificate.all(minimum_protocol_version == /TLSv1.2/)
      )
  - uid: mondoo-aws-security-cloudfront-waf-enabled
    title: Ensure CloudFront distributions have WAF web ACL associated
    impact: 70
    variants:
      - uid: mondoo-aws-security-cloudfront-waf-enabled-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-plan
      - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudFront distributions have an AWS WAF web ACL associated for protection against common web exploits and attacks.

        **Why this matters**

        - Without WAF, CloudFront distributions are exposed to common web attacks such as SQL injection, XSS, and DDoS.
        - WAF provides customizable rules to filter malicious traffic before it reaches your origin servers.
        - AWS Security Hub control CloudFront.6 requires WAF to be associated with CloudFront distributions.

        **Risk mitigation:**

        - **Attack prevention:** Filters malicious web traffic at the edge before it reaches your infrastructure.
        - **DDoS protection:** Rate-limiting rules help mitigate application-layer DDoS attacks.
        - **Compliance:** Meets requirements for web application firewall protection.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon CloudFront Console.
            2. Select the distribution.
            3. Choose the General tab, then Edit.
            4. Under AWS WAF web ACL, select a web ACL.
            5. Choose Save changes.
        - id: cli
          desc: |
            **Using AWS CLI**

            ```bash
            aws cloudfront get-distribution-config --id <distribution-id> > dist-config.json
            # Edit to add WebACLId
            aws cloudfront update-distribution --id <distribution-id> \
              --if-match <etag> --distribution-config file://dist-config.json
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "aws_cloudfront_distribution" "example" {
              web_acl_id = aws_wafv2_web_acl.example.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              Distribution:
                Type: AWS::CloudFront::Distribution
                Properties:
                  DistributionConfig:
                    WebACLId: !GetAtt WebACL.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-awswaf.html
        title: AWS Documentation - Using AWS WAF to control access to your content
  - uid: mondoo-aws-security-cloudfront-waf-enabled-api
    filters: asset.platform == "aws"
    mql: aws.cloudfront.distributions.all(webAclId != empty)
  - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudfront_distribution")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudfront_distribution").all(
        arguments.web_acl_id != empty
      )
  - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudfront_distribution").all(
        change.after.web_acl_id != empty
      )
  - uid: mondoo-aws-security-cloudfront-waf-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudfront_distribution")
    mql: |
      terraform.state.resources.where(type == "aws_cloudfront_distribution").all(
        values.web_acl_id != empty
      )
  - uid: mondoo-aws-security-rds-snapshot-encrypted
    title: Ensure RDS snapshots are encrypted at rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-rds-snapshot-encrypted-single
        tags:
          mondoo.com/filter-title: "AWS RDS Snapshot"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-hcl
      - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-plan
      - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon RDS snapshots are encrypted at rest. RDS snapshots contain full backups of database instances and may include sensitive data such as customer records, credentials, or financial information. Unencrypted snapshots expose this data if the snapshot is shared, copied, or the underlying storage is compromised.

        **Why this matters**

        RDS snapshots inherit the encryption status of their source database. Snapshots from unencrypted databases remain unencrypted and cannot be encrypted in place. Unencrypted snapshots pose several risks:

        - **Data exposure:** If a snapshot is shared with another account or made public, the data is accessible without any encryption protection.
        - **Compliance violations:** Regulatory frameworks such as PCI DSS, HIPAA, and GDPR require encryption of data at rest, including backups.
        - **Lateral movement:** An attacker with access to unencrypted snapshots can restore them to extract sensitive data.

        **Risk mitigation:**

        - **Data Security:** Ensures backup data is encrypted at rest using AWS KMS, protecting against unauthorized access.
        - **Regulatory Compliance:** Meets requirements for data-at-rest encryption in security frameworks.
        - **Centralized Key Management:** Leverages AWS KMS for key lifecycle management and access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon RDS Console.
            2. Select Snapshots in the left panel.
            3. For unencrypted snapshots, create an encrypted copy:
               - Select the snapshot and choose Actions > Copy Snapshot.
               - Check Enable Encryption and select a KMS key.
               - Choose Copy Snapshot.
            4. After verifying the encrypted copy, delete the unencrypted original.

            To prevent future unencrypted snapshots, ensure all RDS instances use encryption at rest.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for unencrypted snapshots:

            ```bash
            aws rds describe-db-snapshots --query "DBSnapshots[?Encrypted==\`false\`].DBSnapshotIdentifier"
            ```

            Create an encrypted copy of an unencrypted snapshot:

            ```bash
            aws rds copy-db-snapshot \
              --source-db-snapshot-identifier <snapshot-id> \
              --target-db-snapshot-identifier <encrypted-snapshot-id> \
              --kms-key-id <kms-key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure RDS instances are encrypted so snapshots inherit encryption:

            ```hcl
            resource "aws_db_instance" "example" {
              engine               = "mysql"
              instance_class       = "db.t3.micro"
              allocated_storage    = 20
              storage_encrypted    = true
              kms_key_id           = aws_kms_key.rds.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RDSInstance:
                Type: AWS::RDS::DBInstance
                Properties:
                  Engine: mysql
                  DBInstanceClass: db.t3.micro
                  AllocatedStorage: 20
                  StorageEncrypted: true
                  KmsKeyId: !GetAtt RDSKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html
        title: AWS Documentation - Encrypting Amazon RDS resources
  - uid: mondoo-aws-security-rds-snapshot-encrypted-single
    filters: asset.platform == "aws-rds-snapshot"
    mql: |
      aws.rds.snapshot.encrypted == true
  - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_db_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_db_instance").all(
        arguments['storage_encrypted'] == true
      )
  - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_db_snapshot")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_db_snapshot").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-rds-snapshot-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_db_snapshot")
    mql: |
      terraform.state.resources.where(type == "aws_db_snapshot").all(
        values.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited
    title: Ensure AMIs owned by the account are not publicly shared
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-hcl
      - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-plan
      - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Machine Images (AMIs) owned by the account are not publicly shared. Public AMIs can be launched by anyone, potentially exposing proprietary software, embedded credentials, internal configurations, or sensitive data baked into the image.

        **Why this matters**

        Publicly shared AMIs pose severe security risks:

        - **Credential exposure:** AMIs may contain embedded SSH keys, API credentials, database passwords, or other secrets that become accessible to anyone who launches the image.
        - **Intellectual property leakage:** Custom software, scripts, and configurations within the AMI become publicly available.
        - **Attack surface expansion:** Attackers can analyze public AMIs for vulnerabilities, then target running instances based on those findings.
        - **Compliance violations:** Sharing AMIs publicly may violate data protection regulations and organizational security policies.

        **Risk mitigation:**

        - **Access control:** Restricts AMI usage to authorized accounts only.
        - **Data protection:** Prevents inadvertent exposure of sensitive data embedded in images.
        - **Compliance:** Meets CIS AWS Foundations Benchmark and organizational security requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon EC2 Console.
            2. Select AMIs under Images in the left panel.
            3. Filter by Owned by me.
            4. Select each AMI and check the Permissions tab.
            5. If the AMI is public, select Edit AMI permissions.
            6. Change the setting from Public to Private.
            7. Optionally add specific AWS account IDs that should have access.
        - id: cli
          desc: |
            **Using AWS CLI**

            List public AMIs owned by your account:

            ```bash
            aws ec2 describe-images --owners self --query "Images[?Public==\`true\`].ImageId"
            ```

            Make a public AMI private:

            ```bash
            aws ec2 modify-image-attribute \
              --image-id <ami-id> \
              --launch-permission "Remove=[{Group=all}]"
            ```

            Enable AMI Block Public Access at the account level:

            ```bash
            aws ec2 enable-image-block-public-access --image-block-public-access-state block-new-sharing
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure AMIs are not publicly shared:

            ```hcl
            resource "aws_ami" "example" {
              name                = "example-ami"
              virtualization_type = "hvm"
              root_device_name    = "/dev/xvda"

              ebs_block_device {
                device_name = "/dev/xvda"
                snapshot_id = aws_ebs_snapshot.example.id
              }
            }

            # Do not add launch permissions with group = "all"
            resource "aws_ami_launch_permission" "example" {
              image_id   = aws_ami.example.id
              account_id = "123456789012"  # Share with specific accounts only
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            AMI sharing is managed through the EC2 API rather than CloudFormation. Use the AWS CLI or Console to manage AMI permissions, or enable AMI Block Public Access at the account level.
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharing-amis.html
        title: AWS Documentation - Share an AMI with specific organizations or accounts
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-public-access-to-amis.html
        title: AWS Documentation - Block public access to your AMIs
  - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-api
    filters: asset.platform == "aws"
    mql: |
      aws.ec2.images.all(
        launchPermissions.none(group == "all")
      )
  - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ami_launch_permission")
    mql: |
      terraform.resources.where(nameLabel == "aws_ami_launch_permission").none(
        arguments.group == "all"
      )
  - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ami_launch_permission")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ami_launch_permission").none(
        change.after.group == "all"
      )
  - uid: mondoo-aws-security-ec2-ami-public-sharing-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ami_launch_permission")
    mql: |
      terraform.state.resources.where(type == "aws_ami_launch_permission").none(
        values.group == "all"
      )
  - uid: mondoo-aws-security-ecs-container-non-root-user
    title: Ensure ECS task definitions specify a non-root user for containers
    impact: 80
    variants:
      - uid: mondoo-aws-security-ecs-container-non-root-user-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-hcl
      - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-plan
      - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ECS task definitions specify a non-root user for all container definitions. Running containers as root grants the process full administrative capabilities within the container, increasing the impact of a container breakout or compromise.

        **Why this matters**

        Running containers as root poses significant security risks:

        - **Container escape:** A root process inside a container has a much higher chance of exploiting kernel vulnerabilities to escape the container boundary and access the host system.
        - **File system access:** A root process inside the container can read and modify all files, including mounted volumes and secrets.
        - **Privilege escalation:** If a container is compromised, root access provides the attacker with maximum capabilities for lateral movement and data exfiltration.

        **Risk mitigation:**

        - **Least privilege:** Running as a non-root user limits what an attacker can do after compromising a container.
        - **Blast radius reduction:** Minimizes the impact of a container compromise.
        - **Compliance:** Meets CIS Docker Benchmark 4.1 and container security best practices.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECS Console.
            2. Select Task definitions in the left panel.
            3. Select the task definition to review.
            4. For each container definition, check the User setting under Container configuration.
            5. Set the User field to a non-root user (e.g., `1000` or `appuser`).
            6. Create a new revision with the updated setting.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for containers running as root in task definitions:

            ```bash
            aws ecs list-task-definitions --status ACTIVE --query "taskDefinitionArns" | \
              xargs -I {} aws ecs describe-task-definition --task-definition {} \
              --query "taskDefinition.containerDefinitions[*].{Name:name, User:user}"
            ```

            Register a new task definition revision with a non-root user:

            ```bash
            aws ecs register-task-definition --cli-input-json file://task-definition.json
            ```

            Ensure the container definition in your JSON file has `"user": "1000"` or a named non-root user.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure container definitions specify a non-root user:

            ```hcl
            resource "aws_ecs_task_definition" "example" {
              family = "example"

              container_definitions = jsonencode([
                {
                  name      = "app"
                  image     = "example:latest"
                  essential = true
                  user      = "1000"  # Non-root user
                }
              ])
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              TaskDefinition:
                Type: "AWS::ECS::TaskDefinition"
                Properties:
                  Family: "example"
                  ContainerDefinitions:
                    - Name: "app"
                      Image: "example:latest"
                      Essential: true
                      User: "1000"
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/security-runtime.html
        title: AWS Documentation - Runtime security for Amazon ECS
      - url: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html
        title: AWS Documentation - Task definition parameters
  - uid: mondoo-aws-security-ecs-container-non-root-user-api
    filters: asset.platform == "aws"
    mql: |
      aws.ecs.taskDefinitions.all(
        containerDefinitions.all(user != "root" && user != "0")
      )
  - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecs_task_definition")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecs_task_definition").all(
        arguments.container_definitions.all(
          _['user'] != "root" && _['user'] != "0"
        )
      )
  - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecs_task_definition").all(
        change.after.container_definitions.all(
          _['user'] != "root" && _['user'] != "0"
        )
      )
  - uid: mondoo-aws-security-ecs-container-non-root-user-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.state.resources.where(type == "aws_ecs_task_definition").all(
        values.container_definitions.all(
          _['user'] != "root" && _['user'] != "0"
        )
      )
  - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption
    title: Ensure ECS task definitions enforce transit encryption for EFS volumes
    impact: 70
    variants:
      - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-api
        tags:
          mondoo.com/filter-title: "AWS Account"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-hcl
      - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-plan
      - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Amazon ECS task definitions configure transit encryption for EFS (Elastic File System) volumes. When EFS volumes are mounted in ECS tasks without transit encryption, data is transmitted in plaintext between the ECS task and the EFS file system, exposing it to potential interception.

        **Why this matters**

        Without transit encryption on EFS volumes:

        - **Data interception:** Network traffic between ECS tasks and EFS can be captured and read by anyone with access to the network path.
        - **Man-in-the-middle attacks:** An attacker on the network could intercept or modify data in transit between the container and the file system.
        - **Compliance violations:** Many security frameworks require encryption of data in transit, especially for sensitive workloads.

        **Risk mitigation:**

        - **Data protection:** TLS encryption protects data as it travels between ECS tasks and EFS.
        - **Regulatory compliance:** Meets encryption-in-transit requirements for PCI DSS, HIPAA, and SOC 2.
        - **Defense in depth:** Adds a layer of protection even if network-level controls are compromised.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon ECS Console.
            2. Select Task definitions in the left panel.
            3. Select the task definition to review.
            4. Under Volumes, check EFS volume configurations.
            5. For each EFS volume, ensure Transit encryption is set to Enabled.
            6. Create a new revision with the updated setting.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check for EFS volumes without transit encryption:

            ```bash
            aws ecs list-task-definitions --status ACTIVE --query "taskDefinitionArns" | \
              xargs -I {} aws ecs describe-task-definition --task-definition {} \
              --query "taskDefinition.volumes[?efsVolumeConfiguration].{Name:name, Transit:efsVolumeConfiguration.transitEncryption}"
            ```

            Register a new task definition revision with transit encryption enabled:

            ```bash
            aws ecs register-task-definition --cli-input-json file://task-definition.json
            ```

            Ensure the volume configuration includes `"transitEncryption": "ENABLED"`.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure EFS volumes in ECS task definitions have transit encryption enabled:

            ```hcl
            resource "aws_ecs_task_definition" "example" {
              family = "example"

              volume {
                name = "efs-volume"

                efs_volume_configuration {
                  file_system_id     = aws_efs_file_system.example.id
                  transit_encryption = "ENABLED"
                  transit_encryption_port = 2999
                }
              }

              container_definitions = jsonencode([
                {
                  name  = "app"
                  image = "example:latest"

                  mountPoints = [
                    {
                      sourceVolume  = "efs-volume"
                      containerPath = "/data"
                    }
                  ]
                }
              ])
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              TaskDefinition:
                Type: "AWS::ECS::TaskDefinition"
                Properties:
                  Family: "example"
                  Volumes:
                    - Name: "efs-volume"
                      EFSVolumeConfiguration:
                        FilesystemId: !Ref EFSFileSystem
                        TransitEncryption: "ENABLED"
                        TransitEncryptionPort: 2999
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html
        title: AWS Documentation - Amazon EFS volumes
      - url: https://docs.aws.amazon.com/efs/latest/ug/encryption-in-transit.html
        title: AWS Documentation - Encrypting data in transit
  - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-api
    filters: asset.platform == "aws"
    mql: |
      aws.ecs.taskDefinitions.all(
        volumes.where(efsVolumeConfiguration != empty).all(
          efsVolumeConfiguration.transitEncryption == "ENABLED"
        )
      )
  - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ecs_task_definition")
    mql: |
      terraform.resources.where(nameLabel == "aws_ecs_task_definition").all(
        blocks.where(type == "volume").all(
          blocks.where(type == "efs_volume_configuration").all(
            attributes.transit_encryption.value == "ENABLED"
          )
        )
      )
  - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ecs_task_definition").all(
        change.after.volume.where(_['efs_volume_configuration'] != empty).all(
          _['efs_volume_configuration']['transit_encryption'] == "ENABLED"
        )
      )
  - uid: mondoo-aws-security-ecs-efs-volume-transit-encryption-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ecs_task_definition")
    mql: |
      terraform.state.resources.where(type == "aws_ecs_task_definition").all(
        values.volume.where(_['efs_volume_configuration'] != empty).all(
          _['efs_volume_configuration']['transit_encryption'] == "ENABLED"
        )
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-retention-set
    title: Ensure CloudWatch log groups have a retention period configured
    impact: 60
    variants:
      - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-api
        tags:
          mondoo.com/filter-title: "AWS CloudWatch Log Group"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-hcl
      - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-plan
      - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudWatch log groups have a defined retention period. Without a retention period, log groups retain data indefinitely by default, which can lead to uncontrolled storage costs and make it harder to manage log data lifecycle. Conversely, organizations need to ensure logs are retained long enough to support security investigations, forensic analysis, and compliance requirements.

        **Why this matters**

        Undefined log retention periods create security and operational risks:

        - **Forensic gaps:** Without explicit retention, log groups may be manually purged or left in an ambiguous state, which could result in the loss of critical data needed for incident investigation.
        - **Compliance requirements:** Security frameworks such as PCI DSS, HIPAA, and SOC 2 require defined log retention periods (often 90 days to 1 year minimum).
        - **Cost management:** Indefinite retention leads to unbounded storage costs that grow over time.

        **Risk mitigation:**

        - **Incident response:** Ensures logs are available for a defined period to support security investigations.
        - **Regulatory compliance:** Meets log retention requirements mandated by security frameworks.
        - **Operational hygiene:** Establishes a clear data lifecycle policy for log data.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon CloudWatch Console.
            2. Select Log Groups from the left panel.
            3. Select a log group.
            4. Under Actions, choose Edit retention setting.
            5. Set the retention period to an appropriate value (e.g., 90 days, 1 year).
            6. Choose Save.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check log groups without retention periods:

            ```bash
            aws logs describe-log-groups --query "logGroups[?!retentionInDays].logGroupName"
            ```

            Set a retention period on a log group:

            ```bash
            aws logs put-retention-policy \
              --log-group-name <log-group-name> \
              --retention-in-days 365
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure CloudWatch log groups have a retention period:

            ```hcl
            resource "aws_cloudwatch_log_group" "example" {
              name              = "example-log-group"
              retention_in_days = 365
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              LogGroup:
                Type: "AWS::Logs::LogGroup"
                Properties:
                  LogGroupName: "example-log-group"
                  RetentionInDays: 365
            ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Working-with-log-groups-and-streams.html
        title: AWS Documentation - Working with log groups and log streams
  - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-api
    filters: asset.platform == "aws-cloudwatch-loggroup"
    mql: |
      aws.cloudwatch.loggroup.retentionInDays > 0
  - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudwatch_log_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudwatch_log_group").all(
        arguments.retention_in_days != empty && arguments.retention_in_days > 0
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudwatch_log_group").all(
        change.after.retention_in_days != empty && change.after.retention_in_days > 0
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-retention-set-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.state.resources.where(type == "aws_cloudwatch_log_group").all(
        values.retention_in_days != empty && values.retention_in_days > 0
      )
  - uid: mondoo-aws-security-redshift-cluster-require-ssl
    title: Ensure Redshift clusters require SSL for connections
    impact: 80
    variants:
      - uid: mondoo-aws-security-redshift-cluster-require-ssl-api
        tags:
          mondoo.com/filter-title: "AWS Redshift Cluster"
          mondoo.com/icon: "aws"
      - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters enforce SSL/TLS for all client connections by setting the `require_ssl` parameter to `true` in the cluster parameter group. Without SSL enforcement, database connections transmit data in plaintext, exposing queries and results to network interception.

        **Why this matters**

        Unencrypted Redshift connections pose significant security risks:

        - **Data interception:** Queries and results are transmitted in plaintext, allowing anyone with network access to capture sensitive data including credentials and business data.
        - **Credential theft:** Database usernames and passwords sent over unencrypted connections can be captured via network sniffing.
        - **Man-in-the-middle attacks:** Without SSL, attackers can intercept and modify queries and responses.
        - **Compliance violations:** PCI DSS, HIPAA, and SOC 2 require encryption of data in transit.

        **Risk mitigation:**

        - **Data protection:** SSL/TLS encrypts all data transmitted between clients and the Redshift cluster.
        - **Authentication:** SSL provides server identity verification, preventing connection to impersonated endpoints.
        - **Regulatory compliance:** Meets encryption-in-transit requirements mandated by security frameworks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console**

            1. Navigate to the Amazon Redshift Console.
            2. Select Configurations > Workload management in the left panel.
            3. Select the parameter group used by your cluster.
            4. Choose Edit parameters.
            5. Set `require_ssl` to `true`.
            6. Choose Save.
            7. Reboot the cluster for changes to take effect.
        - id: cli
          desc: |
            **Using AWS CLI**

            Check the current require_ssl setting:

            ```bash
            aws redshift describe-cluster-parameters \
              --parameter-group-name <parameter-group-name> \
              --query "Parameters[?ParameterName=='require_ssl']"
            ```

            Enable require_ssl:

            ```bash
            aws redshift modify-cluster-parameter-group \
              --parameter-group-name <parameter-group-name> \
              --parameters ParameterName=require_ssl,ParameterValue=true
            ```

            Reboot the cluster to apply changes:

            ```bash
            aws redshift reboot-cluster --cluster-identifier <cluster-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the Redshift parameter group requires SSL:

            ```hcl
            resource "aws_redshift_parameter_group" "example" {
              name   = "example-parameter-group"
              family = "redshift-1.0"

              parameter {
                name  = "require_ssl"
                value = "true"
              }
            }

            resource "aws_redshift_cluster" "example" {
              cluster_identifier        = "example-cluster"
              node_type                 = "dc2.large"
              cluster_parameter_group_name = aws_redshift_parameter_group.example.name
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            ```yaml
            Resources:
              RedshiftParameterGroup:
                Type: AWS::Redshift::ClusterParameterGroup
                Properties:
                  Description: "Parameter group with SSL required"
                  ParameterGroupFamily: redshift-1.0
                  Parameters:
                    - ParameterName: require_ssl
                      ParameterValue: "true"

              RedshiftCluster:
                Type: AWS::Redshift::Cluster
                Properties:
                  ClusterIdentifier: example-cluster
                  NodeType: dc2.large
                  ClusterParameterGroupName: !Ref RedshiftParameterGroup
            ```
    refs:
      - url: https://docs.aws.amazon.com/redshift/latest/mgmt/connecting-ssl-support.html
        title: AWS Documentation - Configure security options for connections
      - url: https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-parameter-groups.html
        title: AWS Documentation - Amazon Redshift parameter groups
  - uid: mondoo-aws-security-redshift-cluster-require-ssl-api
    filters: asset.platform == "aws-redshift-cluster"
    mql: |
      aws.redshift.cluster.parameters.where(_['ParameterName'] == "require_ssl").all(
        _['ParameterValue'] == "true"
      )
  - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_redshift_parameter_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_redshift_parameter_group").all(
        blocks.any(
          attributes.name.value == "require_ssl"
            && attributes.value.value == "true"
        )
      )
  - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_redshift_parameter_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_redshift_parameter_group").all(
        change.after.parameter.where(name == "require_ssl").map(value).first == "true"
      )
  - uid: mondoo-aws-security-redshift-cluster-require-ssl-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_redshift_parameter_group")
    mql: |
      terraform.state.resources.where(type == "aws_redshift_parameter_group").all(
        values.parameter.where(name == "require_ssl").map(value).first == "true"
      )
