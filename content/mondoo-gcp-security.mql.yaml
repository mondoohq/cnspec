# Copyright (c) Mondoo, Inc.
# SPDX-License-Identifier: BUSL-1.1
policies:
  - uid: mondoo-gcp-security
    name: Mondoo Google Cloud (GCP) Security
    version: 5.0.0
    license: BUSL-1.1
    tags:
      mondoo.com/category: security
      mondoo.com/platform: gcp,cloud
    require:
      - provider: gcp
      - provider: terraform
    authors:
      - name: Mondoo, Inc.
        email: hello@mondoo.com
    docs:
      desc: |
        The Mondoo Google Cloud (GCP) Security policy is designed to identify critical misconfigurations that could leave your Google Cloud infrastructure vulnerable to attackers. This policy helps organizations detect and remediate security risks before they can be exploited, reducing the likelihood of unauthorized access, data breaches, privilege escalation, and operational disruptions.

        This policy provides security checks across key GCP services, uncovering misconfigurations that could put critical resources at risk, particularly those exposed to the public internet:

        - API Keys
        - BigQuery
        - Binary Authorization
        - Cloud DNS
        - Cloud Functions
        - Cloud Key Management Service (KMS)
        - Cloud Logging
        - Cloud Run
        - Cloud SQL
        - Cloud Storage
        - Compute Engine instances, firewalls, networks, and subnetworks
        - Dataproc
        - Google Kubernetes Engine (GKE)
        - Identity and Access Management (IAM)
        - Memorystore for Redis / Redis Cluster
        - Pub/Sub
        - Secret Manager

        Have suggestions for new checks in this policy? Visit our [cnspec repository](https://github.com/mondoohq/cnspec).
    groups:
      - title: Cloud Storage
        checks:
          - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
          - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
          - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention
          - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption
          - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked
      - title: BigQuery
        checks:
          - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible
          - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption
          - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption
      - title: Cloud KMS
        checks:
          - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible
          - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days
          - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration
          - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location
          - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured
      - title: Cloud DNS
        checks:
          - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled
          - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used
          - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used
      - title: Compute Engine Instances
        checks:
          - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys
          - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled
          - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled
          - uid: mondoo-gcp-security-compute-instances-no-default-service-account
          - uid: mondoo-gcp-security-compute-instances-no-public-ip
          - uid: mondoo-gcp-security-compute-instances-oslogin-enabled
          - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled
          - uid: mondoo-gcp-security-compute-instances-vtpm-enabled
          - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
          - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
      - title: Compute Firewall
        checks:
          - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet
          - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet
          - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols
          - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet
          - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress
      - title: Compute Network
        checks:
          - uid: mondoo-gcp-security-compute-network-not-legacy
          - uid: mondoo-gcp-security-compute-network-default-deleted
          - uid: mondoo-gcp-security-compute-network-dns-logging-enabled
      - title: Compute Subnetwork
        checks:
          - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled
          - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled
          - uid: mondoo-gcp-security-compute-subnetwork-not-overly-broad-cidr
      - title: GKE
        checks:
          - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled
          - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled
          - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled
          - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled
          - uid: mondoo-gcp-security-gke-cluster-alpha-disabled
          - uid: mondoo-gcp-security-gke-workload-identity-enabled
          - uid: mondoo-gcp-security-gke-private-cluster-enabled
          - uid: mondoo-gcp-security-gke-shielded-nodes-enabled
          - uid: mondoo-gcp-security-gke-release-channel-configured
      - title: Cloud SQL
        checks:
          - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls
          - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed
          - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled
          - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled
          - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls
          - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed
          - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled
          - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled
          - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose
          - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls
          - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed
      - title: Memorystore for Redis / Redis Cluster
        checks:
          - uid: mondoo-gcp-security-cloud-redis-auth-enabled
          - uid: mondoo-gcp-security-cloud-redis-cmek-configured
          - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled
          - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier
          - uid: mondoo-gcp-security-cloud-redis-cluster-iam-auth-enabled
          - uid: mondoo-gcp-security-cloud-redis-cluster-deletion-protection-enabled
      - title: Cloud IAM
        checks:
          - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys
          - uid: mondoo-gcp-security-iam-default-service-accounts-disabled
          - uid: mondoo-gcp-security-iam-service-account-keys-rotated-90-days
          - uid: mondoo-gcp-security-iam-no-disabled-service-account-keys
      - title: Cloud Logging
        checks:
          - uid: mondoo-gcp-security-logging-bucket-retention-30-days
          - uid: mondoo-gcp-security-logging-bucket-locked
          - uid: mondoo-gcp-security-logging-sinks-configured
      - title: Pub/Sub
        checks:
          - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption
          - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured
      - title: Cloud Functions
        checks:
          - uid: mondoo-gcp-security-cloud-functions-ingress-restricted
          - uid: mondoo-gcp-security-cloud-functions-no-default-service-account
          - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured
      - title: Cloud Run
        checks:
          - uid: mondoo-gcp-security-cloud-run-ingress-restricted
          - uid: mondoo-gcp-security-cloud-run-cmek-encryption
          - uid: mondoo-gcp-security-cloud-run-no-default-service-account
      - title: Dataproc
        checks:
          - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured
          - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only
          - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms
      - title: Binary Authorization
        checks:
          - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all
          - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled
      - title: API Keys
        checks:
          - uid: mondoo-gcp-security-api-keys-api-restrictions-configured
          - uid: mondoo-gcp-security-api-keys-application-restrictions-configured
          - uid: mondoo-gcp-security-api-keys-not-stale
      - title: Secret Manager
        checks:
          - uid: mondoo-gcp-security-secretmanager-cmek-encryption
          - uid: mondoo-gcp-security-secretmanager-rotation-configured
          - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible
    scoring_system: highest impact
queries:
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
    title: Ensure that instances are not configured to use the default service account
    impact: 95
    variants:
      - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-gcp
      - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-hcl
      - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-plan
      - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud Compute Engine instances are not configured to use the default service account (-compute@developer.gserviceaccount.com). Instead, instances should use custom service accounts with only the permissions required for their specific function, adhering to the principle of least privilege.

        **Why this matters**

        When the Compute Engine API is enabled on a new Google Cloud project, Google automatically creates a default Compute Engine service account with the IAM Editor role. This account has broad permissions across many Google Cloud services and is frequently used by default unless explicitly overridden:
          - Using the default service account grants more privileges than most applications require, increasing the risk of privilege escalation or lateral movement in the event of compromise.
          - The default service account is shared across all instances in the project, reducing visibility and control over which workloads can access which resources.
          - Misuse or over-permissioning of default service accounts has been the cause of multiple cloud security incidents, particularly when combined with metadata API access.

        If instances continue to use the default service account, it can lead to:
          - Excessive permissions, violating least privilege principles and security best practices.
          - Difficult-to-audit access patterns, as many services share a single identity with broad permissions.
          - Increased blast radius if the service account credentials are leaked or the instance is compromised.
          - Non-compliance with security benchmarks such as CIS Google Cloud Platform Foundations Benchmark and NIST 800-53.

        **Risk mitigation:**
          - Replace default service accounts with custom service accounts that have narrowly scoped IAM roles tailored to the workload.
          - Regularly review and audit service account usage to ensure they are aligned with current access needs.
          - Disable or delete the default service account only after ensuring that no dependent applications or services will be disrupted.
          - Leverage IAM Conditions and organization policies to prevent the use of default service accounts in new deployments.

        By avoiding the use of the default Compute Engine service account, organizations can enforce better identity isolation, minimize unnecessary permissions, and enhance the overall security posture of their Google Cloud environment.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To provision or update a compute instance with a custom service account:

            ```hcl
            resource "google_compute_instance" "default" {
              name         = "secure-instance"
              machine_type = var.machine_type
              zone         = var.zone
              tags = ["terraform"]

              service_account {
                email  = "example@example.com"
                scopes = ["user-email", "compute-ro", "storage-ro"]
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            To change the policy using the GCP Console, follow these steps:

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Select the Organization and Project where the instance you want to update is running.
            3. Navigate to **Compute Engine**.
            4. Select the compute instance that you want to update.
            5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
            6. Select **Edit**.
            7. Scroll down to the Service Account section.
            8. Select a different service account.
            9. Select **Save**.
            10. Select **START**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update the service account using the `gcloud` CLI:

            1. Stop the instance:

              ```bash
              gcloud compute instances stop INSTANCE_NAME
              ```

            2. Update the instance:

              ```bash
              gcloud compute instances set-service-account INSTANCE_NAME --service-account=SERVICE_ACCOUNT --scopes [SCOPE1,SCOPE2...]
              ```

            3. Restart the instance:

              ```bash
              gcloud compute instances start INSTANCE_NAME
              ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance.serviceAccounts.none(
        email == /^\d{12}-(compute|cloudservices)@developer\.gserviceaccount\.com$|^[a-z][a-z0-9\-]{4,28}@appspot\.gserviceaccount\.com$/
      )
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_instance')
    mql: |
      # Check that service_account block exists on all compute instances and no service_account uses default service account email
      terraform.resources('google_compute_instance').any(
        blocks.where(type == 'service_account') != empty &&
        blocks.where(type == 'service_account').none(
          arguments.email == /^\d{12}-(compute|cloudservices)@developer\.gserviceaccount\.com$|^[a-z][a-z0-9\-]{4,28}@appspot\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(
        type == 'google_compute_instance'
      ).all(
        change.after.service_account.none(
          email == /^\d{12}-(compute|cloudservices)@developer\.gserviceaccount\.com$|^[a-z][a-z0-9\-]{4,28}@appspot\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(
        type == 'google_compute_instance'
      ).all(
        values.service_account.none(
          email == /^\d{12}-(compute|cloudservices)@developer\.gserviceaccount\.com$|^[a-z][a-z0-9\-]{4,28}@appspot\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
    title: Ensure instances are not configured to use the default service account with full access to all Cloud APIs
    impact: 90
    variants:
      - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-gcp
      - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-hcl
      - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-plan
      - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud Compute Engine instances are not provisioned to use the default service account with full access to all Google Cloud APIs. Instead, instances should be assigned custom service accounts with narrowly scoped permissions, adhering to the principle of least privilege.

        **Why this matters**

        By default, when creating a Compute Engine instance, users can assign it “Allow full access to all Cloud APIs”, granting unrestricted access to most Google Cloud services. This setting is overly permissive and introduces significant security risk:
          - It allows the instance to interact with nearly any Google Cloud API, regardless of the workload's actual needs.
          - In the event of a compromise, an attacker could use the instance's credentials to access sensitive resources, manipulate cloud infrastructure, or move laterally across services.
          - The broad access complicates auditing and access management, making it harder to identify excessive privileges or detect misuse.

        If instances are provisioned with full API access, it can lead to:
          - Privilege escalation and lateral movement, especially if metadata APIs are accessible from within the VM.
          - Increased blast radius in the event of credential theft or VM compromise.
          - Violations of least privilege and non-compliance with security frameworks such as CIS GCP Foundations Benchmark, NIST 800-53, and ISO 27001.
          - Obscured audit trails, since full access allows interactions with multiple services without role-based segmentation.

        **Risk mitigation:**
          - Assign custom service accounts to instances with only the specific roles required for their function.
          - Avoid using the “Allow full access to all Cloud APIs” option during instance creation.
          - Enforce IAM policies and organizational constraints to block the use of overly permissive API scopes.
          - Continuously review service account permissions and API scopes as part of your identity and access governance strategy.

        Restricting Compute Engine instances to minimal necessary API access helps contain the impact of security incidents, improves visibility and control, and supports a robust and compliant cloud security posture.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To provision or update a compute instance with Terraform:

            ```hcl
            resource "google_service_account" "default" {
              account_id   = "my-custom-sa"
              display_name = "Custom SA for VM Instance"
            }

            resource "google_compute_instance" "default" {
              name         = "secure-instance"
              machine_type = var.machine_type
              zone         = var.zone
              tags = ["terraform"]

              service_account {
                # Google recommends custom service accounts with cloud-platform scope and permissions granted via IAM Roles.
                email  = google_service_account.default.email
                scopes = ["cloud-platform"]
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            To change the policy using the Google Cloud Console:

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Select the Organization and Project where the instance you want to update is running.
            3. Navigate to **Compute Engine**.
            4. Select the compute instance that you want to update.
            5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
            6. Select **Edit**.
            7. Scroll down to the Service Account section.
            8. Select a different service account or ensure Allow full access to all Cloud APIs is not selected.
            9. Select **Save**.
            10. Select **START**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update the service account using the `gcloud` CLI:

            1. Stop the instance:

              ```bash
              gcloud compute instances stop INSTANCE_NAME
              ```

            2. Update the instance:

              ```bash
              gcloud compute instances set-service-account INSTANCE_NAME --service-account=SERVICE_ACCOUNT --scopes [SCOPE1,SCOPE2...]
              ```

            3. Restart the instance:

              ```bash
              gcloud compute instances start INSTANCE_NAME
              ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.serviceAccounts.contains( email == /^\d{12}-(compute|cloudservices)@developer\.gserviceaccount\.com$|^[a-z][a-z0-9\-]{4,28}@appspot\.gserviceaccount\.com$/ )
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance.serviceAccounts.none(
        scopes == 'https://www.googleapis.com/auth/cloud-platform'
      )
  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_instance')
    mql: |
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'service_account') != empty &&
        blocks.where(
          type == 'service_account' &&
          arguments.email.contains(/^(default|\d{12}-compute@developer\.gserviceaccount\.com)$/)
        ).all(
          arguments.scopes.none(
            _ == /(https?:\/\/www\.googleapis\.com\/auth\/)?cloud-platform/
          )
        )
      )
  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(
        type == 'google_compute_instance'
      ).all(
        change.after.service_account.none(
          email == /^(default|\d{12}-compute@developer\.gserviceaccount\.com)$/ &&
          scopes.contains(/(https?:\/\/www\.googleapis\.com\/auth\/)?cloud-platform/)
        )
      )
  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(
        type == 'google_compute_instance'
      ).all(
        values.service_account.none(
          email == /^(default|\d{12}-compute@developer\.gserviceaccount\.com)$/ &&
          scopes.contains(/(https?:\/\/www\.googleapis\.com\/auth\/)?cloud-platform/)
        )
      )
  - uid: mondoo-gcp-security-compute-instances-oslogin-enabled
    title: Ensure oslogin is enabled for compute instances
    impact: 70
    variants:
      - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-gcp
      - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-state
    docs:
      desc: |
        This check ensures that OS Login is enabled on Google Cloud Platform (GCP) Compute Engine instances to manage SSH access through IAM roles rather than relying on SSH keys stored in project or instance metadata. OS Login improves access control, auditability, and security by centralizing identity-based SSH authentication.

        **Why this matters**

        By default, SSH access to GCP Compute Engine instances is managed using manually added SSH keys in project or instance metadata. This method has several limitations:
          - SSH keys are difficult to track, audit, and revoke, especially in large or dynamic environments.
          - Key-based access lacks integration with IAM policies, which makes it harder to enforce centralized identity governance.
          - Users can retain access indefinitely if SSH keys are not manually removed, creating lingering access risks.

        OS Login solves these issues by integrating SSH access with IAM:
          - Access is granted or revoked based on IAM roles (roles/compute.osLogin, roles/compute.osAdminLogin).
          - User access is managed centrally and consistently across all instances.
          - Login activity is auditable through Cloud Audit Logs and linked to the user's Google identity.

        If OS Login is not enabled, it can lead to:
          - Stale or orphaned SSH keys, increasing the risk of unauthorized access.
          - Limited visibility and control over who has access to which instances.
          - Non-compliance with security best practices and frameworks like CIS GCP Foundations Benchmark, NIST 800-53, and ISO 27001.
          - Operational complexity, as access changes require manual updates to metadata.

        **Risk mitigation:**
          - Enable OS Login by setting the enable-oslogin metadata key to TRUE at the project or instance level.
          - Use IAM roles to define which users can access which instances, and whether they have standard or administrative privileges.
          - Leverage OS Login with 2-Step Verification (OS Login 2SV) for enhanced access protection.
          - Regularly review IAM policies and login activity to ensure appropriate access and detect anomalies.

        Enabling OS Login provides a secure, scalable, and manageable way to control SSH access to Compute Engine instances, aligning with best practices for identity-based access control and centralized policy enforcement in GCP environments.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To configure OS Login for a project:

            ```hcl
            resource "google_compute_project_metadata" "default" {
              metadata = {
                enable-oslogin = "TRUE"
              }
            }
            ```

            To provision or update a compute instance with Terraform:

            ```hcl
            resource "google_compute_instance" "default" {
              name         = "secure-instance"
              machine_type = var.machine_type
              zone         = var.zone
              tags = ["terraform"]

              metadata = {
                "enable-oslogin" = "true"
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            To configure OS Login for a project via Google Cloud Console:

            1. In the Google Cloud console, go to the **Metadata** page.
            2. Select **EDIT**.
            3. Add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
            4. Select **SAVE** to apply the changes.

            To configure OS Login for an existing instance:

            1. In the Google Cloud console, go to the **Compute Engine**.
            2. Select the name of the instance that you want to enable OS Login on.
            3. On the instance details page, select **EDIT**.
            4. Under **Custom metadata**, add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
            5. Select **SAVE**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update OS Login for a project using the `gcloud` CLI:

            ```bash
            gcloud compute project-info add-metadata --metadata enable-oslogin=TRUE
            ```

            To update OS Login for an existing instance using the `gcloud` CLI:

            ```bash
            gcloud compute instances add-metadata INSTANCE_NAME --metadata enable-oslogin=TRUE
            ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-gcp
    filters: asset.platform == 'gcp-compute-instance'
    mql: gcp.compute.instance.metadata['enable-oslogin'] == true
  - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_instance' || nameLabel == 'google_compute_project_metadata')
    mql: |
      terraform.resources('google_compute_instance').all(
        arguments.metadata != empty &&
        arguments.metadata['enable-oslogin'] == /true/i
      )
  - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance' || type == 'google_compute_project_metadata')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance').all(
        change.after.metadata['enable-oslogin'] == /true/i
      )
  - uid: mondoo-gcp-security-compute-instances-oslogin-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance' || type == 'google_compute_project_metadata')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance').all(
        values.metadata['enable-oslogin'] == /true/i
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
    title: Ensure that Cloud Storage buckets are not anonymously or publicly accessible
    impact: 90
    variants:
      - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-gcp
      - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-hcl
      - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-plan
      - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud Storage buckets do not have IAM bindings or ACLs that grant access to the allUsers or allAuthenticatedUsers principals. These principals represent unauthenticated and broadly authenticated public access, which significantly increases the risk of unintentional data exposure.

        **Why this matters**

        In Google Cloud, the allUsers principal allows anyone on the internet to access a resource without authentication, while allAuthenticatedUsers allows access to any user with a Google account. Assigning these principals to a Cloud Storage bucket—either directly via IAM roles or indirectly through legacy ACLs—exposes data to a much broader audience than intended.

        This type of access is often misconfigured and can lead to:
          - Public exposure of sensitive data, including personally identifiable information (PII), internal documents, or application configuration files.
          - Data misuse or leakage, especially if access is granted with roles beyond read-only permissions.
          - Non-compliance with regulatory frameworks like GDPR, HIPAA, PCI DSS, ISO 27001, and the CIS GCP Foundations Benchmark.
          - Audit and incident response challenges, since access by allUsers or allAuthenticatedUsers is not attributable to a specific identity.

        **Risk mitigation:**
          - Audit IAM policies and bucket ACLs to detect any bindings involving allUsers or allAuthenticatedUsers.
          - Remove these principals from bucket policies and replace them with specific identities (e.g., service accounts, groups, or individual users) that require access.
          - Enable Public Access Prevention to proactively block public access configuration.
          - Enforce organization policies that restrict or deny the use of these principals across your projects.

        Eliminating access for allUsers and allAuthenticatedUsers on Cloud Storage buckets is a critical step in protecting cloud-resident data, enforcing least privilege access, and ensuring compliance with modern cloud security and privacy standards.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To update public access configuration using Terraform, ensure `allUsers` and `allAuthenticatedUsers` are not set:

            ```hcl
            resource "google_storage_bucket_iam_binding" "binding" {
              bucket = google_storage_bucket.default.name
              role   = "roles/storage.admin"
              members = [
                "user:jane@example.com",
              ]
            }
            ```

            ```hcl
            resource "google_storage_bucket_iam_member" "member" {
              bucket = google_storage_bucket.default.name
              role   = "roles/storage.admin"
              member = "user:jane@example.com"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Cloud Storage Bucket** page.
            2. For the bucket you want to enforce public access prevention on, select the more actions menu.
            3. Select **Edit access** from the drop-down menu.
            4. In the Public access card, select **Prevent public access** to enforce public access prevention.
            5. Select **Confirm**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update public access configuration using the `gcloud` cli, ensure `allUsers` and `allAuthenticatedUsers` are not set by removing them:

            ```bash
            # Example: Remove allUsers binding for objectViewer role
            gcloud storage buckets remove-iam-policy-binding gs://BUCKET_NAME --member=allUsers --role=roles/storage.objectViewer

            # Example: Remove allAuthenticatedUsers binding for objectViewer role
            gcloud storage buckets remove-iam-policy-binding gs://BUCKET_NAME --member=allAuthenticatedUsers --role=roles/storage.objectViewer
            ```
    refs:
      - url: https://cloud.google.com/storage/docs/best-practices#security
        title: Cloud Storage Security Best Practices
  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-gcp
    filters: asset.platform == 'gcp-storage-bucket'
    mql: |
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allUsers'))
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allAuthenticatedUsers'))
  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_storage_bucket_iam_binding' || nameLabel == 'google_storage_bucket_iam_member')
    mql: |
      terraform.resources('google_storage_bucket_iam_binding').all(
        arguments.members.none(member: member == 'allUsers' || member == 'allAuthenticatedUsers')
      )
      terraform.resources('google_storage_bucket_iam_member').all(
        arguments.member != 'allUsers' && arguments.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_storage_bucket_iam_binding' || type == 'google_storage_bucket_iam_member')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket_iam_binding').all(
        change.after.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket_iam_member').all(
        change.after.member != 'allUsers' && change.after.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_storage_bucket_iam_binding' || type == 'google_storage_bucket_iam_member')
    mql: |
      terraform.state.resources.where(type == 'google_storage_bucket_iam_binding').all(
        values.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
      terraform.state.resources.where(type == 'google_storage_bucket_iam_member').all(
        values.member != 'allUsers' && values.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
    title: Ensure that Cloud Storage buckets have uniform bucket-level access enabled
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-gcp
      - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-state
    docs:
      desc: |
        Cloud Storage offers two systems for granting users permission to access your buckets and objects: IAM and Access Control Lists (ACLs). These systems act in parallel - in order for a user to access a Cloud Storage resource, only one of the systems needs to grant the user permission. IAM is used throughout Google Cloud and allows you to grant a variety of permissions at the bucket and project levels. ACLs are used only by Cloud Storage and have limited permission options, but they allow you to grant permissions on a per-object basis.

        It is recommended to enable uniform bucket-level access on Cloud Storage buckets. Uniform bucket-level access is used to unify and simplify how you grant access to your Cloud Storage resources by disabling ACLs and relying solely on IAM for access control.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_storage_bucket" "example" {
              name                        = "test-bucket"
              # Enable uniform bucket-level access
              uniform_bucket_level_access = true
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
            2. In the list of buckets, select the name of the desired bucket.
            3. Select the **Permissions** tab near the top of the page.
            4. In the **Access control** model section, select **Uniform**.
            5. In the pop-up menu that appears, select **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            # Enable uniform bucket-level access
            gcloud storage buckets update gs://BUCKET_NAME --uniform-bucket-level-access

            # Alternatively using gsutil
            gsutil uniformbucketlevelaccess set on gs://BUCKET_NAME
            ```
    refs:
      - url: https://cloud.google.com/storage/docs/best-practices#security
        title: Cloud Storage Security Best Practices
  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-gcp
    filters: asset.platform == 'gcp-storage-bucket'
    mql: gcp.storage.bucket.iamConfiguration.uniformBucketLevelAccess.enabled == true
  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_storage_bucket')
    mql: |
      terraform.resources('google_storage_bucket').all(
        arguments.uniform_bucket_level_access == true
      )
  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_storage_bucket')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket').all(
        change.after.uniform_bucket_level_access == true
      )
  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_storage_bucket')
    mql: |
      terraform.state.resources.where(type == 'google_storage_bucket').all(
        values.uniform_bucket_level_access == true
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention
    title: Ensure that Cloud Storage buckets enforce public access prevention
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-gcp
      - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-hcl
      - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-plan
      - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-state
    docs:
      desc: |
        Public access prevention protects Cloud Storage buckets from being accidentally exposed to the public. When you enforce public access prevention on a bucket, it prevents all public access to the bucket and its objects, regardless of existing IAM policies or ACLs.

        **Why this matters**

        Even with careful IAM configuration, a single misconfigured policy binding could expose sensitive data to the public internet. Public access prevention acts as an additional safeguard:
          - It overrides any IAM or ACL configuration that would grant public access, providing defense-in-depth.
          - It prevents accidental exposure from future IAM changes by team members unfamiliar with the bucket's sensitivity.
          - It ensures compliance with data protection regulations that require restricting public access to sensitive data stores.

        Without public access prevention enforced:
          - A single IAM binding with `allUsers` or `allAuthenticatedUsers` could expose all objects in the bucket.
          - Object-level ACLs could independently grant public access even if bucket-level IAM is correctly configured.
          - Organizational security boundaries may be bypassed by individual project-level permissions.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Set the `public_access_prevention` property to `enforced` in your bucket configuration:

            ```hcl
            resource "google_storage_bucket" "example" {
              name                        = "example-bucket"
              location                    = "US"
              public_access_prevention    = "enforced"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
            2. Select the name of the bucket you want to configure.
            3. Select the **Permissions** tab.
            4. In the **Public access** section, select **Prevent public access**.
            5. Select **Confirm**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud storage buckets update gs://BUCKET_NAME --public-access-prevention
            ```
    refs:
      - url: https://cloud.google.com/storage/docs/best-practices#security
        title: Cloud Storage Security Best Practices
  - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-gcp
    filters: asset.platform == 'gcp-storage-bucket'
    mql: gcp.storage.bucket.iamConfiguration['publicAccessPrevention'] == "enforced"
  - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_storage_bucket')
    mql: |
      terraform.resources('google_storage_bucket').all(
        arguments.public_access_prevention == "enforced"
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_storage_bucket')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket').all(
        change.after.public_access_prevention == "enforced"
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-public-access-prevention-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_storage_bucket')
    mql: |
      terraform.state.resources.where(type == 'google_storage_bucket').all(
        values.public_access_prevention == "enforced"
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption
    title: Ensure that Cloud Storage buckets are encrypted with customer-managed encryption keys (CMEK)
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-gcp
      - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-state
    docs:
      desc: |
        By default, Google Cloud Storage encrypts all data at rest using Google-managed encryption keys. While this provides a baseline level of encryption, using customer-managed encryption keys (CMEK) through Cloud KMS gives organizations greater control over their encryption keys and meets compliance requirements that mandate customer-controlled key management.

        **Why this matters**

        Customer-managed encryption keys provide several advantages over Google-managed keys:
          - Organizations maintain full control over the encryption key lifecycle, including creation, rotation, and destruction.
          - CMEK enables the ability to revoke access to encrypted data by disabling or destroying the encryption key.
          - It satisfies compliance requirements from frameworks such as PCI DSS, HIPAA, and FedRAMP that require customer-controlled encryption.
          - Key usage can be audited through Cloud Audit Logs for Cloud KMS, providing visibility into when and how keys are used.

        Without CMEK encryption:
          - Organizations cannot independently revoke access to encrypted data without deleting the data itself.
          - Compliance requirements for customer-managed key control may not be met.
          - There is no separation of duties between the cloud provider managing encryption and the customer controlling keys.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a Cloud KMS key and set it as the default encryption key for the bucket:

            ```hcl
            resource "google_kms_key_ring" "example" {
              name     = "example-keyring"
              location = "us"
            }

            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id
            }

            resource "google_storage_bucket" "example" {
              name     = "example-bucket"
              location = "US"

              encryption {
                default_kms_key_name = google_kms_crypto_key.example.id
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
            2. Select the name of the bucket you want to configure.
            3. Select the **Configuration** tab.
            4. Under **Encryption type**, click **Edit**.
            5. Select **Customer-managed encryption key**.
            6. Search for or enter the name of the Cloud KMS key you want to use.
            7. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud storage buckets update gs://BUCKET_NAME --default-encryption-key=projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
            ```
    refs:
      - url: https://cloud.google.com/storage/docs/best-practices#security
        title: Cloud Storage Security Best Practices
  - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-gcp
    filters: asset.platform == 'gcp-storage-bucket'
    mql: gcp.storage.bucket.encryption['defaultKmsKeyName'] != "" && gcp.storage.bucket.encryption['defaultKmsKeyName'] != empty
  - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_storage_bucket')
    mql: |
      terraform.resources('google_storage_bucket').all(
        blocks.where(type == 'encryption') != empty &&
        blocks.where(type == 'encryption').all(arguments.default_kms_key_name != empty)
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_storage_bucket')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket').all(
        change.after['encryption'] != empty &&
        change.after['encryption'].any(_['default_kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_storage_bucket')
    mql: |
      terraform.state.resources.where(type == 'google_storage_bucket').all(
        values['encryption'] != empty &&
        values['encryption'].any(_['default_kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked
    title: Ensure that Cloud Storage buckets have a locked retention policy configured
    impact: 50
    variants:
      - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-gcp
      - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-hcl
      - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-plan
      - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-state
    docs:
      desc: |
        A retention policy on a Cloud Storage bucket ensures that objects stored in the bucket cannot be deleted or overwritten for a specified duration. Locking the retention policy makes it irreversible, preventing anyone (including bucket owners) from reducing the retention period or removing the policy.

        **Why this matters**

        Locked retention policies provide immutability guarantees critical for data protection and compliance:
          - They prevent accidental or malicious deletion of important data such as logs, backups, or regulated records.
          - Locked policies satisfy regulatory requirements from SEC Rule 17a-4(f), CFTC Rule 1.31(c)-(d), FINRA, and similar frameworks that require write-once-read-many (WORM) storage.
          - Once locked, the retention policy cannot be removed or reduced, ensuring that data integrity is maintained even if an administrator account is compromised.

        Without a locked retention policy:
          - Critical data can be accidentally or intentionally deleted before its required retention period expires.
          - Compliance with data retention regulations may not be met, exposing the organization to legal and financial risk.
          - An attacker with sufficient permissions could delete evidence of a security breach or other activities.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a retention policy on the bucket. Note that locking a retention policy is an irreversible action:

            ```hcl
            resource "google_storage_bucket" "example" {
              name     = "example-bucket"
              location = "US"

              retention_policy {
                is_locked        = true
                retention_period = 86400  # Retention period in seconds (e.g., 1 day = 86400)
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
            2. Select the name of the bucket you want to configure.
            3. Select the **Protection** tab.
            4. Under **Retention policy**, click **Add a retention policy** if none exists.
            5. Enter the desired retention period.
            6. Click **Save**.
            7. To lock the policy, click **Lock** and confirm. Note that this action is irreversible.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. Set a retention policy on the bucket:

            ```bash
            gcloud storage buckets update gs://BUCKET_NAME --retention-period=DURATION
            ```

            2. Lock the retention policy (this is irreversible):

            ```bash
            gcloud storage buckets update gs://BUCKET_NAME --lock-retention-period
            ```
    refs:
      - url: https://cloud.google.com/storage/docs/best-practices#security
        title: Cloud Storage Security Best Practices
  - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-gcp
    filters: asset.platform == 'gcp-storage-bucket'
    mql: |
      gcp.storage.bucket.retentionPolicy['retentionPeriod'] > 0
      gcp.storage.bucket.retentionPolicy['isLocked'] == true
  - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_storage_bucket')
    mql: |
      terraform.resources('google_storage_bucket').all(
        blocks.where(type == 'retention_policy') != empty &&
        blocks.where(type == 'retention_policy').all(arguments.is_locked == true && arguments.retention_period > 0)
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_storage_bucket')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_storage_bucket').all(
        change.after['retention_policy'] != empty &&
        change.after['retention_policy'].any(_['is_locked'] == true && _['retention_period'] > 0)
      )
  - uid: mondoo-gcp-security-cloud-storage-bucket-retention-policy-locked-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_storage_bucket')
    mql: |
      terraform.state.resources.where(type == 'google_storage_bucket').all(
        values['retention_policy'] != empty &&
        values['retention_policy'].any(_['is_locked'] == true && _['retention_period'] > 0)
      )
  - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible
    title: Ensure that BigQuery datasets are not anonymously or publicly accessible
    impact: 90
    variants:
      - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-gcp
      - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-hcl
      - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-plan
      - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-state
    docs:
      desc: |
        BigQuery datasets can be configured with access controls that grant permissions to specific users, groups, domains, or special groups. Granting access to `allUsers` or `allAuthenticatedUsers` makes the dataset publicly accessible, exposing potentially sensitive data to anyone on the internet or any authenticated Google user.

        **Why this matters**

        BigQuery datasets often contain sensitive business data, customer information, analytics, or financial records. Public access to these datasets can have severe consequences:
          - Any user on the internet (with `allUsers`) or any Google account holder (with `allAuthenticatedUsers`) can query the data, leading to data breaches.
          - Publicly accessible datasets can incur unexpected query costs if external parties run expensive queries against your data.
          - Compliance frameworks such as PCI DSS, HIPAA, SOC 2, and GDPR require strict access controls on data stores containing sensitive information.

        Without restricting public access:
          - Sensitive data such as PII, financial records, or proprietary business intelligence may be exposed.
          - Query costs can escalate as unauthorized users run queries against the dataset.
          - The organization may fail compliance audits and face regulatory penalties.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `access` block in your BigQuery dataset does not include `allUsers` or `allAuthenticatedUsers`:

            ```hcl
            resource "google_bigquery_dataset" "example" {
              dataset_id = "example_dataset"
              location   = "US"

              access {
                role          = "OWNER"
                user_by_email = google_service_account.bqowner.email
              }

              access {
                role   = "READER"
                domain = "example.com"
              }
            }
            ```

            Also ensure that IAM bindings do not include public members:

            ```hcl
            resource "google_bigquery_dataset_iam_binding" "reader" {
              dataset_id = google_bigquery_dataset.example.dataset_id
              role       = "roles/bigquery.dataViewer"
              members = [
                "user:analyst@example.com",
              ]
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **BigQuery** page.
            2. Select the dataset you want to configure.
            3. Click **Sharing** and then **Permissions**.
            4. Review the list of principals and remove any entries for `allUsers` or `allAuthenticatedUsers`.
            5. Click **Done**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. Retrieve the current dataset access configuration:

            ```bash
            bq show --format=prettyjson PROJECT_ID:DATASET_ID
            ```

            2. Review the `access` array in the output and identify entries with `"specialGroup": "allAuthenticatedUsers"` or `"iamMember": "allUsers"`.

            3. Remove the public access entries and update the dataset:

            ```bash
            bq update --source=dataset.json PROJECT_ID:DATASET_ID
            ```
    refs:
      - url: https://cloud.google.com/bigquery/docs/best-practices-security
        title: BigQuery Security Best Practices
  - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-gcp
    filters: asset.platform == "gcp-bigquery-dataset"
    mql: |
      gcp.bigquery.dataset.access.none(entity == "allAuthenticatedUsers")
      gcp.bigquery.dataset.access.none(entity == "allUsers")
  - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_bigquery_dataset')
    mql: |
      terraform.resources('google_bigquery_dataset').all(
        blocks.where(type == 'access').none(arguments.special_group == 'allAuthenticatedUsers') &&
        blocks.where(type == 'access').none(arguments.special_group == 'allUsers')
      )
      if (terraform.resources.where(nameLabel == 'google_bigquery_dataset_iam_binding') != empty) {
        terraform.resources('google_bigquery_dataset_iam_binding').all(
          arguments.members.none(member: member == 'allUsers' || member == 'allAuthenticatedUsers')
        )
      }
      if (terraform.resources.where(nameLabel == 'google_bigquery_dataset_iam_member') != empty) {
        terraform.resources('google_bigquery_dataset_iam_member').all(
          arguments.member != 'allUsers' && arguments.member != 'allAuthenticatedUsers'
        )
      }
  - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_bigquery_dataset')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_bigquery_dataset').all(
        change.after['access'] == empty ||
        change.after['access'].none(_['special_group'] == 'allAuthenticatedUsers' || _['special_group'] == 'allUsers')
      )
  - uid: mondoo-gcp-security-bigquery-dataset-not-publicly-accessible-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_bigquery_dataset')
    mql: |
      terraform.state.resources.where(type == 'google_bigquery_dataset').all(
        values['access'] == empty ||
        values['access'].none(_['special_group'] == 'allAuthenticatedUsers' || _['special_group'] == 'allUsers')
      )
  - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption
    title: Ensure that a default customer-managed encryption key (CMEK) is specified for all BigQuery datasets
    impact: 60
    variants:
      - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-gcp
      - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-state
    docs:
      desc: |
        BigQuery encrypts all data at rest by default using Google-managed encryption keys. However, for organizations that require greater control over their encryption keys, BigQuery supports customer-managed encryption keys (CMEK) through Cloud KMS. Configuring a default CMEK on a dataset ensures that all new tables created within the dataset are automatically encrypted with the specified key.

        **Why this matters**

        Using customer-managed encryption keys provides several benefits over Google-managed keys:
          - Organizations maintain full control over the encryption key lifecycle, including creation, rotation, disabling, and destruction.
          - CMEK enables the ability to revoke access to all encrypted data in the dataset by disabling or destroying the encryption key.
          - Compliance frameworks such as PCI DSS, HIPAA, and FedRAMP often require customer-controlled encryption key management.
          - Key usage can be monitored through Cloud Audit Logs for Cloud KMS, providing visibility into data access patterns.

        Without CMEK encryption:
          - Organizations cannot independently control or revoke access to encrypted data.
          - Compliance requirements for customer-managed key control may not be met.
          - There is reduced separation of duties between the cloud provider and the customer for encryption management.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a Cloud KMS key as the default encryption key for the BigQuery dataset:

            ```hcl
            resource "google_kms_key_ring" "example" {
              name     = "example-keyring"
              location = "us"
            }

            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id
            }

            resource "google_bigquery_dataset" "example" {
              dataset_id = "example_dataset"
              location   = "US"

              default_encryption_configuration {
                kms_key_name = google_kms_crypto_key.example.id
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **BigQuery** page.
            2. Select the dataset you want to configure.
            3. Click **Edit Details**.
            4. Under **Advanced options**, expand **Encryption**.
            5. Select **Customer-managed encryption key (CMEK)**.
            6. Select or enter the Cloud KMS key to use.
            7. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            bq update --default_kms_key=projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY PROJECT_ID:DATASET_ID
            ```
    refs:
      - url: https://cloud.google.com/bigquery/docs/best-practices-security
        title: BigQuery Security Best Practices
  - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-gcp
    filters: asset.platform == "gcp-bigquery-dataset"
    mql: gcp.bigquery.dataset.kmsName != "" && gcp.bigquery.dataset.kmsName != empty
  - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_bigquery_dataset')
    mql: |
      terraform.resources('google_bigquery_dataset').all(
        blocks.where(type == 'default_encryption_configuration') != empty &&
        blocks.where(type == 'default_encryption_configuration').all(arguments.kms_key_name != empty)
      )
  - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_bigquery_dataset')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_bigquery_dataset').all(
        change.after['default_encryption_configuration'] != empty &&
        change.after['default_encryption_configuration'].any(_['kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-bigquery-dataset-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_bigquery_dataset')
    mql: |
      terraform.state.resources.where(type == 'google_bigquery_dataset').all(
        values['default_encryption_configuration'] != empty &&
        values['default_encryption_configuration'].any(_['kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption
    title: Ensure that all BigQuery tables are encrypted with customer-managed encryption keys (CMEK)
    impact: 60
    variants:
      - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-gcp
      - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-state
    docs:
      desc: |
        BigQuery tables can be individually encrypted with customer-managed encryption keys (CMEK) through Cloud KMS. While setting a default CMEK on the dataset ensures new tables inherit encryption, individual tables may have been created before the default was set or may have been explicitly configured with a different key. Verifying that all tables within a dataset use CMEK ensures comprehensive encryption coverage.

        **Why this matters**

        Table-level CMEK encryption is important because:
          - Tables created before a dataset default CMEK was configured may still use Google-managed encryption.
          - Tables can be created with explicit encryption settings that override the dataset default, potentially using weaker encryption.
          - Compliance audits often require verification that all data stores, not just their containers, are encrypted with customer-managed keys.
          - Without table-level verification, there may be gaps in encryption coverage that go undetected.

        Without table-level CMEK encryption:
          - Individual tables may be encrypted with Google-managed keys even if the dataset has a CMEK default.
          - Encryption key revocation at the dataset level may not affect tables with their own encryption settings.
          - Full compliance with encryption requirements cannot be guaranteed.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure CMEK encryption on individual BigQuery tables:

            ```hcl
            resource "google_bigquery_table" "example" {
              dataset_id = google_bigquery_dataset.example.dataset_id
              table_id   = "example_table"

              encryption_configuration {
                kms_key_name = google_kms_crypto_key.example.id
              }

              schema = <<EOF
              [
                {
                  "name": "column1",
                  "type": "STRING"
                }
              ]
              EOF
            }
            ```

            Alternatively, ensure the dataset has a default CMEK configured so all new tables inherit it:

            ```hcl
            resource "google_bigquery_dataset" "example" {
              dataset_id = "example_dataset"
              location   = "US"

              default_encryption_configuration {
                kms_key_name = google_kms_crypto_key.example.id
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **BigQuery** page.
            2. Navigate to the dataset and select the table.
            3. Click **Details** and review the **Encryption** section.
            4. If the table uses Google-managed encryption, recreate it with CMEK or set a dataset-level default CMEK and copy the data.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. Check the encryption configuration of a table:

            ```bash
            bq show --format=prettyjson PROJECT_ID:DATASET_ID.TABLE_ID
            ```

            2. To copy a table with CMEK encryption:

            ```bash
            bq cp --destination_kms_key=projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY PROJECT_ID:DATASET_ID.SOURCE_TABLE PROJECT_ID:DATASET_ID.DEST_TABLE
            ```
    refs:
      - url: https://cloud.google.com/bigquery/docs/best-practices-security
        title: BigQuery Security Best Practices
  - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-gcp
    filters: asset.platform == "gcp-bigquery-dataset"
    mql: gcp.bigquery.dataset.tables.all(kmsName != "" && kmsName != empty)
  - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_bigquery_table')
    mql: |
      terraform.resources('google_bigquery_table').all(
        blocks.where(type == 'encryption_configuration') != empty &&
        blocks.where(type == 'encryption_configuration').all(arguments.kms_key_name != empty)
      )
  - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_bigquery_table')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_bigquery_table').all(
        change.after['encryption_configuration'] != empty &&
        change.after['encryption_configuration'].any(_['kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-bigquery-tables-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_bigquery_table')
    mql: |
      terraform.state.resources.where(type == 'google_bigquery_table').all(
        values['encryption_configuration'] != empty &&
        values['encryption_configuration'].any(_['kms_key_name'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed
    title: Ensure Cloud SQL MySQL instances are not publicly exposed
    impact: 100
    variants:
      - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-gcp
      - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    docs:
      desc: |
        Assigning public IP addresses to Cloud SQL MySQL instances expands the potential attack surface, making databases accessible from the public internet and increasing security risks.

        The recommended practice is to configure instances exclusively with private IP addresses. This enhances security by isolating the database within your VPC network and can reduce latency for internal applications. Be aware that removing a public IP will disrupt existing connections that depend on it; establish and test private connectivity paths before making the change.
      audit: |
        **Using Google Cloud Console**

          1. Navigate to the Cloud SQL Instances page within the Google Cloud Console: https://console.cloud.google.com/sql/instances
          2. Review each MySQL instance listed. For every primary (non-replica) Second Generation instance, examine its networking details to confirm that a Private IP address is assigned and that no Public IP address is present.

        **Using Google Cloud CLI**

          1. Obtain a list of all your Cloud SQL instances:

            ```bash
            gcloud sql instances list
            ```

          2. For each instance identified as `backendType: SECOND_GEN` and `instanceType: CLOUD_SQL_INSTANCE` (primary instance), retrieve its full configuration details. Read replicas (`instanceType: READ_REPLICA_INSTANCE`) inherit network settings, and First Generation instances do not support private IPs, so they can be skipped for this check.

            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```

          3. Inspect the `ipAddresses` section in the output for the instance. Verify that an entry exists with `type: PRIVATE`. Crucially, ensure there is no entry with `type: PRIMARY`, as this indicates a public IP address. While an instance can technically possess both during transitions, the secure state is having only the `PRIVATE` type assigned.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_sql_database_instance" "example" {
              name             = "example-instance"
              database_version = "MYSQL_8_0"  # Or your preferred version
              region           = "us-central1"  # Replace with your region

              settings {
                tier = "db-f1-micro"

                # Remove public IP by setting ip_configuration.ipv4_enabled to false
                ip_configuration {
                  ipv4_enabled    = false
                  private_network = "projects/PROJECT_ID/global/networks/VPC_NETWORK_NAME"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Access the Cloud SQL Instances overview page in the Google Cloud Console: https://console.cloud.google.com/sql/instances
            2.  Select the name of the target instance to view its configuration details.
            3.  Navigate to the **Connections** settings tab.
            4.  Under the **Networking** section, locate and uncheck the box labeled **Public IP**.
            5.  Confirm the modification by selecting the **Save** button.

            **Prevention:**

            To proactively enforce that new Cloud SQL instances are not created with public IP addresses, implement the `Restrict Public IP access on Cloud SQL instances` Organization Policy. You can configure this policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Modify the target instance to remove its public IP address and ensure it's associated with a VPC network for private IP access. Replace `INSTANCE_NAME` with the actual instance name and `VPC_NETWORK_NAME` with the desired VPC network name:
                ```bash
                gcloud sql instances patch INSTANCE_NAME --network=VPC_NETWORK_NAME --no-assign-ip
                ```
                *Note: If the instance is already associated with the correct VPC network for private IP, you might only need the `--no-assign-ip` flag.*
            2.  Verify that the public IP address has been removed by inspecting the instance's configuration:
                ```bash
                gcloud sql instances describe INSTANCE_NAME
                ```
                Check the `ipAddresses` section in the output to confirm the absence of an entry with `type: PRIMARY`.
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-gcp
    filters: asset.platform == "gcp-sql-mysql"
    mql: |
      gcp.sql.instance.ipAddresses.all(type != "PRIMARY")
  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_sql_database_instance' && arguments.database_version.contains("MYSQL"))
    mql: |
      # Check that settings block with ip_configuration exists and  ipv4_enabled is set to false (no public IP) on all SQL instances
      terraform.resources("google_sql_database_instance").where(arguments.database_version.contains("MYSQL")).all(
       	blocks.where(type == 'settings') != empty &&
      	blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == "settings").all(
          blocks.where(type == "ip_configuration").all(arguments.ipv4_enabled == false)
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' &&
        terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(_['ipv4_enabled'] == false)
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')).all(
        values['ip_address'].none(type == 'PRIMARY')
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls
    title: Ensure Cloud SQL MySQL connections require SSL/TLS
    impact: 100
    variants:
      - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-gcp
      - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-state
    docs:
      desc: |
        Requiring SSL/TLS for connections to Cloud SQL MySQL instances encrypts data in transit between the client and the database server. This prevents potential eavesdropping and man-in-the-middle attacks, protecting sensitive data from unauthorized access during transmission.

        It is strongly recommended to configure Cloud SQL instances to enforce SSL/TLS for all incoming connections to maintain data confidentiality and integrity. Note that enabling this setting requires clients to be configured correctly to use SSL/TLS, which might necessitate application updates.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: https://console.cloud.google.com/sql/instances
        2.  Select the name of the MySQL instance you want to audit.
        3.  Select the **Connections** tab.
        4.  Go to the **Security** sub-tab.
        5.  Verify that the checkbox for **Allow only SSL connections** is checked.

        **Using Google Cloud CLI**

        1.  Retrieve the configuration details for the instance:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
        2.  Inspect the output and locate the `settings.ipConfiguration` section.
        3.  Ensure the value for `sslMode` is set to `ENCRYPTED_ONLY`.

            Example relevant output snippet:
            ```yaml
            settings:
              ipConfiguration:
                sslMode: ENCRYPTED_ONLY
            ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Access the Cloud SQL Instances overview page: https://console.cloud.google.com/sql/instances
            2.  Select the name of the target MySQL instance.
            3.  Navigate to the **Connections** tab, then the **Security** sub-tab.
            4.  Check the box labeled **Allow only SSL connections**.
            5.  Select **Save** to apply the change. *Note: This may trigger an instance restart.*

            **Prevention:**

            Always configure new Cloud SQL MySQL instances with the "Allow only SSL connections" option enabled during creation via the Console. Regularly audit instances to ensure compliance.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Enable the SSL Mode to be "ENCRYPTED_ONLY":
                ```bash
                gcloud sql instances patch INSTANCE_NAME --ssl-mode=ENCRYPTED_ONLY
                ```
                *Note: This command may cause the instance to restart.*

            **Prevention:**

            Always configure new Cloud SQL MySQL instances with the `--ssl-mode=ENCRYPTED_ONLY` flag during creation via the CLI. Regularly audit instances to ensure compliance.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `ssl_mode` attribute within the `ip_configuration` block is set to `ENCRYPTED_ONLY`:

            ```hcl
            resource "google_sql_database_instance" "default" {
              name             = "my-mysql-instance"
              database_version = "MYSQL_8_0"
              region           = "us-central1"

              settings {
                tier = "db-f1-micro"
                ip_configuration {
                  ipv4_enabled = true
                  ssl_mode     = "ENCRYPTED_ONLY"
                }
              }
            }
            ```

            **Prevention:**

            Always configure new Cloud SQL MySQL instances with `ssl_mode = "ENCRYPTED_ONLY"` during creation via Terraform. Regularly audit instances to ensure compliance.
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-gcp
    filters: asset.platform == "gcp-sql-mysql"
    mql: |
      gcp.sql.instance.settings.ipConfiguration.sslMode == "ENCRYPTED_ONLY"
  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance') != empty
    mql: |
      # Check that ip_configuration block with ssl_mode exists and ssl_mode is set to ENCRYPTED_ONLY on all MySQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('MYSQL')).all(
        blocks.where(type == 'settings') != empty &&
      	blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'ip_configuration').all(
            arguments.ssl_mode == "ENCRYPTED_ONLY"
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls-terraform-state
    filters: |
      asset.platform == 'terraform-state' &&  terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')).all(
        values['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled
    title: Ensure 'skip_show_database' Database Flag for Cloud SQL MySQL Instances is enabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-gcp
      - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    docs:
      desc: |
        **Why this matters**

        The 'skip_show_database' flag enhances security by restricting the use of the `SHOW DATABASES` command. When enabled ('on'), only users explicitly granted the `SHOW DATABASES` privilege can execute the command, and they will see all databases. If disabled ('off'), any user can run `SHOW DATABASES`, but they will only see databases for which they possess the `SHOW DATABASES` privilege or other specific privileges. Enabling this flag helps prevent users from discovering the existence of databases they shouldn't access. This setting applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `skip_show_database` flag is listed and its value is set to `on`.

        **Using Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="skip_show_database")|.value'
            ```
            Ensure the output for each MySQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['skip_show_database'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
            2.  Select the target MySQL instance.
            3.  Select **Edit**.
            4.  Scroll down to the **Flags** section.
            5.  If the flag isn't present, select **Add item**.
            6.  Choose `skip_show_database` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
            7.  Select **Save**. Review the **Flags** section on the instance overview page to confirm.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the flag for a specific MySQL instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --database-flags skip_show_database=on
            ```
            *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags skip_show_database=on,other_flag=value`).*
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
            ```hcl
            resource "google_sql_database_instance" "mysql_instance" {
              name             = "my-mysql-instance"
              database_version = "MYSQL_8_0"
              region           = "us-central1"
              settings {
                tier = "db-f1-micro"
                database_flags {
                  name  = "skip_show_database"
                  value = "on"
                }
                # Include other settings and flags as needed
              }
            }
            ```
    refs:
      - url: https://docs.cloud.google.com/sql/docs/mysql/flags
        title: Configure database flags
  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-gcp
    filters: asset.platform == "gcp-sql-mysql"
    mql: |
      gcp.sql.instance.settings.databaseFlags["skip_show_database"] == "on"
  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL'))
    mql: |
      # Check if a 'skip_show_database' flag exists and 'skip_show_database' flag is set to 'on' on all setting blocks of all MySQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('MYSQL')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'database_flags') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'database_flags').where(arguments['name'] == 'skip_show_database').all(
            arguments['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')).all(
        change.after['settings'].all(
          _['database_flags'].contains(name == 'skip_show_database') &&
          _['database_flags'].where(name == 'skip_show_database').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')).all(
        values['settings'].all(
          _['database_flags'].contains(name == 'skip_show_database')
        ) &&
        values['settings'].all(
          _['database_flags'].where(name == 'skip_show_database').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled
    title: Ensure the 'local_infile' Database Flag for Cloud SQL MySQL Instance is disabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-gcp
      - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-state
    docs:
      desc: |
        **Why this matters**

        The `local_infile` database flag dictates whether the server permits clients to load data using the `LOAD DATA LOCAL INFILE` statement. Enabling this feature (setting it to `on`) can introduce security vulnerabilities, as a compromised client or a malicious server could potentially access local files on the machine running the client or server, respectively. To mitigate this risk, it is strongly recommended to disable this flag by setting it to `off`. This recommendation applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `local_infile` flag is listed and its value is set to `off`.

        **Using Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="local_infile")|.value'
            ```
            Ensure the output for each MySQL instance is `"off"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['local_infile'] == 'off')"
           ```
           Verify the flag value is `off` for all relevant instances.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
            2.  Select the target MySQL instance.
            3.  Select **Edit**.
            4.  Scroll down to the **Flags** section.
            5.  If the flag isn't present, select **Add item**.
            6.  Choose `local_infile` from the dropdown and set its value to `off`. If the flag exists but is `on`, change its value to `off`.
            7.  Select **Save**. Review the **Flags** section on the instance overview page to confirm.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the flag for a specific MySQL instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --database-flags local_infile=off
            ```
            *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags local_infile=off,other_flag=value`).*
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
            ```hcl
            resource "google_sql_database_instance" "mysql_instance" {
              name             = "my-mysql-instance"
              database_version = "MYSQL_8_0"
              region           = "us-central1"
              settings {
                tier = "db-f1-micro"
                database_flags {
                  name  = "local_infile"
                  value = "off"
                }
                # Include other settings and flags as needed
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-gcp
    filters: asset.platform == "gcp-sql-mysql"
    mql: |
      gcp.sql.instance.settings.databaseFlags["local_infile"] == "off"
  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL'))
    mql: |
      # Check if a 'local_infile' flag exists and is set to 'on' on all setting blocks of all MySQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('MYSQL')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'database_flags') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'database_flags').where(arguments['name'] == 'local_infile').all(
            arguments['value'] == 'off'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')).all(
        change.after['settings'].all(
          _['database_flags'].contains(name == 'local_infile')
        ) &&
        change.after['settings'].all(
          _['database_flags'].where(name == 'local_infile').all(
            _['value'] == "off"
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')).all(
        values['settings'].all(
          _['database_flags'].contains(name == 'local_infile')
        ) &&
        values['settings'].all(
          _['database_flags'].where(name == 'local_infile').all(
            _['value'] == 'off'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose
    title: Ensure the 'log_error_verbosity' Database Flag for Cloud SQL PostgreSQL Instance Is Set to 'DEFAULT' or 'verbose'
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-gcp
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    docs:
      desc: |
        **Why this matters**

        The `log_error_verbosity` flag in PostgreSQL controls the level of detail included in server log messages for errors. Possible settings include `terse` (minimal details), `default` (standard details), and `verbose` (includes SQL state codes, source file, function name, and line number). Logging provides essential information for troubleshooting and security analysis. Setting this flag to `default` or `verbose` ensures sufficient detail is captured without being overly sparse. Setting it to `terse` might omit crucial context needed for effective analysis. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_error_verbosity` flag is listed and its value is set to `default` or `verbose`.

        **Using Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            # This command shows the value, verify it's "default" or "verbose"
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_error_verbosity")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"default"` or `"verbose"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings { databaseFlags['log_error_verbosity'] == 'verbose' })"
           ```
           Verify the flag value is `default` or `verbose` for all relevant instances.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
            2.  Select the target PostgreSQL instance.
            3.  Select **Edit**.
            4.  Scroll down to the **Flags** section.
            5.  If the flag isn't present, select **Add item**.
            6.  Choose `log_error_verbosity` from the dropdown and set its value to `default` or `verbose`. If the flag exists but is set to `terse`, change its value.
            7.  Select **Save**. Review the **Flags** section on the instance overview page to confirm.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the flag for a specific PostgreSQL instance (choose `default` or `verbose`):
            ```bash
            # Example using default
            gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=default

            # Example using VERBOSE
            gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=verbose
            ```
            *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_error_verbosity=default,other_flag=value`).*
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting (choose `default` or `verbose`):
            ```hcl
            resource "google_sql_database_instance" "postgres_instance" {
              name             = "my-postgres-instance"
              database_version = "POSTGRES_15"
              region           = "us-central1"
              settings {
                tier = "db-f1-micro"
                database_flags {
                  name  = "log_error_verbosity"
                  # Choose either "default" or "verbose"
                  value = "default"
                }
                # Include other settings and flags as needed
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-gcp
    filters: |
      asset.platform == 'gcp-sql-postgresql'
    mql: |
      gcp.sql.instance.settings.databaseFlags['log_error_verbosity'] == 'verbose' || gcp.sql.instance.settings.databaseFlags['log_error_verbosity'] == 'default'
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES'))
    mql: |
      # Check if a 'log_error_verbosity' flag exists and is set to 'verbose' or 'default' on all setting blocks of all PostgreSQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'database_flags') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'database_flags').where(arguments['name'] == 'log_error_verbosity').all(
              arguments['value'] == 'verbose' || arguments['value'] == 'default'
            )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')).all(
        // Check for existence of log_error_verbosity
        change.after['settings'].all(
          _['database_flags'].contains(name == 'log_error_verbosity')
        ) &&
        // Verify correct value
        change.after['settings'].all(
          _['database_flags'].where(name == 'log_error_verbosity').all(
            _['value'] == 'verbose' || _['value'] == 'default'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')).all(
        // Check for existence of log_error_verbosity
        values['settings'].all(
          _['database_flags'].contains(name == 'log_error_verbosity')
        ) &&
        // Verify correct value
        values['settings'].all(
          _['database_flags'].where(name == 'log_error_verbosity').all(
            _['value'] == 'verbose' || _['value'] == 'default'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled
    title: Ensure 'log_connections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-gcp
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-state
    docs:
      desc: |
        **Why this matters**

        By default, PostgreSQL does not log connection attempts. Enabling the `log_connections` flag (setting it to `on`) configures the server to record each attempted connection and successful client authentication. This logging is valuable for security monitoring, allowing administrators to identify unusual connection patterns or potential unauthorized access attempts, and for troubleshooting connectivity issues. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_connections` flag is listed and its value is set to `on`.

        **Using Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_connections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_connections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
            2.  Select the target PostgreSQL instance.
            3.  Select **Edit**.
            4.  Scroll down to the **Flags** section.
            5.  If the flag isn't present, select **Add item**.
            6.  Choose `log_connections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
            7.  Select **Save**. Review the **Flags** section on the instance overview page to confirm.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the flag for a specific PostgreSQL instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --database-flags log_connections=on
            ```
            *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_connections=on,other_flag=value`).*
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
            ```hcl
            resource "google_sql_database_instance" "postgres_instance" {
              name             = "my-postgres-instance"
              database_version = "POSTGRES_15"
              region           = "us-central1"
              settings {
                tier = "db-f1-micro"
                database_flags {
                  name  = "log_connections"
                  value = "on"
                }
                # Include other settings and flags as needed
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-gcp
    filters: |
      asset.platform == 'gcp-sql-postgresql'
    mql: |
      gcp.sql.instance.settings.databaseFlags['log_connections'] == 'on'
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES'))
    mql: |
      # Check if a 'log_connections' flag exists and is set to 'on' on all setting blocks of all PostgreSQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'database_flags') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'database_flags').where(arguments['name'] == 'log_connections').all(
            arguments['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')).all(
        change.after['settings'].all(
          _['database_flags'].contains(name == 'log_connections')
        ) &&
        change.after['settings'].all(
          _['database_flags'].where(name == 'log_connections').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')).all(
        values['settings'].all(
          _['database_flags'].contains(name == 'log_connections')
        ) &&
        values['settings'].all(
          _['database_flags'].where(name == 'log_connections').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled
    title: Ensure 'log_disconnections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-gcp
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    docs:
      desc: |
        **Why this matters**

        PostgreSQL, by default, does not log the end of user sessions or their duration. Enabling the `log_disconnections` flag (setting it to `on`) causes the server to log this information. This data complements the information provided by `log_connections` and is crucial for auditing user activity, identifying long-running or unusual sessions, and troubleshooting connection-related issues. It provides a complete picture of the connection lifecycle. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_disconnections` flag is listed and its value is set to `on`.

        **Using Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_disconnections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_disconnections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
            2.  Select the target PostgreSQL instance.
            3.  Select **Edit**.
            4.  Scroll down to the **Flags** section.
            5.  If the flag isn't present, select **Add item**.
            6.  Choose `log_disconnections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
            7.  Select **Save**. Review the **Flags** section on the instance overview page to confirm.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the flag for a specific PostgreSQL instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --database-flags log_disconnections=on
            ```
            *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_disconnections=on,other_flag=value`).*
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
            ```hcl
            resource "google_sql_database_instance" "postgres_instance" {
              name             = "my-postgres-instance"
              database_version = "POSTGRES_15"
              region           = "us-central1"
              settings {
                tier = "db-f1-micro"
                database_flags {
                  name  = "log_disconnections"
                  value = "on"
                }
                # Include other settings and flags as needed, e.g., log_connections
                database_flags {
                  name  = "log_connections"
                  value = "on"
                }
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-gcp
    filters: |
      asset.platform == 'gcp-sql-postgresql'
    mql: |
      gcp.sql.instance.settings.databaseFlags['log_disconnections'] == 'on'
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')) != empty
    mql: |
      # Check if a 'log_disconnections' flag exists and is set to 'on' on all setting blocks of all PostgreSQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')).all(
        blocks.where(type == 'settings') != empty &&
      	blocks.where(type == 'settings').all(blocks.where(type == 'database_flags') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'database_flags').where(arguments['name'] == 'log_disconnections').all(
            arguments['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')).all(
        change.after['settings'].all(
          _['database_flags'].contains(name == 'log_disconnections')
        ) &&
        change.after['settings'].all(
          _['database_flags'].where(name == 'log_disconnections').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')).all(
        values['settings'].all(
          _['database_flags'].contains(name == 'log_disconnections')
        ) &&
        values['settings'].all(
          _['database_flags'].where(name == 'log_disconnections').all(
            _['value'] == 'on'
          )
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-public-ip
    title: Ensure public IP addresses are not assigned to VM instances
    impact: 75
    variants:
      - uid: mondoo-gcp-security-compute-instances-no-public-ip-gcp
      - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-state
    docs:
      desc: |
        Virtual machine (VM) instances within Google Cloud Compute Engine should not be configured with public, external IP addresses.

        **Why this matters**

        Assigning public IP addresses directly to VM instances increases their exposure to potential attacks from the internet. To minimize this attack surface, instances should ideally be placed behind services like Google Cloud Load Balancing, which manage external access securely and efficiently, reducing direct exposure of the VM.

        **Impact:**

        Disabling the external IP address on a Compute instance might disrupt applications or services hosted on that instance if they rely on direct public internet connectivity. Careful planning is required before making this change.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Review the list of VM instances. For each instance, verify that the `External IP` column shows `None`.

        **From Google Cloud CLI**

        Execute the following command to list instances and their network configurations:
        ```bash
        gcloud compute instances list --format=json
        ```

        1. Examine the JSON output for each instance. Ensure that the `networkInterfaces` array does not contain an `accessConfigs` section. The presence of `accessConfigs` indicates an external IP configuration. Note that the `natIP` field within `accessConfigs` might only appear for running instances or stopped instances with a static external IP. Stopped instances configured for ephemeral IPs might not show `natIP`.

        Example indicating an external IP:
        ```json
        "networkInterfaces": [
         {
          "accessConfigs": [
           {
            "kind": "compute#accessConfig",
            "name": "External NAT",
            "networkTier": "PREMIUM",
            "type": "ONE_TO_ONE_NAT"
           }
          ],
          ...
         }
        ]
        ```

        **Exception:**
        Instances managed by Google Kubernetes Engine (GKE) often require external IPs for node pools or specific services. These instances typically have names starting with `gke-` and possess the label `goog-gke-node`. They should be excluded from this check as their network configuration is managed by GKE.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "example" {
              name         = "example-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  image = "debian-cloud/debian-11"
                }
              }

              // Configure the network interface without an access_config block
              // This ensures no external IP is assigned
              network_interface {
                network = "default"
                // No access_config block means no external IP
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select the name of the target instance to open its details page.
            3. Select the `Edit` button at the top.
            4. Scroll down to the `Network interfaces` section.
            5. For the relevant network interface, select the pencil icon to edit it.
            6. Set the `External IP` dropdown menu to `None`.
            7. Select `Done` to close the network interface settings.
            8. Select `Save` at the bottom of the page to apply the changes.

            **Prevention:**
            Utilize the Organization Policy `constraints/compute.vmExternalIpAccess` to restrict or deny the assignment of external IP addresses to VMs across your organization or specific folders/projects. Configure this policy at: [https://console.cloud.google.com/orgpolicies/compute-vmExternalIpAccess](https://console.cloud.google.com/orgpolicies/compute-vmExternalIpAccess)
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. First, identify the name of the access configuration associated with the external IP. Describe the instance:
            ```bash
            gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(networkInterfaces[].accessConfigs)'
            ```
            Look for the `name` field within the `accessConfigs` array (e.g., `External NAT`).

            2. Delete the identified access configuration using its name:
            ```bash
            gcloud compute instances delete-access-config INSTANCE_NAME --zone=ZONE --access-config-name="ACCESS_CONFIG_NAME"
            ```
            Replace `INSTANCE_NAME`, `ZONE`, and `ACCESS_CONFIG_NAME` with the appropriate values.
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-no-public-ip-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance.networkInterfaces.all(accessConfigs == empty)
  - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl" &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'network_interface') != empty &&
        blocks.where(type == 'network_interface').all(
          blocks.where(type == 'access_config') == empty
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-plan
    filters: |
      asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "google_compute_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance").all(
        change.after['network_interface'].all(
          _['access_config'] == empty
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-public-ip-terraform-state
    filters: |
      asset.platform == "terraform-state" && terraform.state.resources.contains(type == "google_compute_instance")
    mql: |
      terraform.state.resources.where(type == "google_compute_instance").all(
        values['network_interface'].all(
          _['access_config'] == empty
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-default-service-account
    title: Ensure the default service account is not used on VM instances
    impact: 80
    variants:
      - uid: mondoo-gcp-security-compute-instances-no-default-service-account-gcp
      - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-state
    docs:
      desc: |
        VM instances should be configured to use dedicated service accounts instead of the default Compute Engine service account.

        **Why this matters**

        The default Compute Engine service account (`[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`) is automatically granted the highly permissive `Editor` role at the project level. If a VM using this default account is compromised, an attacker could potentially gain broad access to modify resources across the project. To adhere to the principle of least privilege and limit the potential impact of a compromised instance, create and assign custom service accounts with only the necessary permissions required by the VM.

        **Impact:**

        Changing the service account associated with a VM requires stopping and starting the instance. Ensure applications running on the VM can tolerate this brief downtime. Using a custom service account with insufficient permissions might cause applications on the VM to fail if they rely on APIs they can no longer access.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of an instance to view its details.
        3. Locate the `API and identity management` section.
        4. Verify that the `Service account` listed is **not** the default Compute Engine service account (which follows the pattern `[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`). Repeat for all relevant instances.

        **From Google Cloud CLI**

        1. List instances along with their associated service account emails:
        ```bash
        gcloud compute instances list --format='value(name,serviceAccounts[0].email)'
        ```
        Alternatively, for more detailed JSON output:
        ```bash
        gcloud compute instances list --format=json
        ```
        Then inspect the `serviceAccounts` array for each instance.

        2. For each instance, ensure the listed service account email does not match the default pattern `[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`. You can find your project number using `gcloud projects describe $(gcloud config get-value project) --format='value(projectNumber)'`.

        **Exception:**
        VMs managed by GKE (names starting with `gke-`, labeled `goog-gke-node`) often use specific service accounts managed by GKE itself, which might include the default service account in some configurations. These should typically be excluded from this check unless specific organizational policies dictate otherwise.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            # Create a custom service account with appropriate permissions
            resource "google_service_account" "custom_sa" {
              account_id   = "custom-service-account"
              display_name = "Custom Service Account"
            }

            # Grant necessary roles to the service account
            resource "google_project_iam_member" "service_account_roles" {
              project = "your-project-id"
              role    = "roles/compute.instanceAdmin.v1"
              member  = "serviceAccount:${google_service_account.custom_sa.email}"
              # Add additional role bindings as needed
            }

            # Configure the VM instance to use the custom service account
            resource "google_compute_instance" "example" {
              name         = "example-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  image = "debian-cloud/debian-11"
                }
              }

              network_interface {
                network = "default"
              }

              # Assign the custom service account to the instance
              service_account {
                email  = google_service_account.custom_sa.email
                scopes = [
                  "https://www.googleapis.com/auth/compute"
                  # Alternatively, you can use more restrictive scopes:
                  # "https://www.googleapis.com/auth/devstorage.read_only",
                  # etc.
                ]
              }
            }
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select the name of the instance you want to modify.
            3. Select the `STOP` button at the top and confirm. Wait for the instance to stop completely.
            4. Once stopped, Select the `Edit` button.
            5. Scroll down to the `API and identity management` section.
            6. In the `Service account` dropdown, select a suitable custom service account. If needed, create a new service account with appropriate permissions first via the `IAM & Admin` -> `Service Accounts` page.
            7. Select `Save` at the bottom.
            8. Select the `START / RESUME` button at the top to restart the instance.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. Stop the target instance:
            ```bash
            gcloud compute instances stop INSTANCE_NAME --zone=ZONE
            ```
            2. Assign the desired custom service account:
            ```bash
            gcloud compute instances set-service-account INSTANCE_NAME --zone=ZONE --service-account=CUSTOM_SERVICE_ACCOUNT_EMAIL
            ```
            Replace `INSTANCE_NAME`, `ZONE`, and `CUSTOM_SERVICE_ACCOUNT_EMAIL` with the correct values.
            3. Start the instance again:
            ```bash
            gcloud compute instances start INSTANCE_NAME --zone=ZONE
            ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-no-default-service-account-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      compute_engine_default_service_account_email = gcp.project.id + '-compute@developer.gserviceaccount.com'
      gcp.compute.instance {
        serviceAccounts.none(
          email == compute_engine_default_service_account_email
        )
      }
  - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'service_account') != empty &&
        blocks.where(type == 'service_account').all(
          arguments.email != /^\d+-compute@developer\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-plan
    filters: |
      asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "google_compute_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance").all(
        change.after['service_account'].none(
          email == /^\d+-compute@developer\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-compute-instances-no-default-service-account-terraform-state
    filters: |
      asset.platform == "terraform-state" && terraform.state.resources.contains(type == "google_compute_instance")
    mql: |
      terraform.state.resources.where(type == "google_compute_instance").all(
        values['service_account'].none(
          _['email'] == /^\d+-compute@developer\.gserviceaccount\.com$/
        )
      )
  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys
    title: Ensure "Block Project-Wide SSH Keys" is enabled for VM instances
    impact: 80
    variants:
      - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-gcp
      - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-state
    docs:
      desc: |
        Configure VM instances to block project-wide SSH keys, favoring instance-specific keys for access.

        **Why this matters**

        Project-wide SSH keys, managed in the project's metadata, allow users associated with those keys to access *all* VM instances within that project by default. While convenient, this creates a significant security risk: if a project-wide key is compromised, all instances become vulnerable. Enabling the "Block Project-Wide SSH Keys" setting on an instance forces the use of instance-level SSH keys (stored in instance metadata), thereby limiting the scope of access and reducing the blast radius if a key is compromised.

        **Impact:**

        Enabling this setting will prevent users from connecting to the instance using project-wide SSH keys via tools like standard SSH clients. Access using the `gcloud compute ssh` command or the SSH-in-browser feature usually remains unaffected, as these tools often manage temporary or instance-specific keys. Users needing direct SSH access with third-party clients will require instance-specific SSH keys to be added to the VM's metadata.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of the instance you want to check.
        3. Scroll down to the `SSH Keys` section.
        4. Verify that the checkbox labeled `Block project-wide SSH keys` is checked. Repeat for all relevant instances.

        **From Google Cloud CLI**

        1. Retrieve the metadata for the instance, specifically looking for the `block-project-ssh-keys` key:
        ```bash
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(metadata.items)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure there is an item where `key` is `block-project-ssh-keys` and its corresponding `value` is `true`. If the key is missing or set to `false`, project-wide keys are not blocked.

        Alternatively, list all instances and filter for the metadata key:
        ```bash
        gcloud compute instances list --format='table(name,zone,metadata.items.filter(key:block-project-ssh-keys).extract(value))'
        ```
        Instances showing `True` in the last column have the setting enabled.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "example" {
              name         = "example-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  image = "debian-cloud/debian-11"
                }
              }

              network_interface {
                network = "default"
              }

              # Block project-wide SSH keys
              metadata = {
                block-project-ssh-keys = "true"
              }

              # Other configuration parameters...
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select the name of the instance to modify.
            3. Select the `Edit` button at the top.
            4. Scroll down to the `SSH Keys` section (it might be under `Security and access` or a similar heading).
            5. Check the box for `Block project-wide SSH keys`.
            6. Select `Save` at the bottom of the page.
            7. Repeat these steps for all instances where project-wide keys should be blocked.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Enable the setting by adding or updating the instance metadata:
            ```bash
            gcloud compute instances add-metadata INSTANCE_NAME --zone=ZONE --metadata block-project-ssh-keys=true
            ```
            Replace `INSTANCE_NAME` and `ZONE` with the appropriate values. This command will either add the key if it doesn't exist or update its value to `true` if it does.
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance {
        metadata['block-project-ssh-keys'] == true
      }
  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      terraform.resources('google_compute_instance').all(
        arguments.metadata['block-project-ssh-keys'] == /true/i
      )
  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == "google_compute_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance').all(
        change.after.metadata['block-project-ssh-keys'] == /true/i
      )
  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == "google_compute_instance")
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance').all(
        values.metadata['block-project-ssh-keys'] == /true/i
      )
  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled
    title: Ensure Confidential VM Service is enabled for all VM instances
    impact: 75
    variants:
      - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-gcp
      - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-state
    docs:
      desc: |
        Enable the Confidential VM service for applicable Compute Engine VM instances to enhance data security during processing.

        **Why this matters**

        While Google Cloud encrypts data at rest and in transit, Confidential Computing adds a layer of protection by encrypting data while it's actively being processed in memory (data-in-use). Confidential VMs utilize hardware-based security features (like AMD) to create an isolated environment where data remains encrypted even during computation. This helps protect sensitive data from potential access by the cloud provider or vulnerabilities in the host system, using hardware-generated, instance-specific keys that are not exportable.

        **Impact:**

        - Confidential VMs currently support specific machine types (primarily N2D series) and may have limitations, such as the lack of support for live migration, meaning instances will be terminated during host maintenance events.
        - Enabling this feature might incur additional costs compared to standard VMs. Refer to the official GCP pricing documentation for details: [https://cloud.google.com/compute/confidential-vm/pricing](https://cloud.google.com/compute/confidential-vm/pricing).
      audit: |
        Note: Confidential Computing is primarily available on N2D machine types. Check current documentation for supported types: [https://cloud.google.com/compute/docs/machine-types#n2d_machine_types](https://cloud.google.com/compute/docs/machine-types#n2d_machine_types)

        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of an N2D instance (or other supported type) to view its details.
        3. Look for the `Confidential VM service` status indicator within the instance properties.
        4. Ensure the status shows as `Enabled` or `On`.

        **From Google Cloud CLI**

        1. List instances and check their confidential computing configuration:
        ```bash
        gcloud compute instances list --format='json(name,machineType,confidentialInstanceConfig)'
        ```
        2. For instances using a supported machine type (e.g., containing "n2d-"), verify that the `confidentialInstanceConfig` section exists and the `enableConfidentialCompute` field is set to `true`.

        Example output for a configured instance:
        ```json
        {
         "confidentialInstanceConfig": {
          "enableConfidentialCompute": true
         },
         "machineType": "...",
         "name": "..."
        }
        ```
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "confidential_vm" {
              name         = "confidential-vm-instance"
              machine_type = "n2d-standard-2"  # Must use an N2D series or other supported machine type
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  image = "debian-cloud/debian-11"
                }
              }

              network_interface {
                network = "default"
              }

              # Enable Confidential Computing
              confidential_instance_config {
                enable_confidential_compute = true
              }

              # Required setting for Confidential VMs
              scheduling {
                on_host_maintenance = "TERMINATE"
              }

              # Other configuration parameters as needed...
            }
            ```
        - id: console
          desc: |
            The Confidential VM service can only be activated when creating a new VM instance. It cannot be enabled on an existing instance.

            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select `CREATE INSTANCE`.
            3. Configure the instance settings (name, region, zone).
            4. Select a supported machine type from the N2D series (or other applicable types) under `Machine configuration`.
            5. Scroll down to the `Confidential VM service` section.
            6. Check the box labeled `Enable the Confidential Computing service on this VM instance`. Note that this usually requires setting the `On host maintenance` policy to `Terminate VM instance`.
            7. Configure other settings as needed (boot disk, networking, etc.).
            8. Select `Create`.
        - id: cli
          desc: |
            The Confidential VM service can only be activated when creating a new VM instance. It cannot be enabled on an existing instance.

            **Using Google Cloud CLI**

            Use the `--confidential-compute` flag during instance creation. You must also set the maintenance policy to `TERMINATE`.

            ```bash
            gcloud compute instances create INSTANCE_NAME \
             --zone=ZONE \
             --machine-type=N2D_MACHINE_TYPE \
             --confidential-compute \
             --maintenance-policy=TERMINATE \
             # Add other necessary flags like --image-project, --image, --network, etc.
            ```

            Replace placeholders like `INSTANCE_NAME`, `ZONE`, and `N2D_MACHINE_TYPE` with appropriate values.
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
      gcp.compute.instance.machineType.name == /n2d-/
    mql: |
      gcp.compute.instance {
        confidentialInstanceConfig['serviceEnabled'] == true
      }
  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      # Check that confidential_instance_config block exists on all compute instances and enable_confidential_compute is set to true
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'confidential_instance_config') != empty &&
        blocks.where(type == 'confidential_instance_config').all(
          arguments.enable_confidential_compute == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance').all(
        change.after.confidential_instance_config.all(
          enable_confidential_compute == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == "google_compute_instance").all(
        values['confidential_instance_config'].all(
          _['enable_confidential_compute'] == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled
    title: Ensure Secure Boot is enabled for all VM instances
    impact: 90
    variants:
      - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-gcp
      - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-state
    docs:
      desc: |
        Enable Secure Boot, a feature of Shielded VMs, on Compute Engine instances to enhance platform security and integrity.

        **Why this matters**

        Shielded VMs provide verifiable integrity for Compute Engine instances, offering protection against boot-level and kernel-level malware and rootkits. Secure Boot is a critical component of this protection. It ensures that the instance boots only with software (like the bootloader and OS kernel) that is digitally signed and trusted. By verifying these signatures against trusted certificates stored in the UEFI firmware, Secure Boot prevents malicious software from taking control during the boot process. Google manages the signing and verification of the firmware itself, establishing a strong root of trust.

        **Impact:**

        Secure Boot requires using a Shielded VM-compatible OS image. Enabling Secure Boot might prevent systems with custom, unsigned kernel drivers or boot components from booting successfully. Ensure all necessary components are properly signed before enabling this feature.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of the instance you want to check.
        3. In the `VM instance details` page, locate the `Shielded VM` section.
        4. Verify that the `Secure Boot` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```bash
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure the `shieldedInstanceConfig` object exists and the `enableSecureBoot` field is set to `true`. If `shieldedInstanceConfig` is absent or `enableSecureBoot` is `false`, the feature is not enabled.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "shielded_vm" {
              name         = "shielded-vm-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  # Use a compatible Shielded VM image
                  image = "gce-uefi-images/ubuntu-2004-focal-v20220419"
                }
              }

              network_interface {
                network = "default"
              }

              # Enable Shielded VM features including Secure Boot
              shielded_instance_config {
                enable_secure_boot          = true
                enable_vtpm                 = true        # Required for Secure Boot
                enable_integrity_monitoring = true        # Recommended with Secure Boot
              }

              # Other configuration parameters as needed...
            }

            # Optional: Enforce Shielded VM at organization level using organization policy
            resource "google_organization_policy" "require_shielded_vm" {
              org_id     = "YOUR_ORGANIZATION_ID"          # Replace with your organization ID
              constraint = "constraints/compute.requireShieldedVm"

              boolean_policy {
                enforced = true
              }
            }
            ```
        - id: console
          desc: |
            Secure Boot can only be enabled on instances using an OS image that supports Shielded VM features.

            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select the name of the instance to modify.
            3. If the instance is running, select `STOP` and confirm. Wait for it to stop.
            4. Select `EDIT`.
            5. Scroll to the `Shielded VM` section.
            6. Check the box or toggle the switch to enable `Secure Boot`. Enabling Secure Boot typically requires vTPM and Integrity Monitoring to also be enabled or automatically enabled alongside it.
            7. Select `Save`.
            8. Select `START / RESUME` to restart the instance.

            **Prevention:**
            Enforce the use of Shielded VMs for all new instances by configuring the `constraints/compute.requireShieldedVm` Organization Policy. Manage this policy at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). See documentation for details: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
        - id: cli
          desc: |
            Secure Boot can only be enabled on instances using an OS image that supports Shielded VM features.

            **Using Google Cloud CLI**

            Ensure the instance uses a compatible image. You can list public Shielded VM images:
            ```bash
            gcloud compute images list --project gce-UEFI-images --no-standard-images --filter="shieldedVmFeatures:(SECURE_BOOT)"
            ```

            1. Stop the instance if it is running:
            ```bash
            gcloud compute instances stop INSTANCE_NAME --zone=ZONE
            ```
            2. Update the instance to enable Secure Boot (this command implicitly enables vTPM and Integrity Monitoring as well):
            ```bash
            gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vm-secure-boot
            ```
            3. Start the instance:
            ```bash
            gcloud compute instances start INSTANCE_NAME --zone=ZONE
            ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance.enableSecureBoot == true
  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_instance')
    mql: |
      # Check that shielded_instance_config block exists on all compute instances and enable_secure_boot is set to true
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'shielded_instance_config') != empty &&
        blocks.where(type == 'shielded_instance_config').all(
          arguments.enable_secure_boot == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(
        type == 'google_compute_instance'
      ).all(
        change.after.shielded_instance_config.all(
          enable_secure_boot == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance').all(
        values.shielded_instance_config.all(
          enable_secure_boot == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled
    title: Ensure vTPM is enabled for all VM instances
    impact: 90
    variants:
      - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-gcp
      - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-state
    docs:
      desc: |
        Enable the virtual Trusted Platform Module (vTPM), a feature of Shielded VMs, on Compute Engine instances to support Measured Boot and enhance integrity verification.

        **Why this matters**

        Shielded VMs leverage several security controls to harden instances against threats. The vTPM is a virtualized version of a hardware TPM, providing secure cryptographic functions and secure storage. Its primary role within Shielded VM is to enable Measured Boot. During Measured Boot, the vTPM securely records cryptographic measurements (hashes) of boot components (firmware, bootloader, kernel). This creates a verifiable record of the boot process, forming an integrity policy baseline essential for Integrity Monitoring.

        **Impact:**

        Enabling vTPM is necessary for using Shielded VM's Measured Boot and Integrity Monitoring capabilities. It generally has negligible impact on instance performance and compatibility, but it requires using a Shielded VM-compatible OS image.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of the instance you want to check.
        3. In the `VM instance details` page, find the `Shielded VM` section.
        4. Verify that the `vTPM` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```bash
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Look at the output. Ensure the `shieldedInstanceConfig` object is present and the `enableVtpm` field is set to `true`. If `shieldedInstanceConfig` is missing or `enableVtpm` is `false`, the feature is disabled.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "vtpm_enabled_vm" {
              name         = "vtpm-enabled-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  # Use a compatible Shielded VM image that supports vTPM
                  image = "gce-uefi-images/ubuntu-2004-focal-v20220419"
                }
              }

              network_interface {
                network = "default"
              }

              # Enable vTPM as part of Shielded VM features
              shielded_instance_config {
                enable_vtpm                 = true
                enable_integrity_monitoring = true  # Optional but recommended
                enable_secure_boot          = false # Optional, set to true if needed
              }

              # Other configuration parameters as needed...
            }

            # Optional: Enforce Shielded VM at organization level using organization policy
            resource "google_organization_policy" "require_shielded_vm" {
              org_id     = "YOUR_ORGANIZATION_ID"  # Replace with your organization ID
              constraint = "constraints/compute.requireShieldedVm"

              boolean_policy {
                enforced = true
              }
            }
            ```
        - id: console
          desc: |
            vTPM can only be enabled on instances using an OS image that supports Shielded VM features.

            **Using Google Cloud Console**

            1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Locate and select the instance you want to modify.
            3. If the instance is running, click `STOP` and confirm. Wait until the instance is fully stopped.
            4. Click `EDIT` to modify the instance settings.
            5. Scroll to the `Shielded VM` section.
            6. Enable the `vTPM` option by checking the corresponding box or toggling the switch.
            7. Click `Save` to apply the changes.
            8. Restart the instance by clicking `START / RESUME`.

            **Prevention:**
            Mandate the use of Shielded VMs (which includes vTPM) for new instances via the `constraints/compute.requireShieldedVm` Organization Policy. Configure it at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). Refer to documentation: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
        - id: cli
          desc: |
            vTPM can only be enabled on instances using an OS image that supports Shielded VM features.

            **Using Google Cloud CLI**

            Ensure the instance uses a compatible image. You can list public Shielded VM images:
            ```bash
            gcloud compute images list --project gce-uefi-images --no-standard-images --filter="shieldedVmFeatures:(VTPM)"
            ```

            1. Stop the instance if it is running:
            ```bash
            gcloud compute instances stop INSTANCE_NAME --zone=ZONE
            ```
            2. Update the instance to enable vTPM:
            ```bash
            gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vtpm
            ```
            Note: This command specifically targets vTPM. If Secure Boot or Integrity Monitoring are desired, they might need separate flags (`--shielded-vm-secure-boot`, `--shielded-vm-integrity-monitoring`) or enabling them might implicitly enable vTPM.
            3. Start the instance:
            ```bash
            gcloud compute instances start INSTANCE_NAME --zone=ZONE
            ```
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance.enableVtpm == true
  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      # Check that shielded_instance_config block exists on all compute instances and enable_vtpm is set to true
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'shielded_instance_config') != empty &&
        blocks.where(type == 'shielded_instance_config').all(
          arguments.enable_vtpm == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(
        type == 'google_compute_instance'
      ).all(
        change.after.shielded_instance_config.all(
          enable_vtpm == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance').all(
        values.shielded_instance_config.all(
          enable_vtpm == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled
    title: Ensure Integrity Monitoring is enabled for all VM instances
    impact: 90
    variants:
      - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-gcp
      - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-state
    docs:
      desc: |
        Enable Integrity Monitoring, a feature of Shielded VMs, on Compute Engine instances to detect potentially malicious modifications to the boot sequence.

        **Why this matters**

        Shielded VMs provide enhanced security for instances. Integrity Monitoring, a key component, leverages the measurements taken by the vTPM during Measured Boot. It compares the boot measurements of the current boot process against a known good baseline established during a previous boot. If discrepancies are detected, it indicates that the bootloader, kernel, or other critical boot components may have been tampered with, potentially by rootkits or boot-level malware. This allows administrators to identify compromised instances and take appropriate action.

        **Impact:**

        Integrity Monitoring requires both a Shielded VM-compatible OS image and vTPM to be enabled. It provides valuable security insights by logging integrity check results to Cloud Logging, with minimal overhead on instance performance.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Select the name of the instance you want to check.
        3. In the `VM instance details` page, locate the `Shielded VM` section.
        4. Verify that the `Integrity Monitoring` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```bash
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure the `shieldedInstanceConfig` object exists and the `enableIntegrityMonitoring` field is set to `true`. If `shieldedInstanceConfig` is absent or `enableIntegrityMonitoring` is `false`, the feature is not enabled.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_compute_instance" "integrity_monitoring_vm" {
              name         = "integrity-monitoring-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              boot_disk {
                initialize_params {
                  # Use a compatible Shielded VM image that supports Integrity Monitoring
                  image = "gce-uefi-images/ubuntu-2004-focal-v20220419"
                }
              }

              network_interface {
                network = "default"
              }

              # Enable Integrity Monitoring and vTPM (required) as part of Shielded VM features
              shielded_instance_config {
                enable_integrity_monitoring = true
                enable_vtpm                 = true  # Required for Integrity Monitoring
                enable_secure_boot          = false # Optional, set to true if needed
              }

              # Other configuration parameters as needed...
            }

            # Optional: Enforce Shielded VM at organization level using organization policy
            resource "google_organization_policy" "require_shielded_vm" {
              org_id     = "YOUR_ORGANIZATION_ID"  # Replace with your organization ID
              constraint = "constraints/compute.requireShieldedVm"

              boolean_policy {
                enforced = true
              }
            }
            ```
        - id: console
          desc: |
            Integrity Monitoring requires an instance using an OS image that supports Shielded VM features, and vTPM must also be enabled.

            **Using Google Cloud Console**

            1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
            2. Select the name of the instance to modify.
            3. If the instance is running, select `STOP` and confirm. Wait for it to stop completely.
            4. Click `EDIT`.
            5. Scroll down to the `Shielded VM` section.
            6. Ensure `vTPM` is enabled.
            7. Check the box or toggle the switch to enable `Integrity Monitoring`.
            8. Click `Save`.
            9. Click `START / RESUME` to restart the instance.

            **Prevention:**
            Enforce the use of Shielded VMs (which includes Integrity Monitoring when enabled) for new instances using the `constraints/compute.requireShieldedVm` Organization Policy. Configure this at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). See documentation: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
        - id: cli
          desc: |
            Integrity Monitoring requires an instance using an OS image that supports Shielded VM features, and vTPM must also be enabled.

            **Using Google Cloud CLI**

            1. Verify that the instance uses a compatible Shielded VM image. You can list public Shielded VM images that support Integrity Monitoring:
            ```bash
            gcloud compute images list --project gce-uefi-images --no-standard-images --filter="shieldedVmFeatures:(INTEGRITY_MONITORING)"
            ```

            2. Stop the instance if it is currently running:
            ```bash
            gcloud compute instances stop INSTANCE_NAME --zone=ZONE
            ```

            3. Update the instance to enable Integrity Monitoring. This command will also enable vTPM if it is not already enabled:
            ```bash
            gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vm-integrity-monitoring
            ```

            4. Start the instance after the update:
            ```bash
            gcloud compute instances start INSTANCE_NAME --zone=ZONE
            ```

            Replace `INSTANCE_NAME` and `ZONE` with the appropriate values for your instance.
    refs:
      - url: https://cloud.google.com/compute/docs/instances/create-start-instance
        title: Google Compute Engine Instance Documentation
      - url: https://cloud.google.com/compute/docs/security
        title: Google Compute Engine Security
  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-gcp
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance.enableIntegrityMonitoring == true
  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_compute_instance') != empty
    mql: |
      # Check that shielded_instance_config block exists on all compute instances and enable_integrity_monitoring is set to true
      terraform.resources('google_compute_instance').all(
        blocks.where(type == 'shielded_instance_config') != empty &&
        blocks.where(type == 'shielded_instance_config').all(
          arguments.enable_integrity_monitoring == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(
        type == 'google_compute_instance'
      ).all(
        change.after.shielded_instance_config.all(
          enable_integrity_monitoring == true
        )
      )
  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance').all(
        values.shielded_instance_config.all(
          enable_integrity_monitoring == true
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed
    title: Ensure Cloud SQL PostgreSQL instances are not publicly exposed
    impact: 100
    variants:
      - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-gcp
      - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-state
    docs:
      desc: |
        Assigning public IP addresses to Cloud SQL PostgreSQL instances expands the potential attack surface, making databases accessible from the public internet and increasing security risks.

        The recommended practice is to configure instances exclusively with private IP addresses. This enhances security by isolating the database within your VPC network and can reduce latency for internal applications. Be aware that removing a public IP will disrupt existing connections that depend on it; establish and test private connectivity paths before making the change. This applies to Second Generation instances.
      audit: |
        **Using Google Cloud Console**

          1. Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
          2. Review the list of PostgreSQL instances. For each primary (non-replica) Second Generation instance:
             - Select the instance name to view its details.
             - Navigate to the **Connections** tab.
             - Confirm that a **Private IP** address is assigned and that no **Public IP** address (type: PRIMARY) is present.

        **Using Google Cloud CLI**

          1. List all Cloud SQL instances in your project:
            ```bash
            gcloud sql instances list
            ```

          2. For each PostgreSQL instance identified as `backendType: SECOND_GEN` and `instanceType: CLOUD_SQL_INSTANCE` (primary instance), retrieve its configuration details:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```

          3. Inspect the `ipAddresses` section in the output:
             - Ensure there is an entry with `type: PRIVATE`.
             - Verify that no entry exists with `type: PRIMARY`, as this indicates a public IP address.

          **Note:** Instances can temporarily have both private and public IPs during transitions. The secure state is when only the **PRIVATE** type is assigned.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud SQL Instances page in the Google Cloud Console: https://console.cloud.google.com/sql/instances.
            2.  Select the name of the target PostgreSQL instance to open its configuration details.
            3.  Navigate to the **Connections** tab.
            4.  In the **Networking** section, uncheck the box labeled **Public IP** to disable public access.
            5.  Click **Save** to apply the changes.

            **Prevention:**

            To ensure new Cloud SQL instances are not created with public IP addresses, enforce the `Restrict Public IP access on Cloud SQL instances` Organization Policy. Configure this policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Modify the target instance to remove its public IP address and ensure it's associated with a VPC network for private IP access. Replace `INSTANCE_NAME` with the actual instance name and `VPC_NETWORK_NAME` with the desired VPC network name:
                ```bash
                gcloud sql instances patch INSTANCE_NAME --network=VPC_NETWORK_NAME --no-assign-ip
                ```
                *Note: If the instance is already associated with the correct VPC network for private IP, you might only need the `--no-assign-ip` flag.*
            2.  Verify that the public IP address has been removed by inspecting the instance's configuration:
                ```bash
                gcloud sql instances describe INSTANCE_NAME
                ```
                Check the `ipAddresses` section in the output to confirm the absence of an entry with `type: PRIMARY`.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `ipv4_enabled` attribute within the `ip_configuration` block is set to `false` or omitted (defaults to false if private network is configured):

            ```hcl
            resource "google_sql_database_instance" "default" {
              name             = "my-postgres-instance"
              database_version = "POSTGRES_15"
              region           = "us-central1"

              settings {
                tier = "db-f1-micro"
                ip_configuration {
                  # Ensure private network is configured
                  private_network = "projects/my-project/global/networks/my-vpc"
                  # Set ipv4_enabled to false or omit it
                  ipv4_enabled    = false
                }
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-gcp
    filters: |
      asset.platform == 'gcp-sql-postgresql'
    mql: |
      gcp.sql.instance.ipAddresses.all(type != "PRIMARY")
  - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')) != empty
    mql: |
      # Check that settings/ip_configuration exists on all PostgreSQL instances is not set or set to false (no public IP)
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'ip_configuration').all(
            arguments['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(
            _['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-instances-not-publicly-exposed-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')).all(
        values['settings'].all(
          _['ip_configuration'].all(
            _['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed
    title: Ensure Cloud SQL for SQL Server instances are not publicly exposed
    impact: 100
    variants:
      - uid: mondoo-gcp-security-cloud-sql-sql-server-instance-not-publicly-exposed-gcp
      - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-state
    docs:
      desc: |
        Assigning public IP addresses to Cloud SQL for SQL Server instances expands the potential attack surface, making databases accessible from the public internet and increasing security risks.

        The recommended practice is to configure instances exclusively with private IP addresses. This enhances security by isolating the database within your VPC network and can reduce latency for internal applications. Be aware that removing a public IP will disrupt existing connections that depend on it; establish and test private connectivity paths before making the change. This applies to Second Generation instances.
      audit: |
        **Using Google Cloud Console**

          1. Navigate to the Cloud SQL Instances page within the Google Cloud Console: https://console.cloud.google.com/sql/instances
          2. Review each SQL Server instance listed. For every primary (non-replica) Second Generation instance, examine its networking details to confirm that a Private IP address is assigned and that no Public IP address (type: PRIMARY) is present.

        **Using Google Cloud CLI**

          1. Obtain a list of all your Cloud SQL instances:

            ```bash
            gcloud sql instances list
            ```

          2. For each SQL Server instance identified as `backendType: SECOND_GEN` and `instanceType: CLOUD_SQL_INSTANCE` (primary instance), retrieve its full configuration details. Read replicas (`instanceType: READ_REPLICA_INSTANCE`) inherit network settings.

            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```

          3. Inspect the `ipAddresses` section in the output for the instance. Verify that an entry exists with `type: PRIVATE`. Crucially, ensure there is no entry with `type: PRIMARY`, as this indicates a public IP address. While an instance can technically possess both during transitions, the secure state is having only the `PRIVATE` type assigned.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Access the Cloud SQL Instances overview page in the Google Cloud Console: https://console.cloud.google.com/sql/instances
            2.  Select the name of the target SQL Server instance to view its configuration details.
            3.  Navigate to the **Connections** settings tab.
            4.  Under the **Networking** section, locate and uncheck the box labeled **Public IP**.
            5.  Confirm the modification by selecting the **Save** button.

            **Prevention:**

            To proactively enforce that new Cloud SQL instances are not created with public IP addresses, implement the `Restrict Public IP access on Cloud SQL instances` Organization Policy. You can configure this policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Modify the target instance to remove its public IP address and ensure it's associated with a VPC network for private IP access. Replace `INSTANCE_NAME` with the actual instance name and `VPC_NETWORK_NAME` with the desired VPC network name:
                ```bash
                gcloud sql instances patch INSTANCE_NAME --network=VPC_NETWORK_NAME --no-assign-ip
                ```
                *Note: If the instance is already associated with the correct VPC network for private IP, you might only need the `--no-assign-ip` flag.*
            2.  Verify that the public IP address has been removed by inspecting the instance's configuration:
                ```bash
                gcloud sql instances describe INSTANCE_NAME
                ```
                Check the `ipAddresses` section in the output to confirm the absence of an entry with `type: PRIMARY`.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `ipv4_enabled` attribute within the `ip_configuration` block is set to `false` or omitted (defaults to false if private network is configured):

            ```hcl
            resource "google_sql_database_instance" "default" {
              name             = "my-sql-server-instance"
              database_version = "SQLSERVER_2019_STANDARD"
              region           = "us-central1"

              settings {
                tier = "db-custom-2-7680" # Example tier
                ip_configuration {
                  # Ensure private network is configured
                  private_network = "projects/my-project/global/networks/my-vpc"
                  # Set ipv4_enabled to false or omit it
                  ipv4_enabled    = false
                }
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-sql-server-instance-not-publicly-exposed-gcp
    filters: |
      asset.platform == 'gcp-sql-sqlserver'
    mql: |
      gcp.sql.instance.ipAddresses.all(type != "PRIMARY")
  - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('SQLSERVER')) != empty
    mql: |
      # Check that settings/ip_configuration exists on all SQL Server instances and ipv4_enabled set to false (no public IP)
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('SQLSERVER')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'ip_configuration').all(
            arguments['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('SQLSERVER'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('SQLSERVER')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(
            _['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-instances-not-publicly-exposed-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('SQLSERVER'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('SQLSERVER')).all(
        values['settings'].all(
          _['ip_configuration'].all(
            _['ipv4_enabled'] == false
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls
    title: Ensure Cloud SQL PostgreSQL connections require SSL/TLS
    impact: 90
    variants:
      - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-gcp
      - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-state
    docs:
      desc: |
        Requiring SSL/TLS for connections to Cloud SQL PostgreSQL instances encrypts data in transit between the client and the database server. This prevents potential eavesdropping and man-in-the-middle attacks, protecting sensitive data from unauthorized access during transmission.

        It is strongly recommended to configure Cloud SQL instances to enforce SSL/TLS for all incoming connections to maintain data confidentiality and integrity. Note that enabling this setting requires clients to be configured correctly to use SSL/TLS, which might necessitate application updates.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: https://console.cloud.google.com/sql/instances
        2.  Select the name of the PostgreSQL instance you want to audit.
        3.  Select the **Connections** tab.
        4.  Go to the **Security** sub-tab.
        5.  Verify that the checkbox for **Allow only SSL connections** is checked.

        **Using Google Cloud CLI**

        1.  Retrieve the configuration details for the instance:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
        2.  Inspect the output and locate the `settings.ipConfiguration` section.
        3.  Ensure the value for `sslMode` is set to `ENCRYPTED_ONLY`.

            Example relevant output snippet:
            ```yaml
            settings:
              ipConfiguration:
                sslMode: ENCRYPTED_ONLY
            ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Access the Cloud SQL Instances overview page: https://console.cloud.google.com/sql/instances
            2.  Select the name of the target PostgreSQL instance.
            3.  Navigate to the **Connections** tab, then the **Security** sub-tab.
            4.  Check the box labeled **Allow only SSL connections**.
            5.  Select **Save** to apply the change. *Note: This may trigger an instance restart.*

            **Prevention:**

            Always configure new Cloud SQL PostgreSQL instances with the "Allow only SSL connections" option enabled during creation via the Console. Regularly audit instances to ensure compliance.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Enable the SSL Mode to be "ENCRYPTED_ONLY":
                ```bash
                gcloud sql instances patch INSTANCE_NAME --ssl-mode=ENCRYPTED_ONLY
                ```
                *Note: This command may cause the instance to restart.*

            **Prevention:**

            Always configure new Cloud SQL PostgreSQL instances with the `--ssl-mode=ENCRYPTED_ONLY` flag during creation via the CLI. Regularly audit instances to ensure compliance.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `ssl_mode` attribute within the `ip_configuration` block is set to `ENCRYPTED_ONLY`:

            ```hcl
            resource "google_sql_database_instance" "default" {
              name             = "my-postgres-instance"
              database_version = "POSTGRES_15"
              region           = "us-central1"

              settings {
                tier = "db-f1-micro"
                ip_configuration {
                  ipv4_enabled = true
                  ssl_mode     = "ENCRYPTED_ONLY"
                }
              }
            }
            ```

            **Prevention:**

            Always configure new Cloud SQL PostgreSQL instances with `ssl_mode = "ENCRYPTED_ONLY"` during creation via Terraform. Regularly audit instances to ensure compliance.
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-gcp
    filters: |
      asset.platform == 'gcp-sql-postgresql'
    mql: |
      gcp.sql.instance.settings.ipConfiguration.sslMode == "ENCRYPTED_ONLY"
  - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')) != empty
    mql: |
      # Check that ip_configuration block with ssl_mode exists and is set to ENCRYPTED_ONLY on all PostgreSQL instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('POSTGRES')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'ip_configuration').all(
            arguments.ssl_mode == "ENCRYPTED_ONLY"
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-postgres-connections-require-ssl-tls-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')).all(
        values['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls
    title: Ensure Cloud SQL for SQL Server connections require SSL/TLS
    impact: 90
    variants:
      - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-gcp
      - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-hcl
      - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-plan
      - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-state
    docs:
      desc: |
        Requiring SSL/TLS for connections to Cloud SQL for SQL Server instances encrypts data in transit between the client and the database server. This prevents potential eavesdropping and man-in-the-middle attacks, protecting sensitive data from unauthorized access during transmission.

        It is strongly recommended to configure Cloud SQL instances to enforce SSL/TLS for all incoming connections to maintain data confidentiality and integrity. Note that enabling this setting requires clients to be configured correctly to use SSL/TLS, which might necessitate application updates.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: https://console.cloud.google.com/sql/instances
        2.  Select the name of the SQL Server instance you want to audit.
        3.  Select the **Connections** tab.
        4.  Go to the **Security** sub-tab.
        5.  Verify that the checkbox for **Allow only SSL connections** is checked.

        **Using Google Cloud CLI**

        1.  Retrieve the configuration details for the instance:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
        2.  Inspect the output and locate the `settings.ipConfiguration` section.
        3.  Ensure the value for `sslMode` is set to `ENCRYPTED_ONLY`.

            Example relevant output snippet:
            ```yaml
            settings:
              ipConfiguration:
                sslMode: ENCRYPTED_ONLY
            ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Access the Cloud SQL Instances overview page: https://console.cloud.google.com/sql/instances
            2.  Select the name of the target SQL Server instance.
            3.  Navigate to the **Connections** tab, then the **Security** sub-tab.
            4.  Check the box labeled **Allow only SSL connections**.
            5.  Select **Save** to apply the change. *Note: This may trigger an instance restart.*

            **Prevention:**

            Always configure new Cloud SQL for SQL Server instances with the "Allow only SSL connections" option enabled during creation via the Console. Regularly audit instances to ensure compliance.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1.  Enable the SSL Mode to be "ENCRYPTED_ONLY":
                ```bash
                gcloud sql instances patch INSTANCE_NAME --ssl-mode=ENCRYPTED_ONLY
                ```
                *Note: This command may cause the instance to restart.*

            **Prevention:**

            Always configure new Cloud SQL for SQL Server instances with the `--ssl-mode=ENCRYPTED_ONLY` flag during creation via the CLI. Regularly audit instances to ensure compliance.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure the `require_ssl` attribute within the `ip_configuration` block is set to `true`:

            ```hcl
            resource "google_sql_database_instance" "default" {
              name             = "my-sql-server-instance"
              database_version = "SQLSERVER_2019_STANDARD"
              region           = "us-central1"

              settings {
                tier = "db-f1-micro"
                ip_configuration {
                  ipv4_enabled = true
                  ssl_mode     = "ENCRYPTED_ONLY"
                }
              }
            }
            ```

            **Prevention:**

            Always configure new Cloud SQL for SQL Server instances with `ssl_mode = "ENCRYPTED_ONLY"` during creation via Terraform. Regularly audit instances to ensure compliance.
    refs:
      - url: https://cloud.google.com/sql/docs/mysql/best-practices
        title: Cloud SQL Best Practices
  - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-gcp
    filters: |
      asset.platform == 'gcp-sql-sqlserver'
    mql: |
      gcp.sql.instance.settings.ipConfiguration.sslMode == "ENCRYPTED_ONLY"
  - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('SQLSERVER')) != empty
    mql: |
      # Check that ip_configuration block with ssl_mode exists and ssl_mode is set to ENCRYPTED_ONLY on all SQL Server instances
      terraform.resources('google_sql_database_instance').where(arguments['database_version'].contains('SQLSERVER')).all(
        blocks.where(type == 'settings') != empty &&
        blocks.where(type == 'settings').all(blocks.where(type == 'ip_configuration') != empty) &&
        blocks.where(type == 'settings').all(
          blocks.where(type == 'ip_configuration').all(
            arguments.ssl_mode == "ENCRYPTED_ONLY"
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_sql_database_instance' && change.after.database_version.contains('SQLSERVER'))
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('SQLSERVER')).all(
        change.after['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-sql-sql-server-connections-require-ssl-tls-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_sql_database_instance' && values.database_version.contains('SQLSERVER'))
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('SQLSERVER')).all(
        values['settings'].all(
          _['ip_configuration'].all(
            _['ssl_mode'] == 'ENCRYPTED_ONLY'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible
    title: Ensure That Cloud KMS Cryptokeys Are Not Anonymously or Publicly Accessible
    impact: 100
    variants:
      - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-gcp
      - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-hcl
      - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-plan
      - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-state
    docs:
      desc: |
        It is recommended to restrict anonymous and/or public access in the Cloud Key Management Service (KMS) Cryptokeys Identity and Access Management (IAM) policy.

        Granting permissions to `allUsers` or `allAuthenticatedUsers` allows broad access to your cryptokeys. Ensuring that anonymous and/or public access is not permitted helps maintain the confidentiality and integrity of your encrypted data.

        Removing `allUsers` and `allAuthenticatedUsers` from the Cloud KMS Cryptokey IAM policy prevents unauthorized anonymous or public access to your cryptokeys, thereby enhancing the security posture of your encrypted data.
      audit: |
        **Using Google Cloud Console**

        1.  Navigate to the Cloud KMS Keys page: https://console.cloud.google.com/security/kms/keys
        2.  Select a key ring to view its cryptokeys.
        3.  For each cryptokey, click the **Permissions** tab.
        4.  Verify that neither `allUsers` nor `allAuthenticatedUsers` appears in the member list.

        **Using Google Cloud CLI**

        1. List all Cloud KMS `Cryptokeys`:
        ```bash
        gcloud kms keys list --keyring=[key_ring_name] --location=global --format=json | jq '.[].name'
        ```
        2. Ensure the below command's output does not contain `allUsers` or `allAuthenticatedUsers`:
        ```bash
        gcloud kms keys get-iam-policy [key_name] --keyring=[key_ring_name] --location=global --format=json | jq '.bindings[].members[]'
        ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1.  Navigate to the Cloud KMS Keys page: https://console.cloud.google.com/security/kms/keys
            2.  Select the key ring containing the target cryptokey.
            3.  Click on the cryptokey name to view its details.
            4.  Navigate to the **Permissions** tab.
            5.  For any binding that includes `allUsers` or `allAuthenticatedUsers`:
                - Click the **Edit** (pencil) icon for that binding.
                - Remove `allUsers` and/or `allAuthenticatedUsers` from the members list.
                - Click **Save** to apply the changes.

            **Prevention:**

            When creating new cryptokeys or modifying IAM policies, ensure that `allUsers` and `allAuthenticatedUsers` are never added as members. Regularly audit cryptokey permissions to ensure compliance.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. List all Cloud KMS `Cryptokeys`:
            ```bash
            gcloud kms keys list --keyring=[key_ring_name] --location=global --format=json | jq '.[].name'
            ```
            2. Remove IAM policy binding for a KMS key to remove access to `allUsers` and `allAuthenticatedUsers`:
            ```bash
            gcloud kms keys remove-iam-policy-binding [key_name] --keyring=[key_ring_name] --location=global --member='allAuthenticatedUsers' --role='[role]'

            gcloud kms keys remove-iam-policy-binding [key_name] --keyring=[key_ring_name] --location=global --member='allUsers' --role='[role]'
            ```

            **Prevention:**

            When creating new cryptokeys or modifying IAM policies via CLI, ensure that `allUsers` and `allAuthenticatedUsers` are never included in policy bindings. Regularly audit cryptokey permissions to ensure compliance.
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure that IAM policy resources for KMS crypto keys do not include `allUsers` or `allAuthenticatedUsers` as members:

            ```hcl
            # Good example - specific users/service accounts only
            resource "google_kms_crypto_key_iam_binding" "crypto_key" {
              crypto_key_id = google_kms_crypto_key.key.id
              role          = "roles/cloudkms.cryptoKeyEncrypter"

              members = [
                "user:jane@example.com",
                "serviceAccount:my-service@project.iam.gserviceaccount.com",
              ]
            }

            # Avoid - public access
            resource "google_kms_crypto_key_iam_binding" "crypto_key_bad" {
              crypto_key_id = google_kms_crypto_key.key.id
              role          = "roles/cloudkms.cryptoKeyEncrypter"

              members = [
                "allUsers",                    # Remove this
                "allAuthenticatedUsers",       # Remove this
                "user:jane@example.com",
              ]
            }
            ```

            **Prevention:**

            Always review IAM policies for KMS crypto keys during code reviews. Use Terraform validation rules or policy-as-code tools to prevent public access grants. Regularly audit your Terraform configurations to ensure compliance.
    refs:
      - url: https://cloud.google.com/kms/docs/reference
        title: Cloud KMS Documentation
  - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-gcp
    filters: asset.platform == "gcp-kms-keyring"
    mql: |
      gcp.project.kms.keyring.cryptokeys.all(
        iamPolicy.all(
          members.none(_ == "allUsers" || _ == "allAuthenticatedUsers")
        )
      )
  - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.where( nameLabel.in(['google_kms_crypto_key_iam_policy', 'google_kms_crypto_key_iam_binding','google_kms_crypto_key_iam_member'])) != empty
    mql: |
      terraform.resources.where(nameLabel == 'google_kms_crypto_key_iam_policy' || nameLabel == 'google_kms_crypto_key_iam_binding')
        .all(
          arguments.members == empty || arguments.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
        )
      terraform.resources('google_kms_crypto_key_iam_member').all(
        arguments.member != 'allUsers' && arguments.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key_iam_policy') ||
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key_iam_binding') ||
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key_iam_member')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_kms_crypto_key_iam_policy' || type == 'google_kms_crypto_key_iam_binding' || type == 'google_kms_crypto_key_iam_member').all(
        change.after.members == empty ||
          change.after.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
  - uid: mondoo-gcp-security-cloud-kms-cryptokeys-not-publicly-accessible-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_kms_crypto_key_iam_policy') ||
      terraform.state.resources.contains(type == 'google_kms_crypto_key_iam_binding') ||
      terraform.state.resources.contains(type == 'google_kms_crypto_key_iam_member')
    mql: |
      terraform.state.resources.where(type == 'google_kms_crypto_key_iam_policy' || type == 'google_kms_crypto_key_iam_binding' || type == 'google_kms_crypto_key_iam_member').all(
        values.members == empty ||
          values.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days
    title: Ensure KMS Encryption Keys Are Rotated Within a Period of 90 Days
    impact: 30
    variants:
      - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-gcp
      - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-hcl
      - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-plan
      - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-state
    docs:
      desc: |
        Google Cloud Key Management Service (KMS) stores cryptographic keys hierarchically with robust access control. Configure a key rotation period and start time to ensure regular updates, enhancing security for data encrypted by these keys. The gcloud CLI requires the next rotation time in ISO or RFC3339 format, and the rotation period as INTEGER[UNIT] (s, m, h, or d). Note that after rotation, the older key version is still required to decrypt data encrypted with it.
      audit: |
        **Using Google Cloud Console**

        1. Navigate to the Cryptographic Keys section of the Google Cloud Console by visiting: [https://console.cloud.google.com/security/kms](https://console.cloud.google.com/security/kms).

        2. Select each key ring sequentially. Within each key ring, verify that every key's "Next Rotation" is scheduled to occur within 90 days from the current date.

        **Using Google Cloud CLI**

        1. To confirm that a rotation schedule is configured for each key, including both the ROTATION_PERIOD and NEXT_ROTATION_TIME, use the following command:

        ```bash
        gcloud kms keys list --keyring=<KEY_RING> --location=<LOCATION> --format=json'(rotationPeriod)'
        ```

        Ensure the returned values for rotationPeriod and nextRotationTime adhere to the following criteria:

        - `rotationPeriod` must not exceed 129600m (minutes).
        - `rotationPeriod` must not exceed 7776000s (seconds).
        - `rotationPeriod` must not exceed 2160h (hours).
        - `rotationPeriod` must not exceed 90d (days).
        - `nextRotationTime` must be scheduled within 90 days from the current date.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Access the `Cryptographic Keys` page: [https://console.cloud.google.com/security/kms](https://console.cloud.google.com/security/kms).
            2. Select the desired key ring.
            3. From the list of keys, locate and click the three-dot menu icon on the right side of the specific key.
            4. Choose "Edit rotation period" from the options.
            5. In the pop-up window, set a new rotation period (in days) to be less than 90 days, and specify a "Starting on" date for the rotation to begin.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update and schedule rotation by `ROTATION_PERIOD` and `NEXT_ROTATION_TIME` for each key:

            ```bash
            gcloud kms keys update KEY_NAME --keyring=KEY_RING --location=LOCATION --next-rotation-time=NEXT_ROTATION_TIME --rotation-period=ROTATION_PERIOD
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Configure automatic key rotation for your KMS cryptokeys by setting a rotation period of 90 days or less:

            ```hcl
            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id

              # Rotate every 90 days (maximum)
              rotation_period = "7776000s"  # 90 days in seconds

              lifecycle {
                prevent_destroy = true
              }
            }

            resource "google_kms_key_ring" "example" {
              name     = "example-keyring"
              location = "global"
            }
            ```

            **Prevention:**

            Always configure key rotation periods in your Terraform KMS configurations. Use Terraform validation rules or policy-as-code tools to ensure rotation periods are set to 90 days or less. Regularly audit your Terraform configurations to ensure compliance with key rotation requirements.
    refs:
      - url: https://cloud.google.com/kms/docs/reference
        title: Cloud KMS Documentation
  - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-gcp
    filters: asset.platform == "gcp-kms-keyring"
    mql: |
      gcp.project.kms.keyring.cryptokeys.where(primary.state == "ENABLED").all(rotationPeriod.seconds <= 7776000)
  - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_kms_crypto_key') != empty
    mql: |
      terraform.resources('google_kms_crypto_key').all(
        arguments['rotation_period'] != null && arguments['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_kms_crypto_key').all(
        change.after['rotation_period'] != null && change.after['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-rotated-90-days-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.state.resources.where(type == 'google_kms_crypto_key').all(
        values['rotation_period'] != null && values['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration
    title: Ensure KMS crypto keys have a destroy scheduled duration of at least 24 hours
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-gcp
      - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-hcl
      - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-plan
      - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud KMS crypto keys have a destroy scheduled duration of at least 24 hours. When a crypto key version is scheduled for destruction, the destroy scheduled duration determines how long it remains in the DESTROY_SCHEDULED state before being permanently destroyed. A minimum of 24 hours provides a safety window to recover keys that were accidentally scheduled for destruction.

        **Why this matters**

        Crypto key destruction is an irreversible operation. Once a key version is permanently destroyed, any data encrypted with that key version becomes unrecoverable. The destroy scheduled duration provides a critical safety net:
          - Accidental key destruction can be reversed during the scheduled destruction window.
          - Security teams have time to review and approve key destruction requests.
          - Automated processes that inadvertently trigger key destruction can be caught before permanent data loss occurs.

        If the destroy scheduled duration is too short, it can lead to:
          - Permanent, unrecoverable data loss if a key is accidentally destroyed before the error is detected.
          - Inability to decrypt data that was encrypted with the destroyed key version.
          - Compliance violations, as many regulatory frameworks require data retention capabilities that depend on encryption key availability.
          - Operational disruptions if applications lose access to required encryption keys.

        **Risk mitigation:**
          - Set the destroy scheduled duration to at least 24 hours (86400 seconds) for all crypto keys.
          - Consider longer durations (e.g., 30 days) for keys protecting critical or regulated data.
          - Implement alerting on key destruction events to ensure timely review.
          - Use IAM policies to restrict who can schedule key destruction.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure the destroy scheduled duration when creating crypto keys:

            ```hcl
            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id

              # At least 24 hours (86400 seconds)
              destroy_scheduled_duration = "86400s"

              rotation_period = "7776000s"

              lifecycle {
                prevent_destroy = true
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            The destroy scheduled duration is set at key creation time and cannot be modified after creation. To ensure compliance:

            1. Navigate to **Security** > **Key Management** in the GCP Console.
            2. When creating a new crypto key, expand **Advanced settings**.
            3. Set the **Scheduled for destruction duration** to at least 24 hours.
            4. For existing keys with insufficient duration, create a new key with the correct duration and re-encrypt data with the new key.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Set the destroy scheduled duration when creating a new crypto key:

            ```bash
            gcloud kms keys create KEY_NAME \
              --keyring=KEY_RING \
              --location=LOCATION \
              --purpose=encryption \
              --destroy-scheduled-duration=24h
            ```

            For existing keys, the destroy scheduled duration cannot be changed. Create a new key with the correct duration and migrate encrypted data.
    refs:
      - url: https://cloud.google.com/kms/docs/reference
        title: Cloud KMS Documentation
  - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-gcp
    filters: asset.platform == "gcp-kms-keyring"
    mql: |
      gcp.project.kms.keyring.cryptokeys.where(primary.state == "ENABLED").all(destroyScheduledDuration.seconds >= 86400)
  - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_kms_crypto_key') != empty
    mql: |
      terraform.resources('google_kms_crypto_key').all(
        arguments['destroy_scheduled_duration'] == empty || arguments['destroy_scheduled_duration'] >= "86400s"
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_kms_crypto_key').all(
        change.after['destroy_scheduled_duration'] == empty || change.after['destroy_scheduled_duration'] >= "86400s"
      )
  - uid: mondoo-gcp-security-cloud-kms-keys-destroy-scheduled-duration-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.state.resources.where(type == 'google_kms_crypto_key').all(
        values['destroy_scheduled_duration'] == empty || values['destroy_scheduled_duration'] >= "86400s"
      )
  - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location
    title: Ensure KMS keyrings are not in the global location
    impact: 40
    variants:
      - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-gcp
      - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-hcl
      - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-plan
      - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud KMS keyrings are created in a specific regional location rather than the 'global' location. Using regional locations for keyrings helps meet data residency requirements and provides better control over where cryptographic operations are performed.

        **Why this matters**

        When a KMS keyring is created in the 'global' location, cryptographic operations can be performed in any Google Cloud region. While this provides flexibility, it creates challenges for organizations with data residency requirements:
          - Cryptographic operations may be performed in regions that violate data sovereignty regulations.
          - Audit and compliance teams cannot guarantee that key material is processed within approved geographic boundaries.
          - Regional keyrings provide a clear boundary for where cryptographic operations occur.

        If keyrings are created in the global location, it can lead to:
          - Non-compliance with data residency regulations such as GDPR, which requires data processing within specific geographic boundaries.
          - Inability to meet contractual obligations regarding data locality.
          - Reduced visibility into where cryptographic operations are performed.
          - Challenges during compliance audits when demonstrating geographic controls.

        **Risk mitigation:**
          - Create KMS keyrings in specific regional locations that align with your data residency requirements.
          - Use organization policies to restrict the allowed locations for KMS resources.
          - Document and enforce a key management policy that specifies approved locations.
          - Migrate existing global keyrings to regional keyrings where possible (note: keyrings cannot be moved; create new regional keyrings and re-encrypt data).
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Create keyrings in a specific regional location:

            ```hcl
            resource "google_kms_key_ring" "example" {
              name     = "example-keyring"
              location = "us-central1"  # Use a specific region, not "global"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            KMS keyring location cannot be changed after creation. To create a properly located keyring:

            1. Navigate to **Security** > **Key Management** in the GCP Console.
            2. Click **Create Key Ring**.
            3. Under **Key ring location**, select a specific region (e.g., us-central1) instead of 'global'.
            4. Complete the key ring creation.
            5. For existing global keyrings, create a new regional keyring, create new keys, and re-encrypt data with the new keys.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Create a keyring in a specific regional location:

            ```bash
            gcloud kms keyrings create KEY_RING_NAME \
              --location=us-central1
            ```

            Avoid using `--location=global`. For existing global keyrings, create a new regional keyring and migrate:

            ```bash
            # Create new regional keyring
            gcloud kms keyrings create NEW_KEY_RING \
              --location=us-central1

            # Create new key in regional keyring
            gcloud kms keys create NEW_KEY \
              --keyring=NEW_KEY_RING \
              --location=us-central1 \
              --purpose=encryption \
              --rotation-period=7776000s
            ```
    refs:
      - url: https://cloud.google.com/kms/docs/reference
        title: Cloud KMS Documentation
  - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-gcp
    filters: asset.platform == "gcp-kms-keyring"
    mql: gcp.project.kms.keyring.location != "global"
  - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_kms_key_ring') != empty
    mql: |
      terraform.resources('google_kms_key_ring').all(
        arguments.location != 'global'
      )
  - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_kms_key_ring')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_kms_key_ring').all(
        change.after.location != 'global'
      )
  - uid: mondoo-gcp-security-cloud-kms-keyring-not-global-location-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_kms_key_ring')
    mql: |
      terraform.state.resources.where(type == 'google_kms_key_ring').all(
        values.location != 'global'
      )
  - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured
    title: Ensure KMS ENCRYPT_DECRYPT crypto keys have automatic rotation configured
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-gcp
      - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-hcl
      - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-plan
      - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-state
    docs:
      desc: |
        This check ensures that Google Cloud KMS crypto keys with the ENCRYPT_DECRYPT purpose have automatic rotation configured. Automatic key rotation creates new key versions on a regular schedule, ensuring that data encryption uses current key material without requiring manual intervention.

        **Why this matters**

        Symmetric encryption keys (ENCRYPT_DECRYPT purpose) support automatic rotation in Cloud KMS. When automatic rotation is configured, KMS creates a new primary key version on the specified schedule, and new encryption requests automatically use the new version. Without automatic rotation:
          - Key material may remain static indefinitely, increasing the window of exposure if a key is compromised.
          - Organizations must rely on manual processes to rotate keys, which are error-prone and often neglected.
          - The volume of data encrypted under a single key version grows continuously, increasing the impact of a potential key compromise.

        If automatic rotation is not configured for ENCRYPT_DECRYPT keys, it can lead to:
          - Extended use of the same key material, violating the principle of cryptographic key hygiene.
          - Increased risk if a key version is compromised, as all data encrypted since the last rotation is affected.
          - Non-compliance with security frameworks such as CIS Google Cloud Platform Foundations Benchmark, NIST 800-57, and PCI DSS which require regular key rotation.
          - Operational overhead from manual key rotation processes.

        **Risk mitigation:**
          - Enable automatic rotation for all ENCRYPT_DECRYPT crypto keys with a rotation period of 90 days or less.
          - Monitor key rotation events to ensure rotations occur as scheduled.
          - Review keys that are marked as import-only, as these cannot be automatically rotated and require manual processes.
          - Implement alerting for keys approaching their next rotation time.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure automatic rotation for ENCRYPT_DECRYPT crypto keys:

            ```hcl
            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id
              purpose  = "ENCRYPT_DECRYPT"

              # Rotate every 90 days
              rotation_period = "7776000s"

              lifecycle {
                prevent_destroy = true
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security** > **Key Management** in the GCP Console.
            2. Select the key ring containing the target crypto key.
            3. Click the three-dot menu for the crypto key and select **Edit rotation period**.
            4. Set a rotation period (e.g., 90 days) and a starting date.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Configure automatic rotation for an existing crypto key:

            ```bash
            gcloud kms keys update KEY_NAME \
              --keyring=KEY_RING \
              --location=LOCATION \
              --rotation-period=90d \
              --next-rotation-time=$(date -u -v+90d +%Y-%m-%dT%H:%M:%SZ)
            ```

            For new keys, set rotation at creation time:

            ```bash
            gcloud kms keys create KEY_NAME \
              --keyring=KEY_RING \
              --location=LOCATION \
              --purpose=encryption \
              --rotation-period=90d \
              --next-rotation-time=$(date -u -v+90d +%Y-%m-%dT%H:%M:%SZ)
            ```
    refs:
      - url: https://cloud.google.com/kms/docs/reference
        title: Cloud KMS Documentation
  - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-gcp
    filters: asset.platform == "gcp-kms-keyring"
    mql: |
      gcp.project.kms.keyring.cryptokeys.where(primary.state == "ENABLED" && purpose == "ENCRYPT_DECRYPT").all(rotationPeriod != empty)
  - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_kms_crypto_key') != empty
    mql: |
      terraform.resources('google_kms_crypto_key').where(
        arguments.purpose == empty || arguments.purpose == 'ENCRYPT_DECRYPT'
      ).all(
        arguments['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_kms_crypto_key').where(
        change.after.purpose == empty || change.after.purpose == 'ENCRYPT_DECRYPT'
      ).all(
        change.after['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-kms-encrypt-decrypt-keys-rotation-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_kms_crypto_key')
    mql: |
      terraform.state.resources.where(type == 'google_kms_crypto_key').where(
        values.purpose == empty || values.purpose == 'ENCRYPT_DECRYPT'
      ).all(
        values['rotation_period'] != empty
      )
  - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled
    title: Ensure That DNSSEC Is Enabled for Cloud DNS
    impact: 70
    variants:
      - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-gcp
      - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-state
    docs:
      desc: |
        Cloud DNS with DNSSEC provides a secure, reliable, and cost-effective domain name system. DNSSEC protects domains from hijacking and man-in-the-middle attacks by cryptographically signing DNS records, ensuring the authenticity of DNS responses. This prevents attackers from redirecting users to malicious sites through fake DNS lookups.
      audit: |
        **Using Google Cloud Console**

        1. Go to `Cloud DNS` by navigating to [https://console.cloud.google.com/net-services/dns/zones](https://console.cloud.google.com/net-services/dns/zones).
        2. For each zone of `Type` `Public`, make sure that `DNSSEC` is set to `On`.

        **Using Google Cloud CLI**

        1. List all Managed Zones in a project:

        ```bash
        gcloud dns managed-zones list
        ```

        2. For each zone of `VISIBILITY` `public`, describe its metadata:

        ```bash
        gcloud dns managed-zones describe ZONE_NAME
        ```

        3. Make sure that `dnssecConfig.state` property is `on`.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to `Cloud DNS` by navigating to [https://console.cloud.google.com/net-services/dns/zones](https://console.cloud.google.com/net-services/dns/zones).
            2. For each zone of `Type` `Public`, switch `DNSSEC` to `On`.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Use the below command to enable `DNSSEC` for Cloud DNS Zone Name:
            ```bash
            gcloud dns managed-zones update ZONE_NAME --dnssec-state on
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Enable DNSSEC for managed DNS zones by setting the `dnssec_config` block with `state = "on"`:

            ```hcl
            resource "google_dns_managed_zone" "example" {
              name         = "example-zone"
              dns_name     = "example.com."
              description  = "Example managed zone"
              visibility   = "public"

              dnssec_config {
                state = "on"
                default_key_specs {
                  algorithm  = "rsasha256"
                  key_length = 2048
                  key_type   = "keySigning"
                }
                default_key_specs {
                  algorithm  = "rsasha256"
                  key_length = 2048
                  key_type   = "zoneSigning"
                }
              }
            }
            ```

            **Prevention:**

            Always configure DNSSEC for public DNS zones in your Terraform configurations. Use Terraform validation rules or policy-as-code tools to ensure DNSSEC is enabled for all public zones. Regularly audit your Terraform configurations to ensure compliance.
    refs:
      - url: https://cloud.google.com/dns/docs/dnssec
        title: Cloud DNS DNSSEC
  - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-gcp
    filters: |
      asset.platform == "gcp-dns-managedzone"
      gcp.project.dnsService.managedzone.visibility == "public"
    mql: |
      gcp.dns.managedzone.dnssecConfig['state'] == 'on'
  - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_dns_managed_zone') != empty
    mql: |
      terraform.resources('google_dns_managed_zone').where(arguments['visibility'] == 'public' || arguments['visibility'] == empty) != empty
      terraform.resources('google_dns_managed_zone').where(arguments['visibility'] == 'public' || arguments['visibility'] == empty).all(
        blocks.where(type == 'dnssec_config').any(arguments['state'] == 'on')
      )
  - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_dns_managed_zone')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dns_managed_zone').where(change.after['visibility'] == 'public' || change.after['visibility'] == empty).all(
        change.after['dnssec_config'] != empty && change.after['dnssec_config'].any(_['state'] == "on")
      )
  - uid: mondoo-gcp-security-cloud-dns-dnssec-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' &&
        terraform.state.resources.where(type == 'google_dns_managed_zone') != empty
    mql: |
      terraform.state.resources.where(type == 'google_dns_managed_zone').where(values['visibility'] == 'public' || values['visibility'] == empty).all(
        values['dnssec_config'] != empty && values['dnssec_config'].any(_['state'] == "on")
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used
    title: Ensure That RSASHA1 Is Not Used for the Key-Signing Key in Cloud DNS DNSSEC
    impact: 30
    variants:
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-gcp
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-hcl
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-plan
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-state
    docs:
      desc: |
        When configuring DNSSEC for a managed zone, choose strong, recommended algorithms for key signing and denial-of-existence. While various DNSSEC algorithms are available, some are better suited for zone signing or transaction security. Note that SHA1 is deprecated by Google and requires a Google Cloud support contract and allowlisting for use. To modify DNSSEC settings on an enabled zone, disable and then re-enable it with the new configuration.
      audit: |
        **Using Google Cloud CLI**

        Ensure the property algorithm for keyType keySigning is not using `RSASHA1`:

        ```bash
        gcloud dns managed-zones describe ZONE_NAME --format="json(dnsName,dnssecConfig.state,dnssecConfig.defaultKeySpecs)"
        ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Network services > Cloud DNS** in the Google Cloud Console.
            2. Select the managed zone you want to configure.
            3. Click **DNSSEC** and then **Manage DNSSEC**.
            4. If DNSSEC is already enabled, first set it to **Off** and save.
            5. Re-enable DNSSEC by setting it to **On**.
            6. Under **Key-signing key algorithm**, select a strong algorithm such as **RSASHA256**, **ECDSAP256SHA256**, or **ECDSAP384SHA384**.
            7. Click **Save** to apply the new configuration.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. To change DNSSEC settings on an already enabled managed zone, first disable it:

            ```bash
            gcloud dns managed-zones update ZONE_NAME --dnssec-state off
            ```

            2. Then, re-enable it with the desired key-signing and denial-of-existence settings:

            ```bash
            gcloud dns managed-zones update ZONE_NAME --dnssec-state on --ksk-algorithm KSK_ALGORITHM --ksk-key-length KSK_KEY_LENGTH --zsk-algorithm ZSK_ALGORITHM --zsk-key-length ZSK_KEY_LENGTH --denial-of-existence DENIAL_OF_EXISTENCE
            ```

            **Supported algorithm options and key lengths:**

            | Algorithm | KSK Length | ZSK Length |
            |-----------|------------|------------|
            | RSASHA1 | 1024,2048 | 1024,2048 |
            | RSASHA256 | 1024,2048 | 1024,2048 |
            | RSASHA512 | 1024,2048 | 1024,2048 |
            | ECDSAP256SHA256 | 256 | 256 |
            | ECDSAP384SHA384 | 384 | 384 |
        - id: terraform
          desc: |
            **Using Terraform**

            Avoid using RSASHA1 for key-signing keys in your DNSSEC configuration. Use stronger algorithms like RSASHA256, RSASHA512, or ECDSA variants:

            ```hcl
            resource "google_dns_managed_zone" "example" {
              name         = "example-zone"
              dns_name     = "example.com."
              description  = "Example managed zone"
              visibility   = "public"

              dnssec_config {
                state = "on"
                # Use RSASHA256 instead of RSASHA1 for key-signing
                default_key_specs {
                  algorithm  = "rsasha256"  # Not rsasha1
                  key_length = 2048
                  key_type   = "keySigning"
                }
                default_key_specs {
                  algorithm  = "rsasha256"
                  key_length = 2048
                  key_type   = "zoneSigning"
                }
              }
            }
            ```

            **Prevention:**

            Always use strong cryptographic algorithms in your Terraform DNSSEC configurations. Avoid RSASHA1 and prefer RSASHA256, RSASHA512, or ECDSA algorithms. Use Terraform validation rules to prevent weak algorithms from being deployed.
    refs:
      - url: https://cloud.google.com/dns/docs/dnssec
        title: Cloud DNS DNSSEC
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-gcp
    filters: |
      asset.platform == "gcp-dns-managedzone"
      gcp.project.dnsService.managedzone.visibility != "private"
    mql: |
      gcp.dns.managedzone.dnssecConfig['state'] == 'on'
      gcp.dns.managedzone.dnssecConfig.defaultKeySpecs.where(keyType == 'keySigning').all(algorithm != 'RSASHA1')
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_dns_managed_zone') != empty
    mql: |
      terraform.resources('google_dns_managed_zone').where(arguments['visibility'] == 'public' || arguments['visibility'] == empty).all(
        blocks.where(type == 'dnssec_config').where(arguments.state == "on").all(
          blocks.where(type == 'default_key_specs' && arguments.key_type == "keySigning").all(
            arguments.algorithm != 'rsasha1'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_dns_managed_zone')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dns_managed_zone').where(change.after['visibility'] == 'public' || change.after['visibility'] == empty).all(
        change.after['dnssec_config'] != empty &&
        change.after['dnssec_config'].where(_['state'] == "on").all(
          _['default_key_specs'].where(_['key_type'] == "keySigning").all(_['algorithm'] != "rsasha1")
        )
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-ksk-not-used-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_dns_managed_zone')
    mql: |
      terraform.state.resources.where(type == 'google_dns_managed_zone').where(values['visibility'] == 'public' || values['visibility'] == empty).all(
        values['dnssec_config'] != empty &&
        values['dnssec_config'].where(_['state'] == "on").all(
          _['default_key_specs'].where(_['key_type'] == "keySigning").all(_['algorithm'] != "rsasha1")
        )
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used
    title: Ensure That RSASHA1 Is Not Used for the Zone-Signing Key in Cloud DNS DNSSEC
    impact: 30
    variants:
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-gcp
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-hcl
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-plan
      - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-state
    docs:
      desc: |
        DNSSEC algorithm numbers in this registry may be used in CERT RRs. Zone-signing is used for authenticating DNS zone data. Using a weak algorithm like RSASHA1 for zone signing undermines the security guarantees of DNSSEC. SHA-1 is considered cryptographically weak and is deprecated by Google, requiring a support contract and allowlisting for use. Stronger alternatives such as RSASHA256, RSASHA512, ECDSAP256SHA256, or ECDSAP384SHA384 should be used for zone-signing keys.

        To modify DNSSEC settings on an already enabled zone, you must first disable DNSSEC and then re-enable it with the updated configuration.
      audit: |
        **Using Google Cloud CLI**

        Ensure the property algorithm for keyType zoneSigning is not using `RSASHA1`:

        ```bash
        gcloud dns managed-zones describe ZONE_NAME --format="json(dnsName,dnssecConfig.state,dnssecConfig.defaultKeySpecs)"
        ```
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Network services > Cloud DNS** in the Google Cloud Console.
            2. Select the managed zone you want to configure.
            3. Click **DNSSEC** and then **Manage DNSSEC**.
            4. If DNSSEC is already enabled, first set it to **Off** and save.
            5. Re-enable DNSSEC by setting it to **On**.
            6. Under **Zone-signing key algorithm**, select a strong algorithm such as **RSASHA256**, **ECDSAP256SHA256**, or **ECDSAP384SHA384**.
            7. Click **Save** to apply the new configuration.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. To change DNSSEC settings on an already enabled managed zone, first disable it:

            ```bash
            gcloud dns managed-zones update ZONE_NAME --dnssec-state off
            ```

            2. Then, re-enable it with the desired key-signing and zone-signing settings:

            ```bash
            gcloud dns managed-zones update ZONE_NAME --dnssec-state on --ksk-algorithm KSK_ALGORITHM --ksk-key-length KSK_KEY_LENGTH --zsk-algorithm ZSK_ALGORITHM --zsk-key-length ZSK_KEY_LENGTH --denial-of-existence DENIAL_OF_EXISTENCE
            ```

            **Supported algorithm options and key lengths:**

            | Algorithm | KSK Length | ZSK Length |
            |-----------|------------|------------|
            | RSASHA1 | 1024,2048 | 1024,2048 |
            | RSASHA256 | 1024,2048 | 1024,2048 |
            | RSASHA512 | 1024,2048 | 1024,2048 |
            | ECDSAP256SHA256 | 256 | 256 |
            | ECDSAP384SHA384 | 384 | 384 |
        - id: terraform
          desc: |
            **Using Terraform**

            Avoid using RSASHA1 for zone-signing keys in your DNSSEC configuration. Use stronger algorithms like RSASHA256, RSASHA512, or ECDSA variants:

            ```hcl
            resource "google_dns_managed_zone" "example" {
              name         = "example-zone"
              dns_name     = "example.com."
              description  = "Example managed zone"
              visibility   = "public"

              dnssec_config {
                state = "on"
                default_key_specs {
                  algorithm  = "rsasha256"
                  key_length = 2048
                  key_type   = "keySigning"
                }
                # Use RSASHA256 instead of RSASHA1 for zone-signing
                default_key_specs {
                  algorithm  = "rsasha256"  # Not rsasha1
                  key_length = 2048
                  key_type   = "zoneSigning"
                }
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/dns/docs/dnssec
        title: Cloud DNS DNSSEC
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-gcp
    filters: |
      asset.platform == "gcp-dns-managedzone"
      gcp.project.dnsService.managedzone.visibility != "private"
    mql: |
      gcp.dns.managedzone.dnssecConfig['state'] == 'on'
      gcp.dns.managedzone.dnssecConfig.defaultKeySpecs.where(keyType == 'zoneSigning').all(algorithm != 'RSASHA1')
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources('google_dns_managed_zone') != empty
    mql: |
      terraform.resources('google_dns_managed_zone').where(arguments['visibility'] == 'public' || arguments['visibility'] == empty).all(
        blocks.where(type == 'dnssec_config').where(arguments.state == "on").all(
          blocks.where(type == 'default_key_specs' && arguments.key_type == "zoneSigning").all(
            arguments.algorithm != 'rsasha1'
          )
        )
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_dns_managed_zone')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dns_managed_zone').where(change.after['visibility'] == 'public' || change.after['visibility'] == empty).all(
        change.after['dnssec_config'] != empty &&
        change.after['dnssec_config'].where(_['state'] == "on").all(
          _['default_key_specs'].where(_['key_type'] == "zoneSigning").all(_['algorithm'] != "rsasha1")
        )
      )
  - uid: mondoo-gcp-security-cloud-dns-rsasha1-zsk-not-used-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_dns_managed_zone')
    mql: |
      terraform.state.resources.where(type == 'google_dns_managed_zone').where(values['visibility'] == 'public' || values['visibility'] == empty).all(
        values['dnssec_config'] != empty &&
        values['dnssec_config'].where(_['state'] == "on").all(
          _['default_key_specs'].where(_['key_type'] == "zoneSigning").all(_['algorithm'] != "rsasha1")
        )
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet
    title: Ensure SSH access is restricted from the internet
    impact: 80
    variants:
      - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-gcp
      - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-hcl
      - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-plan
      - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-state
    docs:
      desc: |
        This check ensures that GCP firewall rules do not allow unrestricted SSH access (TCP port 22) from the entire internet (0.0.0.0/0 or ::/0). Firewall rules should restrict SSH access to specific trusted IP ranges to minimize the attack surface.

        **Why this matters**

        SSH provides direct command-line access to virtual machine instances. If a firewall rule allows SSH traffic from any IP address on the internet, it creates a significant exposure:
          - Attackers can attempt brute-force or credential-stuffing attacks against SSH services from any location.
          - Compromised credentials or key material can be exploited remotely without any network-level restriction.
          - Automated scanning tools continuously probe for open SSH ports across public IP ranges, increasing the likelihood of targeted attacks.

        If SSH access is not restricted to trusted IP ranges, it can lead to:
          - Unauthorized remote access to compute instances, enabling data theft, privilege escalation, or lateral movement.
          - Increased blast radius in the event of a credential compromise.
          - Non-compliance with security benchmarks such as CIS Google Cloud Platform Foundations Benchmark (Control 3.6), NIST 800-53, and PCI DSS.

        **Risk mitigation:**
          - Restrict source ranges in firewall rules to only known and trusted CIDR blocks (e.g., corporate VPN ranges, bastion host IPs).
          - Use Identity-Aware Proxy (IAP) for SSH access instead of exposing port 22 directly.
          - Implement OS Login with two-factor authentication for an additional layer of access control.
          - Regularly audit firewall rules for overly permissive source ranges.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To restrict SSH access to a specific IP range:

            ```hcl
            resource "google_compute_firewall" "allow_ssh" {
              name    = "allow-ssh-restricted"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["22"]
              }

              # Restrict to trusted IP ranges instead of 0.0.0.0/0
              source_ranges = ["10.0.0.0/8"]
            }
            ```

            Alternatively, use IAP for SSH access:

            ```hcl
            resource "google_compute_firewall" "allow_ssh_iap" {
              name    = "allow-ssh-iap"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["22"]
              }

              # IAP's IP range
              source_ranges = ["35.235.240.0/20"]
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Navigate to **VPC Network** > **Firewall**.
            3. Identify any firewall rules that allow TCP port 22 with a source range of 0.0.0.0/0 or ::/0.
            4. Select the rule and click **Edit**.
            5. Under **Source IPv4 ranges**, replace 0.0.0.0/0 with your trusted CIDR ranges.
            6. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update a firewall rule to restrict SSH access:

            ```bash
            gcloud compute firewall-rules update RULE_NAME \
              --source-ranges=TRUSTED_CIDR_RANGE
            ```

            For example, to restrict to a corporate VPN range:

            ```bash
            gcloud compute firewall-rules update allow-ssh \
              --source-ranges=10.0.0.0/8
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/firewalls
        title: VPC Firewall Rules
  - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-gcp
    filters: |
      asset.platform == 'gcp-compute-firewall'
      gcp.compute.firewall.direction == "INGRESS"
      gcp.compute.firewall.allowed.any(ipProtocol == "tcp" && _['ports'] == empty || ipProtocol == "tcp" && _['ports'].contains("22"))
    mql: |
      gcp.compute.firewall.sourceRanges.none(_ == "0.0.0.0/0")
      gcp.compute.firewall.sourceRanges.none(_ == "::/0")
  - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_firewall')
    mql: |
      terraform.resources('google_compute_firewall').where(
        arguments.direction == empty || arguments.direction == 'INGRESS'
      ).where(
        blocks.where(type == 'allow').any(arguments.protocol == 'tcp' && arguments.ports == empty || arguments.protocol == 'tcp' && arguments.ports.contains("22"))
      ).all(
        arguments.source_ranges.none(_ == '0.0.0.0/0') &&
        arguments.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_firewall')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_firewall').where(
        change.after.direction == empty || change.after.direction == 'INGRESS'
      ).where(
        change.after.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("22"))
      ).all(
        change.after.source_ranges.none(_ == '0.0.0.0/0') &&
        change.after.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-ssh-from-internet-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_firewall')
    mql: |
      terraform.state.resources.where(type == 'google_compute_firewall').where(
        values.direction == empty || values.direction == 'INGRESS'
      ).where(
        values.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("22"))
      ).all(
        values.source_ranges.none(_ == '0.0.0.0/0') &&
        values.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet
    title: Ensure RDP access is restricted from the internet
    impact: 80
    variants:
      - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-gcp
      - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-hcl
      - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-plan
      - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-state
    docs:
      desc: |
        This check ensures that GCP firewall rules do not allow unrestricted RDP access (TCP port 3389) from the entire internet (0.0.0.0/0 or ::/0). Firewall rules should restrict RDP access to specific trusted IP ranges to minimize exposure of Windows instances.

        **Why this matters**

        RDP provides full graphical remote desktop access to Windows instances. If a firewall rule allows RDP traffic from any IP address on the internet, it creates a critical exposure:
          - RDP is one of the most commonly targeted protocols in brute-force and credential-stuffing attacks.
          - Vulnerabilities in RDP implementations (such as BlueKeep) have been actively exploited for remote code execution.
          - Automated scanning tools continuously probe for open RDP ports, making exposed instances easy targets.

        If RDP access is not restricted to trusted IP ranges, it can lead to:
          - Unauthorized remote access to Windows instances, enabling ransomware deployment, data exfiltration, or lateral movement.
          - Exploitation of known RDP vulnerabilities, particularly on unpatched systems.
          - Non-compliance with security benchmarks such as CIS Google Cloud Platform Foundations Benchmark (Control 3.7), NIST 800-53, and PCI DSS.

        **Risk mitigation:**
          - Restrict source ranges in firewall rules to only known and trusted CIDR blocks (e.g., corporate VPN ranges, bastion host IPs).
          - Use Identity-Aware Proxy (IAP) for remote access instead of exposing port 3389 directly.
          - Deploy a VPN or bastion host architecture to provide a controlled entry point for RDP connections.
          - Regularly audit firewall rules for overly permissive source ranges.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            To restrict RDP access to a specific IP range:

            ```hcl
            resource "google_compute_firewall" "allow_rdp" {
              name    = "allow-rdp-restricted"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["3389"]
              }

              # Restrict to trusted IP ranges instead of 0.0.0.0/0
              source_ranges = ["10.0.0.0/8"]
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Navigate to **VPC Network** > **Firewall**.
            3. Identify any firewall rules that allow TCP port 3389 with a source range of 0.0.0.0/0 or ::/0.
            4. Select the rule and click **Edit**.
            5. Under **Source IPv4 ranges**, replace 0.0.0.0/0 with your trusted CIDR ranges.
            6. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update a firewall rule to restrict RDP access:

            ```bash
            gcloud compute firewall-rules update RULE_NAME \
              --source-ranges=TRUSTED_CIDR_RANGE
            ```

            For example, to restrict to a corporate VPN range:

            ```bash
            gcloud compute firewall-rules update allow-rdp \
              --source-ranges=10.0.0.0/8
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/firewalls
        title: VPC Firewall Rules
  - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-gcp
    filters: |
      asset.platform == 'gcp-compute-firewall'
      gcp.compute.firewall.direction == "INGRESS"
      gcp.compute.firewall.allowed.any(ipProtocol == "tcp" && _['ports'] == empty || ipProtocol == "tcp" && _['ports'].contains("3389"))
    mql: |
      gcp.compute.firewall.sourceRanges.none(_ == "0.0.0.0/0")
      gcp.compute.firewall.sourceRanges.none(_ == "::/0")
  - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_firewall')
    mql: |
      terraform.resources('google_compute_firewall').where(
        arguments.direction == empty || arguments.direction == 'INGRESS'
      ).where(
        blocks.where(type == 'allow').any(arguments.protocol == 'tcp' && arguments.ports == empty || arguments.protocol == 'tcp' && arguments.ports.contains("3389"))
      ).all(
        arguments.source_ranges.none(_ == '0.0.0.0/0') &&
        arguments.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_firewall')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_firewall').where(
        change.after.direction == empty || change.after.direction == 'INGRESS'
      ).where(
        change.after.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("3389"))
      ).all(
        change.after.source_ranges.none(_ == '0.0.0.0/0') &&
        change.after.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-rdp-from-internet-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_firewall')
    mql: |
      terraform.state.resources.where(type == 'google_compute_firewall').where(
        values.direction == empty || values.direction == 'INGRESS'
      ).where(
        values.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("3389"))
      ).all(
        values.source_ranges.none(_ == '0.0.0.0/0') &&
        values.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols
    title: Ensure firewall rules do not allow unrestricted ingress on all protocols
    impact: 90
    variants:
      - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-gcp
      - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-hcl
      - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-plan
      - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-state
    docs:
      desc: |
        This check ensures that GCP firewall rules do not allow unrestricted ingress traffic on all protocols and ports from the entire internet (0.0.0.0/0 or ::/0). Firewall rules that allow all traffic from any source create the broadest possible network exposure and should never be used in production environments.

        **Why this matters**

        A firewall rule that allows all protocols from 0.0.0.0/0 effectively disables network-level access control for all matching instances:
          - Every service running on the instance becomes reachable from the internet, regardless of whether it was intended to be exposed.
          - Internal services, debugging endpoints, management interfaces, and unpatched software all become potential attack vectors.
          - This configuration provides no defense-in-depth, meaning a single application vulnerability can lead to full compromise.

        If unrestricted ingress on all protocols is allowed, it can lead to:
          - Complete exposure of all network services, dramatically increasing the attack surface.
          - Exploitation of unintentionally exposed services such as databases, caches, or internal APIs.
          - Non-compliance with virtually all security frameworks including CIS Google Cloud Platform Foundations Benchmark, NIST 800-53, PCI DSS, and SOC 2.
          - Rapid compromise in the event of any service-level vulnerability.

        **Risk mitigation:**
          - Follow the principle of least privilege: only allow the specific protocols and ports required for each workload.
          - Restrict source ranges to known and trusted CIDR blocks.
          - Use separate firewall rules for each service with specific port allowances.
          - Regularly audit firewall rules and remove overly permissive configurations.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Instead of allowing all protocols, create targeted rules for specific services:

            ```hcl
            resource "google_compute_firewall" "allow_https" {
              name    = "allow-https"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["443"]
              }

              source_ranges = ["0.0.0.0/0"]
            }
            ```

            Remove or modify any rules that use `protocol = "all"` with `source_ranges = ["0.0.0.0/0"]`.
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Navigate to **VPC Network** > **Firewall**.
            3. Identify any firewall rules that allow all protocols with a source range of 0.0.0.0/0 or ::/0.
            4. Select the rule and click **Edit**.
            5. Change the **Protocols and ports** setting to specify only the required protocols and ports.
            6. Restrict the **Source IPv4 ranges** to trusted CIDR ranges where possible.
            7. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To delete an overly permissive firewall rule:

            ```bash
            gcloud compute firewall-rules delete RULE_NAME
            ```

            To create a replacement rule with specific protocols and ports:

            ```bash
            gcloud compute firewall-rules create RULE_NAME \
              --direction=INGRESS \
              --priority=1000 \
              --network=NETWORK_NAME \
              --action=ALLOW \
              --rules=tcp:443 \
              --source-ranges=TRUSTED_CIDR_RANGE
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/firewalls
        title: VPC Firewall Rules
  - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-gcp
    filters: |
      asset.platform == 'gcp-compute-firewall'
      gcp.compute.firewall.direction == "INGRESS"
      gcp.compute.firewall.allowed.any(ipProtocol == "all")
    mql: |
      gcp.compute.firewall.sourceRanges.none(_ == "0.0.0.0/0")
      gcp.compute.firewall.sourceRanges.none(_ == "::/0")
  - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_firewall')
    mql: |
      terraform.resources('google_compute_firewall').where(
        arguments.direction == empty || arguments.direction == 'INGRESS'
      ).where(
        blocks.where(type == 'allow').any(arguments.protocol == 'all')
      ).all(
        arguments.source_ranges.none(_ == '0.0.0.0/0') &&
        arguments.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_firewall')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_firewall').where(
        change.after.direction == empty || change.after.direction == 'INGRESS'
      ).where(
        change.after.allow.any(_['protocol'] == 'all')
      ).all(
        change.after.source_ranges.none(_ == '0.0.0.0/0') &&
        change.after.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-unrestricted-ingress-all-protocols-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_firewall')
    mql: |
      terraform.state.resources.where(type == 'google_compute_firewall').where(
        values.direction == empty || values.direction == 'INGRESS'
      ).where(
        values.allow.any(_['protocol'] == 'all')
      ).all(
        values.source_ranges.none(_ == '0.0.0.0/0') &&
        values.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet
    title: Ensure firewall rules do not allow ingress to database ports from the internet
    impact: 80
    variants:
      - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-gcp
      - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-hcl
      - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-plan
      - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-state
    docs:
      desc: |
        This check ensures that GCP firewall rules do not allow unrestricted ingress to common database ports from the entire internet (0.0.0.0/0 or ::/0). Database services should never be directly exposed to the internet, as they contain sensitive data and are frequent targets for automated attacks.

        The following database ports are checked:
          - **3306** (MySQL)
          - **5432** (PostgreSQL)
          - **1433** (Microsoft SQL Server)
          - **27017** (MongoDB)

        **Why this matters**

        Database services are designed to be accessed by application servers and administrators, not the general internet. Exposing database ports publicly creates severe risks:
          - Databases are high-value targets because they store sensitive data including credentials, personal information, and business-critical records.
          - Many database services have known default credentials or authentication bypass vulnerabilities that are trivially exploited when exposed.
          - Automated attack tools specifically scan for open database ports and attempt exploitation within minutes of discovery.

        If database ports are exposed to the internet, it can lead to:
          - Data breaches through direct database access, SQL injection, or credential attacks.
          - Ransomware attacks where attackers encrypt database contents and demand payment.
          - Non-compliance with data protection regulations including GDPR, HIPAA, PCI DSS, and SOC 2.
          - Complete loss of data confidentiality, integrity, and availability.

        **Risk mitigation:**
          - Restrict database firewall rules to only allow access from application server IP ranges or VPC-internal CIDR blocks.
          - Use Cloud SQL Auth Proxy or Private Service Connect for secure database connectivity.
          - Place databases in private subnets without public IP addresses.
          - Implement VPN or IAP tunnels for administrative database access.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Restrict database access to internal networks only:

            ```hcl
            resource "google_compute_firewall" "allow_mysql" {
              name    = "allow-mysql-internal"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["3306"]
              }

              # Only allow from internal application servers
              source_ranges = ["10.0.0.0/8"]
            }
            ```

            For Cloud SQL instances, prefer using Cloud SQL Auth Proxy or private IP connectivity instead of firewall rules.
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Navigate to **VPC Network** > **Firewall**.
            3. Identify any firewall rules that allow TCP ports 3306, 5432, 1433, or 27017 with a source range of 0.0.0.0/0 or ::/0.
            4. Select the rule and click **Edit**.
            5. Under **Source IPv4 ranges**, replace 0.0.0.0/0 with your internal network CIDR ranges (e.g., 10.0.0.0/8).
            6. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update a firewall rule to restrict database port access:

            ```bash
            gcloud compute firewall-rules update RULE_NAME \
              --source-ranges=INTERNAL_CIDR_RANGE
            ```

            For example, to restrict MySQL access to an internal network:

            ```bash
            gcloud compute firewall-rules update allow-mysql \
              --source-ranges=10.0.0.0/8
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/firewalls
        title: VPC Firewall Rules
  - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-gcp
    filters: |
      asset.platform == 'gcp-compute-firewall'
      gcp.compute.firewall.direction == "INGRESS"
      gcp.compute.firewall.allowed.any(ipProtocol == "tcp" && _['ports'] == empty || ipProtocol == "tcp" && _['ports'].contains("3306") || ipProtocol == "tcp" && _['ports'].contains("5432") || ipProtocol == "tcp" && _['ports'].contains("1433") || ipProtocol == "tcp" && _['ports'].contains("27017"))
    mql: |
      gcp.compute.firewall.sourceRanges.none(_ == "0.0.0.0/0")
      gcp.compute.firewall.sourceRanges.none(_ == "::/0")
  - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_firewall')
    mql: |
      terraform.resources('google_compute_firewall').where(
        arguments.direction == empty || arguments.direction == 'INGRESS'
      ).where(
        blocks.where(type == 'allow').any(arguments.protocol == 'tcp' && arguments.ports == empty || arguments.protocol == 'tcp' && arguments.ports.contains("3306") || arguments.protocol == 'tcp' && arguments.ports.contains("5432") || arguments.protocol == 'tcp' && arguments.ports.contains("1433") || arguments.protocol == 'tcp' && arguments.ports.contains("27017"))
      ).all(
        arguments.source_ranges.none(_ == '0.0.0.0/0') &&
        arguments.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_firewall')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_firewall').where(
        change.after.direction == empty || change.after.direction == 'INGRESS'
      ).where(
        change.after.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("3306") || _['protocol'] == 'tcp' && _['ports'].contains("5432") || _['protocol'] == 'tcp' && _['ports'].contains("1433") || _['protocol'] == 'tcp' && _['ports'].contains("27017"))
      ).all(
        change.after.source_ranges.none(_ == '0.0.0.0/0') &&
        change.after.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-ingress-database-ports-from-internet-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_firewall')
    mql: |
      terraform.state.resources.where(type == 'google_compute_firewall').where(
        values.direction == empty || values.direction == 'INGRESS'
      ).where(
        values.allow.any(_['protocol'] == 'tcp' && _['ports'] == empty || _['protocol'] == 'tcp' && _['ports'].contains("3306") || _['protocol'] == 'tcp' && _['ports'].contains("5432") || _['protocol'] == 'tcp' && _['ports'].contains("1433") || _['protocol'] == 'tcp' && _['ports'].contains("27017"))
      ).all(
        values.source_ranges.none(_ == '0.0.0.0/0') &&
        values.source_ranges.none(_ == '::/0')
      )
  - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress
    title: Ensure firewall rules do not allow ingress from the internet without port restrictions
    impact: 70
    variants:
      - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-gcp
      - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-hcl
      - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-plan
      - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-state
    docs:
      desc: |
        This check ensures that GCP firewall rules which allow ingress from the entire internet (0.0.0.0/0 or ::/0) specify explicit port restrictions. Firewall rules that allow traffic from the internet should always be scoped to the minimum required set of ports rather than leaving ports unrestricted.

        **Why this matters**

        A firewall rule that allows internet traffic on a specific protocol (e.g., TCP) without specifying ports effectively opens all 65,535 ports on that protocol to the internet:
          - Any service listening on any port becomes reachable, including internal tools, management interfaces, and development services that were never intended to be public.
          - This dramatically increases the attack surface and the likelihood of discovering exploitable services.
          - Changes to running services (e.g., starting a new process that listens on a port) immediately expose that service to the internet without any additional firewall change.

        If firewall rules allow internet ingress without port restrictions, it can lead to:
          - Unintentional exposure of sensitive services that happen to bind to a port.
          - Increased risk from service misconfigurations or vulnerabilities on any port.
          - Difficulty in maintaining a clear understanding of what is actually exposed.
          - Non-compliance with security best practices and frameworks that require least-privilege network access.

        **Risk mitigation:**
          - Always specify explicit port numbers in firewall allow rules.
          - Create separate firewall rules for each service with the minimum required ports.
          - Use network tags or service accounts to target rules to specific instances.
          - Regularly audit firewall rules to identify and remediate overly permissive configurations.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Always specify explicit ports in firewall allow rules:

            ```hcl
            resource "google_compute_firewall" "allow_web" {
              name    = "allow-web"
              network = google_compute_network.default.name

              allow {
                protocol = "tcp"
                ports    = ["80", "443"]  # Always specify explicit ports
              }

              source_ranges = ["0.0.0.0/0"]
            }
            ```

            Avoid configurations like this:

            ```hcl
            # BAD: No ports specified means all ports are open
            allow {
              protocol = "tcp"
              # Missing ports = all TCP ports allowed
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Log in to the GCP Console at https://console.cloud.google.com.
            2. Navigate to **VPC Network** > **Firewall**.
            3. Identify any firewall rules that allow traffic from 0.0.0.0/0 or ::/0 without specific port restrictions.
            4. Select the rule and click **Edit**.
            5. Under **Protocols and ports**, change from **Allow all** to **Specified protocols and ports**.
            6. Enter only the specific ports required (e.g., tcp:80,443).
            7. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            To update a firewall rule to specify explicit ports:

            ```bash
            gcloud compute firewall-rules update RULE_NAME \
              --rules=tcp:80,tcp:443
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/firewalls
        title: VPC Firewall Rules
  - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-gcp
    filters: |
      asset.platform == 'gcp-compute-firewall'
      gcp.compute.firewall.direction == "INGRESS"
      gcp.compute.firewall.sourceRanges.any(_ == "0.0.0.0/0" || _ == "::/0")
    mql: |
      gcp.compute.firewall.allowed.none(ipProtocol == "all")
      gcp.compute.firewall.allowed.all(_['ports'] != empty && _['ports'].length > 0)
  - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_firewall')
    mql: |
      terraform.resources('google_compute_firewall').where(
        arguments.direction == empty || arguments.direction == 'INGRESS'
      ).where(
        arguments.source_ranges.any(_ == '0.0.0.0/0' || _ == '::/0')
      ).all(
        blocks.where(type == 'allow').none(arguments.protocol == 'all') &&
        blocks.where(type == 'allow').all(arguments.ports != empty)
      )
  - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_compute_firewall')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_firewall').where(
        change.after.direction == empty || change.after.direction == 'INGRESS'
      ).where(
        change.after.source_ranges.any(_ == '0.0.0.0/0' || _ == '::/0')
      ).all(
        change.after.allow.none(_['protocol'] == 'all') &&
        change.after.allow.all(_['ports'] != empty && _['ports'].length > 0)
      )
  - uid: mondoo-gcp-security-firewall-no-overly-permissive-ingress-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_firewall')
    mql: |
      terraform.state.resources.where(type == 'google_compute_firewall').where(
        values.direction == empty || values.direction == 'INGRESS'
      ).where(
        values.source_ranges.any(_ == '0.0.0.0/0' || _ == '::/0')
      ).all(
        values.allow.none(_['protocol'] == 'all') &&
        values.allow.all(_['ports'] != empty && _['ports'].length > 0)
      )
  - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled
    title: Ensure legacy authorization (ABAC) is disabled on GKE clusters
    impact: 80
    variants:
      - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-gcp
      - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-plan
      - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-state
    docs:
      desc: |
        Attribute-Based Access Control (ABAC) is a legacy authorization mechanism in Kubernetes that has been superseded by Role-Based Access Control (RBAC). Legacy ABAC grants broad access permissions based on simple attribute matching, making it difficult to implement fine-grained access control.

        **Why this matters**

        Legacy ABAC authorization is less secure than RBAC and should be disabled:
          - ABAC policies are coarse-grained and cannot express the fine-grained permissions that RBAC provides.
          - With ABAC enabled, any authenticated user may have broader access to cluster resources than intended.
          - RBAC provides better audit trails and is the recommended authorization mode for all GKE clusters.
          - Compliance frameworks such as CIS GKE Benchmark require ABAC to be disabled.

        With legacy ABAC enabled:
          - Users may gain unintended access to cluster resources through overly permissive attribute-based policies.
          - It becomes difficult to audit and control who has access to what within the cluster.
          - The cluster does not meet security benchmarks and best practices.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Disable legacy ABAC in your GKE cluster configuration:

            ```hcl
            resource "google_container_cluster" "example" {
              name     = "example-cluster"
              location = "us-central1"

              # Disable legacy ABAC
              enable_legacy_abac = false
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Kubernetes Engine > Clusters** page.
            2. Select the cluster you want to configure.
            3. Click **Edit**.
            4. In the **Security** section, ensure **Legacy authorization** is disabled.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME --zone ZONE --no-enable-legacy-authorization
            ```
    refs:
      - url: https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
        title: GKE Security Overview
  - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-gcp
    filters: asset.platform == "gcp-gke-cluster"
    mql: gcp.project.gkeService.cluster.legacyAbac['enabled'] != true
  - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        arguments.enable_legacy_abac != true
      )
  - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after['enable_legacy_abac'] != true
      )
  - uid: mondoo-gcp-security-gke-cluster-legacy-abac-disabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values['enable_legacy_abac'] != true
      )
  - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled
    title: Ensure master authorized networks are enabled on GKE clusters
    impact: 70
    variants:
      - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-gcp
      - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-state
    docs:
      desc: |
        Master authorized networks restrict access to the GKE cluster's Kubernetes API server to specific trusted CIDR ranges. Without this configuration, the API server is accessible from any IP address, increasing the attack surface.

        **Why this matters**

        The Kubernetes API server is the central control plane for the cluster. Unrestricted access creates significant security risks:
          - Attackers who obtain valid credentials can access the API server from any location on the internet.
          - Brute-force and credential-stuffing attacks against the API server are possible from any IP address.
          - Restricting API access to known networks (corporate VPNs, bastion hosts) reduces the attack surface significantly.
          - CIS GKE Benchmark and other security frameworks require master authorized networks to be configured.

        Without master authorized networks:
          - The Kubernetes API server is exposed to the entire internet.
          - Any compromised credential can be used from any location to manage the cluster.
          - Security audits will flag the cluster as non-compliant.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Enable master authorized networks in your GKE cluster configuration:

            ```hcl
            resource "google_container_cluster" "example" {
              name     = "example-cluster"
              location = "us-central1"

              master_authorized_networks_config {
                cidr_blocks {
                  cidr_block   = "10.0.0.0/8"
                  display_name = "Corporate network"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Kubernetes Engine > Clusters** page.
            2. Select the cluster you want to configure.
            3. Click **Edit**.
            4. In the **Networking** section, enable **Control plane authorized networks**.
            5. Add the CIDR blocks for authorized networks.
            6. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME --zone ZONE --enable-master-authorized-networks --master-authorized-networks CIDR1,CIDR2
            ```
    refs:
      - url: https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
        title: GKE Security Overview
  - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-gcp
    filters: asset.platform == "gcp-gke-cluster"
    mql: gcp.project.gkeService.cluster.masterAuthorizedNetworksConfig['enabled'] == true
  - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'master_authorized_networks_config') != empty
      )
  - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after['master_authorized_networks_config'] != empty
      )
  - uid: mondoo-gcp-security-gke-cluster-master-authorized-networks-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values['master_authorized_networks_config'] != empty
      )
  - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled
    title: Ensure Stackdriver Kubernetes Engine Monitoring is enabled on GKE clusters
    impact: 70
    variants:
      - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-gcp
      - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-state
    docs:
      desc: |
        GKE clusters should use Cloud Logging (formerly Stackdriver Logging) for centralized log management. When properly configured, the logging service captures system and workload logs from the cluster, providing visibility into cluster operations and security events.

        **Why this matters**

        Cloud Logging integration is essential for GKE cluster security and operations:
          - Cluster logs provide critical visibility into API server activity, authentication events, and resource modifications.
          - Security incident investigation requires comprehensive logging to identify the scope and impact of a breach.
          - Compliance frameworks require centralized logging for audit trails and forensic analysis.
          - Without proper logging, suspicious activity in the cluster may go undetected.

        Without Cloud Logging enabled:
          - Security events and anomalies in the cluster cannot be detected or investigated.
          - Compliance requirements for centralized logging and audit trails cannot be met.
          - Operational issues are harder to diagnose without comprehensive log data.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Enable Cloud Logging in your GKE cluster configuration:

            ```hcl
            resource "google_container_cluster" "example" {
              name     = "example-cluster"
              location = "us-central1"

              logging_service = "logging.googleapis.com/kubernetes"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Kubernetes Engine > Clusters** page.
            2. Select the cluster you want to configure.
            3. Click **Edit**.
            4. In the **Features** section, ensure **Cloud Logging** is enabled with **System and workload logging**.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME --zone ZONE --logging=SYSTEM,WORKLOAD
            ```
    refs:
      - url: https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
        title: GKE Security Overview
  - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-gcp
    filters: asset.platform == "gcp-gke-cluster"
    mql: gcp.project.gkeService.cluster.loggingService == "logging.googleapis.com/kubernetes"
  - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        arguments.logging_service == empty || arguments.logging_service == "logging.googleapis.com/kubernetes"
      )
  - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after['logging_service'] == empty || change.after['logging_service'] == "logging.googleapis.com/kubernetes"
      )
  - uid: mondoo-gcp-security-gke-cluster-stackdriver-logging-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values['logging_service'] == empty || values['logging_service'] == "logging.googleapis.com/kubernetes"
      )
  - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled
    title: Ensure network policy is enabled on GKE clusters
    impact: 70
    variants:
      - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-gcp
      - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-state
    docs:
      desc: |
        Kubernetes network policies control traffic flow between pods and between pods and external endpoints. Without network policies, all pods in a cluster can communicate freely with each other, which violates the principle of least privilege and increases the blast radius of a compromised pod.

        **Why this matters**

        Enabling network policy enforcement on GKE clusters is critical for microsegmentation:
          - By default, all pods in a Kubernetes cluster can communicate with all other pods without restriction.
          - A compromised pod can be used to move laterally to other pods and services in the cluster.
          - Network policies enable microsegmentation, allowing only the traffic flows that are explicitly needed.
          - CIS GKE Benchmark and security best practices require network policy enforcement to be enabled.

        Without network policy enforcement:
          - All pod-to-pod communication is unrestricted, increasing lateral movement risk.
          - Sensitive workloads cannot be isolated from less trusted workloads within the same cluster.
          - The cluster cannot enforce zero-trust networking principles.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Enable network policy in your GKE cluster configuration:

            ```hcl
            resource "google_container_cluster" "example" {
              name     = "example-cluster"
              location = "us-central1"

              network_policy {
                enabled  = true
                provider = "CALICO"
              }

              addons_config {
                network_policy_config {
                  disabled = false
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **Kubernetes Engine > Clusters** page.
            2. Select the cluster you want to configure.
            3. Click **Edit**.
            4. In the **Networking** section, enable **Network policy enforcement**.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME --zone ZONE --update-addons=NetworkPolicy=ENABLED
            gcloud container clusters update CLUSTER_NAME --zone ZONE --enable-network-policy
            ```
    refs:
      - url: https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
        title: GKE Security Overview
  - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-gcp
    filters: asset.platform == "gcp-gke-cluster"
    mql: gcp.project.gkeService.cluster.addonsConfig.networkPolicyConfig['disabled'] != true
  - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'network_policy').any(arguments.enabled == true)
      )
  - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after['network_policy'] != empty &&
        change.after['network_policy'].any(_['enabled'] == true)
      )
  - uid: mondoo-gcp-security-gke-cluster-network-policy-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values['network_policy'] != empty &&
        values['network_policy'].any(_['enabled'] == true)
      )
  - uid: mondoo-gcp-security-gke-cluster-alpha-disabled
    title: Ensure Kubernetes alpha features are disabled on GKE clusters
    impact: 60
    variants:
      - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-gcp
      - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-plan
      - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-state
    docs:
      desc: |
        Kubernetes alpha features are experimental and may change or be removed in future releases. Alpha clusters are not covered by GKE SLA, cannot be upgraded, and will be automatically deleted after 30 days. Enabling alpha features on production clusters introduces instability and security risks.

        **Why this matters**

        Alpha features should not be enabled on production GKE clusters:
          - Alpha features are not thoroughly tested and may contain bugs or security vulnerabilities.
          - Alpha clusters cannot be upgraded to newer Kubernetes versions, preventing the application of security patches.
          - Alpha clusters are automatically deleted after 30 days, making them unsuitable for persistent workloads.
          - Alpha APIs may not have the same security controls and audit logging as stable APIs.

        With alpha features enabled:
          - The cluster may be exposed to unpatched vulnerabilities in experimental code.
          - The cluster cannot receive security updates through version upgrades.
          - Workloads are at risk of being deleted when the alpha cluster expires.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure alpha features are not enabled in your GKE cluster configuration:

            ```hcl
            resource "google_container_cluster" "example" {
              name     = "example-cluster"
              location = "us-central1"

              # Do not set enable_kubernetes_alpha = true
            }
            ```

            Note: Alpha features cannot be disabled on an existing cluster. You must create a new cluster without alpha features and migrate your workloads.
        - id: console
          desc: |
            **Using Google Cloud Console**

            Alpha features cannot be disabled on an existing cluster. To remediate:

            1. Create a new GKE cluster without alpha features enabled.
            2. Migrate your workloads to the new cluster.
            3. Delete the alpha cluster.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Alpha features cannot be disabled on an existing cluster. Create a new cluster without the `--enable-kubernetes-alpha` flag:

            ```bash
            gcloud container clusters create CLUSTER_NAME --zone ZONE
            ```
    refs:
      - url: https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
        title: GKE Security Overview
  - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-gcp
    filters: asset.platform == "gcp-gke-cluster"
    mql: gcp.project.gkeService.cluster.enableKubernetesAlpha == false
  - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        arguments.enable_kubernetes_alpha != true
      )
  - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after['enable_kubernetes_alpha'] != true
      )
  - uid: mondoo-gcp-security-gke-cluster-alpha-disabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values['enable_kubernetes_alpha'] != true
      )
  - uid: mondoo-gcp-security-gke-workload-identity-enabled
    title: Ensure Workload Identity is enabled on GKE clusters
    impact: 85
    variants:
      - uid: mondoo-gcp-security-gke-workload-identity-enabled-gcp
      - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Workload Identity is enabled on Google Kubernetes Engine (GKE) clusters. Workload Identity is the recommended way for workloads running on GKE to access Google Cloud services securely, replacing the need for node-level service account keys or metadata server access.

        **Why this matters**

        Without Workload Identity, pods on a GKE cluster may access Google Cloud APIs using the node's service account via the metadata server. This creates several security risks:
          -  All pods on a node share the same Google Cloud identity, violating the principle of least privilege.
          -  Compromised pods can access the metadata server to obtain credentials with broad permissions.
          -  Managing and rotating service account keys becomes complex and error-prone.

        Workload Identity maps Kubernetes service accounts to Google Cloud IAM service accounts, enabling:
          -  Fine-grained, per-pod identity and access control to Google Cloud services.
          -  Elimination of service account key management.
          -  Protection of the node metadata server from unauthorized pod access.

        **Risk mitigation:**
          -  Enable Workload Identity at the cluster level and configure Kubernetes service accounts to use Google Cloud IAM service accounts.
          -  Remove any exported service account keys that are no longer needed.
          -  Regularly audit the IAM bindings between Kubernetes and Google Cloud service accounts.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_container_cluster" "primary" {
              name     = "my-cluster"
              location = "us-central1"

              workload_identity_config {
                workload_pool = "${var.project_id}.svc.id.goog"
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Kubernetes Engine > Clusters** page in the Google Cloud Console.
            2. Select the cluster you want to update.
            3. Select **Security**.
            4. In the **Workload Identity** section, select **Edit**.
            5. Enable **Workload Identity** and specify the workload pool.
            6. Select **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME \
              --workload-pool=PROJECT_ID.svc.id.goog \
              --zone ZONE
            ```
    refs:
      - title: GKE Workload Identity documentation
        url: https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
  - uid: mondoo-gcp-security-gke-workload-identity-enabled-gcp
    filters: asset.platform == 'gcp-gke-cluster'
    mql: |
      gcp.project.gkeService.cluster.workloadIdentityConfig['workloadPool'] != null
      gcp.project.gkeService.cluster.workloadIdentityConfig['workloadPool'] != ""
  - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'workload_identity_config') != empty
      )
  - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after.workload_identity_config != null &&
        change.after.workload_identity_config != empty
      )
  - uid: mondoo-gcp-security-gke-workload-identity-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values.workload_identity_config != null &&
        values.workload_identity_config != empty
      )
  - uid: mondoo-gcp-security-gke-private-cluster-enabled
    title: Ensure private cluster is enabled on GKE clusters
    impact: 85
    variants:
      - uid: mondoo-gcp-security-gke-private-cluster-enabled-gcp
      - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-state
    docs:
      desc: |
        This check ensures that GKE clusters are configured as private clusters, where nodes only have internal IP addresses and are isolated from the public internet. Private clusters reduce the attack surface by preventing direct internet access to cluster nodes.

        **Why this matters**

        By default, GKE cluster nodes are assigned both internal and external IP addresses, making them accessible from the internet:
          -  Public nodes are exposed to network-based attacks including port scanning, exploitation of node-level vulnerabilities, and unauthorized access.
          -  Attackers who compromise a publicly accessible node can potentially pivot to other resources in the cluster or VPC.
          -  Data exfiltration is easier when nodes have direct internet access.

        Private clusters provide:
          -  Nodes with only internal IP addresses, reducing the external attack surface.
          -  Controlled egress through Cloud NAT or other managed gateways.
          -  Better compliance with network segmentation requirements.

        **Risk mitigation:**
          -  Enable private nodes when creating or updating GKE clusters.
          -  Use Cloud NAT for outbound internet access when needed.
          -  Configure master authorized networks to restrict access to the control plane.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_container_cluster" "primary" {
              name     = "my-cluster"
              location = "us-central1"

              private_cluster_config {
                enable_private_nodes    = true
                enable_private_endpoint = false
                master_ipv4_cidr_block  = "172.16.0.0/28"
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            Note: Private cluster configuration cannot be changed on an existing cluster. You must create a new cluster:

            1. Go to the **Kubernetes Engine > Clusters** page in the Google Cloud Console.
            2. Select **Create**.
            3. In the **Networking** section, select **Private cluster**.
            4. Enable **Access control plane using its external IP address** if needed.
            5. Configure the **Control plane IP range**.
            6. Complete the cluster creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters create CLUSTER_NAME \
              --enable-private-nodes \
              --master-ipv4-cidr=172.16.0.0/28 \
              --zone ZONE
            ```
    refs:
      - title: GKE Private cluster documentation
        url: https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters
  - uid: mondoo-gcp-security-gke-private-cluster-enabled-gcp
    filters: asset.platform == 'gcp-gke-cluster'
    mql: |
      gcp.project.gkeService.cluster.privateClusterConfig['enablePrivateNodes'] == true
  - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'private_cluster_config').any(arguments.enable_private_nodes == true)
      )
  - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after.private_cluster_config != null &&
        change.after.private_cluster_config.any(_['enable_private_nodes'] == true)
      )
  - uid: mondoo-gcp-security-gke-private-cluster-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values.private_cluster_config != null &&
        values.private_cluster_config.any(_['enable_private_nodes'] == true)
      )
  - uid: mondoo-gcp-security-gke-shielded-nodes-enabled
    title: Ensure shielded GKE nodes are enabled
    impact: 80
    variants:
      - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-gcp
      - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-hcl
      - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-plan
      - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Shielded GKE Nodes are enabled on GKE clusters. Shielded Nodes provide verifiable node identity and integrity, protecting against boot-level and kernel-level attacks on cluster nodes.

        **Why this matters**

        Without Shielded Nodes, GKE cluster nodes are vulnerable to:
          -  Boot-level rootkits and bootkits that can persist across reboots and compromise the node before the operating system loads.
          -  Kernel-level malware that can manipulate the node's operating system.
          -  Node identity spoofing, where an attacker impersonates a legitimate node to join the cluster.

        Shielded Nodes provide:
          -  Secure Boot, which ensures only trusted software runs during the boot process.
          -  Virtual Trusted Platform Module (vTPM) for measured boot and node integrity verification.
          -  Integrity monitoring to detect unauthorized changes to the node's boot sequence.

        **Risk mitigation:**
          -  Enable Shielded Nodes on all GKE clusters.
          -  Monitor integrity validation failures through Cloud Logging.
          -  Use Shielded Nodes in combination with Binary Authorization for defense-in-depth.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_container_cluster" "primary" {
              name     = "my-cluster"
              location = "us-central1"

              node_config {
                shielded_instance_config {
                  enable_secure_boot          = true
                  enable_integrity_monitoring = true
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Kubernetes Engine > Clusters** page in the Google Cloud Console.
            2. Select the cluster you want to update.
            3. Select **Security**.
            4. Ensure that **Shielded GKE Nodes** is enabled.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME \
              --enable-shielded-nodes \
              --zone ZONE
            ```
    refs:
      - title: GKE Shielded Nodes documentation
        url: https://cloud.google.com/kubernetes-engine/docs/how-to/shielded-gke-nodes
  - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-gcp
    filters: asset.platform == 'gcp-gke-cluster'
    mql: |
      gcp.project.gkeService.cluster.shieldedNodesConfig['enabled'] == true
  - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'node_config').any(
          blocks.where(type == 'shielded_instance_config').any(
            arguments.enable_secure_boot == true && arguments.enable_integrity_monitoring == true
          )
        )
      )
  - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after.node_config != null &&
        change.after.node_config.any(
          _['shielded_instance_config'] != null &&
          _['shielded_instance_config'].any(_['enable_secure_boot'] == true && _['enable_integrity_monitoring'] == true)
        )
      )
  - uid: mondoo-gcp-security-gke-shielded-nodes-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values.node_config != null &&
        values.node_config.any(
          _['shielded_instance_config'] != null &&
          _['shielded_instance_config'].any(_['enable_secure_boot'] == true && _['enable_integrity_monitoring'] == true)
        )
      )
  - uid: mondoo-gcp-security-gke-release-channel-configured
    title: Ensure GKE clusters use a release channel for version management
    impact: 60
    variants:
      - uid: mondoo-gcp-security-gke-release-channel-configured-gcp
      - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-hcl
      - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-plan
      - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-state
    docs:
      desc: |
        This check ensures that GKE clusters are subscribed to a release channel (Regular, Rapid, or Stable) for automated version management. Release channels ensure clusters receive automatic upgrades with security patches and bug fixes.

        **Why this matters**

        Clusters not enrolled in a release channel require manual version management, which increases the risk of running outdated or vulnerable versions:
          -  Security patches may not be applied promptly, leaving clusters vulnerable to known exploits.
          -  Manual upgrades are error-prone and may be deferred indefinitely.
          -  Without a release channel, clusters do not benefit from Google's tested and validated upgrade paths.

        Release channels provide:
          -  Automatic upgrades with versions that have been validated and tested by Google.
          -  Timely application of security patches and bug fixes.
          -  Predictable upgrade cadence based on the chosen channel (Rapid, Regular, or Stable).

        **Risk mitigation:**
          -  Enroll all GKE clusters in an appropriate release channel based on workload requirements.
          -  Use the Regular channel for production workloads that need a balance between new features and stability.
          -  Use maintenance windows to control when upgrades are applied.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_container_cluster" "primary" {
              name     = "my-cluster"
              location = "us-central1"

              release_channel {
                channel = "REGULAR"
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Kubernetes Engine > Clusters** page in the Google Cloud Console.
            2. Select the cluster you want to update.
            3. Select **Cluster basics**.
            4. Under **Release channel**, select **Edit**.
            5. Choose a release channel (Rapid, Regular, or Stable).
            6. Select **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud container clusters update CLUSTER_NAME \
              --release-channel=regular \
              --zone ZONE
            ```
    refs:
      - title: GKE Release channels documentation
        url: https://cloud.google.com/kubernetes-engine/docs/concepts/release-channels
  - uid: mondoo-gcp-security-gke-release-channel-configured-gcp
    filters: asset.platform == 'gcp-gke-cluster'
    mql: |
      gcp.project.gkeService.cluster.releaseChannel != ""
      gcp.project.gkeService.cluster.releaseChannel != "unspecified"
  - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_container_cluster')
    mql: |
      terraform.resources('google_container_cluster').all(
        blocks.where(type == 'release_channel') != empty &&
        blocks.where(type == 'release_channel').all(arguments.channel != "UNSPECIFIED")
      )
  - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_container_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_container_cluster').all(
        change.after.release_channel != null &&
        change.after.release_channel != empty &&
        change.after.release_channel.all(_['channel'] != "UNSPECIFIED")
      )
  - uid: mondoo-gcp-security-gke-release-channel-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_container_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_container_cluster').all(
        values.release_channel != null &&
        values.release_channel != empty &&
        values.release_channel.all(_['channel'] != "UNSPECIFIED")
      )
  - uid: mondoo-gcp-security-compute-network-not-legacy
    title: Ensure legacy networks do not exist in the project
    impact: 70
    variants:
      - uid: mondoo-gcp-security-compute-network-not-legacy-gcp
      - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-hcl
      - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-plan
      - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-state
    docs:
      desc: |
        Legacy networks are a single, flat network that spans the entire project and do not support subnets. Legacy networks lack modern networking features including VPC Flow Logs, Private Google Access, and fine-grained firewall rules that operate at the subnet level.

        **Why this matters**

        Legacy networks should not be used for the following reasons:
          - Legacy networks apply firewall rules at the network level rather than the subnet level, making it impossible to implement fine-grained network segmentation.
          - VPC Flow Logs, which are critical for security monitoring and forensic analysis, are not available on legacy networks.
          - Private Google Access, which allows VMs without external IPs to reach Google APIs, is not supported on legacy networks.
          - Legacy networks cannot be converted to VPC networks and must be recreated.

        Using legacy networks:
          - Prevents implementation of subnet-level security controls and network segmentation.
          - Eliminates the ability to monitor network traffic through VPC Flow Logs.
          - Forces all instances into a flat network, increasing the blast radius of any security incident.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Always create VPC networks in custom subnet mode:

            ```hcl
            resource "google_compute_network" "example" {
              name                    = "example-network"
              auto_create_subnetworks = false  # custom subnet mode
            }
            ```

            Note: To migrate from a legacy network, create a new VPC network, migrate resources, and then delete the legacy network.
        - id: console
          desc: |
            **Using Google Cloud Console**

            Legacy networks cannot be converted to VPC networks. To remediate:

            1. Create a new VPC network in custom mode.
            2. Create subnets in the regions you need.
            3. Migrate VMs and other resources to the new network.
            4. Update firewall rules for the new network.
            5. Delete the legacy network.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Create a new VPC network in custom mode and migrate resources:

            ```bash
            # Create a new VPC network
            gcloud compute networks create NEW_NETWORK_NAME --subnet-mode=custom

            # Create subnets
            gcloud compute networks subnets create SUBNET_NAME --network=NEW_NETWORK_NAME --region=REGION --range=CIDR_RANGE
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/vpc
        title: Google Cloud VPC Documentation
  - uid: mondoo-gcp-security-compute-network-not-legacy-gcp
    filters: asset.platform == "gcp-compute-network"
    mql: gcp.compute.network.mode != "legacy"
  - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_compute_network')
    mql: |
      terraform.resources('google_compute_network').all(
        arguments.auto_create_subnetworks != empty
      )
  - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_compute_network')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_network').all(
        change.after['auto_create_subnetworks'] != empty
      )
  - uid: mondoo-gcp-security-compute-network-not-legacy-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_compute_network')
    mql: |
      terraform.state.resources.where(type == 'google_compute_network').all(
        values['auto_create_subnetworks'] != empty
      )
  - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled
    title: Ensure VPC Flow Logs are enabled on subnetworks
    impact: 70
    variants:
      - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-gcp
      - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-state
    docs:
      desc: |
        VPC Flow Logs record a sample of network flows sent from and received by VM instances, including traffic between VMs in the same VPC. Flow logs can be used for network monitoring, forensic analysis, real-time security analysis, and expense optimization.

        **Why this matters**

        VPC Flow Logs are essential for network security monitoring and incident response:
          - Flow logs provide visibility into network traffic patterns, enabling detection of anomalous communication between resources.
          - Security teams can use flow logs for forensic analysis during incident investigation to understand the scope and timeline of a breach.
          - Network-level threats such as data exfiltration, lateral movement, and command-and-control traffic can be identified through flow log analysis.
          - Compliance frameworks such as CIS GCP Benchmark, PCI DSS, and NIST 800-53 require network traffic logging.

        Without VPC Flow Logs:
          - Network-level security incidents may go undetected.
          - Forensic investigation of security breaches lacks critical network traffic data.
          - The organization cannot meet compliance requirements for network traffic monitoring.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Enable VPC Flow Logs on subnetworks:

            ```hcl
            resource "google_compute_subnetwork" "example" {
              name          = "example-subnet"
              ip_cidr_range = "10.0.0.0/24"
              region        = "us-central1"
              network       = google_compute_network.example.id

              log_config {
                aggregation_interval = "INTERVAL_5_SEC"
                flow_sampling        = 0.5
                metadata             = "INCLUDE_ALL_METADATA"
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **VPC network > VPC networks** page.
            2. Select the network containing the subnet.
            3. Select the subnet you want to configure.
            4. Click **Edit**.
            5. Under **Flow logs**, select **On**.
            6. Configure the aggregation interval, sampling rate, and metadata settings.
            7. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud compute networks subnets update SUBNET_NAME --region=REGION --enable-flow-logs --logging-aggregation-interval=interval-5-sec --logging-flow-sampling=0.5 --logging-metadata=include-all
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/vpc
        title: Google Cloud VPC Documentation
  - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-gcp
    filters: asset.platform == "gcp-compute-subnetwork"
    mql: gcp.compute.subnetwork.enableFlowLogs == true
  - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_compute_subnetwork')
    mql: |
      terraform.resources('google_compute_subnetwork').all(
        blocks.where(type == 'log_config') != empty
      )
  - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_compute_subnetwork')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_subnetwork').all(
        change.after['log_config'] != empty
      )
  - uid: mondoo-gcp-security-compute-subnetwork-flow-logs-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_compute_subnetwork')
    mql: |
      terraform.state.resources.where(type == 'google_compute_subnetwork').all(
        values['log_config'] != empty
      )
  - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled
    title: Ensure Private Google Access is enabled on subnetworks
    impact: 60
    variants:
      - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-gcp
      - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-state
    docs:
      desc: |
        Private Google Access enables VM instances on a subnet to reach Google APIs and services using an internal IP address rather than an external IP address. This allows VMs without external IPs to access services like Cloud Storage, BigQuery, and other Google Cloud APIs.

        **Why this matters**

        Private Google Access reduces the need for external IP addresses and improves security:
          - VMs can access Google APIs without requiring external IP addresses, reducing the attack surface by eliminating direct internet connectivity.
          - Data transfer between VMs and Google services stays within Google's network, reducing exposure to network-level threats.
          - It enables a more secure network architecture where only essential resources have external IPs.
          - Compliance frameworks recommend minimizing the number of resources with external IP addresses.

        Without Private Google Access:
          - VMs that need to access Google APIs require external IP addresses, increasing the attack surface.
          - Network traffic to Google services must traverse the public internet rather than staying within Google's network.
          - It becomes harder to implement a zero-trust network architecture.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Enable Private Google Access on subnetworks:

            ```hcl
            resource "google_compute_subnetwork" "example" {
              name                     = "example-subnet"
              ip_cidr_range            = "10.0.0.0/24"
              region                   = "us-central1"
              network                  = google_compute_network.example.id
              private_ip_google_access = true
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. In the Google Cloud console, go to the **VPC network > VPC networks** page.
            2. Select the network containing the subnet.
            3. Select the subnet you want to configure.
            4. Click **Edit**.
            5. Under **Private Google Access**, select **On**.
            6. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud compute networks subnets update SUBNET_NAME --region=REGION --enable-private-ip-google-access
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/vpc
        title: Google Cloud VPC Documentation
  - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-gcp
    filters: asset.platform == "gcp-compute-subnetwork"
    mql: gcp.compute.subnetwork.privateIpGoogleAccess == true
  - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.contains(nameLabel == 'google_compute_subnetwork')
    mql: |
      terraform.resources('google_compute_subnetwork').all(
        arguments.private_ip_google_access == true
      )
  - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_compute_subnetwork')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_subnetwork').all(
        change.after['private_ip_google_access'] == true
      )
  - uid: mondoo-gcp-security-compute-subnetwork-private-google-access-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_compute_subnetwork')
    mql: |
      terraform.state.resources.where(type == 'google_compute_subnetwork').all(
        values['private_ip_google_access'] == true
      )
  - uid: mondoo-gcp-security-cloud-redis-auth-enabled
    title: Ensure authentication is enabled for Cloud Redis instances
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-redis-auth-enabled-memorystore-redis
      - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Redis AUTH is enabled on Cloud Memorystore for Redis instances. Redis AUTH requires clients to authenticate with a password before executing commands, providing an additional layer of security beyond network-level access controls.

        **Why this matters**

        Without AUTH enabled, any client that can reach the Redis instance over the network can execute any Redis command without authentication:
          •  Unauthorized clients can read, modify, or delete cached data.
          •  Attackers with network access can use Redis commands for data exfiltration or to disrupt service availability.
          •  Redis instances without authentication are a common target in cloud environments.

        Enabling AUTH provides:
          •  Client-level authentication as an additional security control beyond VPC and firewall rules.
          •  Protection against unauthorized data access from compromised workloads within the same network.
          •  Better alignment with defense-in-depth security principles.

        **Risk mitigation:**
          •  Enable AUTH on all Cloud Redis instances.
          •  Store the AUTH string securely using Secret Manager.
          •  Rotate AUTH strings regularly.
          •  Combine AUTH with VPC network isolation for defense-in-depth.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_redis_instance" "cache" {
              name           = "my-redis-instance"
              tier           = "STANDARD_HA"
              memory_size_gb = 1
              region         = "us-central1"

              auth_enabled = true
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Memorystore > Redis** page in the Google Cloud Console.
            2. Select the instance you want to update.
            3. Select **Edit**.
            4. Enable **AUTH**.
            5. Select **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud redis instances update INSTANCE_NAME \
              --enable-auth \
              --region=REGION
            ```
    refs:
      - title: Cloud Memorystore Redis AUTH documentation
        url: https://cloud.google.com/memorystore/docs/redis/auth-overview
  - uid: mondoo-gcp-security-cloud-redis-auth-enabled-memorystore-redis
    filters: asset.platform == "gcp-memorystore-redis"
    mql: |
      gcp.project.redisService.instance.authEnabled == true
  - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_redis_instance')
    mql: |
      terraform.resources('google_redis_instance').all(
        arguments.auth_enabled == true
      )
  - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_redis_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_redis_instance').all(
        change.after.auth_enabled == true
      )
  - uid: mondoo-gcp-security-cloud-redis-auth-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_redis_instance')
    mql: |
      terraform.state.resources.where(type == 'google_redis_instance').all(
        values.auth_enabled == true
      )
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured
    title: Ensure customer-managed encryption keys (CMEK) are configured for Cloud Redis instances
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-redis-cmek-configured-memorystore-redis
      - uid: mondoo-gcp-security-cloud-redis-cmek-configured-memorystore-rediscluster
      - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-hcl
      - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-plan
      - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Memorystore for Redis instances are encrypted using customer-managed encryption keys (CMEK) rather than default Google-managed keys. CMEK gives organizations full control over the encryption key lifecycle, including rotation, access policies, and the ability to revoke access by disabling or destroying keys.

        **Why this matters**

        By default, Google Cloud encrypts data at rest using Google-managed encryption keys. While this provides baseline protection, it does not give organizations control over key management:
          -  Google-managed keys cannot be independently rotated on a custom schedule.
          -  Organizations cannot revoke access to encrypted data by destroying or disabling the key.
          -  Audit logs for key usage are not available with Google-managed keys.
          -  Compliance frameworks such as PCI-DSS, HIPAA, and SOC 2 may require customer-managed encryption for sensitive data stores.

        CMEK provides:
          -  Full control over encryption key lifecycle, including creation, rotation, and destruction.
          -  Ability to revoke access to Redis data by disabling or destroying the encryption key.
          -  Cloud Audit Logs for all key usage, enabling monitoring and compliance reporting.
          -  Separation of duties between data administrators and key administrators.

        **Risk mitigation:**
          -  Configure CMEK for all Cloud Redis instances that store sensitive data.
          -  Use Cloud KMS to manage encryption keys with appropriate IAM policies.
          -  Enable automatic key rotation on a schedule that meets compliance requirements.
          -  Monitor key usage through Cloud Audit Logs.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_redis_instance" "cache" {
              name           = "my-redis-instance"
              tier           = "STANDARD_HA"
              memory_size_gb = 1
              region         = "us-central1"

              customer_managed_key = google_kms_crypto_key.redis_key.id
            }

            resource "google_kms_crypto_key" "redis_key" {
              name     = "redis-encryption-key"
              key_ring = google_kms_key_ring.redis_ring.id
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            Note: CMEK must be configured at instance creation time and cannot be added to an existing instance.

            1. Go to the **Memorystore > Redis** page in the Google Cloud Console.
            2. Select **Create Instance**.
            3. In the **Encryption** section, select **Customer-managed key**.
            4. Select or create a Cloud KMS key.
            5. Complete the instance creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Note: CMEK must be configured at instance creation time.

            ```bash
            gcloud redis instances create INSTANCE_NAME \
              --region=REGION \
              --tier=STANDARD_HA \
              --size=1 \
              --customer-managed-key=projects/PROJECT/locations/LOCATION/keyRings/RING/cryptoKeys/KEY
            ```
    refs:
      - title: Cloud Memorystore Redis CMEK documentation
        url: https://cloud.google.com/memorystore/docs/redis/about-cmek
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured-memorystore-redis
    filters: asset.platform == "gcp-memorystore-redis"
    mql: |
      gcp.project.redisService.instance.customerManagedKey != ""
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured-memorystore-rediscluster
    filters: asset.platform == "gcp-memorystore-rediscluster"
    mql: |
      gcp.project.redisService.cluster.kmsKey != ""
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_redis_instance')
    mql: |
      terraform.resources('google_redis_instance').all(
        arguments.customer_managed_key != null &&
        arguments.customer_managed_key != ""
      )
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_redis_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_redis_instance').all(
        change.after.customer_managed_key != null &&
        change.after.customer_managed_key != ""
      )
  - uid: mondoo-gcp-security-cloud-redis-cmek-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_redis_instance')
    mql: |
      terraform.state.resources.where(type == 'google_redis_instance').all(
        values.customer_managed_key != null &&
        values.customer_managed_key != ""
      )
  # ============================================================================
  # Cloud IAM Checks
  # ============================================================================
  - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys
    title: Ensure user-managed service account keys are not created
    impact: 80
    variants:
      - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-gcp
      - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-hcl
      - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-plan
      - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-state
    docs:
      desc: |
        This check ensures that user-managed service account keys are not created in the Google Cloud project. User-managed keys are a significant security risk because they can be leaked, are difficult to track, and do not expire by default. Google-managed keys or Workload Identity Federation should be used instead.

        **Why this matters**

        User-managed service account keys are long-lived credentials that are stored outside of Google Cloud infrastructure:
          - Keys can be accidentally committed to source code repositories, shared in emails, or stored in insecure locations.
          - Unlike Google-managed keys, user-managed keys do not automatically rotate and have no built-in expiration.
          - Compromised keys grant full access to all resources the service account can access, often for extended periods before detection.
          - Managing key lifecycle across teams and environments creates significant operational overhead and increases the risk of security gaps.

        If user-managed service account keys are in use, it can lead to:
          - Credential leakage through insecure storage, version control, or lateral sharing.
          - Persistent unauthorized access if keys are compromised but not detected or rotated.
          - Non-compliance with security frameworks such as CIS GCP Foundations Benchmark, NIST 800-53, and ISO 27001.
          - Difficult-to-audit access patterns, as key usage is harder to trace than federated identity.

        **Risk mitigation:**
          - Use Workload Identity Federation for external workloads instead of service account keys.
          - Use attached service accounts (Google-managed keys) for GCP workloads.
          - If user-managed keys are absolutely necessary, implement strict key rotation policies and audit procedures.
          - Monitor key creation events using Cloud Audit Logs and set up alerts for new key creation.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Avoid creating `google_service_account_key` resources. Instead, use attached service accounts:

            ```hcl
            resource "google_service_account" "example" {
              account_id   = "my-custom-sa"
              display_name = "Custom SA"
            }

            resource "google_compute_instance" "example" {
              name         = "example-instance"
              machine_type = "e2-medium"
              zone         = "us-central1-a"

              service_account {
                email  = google_service_account.example.email
                scopes = ["cloud-platform"]
              }

              boot_disk {
                initialize_params {
                  image = "debian-cloud/debian-11"
                }
              }

              network_interface {
                network = "default"
              }
            }
            ```

            Remove any existing `google_service_account_key` resources from your Terraform configuration.
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **IAM & Admin > Service Accounts** in the Google Cloud Console.
            2. Select each service account and go to the **Keys** tab.
            3. Identify and delete any user-managed keys.
            4. Migrate workloads to use attached service accounts or Workload Identity Federation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            List all user-managed keys for a service account:

            ```bash
            gcloud iam service-accounts keys list --iam-account=SA_EMAIL --managed-by=user
            ```

            Delete a user-managed key:

            ```bash
            gcloud iam service-accounts keys delete KEY_ID --iam-account=SA_EMAIL
            ```
    refs:
      - url: https://cloud.google.com/iam/docs/best-practices-for-managing-service-account-keys
        title: Best practices for managing service account keys
      - url: https://cloud.google.com/iam/docs/service-account-overview
        title: Service account overview
  - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.iamService.serviceAccounts.all(
        keys().where(keyType == "USER_MANAGED").length == 0
      )
  - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_service_account_key').length == 0
  - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_service_account_key').length == 0
  - uid: mondoo-gcp-security-iam-no-user-managed-service-account-keys-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_service_account_key').length == 0
  - uid: mondoo-gcp-security-iam-default-service-accounts-disabled
    title: Ensure default Compute Engine and App Engine service accounts are disabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-iam-default-service-accounts-disabled-gcp
    docs:
      desc: |
        This check ensures that default Compute Engine and App Engine service accounts are disabled when not needed. Default service accounts are automatically created with overly broad permissions (Editor role) and should be disabled or replaced with custom service accounts following the principle of least privilege.

        **Why this matters**

        When certain Google Cloud APIs are enabled, default service accounts are automatically created with the Editor role:
          - The default Compute Engine service account (`PROJECT_NUMBER-compute@developer.gserviceaccount.com`) has Editor access to nearly all project resources.
          - The default App Engine service account (`PROJECT_ID@appspot.gserviceaccount.com`) similarly has broad permissions.
          - These accounts are frequently used by default unless explicitly overridden, creating unnecessary risk.
          - Compromising a workload using a default service account grants access to a wide range of project resources.

        If default service accounts remain enabled and active, it can lead to:
          - Excessive permissions for workloads that only require access to specific resources.
          - Increased blast radius in the event of credential compromise.
          - Violation of least privilege principles required by CIS GCP Foundations Benchmark and NIST 800-53.
          - Difficult-to-audit access, as many services may share the same overly privileged identity.

        **Risk mitigation:**
          - Create custom service accounts with narrowly scoped IAM roles for each workload.
          - Disable default service accounts after migrating all workloads to custom accounts.
          - Use organization policies to prevent the use of default service accounts.
          - Regularly audit service account usage and permissions.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **IAM & Admin > Service Accounts** in the Google Cloud Console.
            2. Identify the default Compute Engine service account (`PROJECT_NUMBER-compute@developer.gserviceaccount.com`) and App Engine service account (`PROJECT_ID@appspot.gserviceaccount.com`).
            3. Select the service account, then click **Disable service account**.
            4. Ensure all workloads have been migrated to custom service accounts before disabling.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Disable the default Compute Engine service account:

            ```bash
            gcloud iam service-accounts disable PROJECT_NUMBER-compute@developer.gserviceaccount.com
            ```

            Disable the default App Engine service account:

            ```bash
            gcloud iam service-accounts disable PROJECT_ID@appspot.gserviceaccount.com
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Use custom service accounts for your workloads instead of default service accounts. Create dedicated service accounts with minimal permissions:

            ```hcl
            resource "google_service_account" "custom" {
              account_id   = "custom-sa"
              display_name = "Custom Service Account"
              project      = "PROJECT_ID"
            }

            resource "google_project_iam_member" "custom_role" {
              project = "PROJECT_ID"
              role    = "roles/viewer"
              member  = "serviceAccount:${google_service_account.custom.email}"
            }
            ```

            To enforce that default service accounts cannot be used, apply an organization policy:

            ```hcl
            resource "google_project_organization_policy" "disable_default_sa" {
              project    = "PROJECT_ID"
              constraint = "iam.automaticIamGrantsForDefaultServiceAccounts"

              boolean_policy {
                enforced = true
              }
            }
            ```
    refs:
      - url: https://cloud.google.com/iam/docs/service-account-types#default
        title: Default service accounts
      - url: https://cloud.google.com/iam/docs/best-practices-service-accounts
        title: Best practices for service accounts
  - uid: mondoo-gcp-security-iam-default-service-accounts-disabled-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.iamService.serviceAccounts
        .where(email == /^\d+-compute@developer\.gserviceaccount\.com$/ || email == /^[a-z0-9\-]+@appspot\.gserviceaccount\.com$/)
        .all(disabled == true)
  - uid: mondoo-gcp-security-iam-service-account-keys-rotated-90-days
    title: Ensure service account keys are rotated within 90 days
    impact: 70
    variants:
      - uid: mondoo-gcp-security-iam-service-account-keys-rotated-90-days-gcp
    docs:
      desc: |
        This check ensures that user-managed service account keys are rotated at least every 90 days. Long-lived credentials that are not regularly rotated increase the window of opportunity for an attacker to use compromised credentials without detection.

        **Why this matters**

        Service account keys that are not rotated regularly pose significant security risks:
          - Compromised keys remain valid indefinitely unless manually revoked, allowing persistent unauthorized access.
          - The longer a key exists, the more likely it is to have been exposed through accidental sharing, repository commits, or insecure storage.
          - Regular rotation limits the useful lifetime of any compromised key material.
          - Many compliance frameworks require periodic rotation of credentials as part of access management controls.

        If service account keys are not rotated, it can lead to:
          - Extended unauthorized access through leaked or stolen credentials.
          - Non-compliance with security policies requiring credential rotation (CIS GCP Benchmark, PCI DSS, SOC 2).
          - Difficulty identifying which keys are still actively used versus those that should be decommissioned.
          - Increased risk of key reuse across environments or teams.

        **Risk mitigation:**
          - Implement automated key rotation processes that generate new keys and retire old ones within 90 days.
          - Use Cloud Monitoring alerts to detect keys approaching the rotation deadline.
          - Prefer Workload Identity Federation or Google-managed keys over user-managed keys to avoid rotation requirements entirely.
          - Maintain an inventory of all service account keys with their creation dates and intended use.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **IAM & Admin > Service Accounts** in the Google Cloud Console.
            2. For each service account, select the **Keys** tab.
            3. Identify any keys with a creation date older than 90 days.
            4. Create a new key, update all consumers, then delete the old key.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            List keys and their creation dates:

            ```bash
            gcloud iam service-accounts keys list --iam-account=SA_EMAIL --managed-by=user
            ```

            Create a new key:

            ```bash
            gcloud iam service-accounts keys create ~/key.json --iam-account=SA_EMAIL
            ```

            Delete the old key after updating consumers:

            ```bash
            gcloud iam service-accounts keys delete OLD_KEY_ID --iam-account=SA_EMAIL
            ```
    refs:
      - url: https://cloud.google.com/iam/docs/best-practices-for-managing-service-account-keys
        title: Best practices for managing service account keys
  - uid: mondoo-gcp-security-iam-service-account-keys-rotated-90-days-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.iamService.serviceAccounts.all(
        keys().where(keyType == "USER_MANAGED").all(
          validAfterTime > time.now - 90 * time.day
        )
      )
  - uid: mondoo-gcp-security-iam-no-disabled-service-account-keys
    title: Ensure there are no disabled service account keys left undeleted
    impact: 50
    variants:
      - uid: mondoo-gcp-security-iam-no-disabled-service-account-keys-gcp
    docs:
      desc: |
        This check ensures that disabled service account keys are deleted rather than left in a disabled state. Disabled keys represent unnecessary credential material that can be re-enabled and should be fully removed to reduce the attack surface.

        **Why this matters**

        Disabled service account keys still exist as credential material in the project:
          - A disabled key can be re-enabled by anyone with the appropriate IAM permissions, potentially restoring access that was intentionally revoked.
          - Leaving disabled keys creates confusion about which credentials are actively managed versus abandoned.
          - Each unnecessary key increases the credential surface area that must be tracked and audited.

        If disabled keys are not deleted, it can lead to:
          - Accidental or malicious re-enablement of revoked credentials.
          - Cluttered key management that obscures the active credential inventory.
          - Increased audit complexity when reviewing service account access.

        **Risk mitigation:**
          - Delete disabled keys promptly after confirming no active workloads depend on them.
          - Implement automation to identify and remove disabled keys as part of periodic credential hygiene.
          - Monitor key status changes using Cloud Audit Logs.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **IAM & Admin > Service Accounts** in the Google Cloud Console.
            2. For each service account, select the **Keys** tab.
            3. Identify any disabled keys.
            4. Select the disabled key and click **Delete**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            List keys and identify disabled ones:

            ```bash
            gcloud iam service-accounts keys list --iam-account=SA_EMAIL --managed-by=user
            ```

            Delete a disabled key:

            ```bash
            gcloud iam service-accounts keys delete KEY_ID --iam-account=SA_EMAIL
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Terraform manages service account keys declaratively. To ensure disabled keys are removed, avoid managing keys outside of Terraform. If you use the `google_service_account_key` resource, Terraform will track the key lifecycle:

            ```hcl
            resource "google_service_account_key" "example" {
              service_account_id = google_service_account.example.name
            }
            ```

            If a key needs to be decommissioned, remove the corresponding `google_service_account_key` resource from your configuration and run `terraform apply`. This ensures the key is fully deleted rather than left in a disabled state.

            To avoid user-managed keys entirely, use Workload Identity Federation instead:

            ```hcl
            resource "google_service_account_iam_member" "workload_identity" {
              service_account_id = google_service_account.example.name
              role               = "roles/iam.workloadIdentityUser"
              member             = "principalSet://iam.googleapis.com/projects/PROJECT_NUMBER/locations/global/workloadIdentityPools/POOL_ID/attribute.repository/REPO"
            }
            ```
    refs:
      - url: https://cloud.google.com/iam/docs/creating-managing-service-account-keys
        title: Creating and managing service account keys
  - uid: mondoo-gcp-security-iam-no-disabled-service-account-keys-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.iamService.serviceAccounts.all(
        keys().none(disabled == true)
      )
  # ============================================================================
  # Cloud Logging Checks
  # ============================================================================
  - uid: mondoo-gcp-security-logging-bucket-retention-30-days
    title: Ensure Cloud Logging log buckets have a retention period of at least 30 days
    impact: 60
    variants:
      - uid: mondoo-gcp-security-logging-bucket-retention-30-days-gcp
      - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-hcl
      - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-plan
      - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Logging log buckets have a retention period of at least 30 days. Adequate log retention is essential for incident response, forensic investigation, and compliance with regulatory frameworks.

        **Why this matters**

        Log retention determines how long log entries remain accessible for analysis and auditing:
          - Insufficient retention periods may result in critical security event data being deleted before it can be investigated.
          - Many compliance frameworks (PCI DSS, HIPAA, SOC 2) require minimum log retention periods ranging from 30 days to several years.
          - Security incidents are frequently discovered weeks or months after the initial compromise, requiring access to historical log data.
          - Short retention periods can prevent effective threat hunting and trend analysis.

        If log buckets have insufficient retention, it can lead to:
          - Loss of critical evidence during security incident investigations.
          - Inability to meet compliance and audit requirements for log retention.
          - Gaps in security monitoring and threat detection capabilities.
          - Reduced ability to perform root cause analysis after incidents.

        **Risk mitigation:**
          - Set log bucket retention to at least 30 days for operational logs and longer for compliance-sensitive logs.
          - Configure log sinks to export logs to long-term storage (Cloud Storage, BigQuery) for extended retention.
          - Review retention policies regularly to ensure they meet organizational and regulatory requirements.
          - Use locked retention policies where compliance requires guaranteed retention.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure log bucket retention:

            ```hcl
            resource "google_logging_project_bucket_config" "example" {
              project        = var.project_id
              location       = "global"
              bucket_id      = "my-log-bucket"
              retention_days = 30
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Logging > Logs Storage** in the Google Cloud Console.
            2. Select the log bucket you want to configure.
            3. Click **Edit** and set the retention period to at least 30 days.
            4. Click **Update bucket** to save.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update the retention period for a log bucket:

            ```bash
            gcloud logging buckets update BUCKET_ID --location=LOCATION --retention-days=30
            ```
    refs:
      - url: https://cloud.google.com/logging/docs/buckets
        title: Cloud Logging buckets overview
      - url: https://cloud.google.com/logging/docs/storage
        title: Cloud Logging storage
  - uid: mondoo-gcp-security-logging-bucket-retention-30-days-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.loggingservice.buckets().all(retentionDays >= 30)
  - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_logging_project_bucket_config')
    mql: |
      terraform.resources('google_logging_project_bucket_config').all(
        arguments.retention_days != empty && arguments.retention_days >= 30
      )
  - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_logging_project_bucket_config')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_logging_project_bucket_config').all(
        change.after.retention_days != empty && change.after.retention_days >= 30
      )
  - uid: mondoo-gcp-security-logging-bucket-retention-30-days-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_logging_project_bucket_config')
    mql: |
      terraform.state.resources.where(type == 'google_logging_project_bucket_config').all(
        values.retention_days != empty && values.retention_days >= 30
      )
  - uid: mondoo-gcp-security-logging-bucket-locked
    title: Ensure Cloud Logging log buckets are locked to prevent tampering
    impact: 70
    variants:
      - uid: mondoo-gcp-security-logging-bucket-locked-gcp
      - uid: mondoo-gcp-security-logging-bucket-locked-terraform-hcl
      - uid: mondoo-gcp-security-logging-bucket-locked-terraform-plan
      - uid: mondoo-gcp-security-logging-bucket-locked-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Logging log buckets (excluding system-managed _Default and _Required buckets) are locked to prevent modification or deletion. Locked buckets guarantee that log data cannot be tampered with, which is critical for forensic integrity and compliance.

        **Why this matters**

        Locking a log bucket provides immutability guarantees for audit logs:
          - A locked bucket cannot be deleted and its retention period cannot be reduced, ensuring log data persists for the required duration.
          - Locking prevents malicious actors who gain project access from covering their tracks by deleting or modifying logs.
          - Many compliance frameworks require tamper-proof audit trails for security events.
          - Once locked, a bucket cannot be unlocked, providing a strong guarantee of log integrity.

        If log buckets are not locked, it can lead to:
          - Accidental or malicious deletion of critical audit logs.
          - Tampering with log data to hide unauthorized activity.
          - Non-compliance with regulatory requirements for immutable audit trails.
          - Loss of forensic evidence during incident investigations.

        **Risk mitigation:**
          - Lock custom log buckets that store security-critical or compliance-relevant logs.
          - Ensure adequate retention is configured before locking, as the retention period cannot be reduced after locking.
          - Use the _Required bucket for admin activity and system event logs which are automatically protected.
          - Export logs to additional locked storage destinations for defense in depth.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a locked log bucket:

            ```hcl
            resource "google_logging_project_bucket_config" "example" {
              project        = var.project_id
              location       = "global"
              bucket_id      = "my-audit-bucket"
              retention_days = 365
              locked         = true
            }
            ```

            Note: Once a bucket is locked, it cannot be unlocked or deleted.
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Logging > Logs Storage** in the Google Cloud Console.
            2. Select the log bucket you want to lock.
            3. Click **Edit** and enable the **Lock bucket** option.
            4. Confirm the action. Note: This action is irreversible.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Lock a log bucket:

            ```bash
            gcloud logging buckets update BUCKET_ID --location=LOCATION --locked
            ```

            Note: This action is irreversible. Ensure retention settings are correct before locking.
    refs:
      - url: https://cloud.google.com/logging/docs/buckets
        title: Cloud Logging buckets overview
      - url: https://cloud.google.com/logging/docs/storage#locked-bucket
        title: Locked log buckets
  - uid: mondoo-gcp-security-logging-bucket-locked-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.loggingservice.buckets()
        .where(name != "_Default" && name != "_Required")
        .all(locked == true)
  - uid: mondoo-gcp-security-logging-bucket-locked-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_logging_project_bucket_config')
    mql: |
      terraform.resources('google_logging_project_bucket_config').all(
        arguments.locked == true
      )
  - uid: mondoo-gcp-security-logging-bucket-locked-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_logging_project_bucket_config')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_logging_project_bucket_config').all(
        change.after.locked == true
      )
  - uid: mondoo-gcp-security-logging-bucket-locked-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_logging_project_bucket_config')
    mql: |
      terraform.state.resources.where(type == 'google_logging_project_bucket_config').all(
        values.locked == true
      )
  - uid: mondoo-gcp-security-logging-sinks-configured
    title: Ensure Cloud Logging has at least one sink configured for log export
    impact: 60
    variants:
      - uid: mondoo-gcp-security-logging-sinks-configured-gcp
      - uid: mondoo-gcp-security-logging-sinks-configured-terraform-hcl
      - uid: mondoo-gcp-security-logging-sinks-configured-terraform-plan
      - uid: mondoo-gcp-security-logging-sinks-configured-terraform-state
    docs:
      desc: |
        This check ensures that at least one Cloud Logging sink is configured in the project to export logs to an external destination. Log sinks enable long-term retention, centralized analysis, and security monitoring by routing logs to Cloud Storage, BigQuery, Pub/Sub, or external SIEM systems.

        **Why this matters**

        Without configured log sinks, logs are only available in Cloud Logging for the default retention period:
          - Default log retention (30 days for most log types) may be insufficient for compliance and forensic requirements.
          - Centralized log analysis across multiple projects requires log export to a shared destination.
          - Security Information and Event Management (SIEM) integrations depend on log sinks to receive GCP log data.
          - Log sinks enable real-time streaming of logs for threat detection and automated response.

        If no log sinks are configured, it can lead to:
          - Loss of historical log data after the default retention period expires.
          - Inability to perform cross-project log correlation and analysis.
          - Gaps in security monitoring when logs are not forwarded to SIEM or monitoring tools.
          - Non-compliance with regulatory requirements for centralized audit log management.

        **Risk mitigation:**
          - Configure at least one log sink to export security-critical logs to long-term storage.
          - Use organization-level sinks for consistent log export across all projects.
          - Consider multiple sinks for different log types (e.g., audit logs to BigQuery, security logs to SIEM).
          - Monitor sink health and ensure destinations are accessible and have sufficient capacity.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a log sink:

            ```hcl
            resource "google_logging_project_sink" "audit_sink" {
              name                   = "audit-log-sink"
              destination            = "storage.googleapis.com/${google_storage_bucket.audit_logs.name}"
              filter                 = "logName:\"cloudaudit.googleapis.com\""
              unique_writer_identity = true
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Logging > Log Router** in the Google Cloud Console.
            2. Click **Create Sink**.
            3. Enter a sink name and optional description.
            4. Select a destination (Cloud Storage, BigQuery, Pub/Sub, or another project's log bucket).
            5. Optionally add an inclusion or exclusion filter.
            6. Click **Create Sink**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Create a log sink to Cloud Storage:

            ```bash
            gcloud logging sinks create SINK_NAME storage.googleapis.com/BUCKET_NAME \
              --log-filter='logName:"cloudaudit.googleapis.com"'
            ```
    refs:
      - url: https://cloud.google.com/logging/docs/export
        title: Routing and storage overview
      - url: https://cloud.google.com/logging/docs/export/configure_export_v2
        title: Configure log sinks
  - uid: mondoo-gcp-security-logging-sinks-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.loggingservice.sinks().where(id != "_Required" && id != "_Default").length > 0
  - uid: mondoo-gcp-security-logging-sinks-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_logging_project_sink').length > 0
  - uid: mondoo-gcp-security-logging-sinks-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_logging_project_sink').length > 0
  - uid: mondoo-gcp-security-logging-sinks-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_logging_project_sink').length > 0
  # ============================================================================
  # Pub/Sub Checks
  # ============================================================================
  - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption
    title: Ensure Pub/Sub topics are encrypted with customer-managed encryption keys (CMEK)
    impact: 60
    variants:
      - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-gcp
      - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Pub/Sub topics are encrypted using customer-managed encryption keys (CMEK) rather than default Google-managed keys. CMEK provides organizations with full control over the encryption key lifecycle for message data at rest.

        **Why this matters**

        Pub/Sub topics may process sensitive or regulated data that requires enhanced encryption controls:
          - Google-managed encryption keys do not allow organizations to control key rotation, access, or revocation.
          - CMEK enables organizations to revoke access to encrypted data by disabling or destroying the key.
          - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 may require customer-managed encryption for data in transit and at rest.
          - CMEK provides audit trails through Cloud KMS for all key usage operations.

        If Pub/Sub topics are not encrypted with CMEK, it can lead to:
          - Inability to independently manage the encryption key lifecycle.
          - Non-compliance with data protection requirements mandating customer-managed encryption.
          - Limited auditability of encryption key operations.

        **Risk mitigation:**
          - Configure CMEK for all Pub/Sub topics that handle sensitive data.
          - Use Cloud KMS to manage encryption keys with appropriate IAM policies and automatic rotation.
          - Monitor key usage through Cloud Audit Logs.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_pubsub_topic" "example" {
              name         = "example-topic"
              kms_key_name = google_kms_crypto_key.example.id
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Pub/Sub > Topics** in the Google Cloud Console.
            2. Click **Create Topic** or select an existing topic.
            3. Under **Encryption**, select **Customer-managed encryption key**.
            4. Select or create a Cloud KMS key.
            5. Click **Create** or **Update**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Create a topic with CMEK:

            ```bash
            gcloud pubsub topics create TOPIC_NAME \
              --message-encryption-key-name=projects/PROJECT/locations/LOCATION/keyRings/RING/cryptoKeys/KEY
            ```
    refs:
      - url: https://cloud.google.com/pubsub/docs/encryption
        title: Pub/Sub encryption
  - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.pubsubService.topics().all(
        config().kmsKeyName != ""
      )
  - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_pubsub_topic')
    mql: |
      terraform.resources('google_pubsub_topic').all(
        arguments.kms_key_name != empty
      )
  - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_pubsub_topic')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_pubsub_topic').all(
        change.after.kms_key_name != empty
      )
  - uid: mondoo-gcp-security-pubsub-topic-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_pubsub_topic')
    mql: |
      terraform.state.resources.where(type == 'google_pubsub_topic').all(
        values.kms_key_name != empty
      )
  - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured
    title: Ensure Pub/Sub subscriptions have an expiration policy configured
    impact: 40
    variants:
      - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-gcp
      - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-hcl
      - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-plan
      - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-state
    docs:
      desc: |
        This check ensures that Pub/Sub subscriptions have an expiration policy configured to prevent orphaned subscriptions from accumulating indefinitely. Subscriptions without expiration policies can persist after their consumers are decommissioned, creating unnecessary resource overhead and potential data access points.

        **Why this matters**

        Orphaned subscriptions that remain active without consumers can create security and operational risks:
          - Unused subscriptions still have access to topic messages and may retain unacknowledged messages.
          - Accumulated orphaned subscriptions increase the attack surface and complicate access auditing.
          - Without expiration, manual cleanup is required to identify and remove stale subscriptions.

        **Risk mitigation:**
          - Configure expiration policies on all subscriptions to automatically clean up inactive ones.
          - The default expiration is 31 days of inactivity; adjust based on operational requirements.
          - Regularly audit subscription usage to identify and remove unused subscriptions.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_pubsub_subscription" "example" {
              name  = "example-subscription"
              topic = google_pubsub_topic.example.id

              expiration_policy {
                ttl = "2678400s"  # 31 days
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Pub/Sub > Subscriptions** in the Google Cloud Console.
            2. Select the subscription to update.
            3. Click **Edit**.
            4. Configure the **Expiration** policy with an appropriate TTL.
            5. Click **Update**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud pubsub subscriptions update SUBSCRIPTION_NAME \
              --expiration-period=31d
            ```
    refs:
      - url: https://cloud.google.com/pubsub/docs/subscription-properties
        title: Subscription properties
  - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.pubsubService.subscriptions().all(
        config().expirationPolicy != empty
      )
  - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_pubsub_subscription')
    mql: |
      terraform.resources('google_pubsub_subscription').all(
        blocks.where(type == 'expiration_policy') != empty
      )
  - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_pubsub_subscription')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_pubsub_subscription').all(
        change.after.expiration_policy != empty
      )
  - uid: mondoo-gcp-security-pubsub-subscription-expiration-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_pubsub_subscription')
    mql: |
      terraform.state.resources.where(type == 'google_pubsub_subscription').all(
        values.expiration_policy != empty
      )
  # ============================================================================
  # Cloud Functions Checks
  # ============================================================================
  - uid: mondoo-gcp-security-cloud-functions-ingress-restricted
    title: Ensure Cloud Functions do not allow all ingress traffic
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-gcp
      - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-hcl
      - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-plan
      - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Functions do not have their ingress settings configured to allow all traffic (ALLOW_ALL). Functions should restrict ingress to internal traffic only or internal traffic plus Cloud Load Balancing to minimize their attack surface.

        **Why this matters**

        Cloud Functions with unrestricted ingress are accessible from the public internet:
          - Any HTTP endpoint exposed by the function can be called from any source, increasing the risk of unauthorized access, abuse, or denial-of-service attacks.
          - Functions that process sensitive data or perform privileged operations should not be directly accessible from the internet.
          - Internal-only ingress ensures that only traffic from within the VPC or Google Cloud services can reach the function.
          - Even with authentication enabled, restricting network access provides defense in depth.

        If Cloud Functions allow all ingress, it can lead to:
          - Unauthorized invocations of functions by external actors.
          - Exposure to brute-force attacks, credential stuffing, or exploitation of function vulnerabilities.
          - Data exfiltration through functions that access internal resources.
          - Unexpected cost increases from malicious or abusive traffic.

        **Risk mitigation:**
          - Set ingress settings to ALLOW_INTERNAL_ONLY or ALLOW_INTERNAL_AND_GCLB.
          - Use Cloud Load Balancing with Cloud Armor for functions that need external access with protection.
          - Implement authentication requirements on all function endpoints.
          - Monitor function invocation logs for suspicious patterns.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_cloudfunctions_function" "example" {
              name        = "example-function"
              runtime     = "python312"
              entry_point = "main"

              ingress_settings = "ALLOW_INTERNAL_ONLY"

              source_archive_bucket = google_storage_bucket.source.name
              source_archive_object = google_storage_bucket_object.archive.name
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Functions** in the Google Cloud Console.
            2. Select the function to update.
            3. Click **Edit**.
            4. Under **Networking**, set **Ingress settings** to **Allow internal traffic only** or **Allow internal traffic and traffic from Cloud Load Balancing**.
            5. Click **Next** and then **Deploy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Update ingress settings:

            ```bash
            gcloud functions deploy FUNCTION_NAME \
              --ingress-settings=internal-only
            ```
    refs:
      - url: https://cloud.google.com/functions/docs/networking/network-settings
        title: Cloud Functions networking settings
  - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudFunctions.all(
        ingressSettings != "ALLOW_ALL"
      )
  - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function')
    mql: |
      terraform.resources.where(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function').all(
        arguments.ingress_settings != "ALLOW_ALL" && arguments.ingress_settings != empty
      )
  - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        change.after.ingress_settings != "ALLOW_ALL"
      )
  - uid: mondoo-gcp-security-cloud-functions-ingress-restricted-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.state.resources.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        values.ingress_settings != "ALLOW_ALL"
      )
  - uid: mondoo-gcp-security-cloud-functions-no-default-service-account
    title: Ensure Cloud Functions do not use the default service account
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-gcp
      - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-hcl
      - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-plan
      - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Functions are not configured to use the default Compute Engine or App Engine service account. Default service accounts have overly broad permissions and should be replaced with custom service accounts following the principle of least privilege.

        **Why this matters**

        Cloud Functions using default service accounts inherit excessive permissions:
          - The default Compute Engine service account has the Editor role, granting broad access to most project resources.
          - A compromised function with a default service account can be used to access, modify, or delete resources across the entire project.
          - Custom service accounts with narrowly scoped roles limit the blast radius of any security incident.
          - Using dedicated service accounts improves auditability by clearly linking function actions to specific identities.

        If Cloud Functions use the default service account, it can lead to:
          - Privilege escalation through a compromised function.
          - Lateral movement across project resources.
          - Violation of least privilege requirements in CIS GCP Foundations Benchmark and NIST 800-53.

        **Risk mitigation:**
          - Create dedicated service accounts with only the IAM roles needed for each function's operation.
          - Assign the custom service account when deploying the function.
          - Regularly review and audit function service account permissions.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_service_account" "function_sa" {
              account_id   = "function-sa"
              display_name = "Cloud Function Service Account"
            }

            resource "google_cloudfunctions_function" "example" {
              name                  = "example-function"
              runtime               = "python312"
              entry_point           = "main"
              service_account_email = google_service_account.function_sa.email

              source_archive_bucket = google_storage_bucket.source.name
              source_archive_object = google_storage_bucket_object.archive.name
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Functions** in the Google Cloud Console.
            2. Select the function to update.
            3. Click **Edit**.
            4. Under **Runtime, build, connections and security settings**, expand **Runtime service account**.
            5. Select a custom service account instead of the default.
            6. Click **Next** and then **Deploy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud functions deploy FUNCTION_NAME \
              --service-account=CUSTOM_SA_EMAIL
            ```
    refs:
      - url: https://cloud.google.com/functions/docs/securing/function-identity
        title: Cloud Functions identity
  - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudFunctions.all(
        serviceAccountEmail != /^\d+-compute@developer\.gserviceaccount\.com$/ &&
        serviceAccountEmail != /^[a-z0-9\-]+@appspot\.gserviceaccount\.com$/
      )
  - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function')
    mql: |
      terraform.resources.where(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function').all(
        arguments.service_account_email != empty
      )
  - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        change.after.service_account_email != empty
      )
  - uid: mondoo-gcp-security-cloud-functions-no-default-service-account-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.state.resources.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        values.service_account_email != /^\d+-compute@developer\.gserviceaccount\.com$/ &&
        values.service_account_email != /^[a-z0-9\-]+@appspot\.gserviceaccount\.com$/
      )
  - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured
    title: Ensure Cloud Functions have a VPC connector configured
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-gcp
      - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-hcl
      - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-plan
      - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Functions have a VPC connector configured to enable secure communication with resources in a VPC network. Without a VPC connector, functions can only reach internal resources through public internet paths, increasing exposure and latency.

        **Why this matters**

        A VPC connector enables Cloud Functions to access resources using internal IP addresses:
          - Functions without VPC connectors must route traffic through the public internet to reach VPC resources like databases, caches, or internal APIs.
          - Internal traffic routing reduces exposure to network-based attacks and eavesdropping.
          - VPC connectors enable network-level access controls through firewall rules and VPC Service Controls.
          - Private connectivity is essential for compliance with data protection requirements that mandate encrypted internal communication paths.

        **Risk mitigation:**
          - Configure a Serverless VPC Access connector for each function that accesses VPC resources.
          - Use VPC connector egress settings to control which traffic routes through the connector.
          - Monitor connector throughput and scale as needed.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_vpc_access_connector" "connector" {
              name          = "function-connector"
              region        = "us-central1"
              ip_cidr_range = "10.8.0.0/28"
              network       = "default"
            }

            resource "google_cloudfunctions_function" "example" {
              name                  = "example-function"
              runtime               = "python312"
              entry_point           = "main"
              vpc_connector         = google_vpc_access_connector.connector.id
              vpc_connector_egress_settings = "ALL_TRAFFIC"

              source_archive_bucket = google_storage_bucket.source.name
              source_archive_object = google_storage_bucket_object.archive.name
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Functions** in the Google Cloud Console.
            2. Select the function to update.
            3. Click **Edit**.
            4. Under **Runtime, build, connections and security settings**, expand **Connections**.
            5. Under **Egress settings**, select a VPC connector or create a new one.
            6. Click **Next** and then **Deploy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud functions deploy FUNCTION_NAME \
              --vpc-connector=projects/PROJECT/locations/REGION/connectors/CONNECTOR_NAME \
              --egress-settings=all
            ```
    refs:
      - url: https://cloud.google.com/functions/docs/networking/connecting-vpc
        title: Connecting to a VPC network
  - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudFunctions.all(vpcConnector != "")
  - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function')
    mql: |
      terraform.resources.where(nameLabel == 'google_cloudfunctions_function' || nameLabel == 'google_cloudfunctions2_function').all(
        arguments.vpc_connector != empty
      )
  - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        change.after.vpc_connector != empty
      )
  - uid: mondoo-gcp-security-cloud-functions-vpc-connector-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function')
    mql: |
      terraform.state.resources.where(type == 'google_cloudfunctions_function' || type == 'google_cloudfunctions2_function').all(
        values.vpc_connector != empty
      )
  # ============================================================================
  # Cloud Run Checks
  # ============================================================================
  - uid: mondoo-gcp-security-cloud-run-ingress-restricted
    title: Ensure Cloud Run services do not allow all ingress traffic
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-run-ingress-restricted-gcp
      - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-hcl
      - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-plan
      - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Run services are not configured with ingress set to INGRESS_TRAFFIC_ALL, which allows traffic from the public internet. Services should restrict ingress to internal traffic or internal traffic with Cloud Load Balancing to reduce the attack surface.

        **Why this matters**

        Cloud Run services with unrestricted ingress accept HTTP requests from any source on the internet:
          - Publicly accessible services are exposed to unauthorized access attempts, brute-force attacks, and exploitation of application vulnerabilities.
          - Services handling sensitive data or performing privileged operations should not be directly reachable from the internet.
          - Restricting ingress to internal traffic ensures that only requests from within the VPC or through Google Cloud Load Balancing can reach the service.
          - Using Cloud Armor with internal ingress and load balancing provides DDoS protection and WAF capabilities.

        If Cloud Run services allow all ingress, it can lead to:
          - Unauthorized access to internal APIs or services.
          - Data exfiltration through publicly accessible endpoints.
          - Increased attack surface for application-level exploits.
          - Unexpected costs from malicious or abusive traffic.

        **Risk mitigation:**
          - Set ingress to INGRESS_TRAFFIC_INTERNAL_ONLY or INGRESS_TRAFFIC_INTERNAL_LOAD_BALANCER.
          - Use Cloud Load Balancing with Cloud Armor for services requiring external access.
          - Implement IAM-based authentication for all Cloud Run services.
          - Monitor service access logs for suspicious traffic patterns.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_cloud_run_v2_service" "example" {
              name     = "example-service"
              location = "us-central1"
              ingress  = "INGRESS_TRAFFIC_INTERNAL_ONLY"

              template {
                containers {
                  image = "us-docker.pkg.dev/cloudrun/container/hello"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Run** in the Google Cloud Console.
            2. Select the service to update.
            3. Click **Edit & Deploy New Revision**.
            4. Under **Networking**, set **Ingress** to **Internal** or **Internal and Cloud Load Balancing**.
            5. Click **Deploy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud run services update SERVICE_NAME \
              --ingress=internal \
              --region=REGION
            ```
    refs:
      - url: https://cloud.google.com/run/docs/securing/ingress
        title: Restricting ingress for Cloud Run
  - uid: mondoo-gcp-security-cloud-run-ingress-restricted-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudRunService.services().all(
        ingress != "INGRESS_TRAFFIC_ALL"
      )
  - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloud_run_v2_service')
    mql: |
      terraform.resources('google_cloud_run_v2_service').all(
        arguments.ingress != "INGRESS_TRAFFIC_ALL" && arguments.ingress != empty
      )
  - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloud_run_v2_service').all(
        change.after.ingress != "INGRESS_TRAFFIC_ALL"
      )
  - uid: mondoo-gcp-security-cloud-run-ingress-restricted-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.state.resources.where(type == 'google_cloud_run_v2_service').all(
        values.ingress != "INGRESS_TRAFFIC_ALL"
      )
  - uid: mondoo-gcp-security-cloud-run-cmek-encryption
    title: Ensure Cloud Run services use customer-managed encryption keys (CMEK)
    impact: 60
    variants:
      - uid: mondoo-gcp-security-cloud-run-cmek-encryption-gcp
      - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Run services are encrypted using customer-managed encryption keys (CMEK) rather than default Google-managed keys. CMEK provides organizations with control over the encryption key lifecycle for container images and data at rest.

        **Why this matters**

        Cloud Run services process and store data that may be subject to regulatory encryption requirements:
          - CMEK enables organizations to control key rotation, access policies, and revocation.
          - Organizations can revoke access to encrypted data by disabling or destroying the CMEK key.
          - Cloud Audit Logs provide visibility into all key usage operations.
          - Compliance frameworks may require customer-managed encryption for workloads handling sensitive data.

        **Risk mitigation:**
          - Configure CMEK for Cloud Run services handling sensitive or regulated data.
          - Use Cloud KMS to manage keys with appropriate IAM policies and automatic rotation.
          - Monitor key usage through Cloud Audit Logs.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_cloud_run_v2_service" "example" {
              name     = "example-service"
              location = "us-central1"

              template {
                encryption_key = google_kms_crypto_key.example.id

                containers {
                  image = "us-docker.pkg.dev/cloudrun/container/hello"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Run** in the Google Cloud Console.
            2. Select the service or click **Create Service**.
            3. Under **Security**, select **Customer-managed encryption key**.
            4. Choose or create a Cloud KMS key.
            5. Deploy the service.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud run services update SERVICE_NAME \
              --key=projects/PROJECT/locations/LOCATION/keyRings/RING/cryptoKeys/KEY \
              --region=REGION
            ```
    refs:
      - url: https://cloud.google.com/run/docs/securing/using-cmek
        title: Using customer-managed encryption keys with Cloud Run
  - uid: mondoo-gcp-security-cloud-run-cmek-encryption-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudRunService.services().all(
        template.encryptionKey != ""
      )
  - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloud_run_v2_service')
    mql: |
      terraform.resources('google_cloud_run_v2_service').all(
        blocks.where(type == 'template').all(
          arguments.encryption_key != empty
        )
      )
  - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloud_run_v2_service').all(
        change.after.template != empty &&
        change.after.template.all(_['encryption_key'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-run-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.state.resources.where(type == 'google_cloud_run_v2_service').all(
        values.template != empty &&
        values.template.all(_['encryption_key'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-run-no-default-service-account
    title: Ensure Cloud Run services do not use the default service account
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-run-no-default-service-account-gcp
      - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-hcl
      - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-plan
      - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Run services are not using the default Compute Engine service account. Default service accounts have overly broad permissions (Editor role) and should be replaced with custom service accounts scoped to only the permissions required by the service.

        **Why this matters**

        Cloud Run services using default service accounts inherit excessive permissions:
          - The default Compute Engine service account has broad access to project resources via the Editor role.
          - A compromised Cloud Run service with a default service account can access, modify, or delete resources across the entire project.
          - Custom service accounts with narrowly scoped roles limit the blast radius of security incidents.
          - Dedicated service accounts improve auditability by linking service actions to specific identities.

        If Cloud Run services use the default service account, it can lead to:
          - Privilege escalation through a compromised container.
          - Lateral movement across project resources.
          - Violation of least privilege requirements in security frameworks.

        **Risk mitigation:**
          - Create dedicated service accounts with only the IAM roles needed for each service.
          - Specify the custom service account in the service's revision template.
          - Regularly audit service account permissions and usage.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_service_account" "run_sa" {
              account_id   = "cloud-run-sa"
              display_name = "Cloud Run Service Account"
            }

            resource "google_cloud_run_v2_service" "example" {
              name     = "example-service"
              location = "us-central1"

              template {
                service_account = google_service_account.run_sa.email

                containers {
                  image = "us-docker.pkg.dev/cloudrun/container/hello"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Cloud Run** in the Google Cloud Console.
            2. Select the service to update.
            3. Click **Edit & Deploy New Revision**.
            4. Under **Security**, select a custom service account from the **Service account** dropdown.
            5. Click **Deploy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud run services update SERVICE_NAME \
              --service-account=CUSTOM_SA_EMAIL \
              --region=REGION
            ```
    refs:
      - url: https://cloud.google.com/run/docs/securing/service-identity
        title: Cloud Run service identity
  - uid: mondoo-gcp-security-cloud-run-no-default-service-account-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.cloudRunService.services().all(
        template.serviceAccountEmail != "" &&
        template.serviceAccountEmail != /^\d+-compute@developer\.gserviceaccount\.com$/ &&
        template.serviceAccountEmail != /^[a-z0-9\-]+@appspot\.gserviceaccount\.com$/
      )
  - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_cloud_run_v2_service')
    mql: |
      terraform.resources('google_cloud_run_v2_service').all(
        blocks.where(type == 'template').all(
          arguments.service_account != empty
        )
      )
  - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_cloud_run_v2_service').all(
        change.after.template != empty &&
        change.after.template.all(_['service_account'] != empty)
      )
  - uid: mondoo-gcp-security-cloud-run-no-default-service-account-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_cloud_run_v2_service')
    mql: |
      terraform.state.resources.where(type == 'google_cloud_run_v2_service').all(
        values.template != empty &&
        values.template.all(
          _['service_account'] != empty &&
          _['service_account'] != /^\d+-compute@developer\.gserviceaccount\.com$/
        )
      )
  # ============================================================================
  # Dataproc Checks
  # ============================================================================
  - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured
    title: Ensure Dataproc clusters have disk encryption configured with CMEK
    impact: 70
    variants:
      - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-gcp
      - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-hcl
      - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-plan
      - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-state
    docs:
      desc: |
        This check ensures that Dataproc clusters use customer-managed encryption keys (CMEK) to encrypt persistent disks. CMEK provides control over the encryption key lifecycle for data at rest on cluster nodes, enabling organizations to manage key rotation, access policies, and revocation.

        **Why this matters**

        Dataproc clusters process and store data on persistent disks that may contain sensitive information:
          - Without CMEK, disks are encrypted with Google-managed keys that the organization cannot independently control.
          - CMEK enables organizations to revoke access to cluster data by disabling or destroying encryption keys.
          - Compliance frameworks may require customer-managed encryption for data processing environments.
          - Audit trails for key usage support security monitoring and compliance reporting.

        **Risk mitigation:**
          - Configure CMEK when creating Dataproc clusters by specifying a KMS key for GCE PD encryption.
          - Use Cloud KMS to manage encryption keys with appropriate IAM policies.
          - Enable automatic key rotation on encryption keys used by Dataproc clusters.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_dataproc_cluster" "example" {
              name   = "example-cluster"
              region = "us-central1"

              cluster_config {
                encryption_config {
                  kms_key_name = google_kms_crypto_key.example.id
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Dataproc > Clusters** in the Google Cloud Console.
            2. Click **Create Cluster**.
            3. Under **Manage security**, expand **Encryption**.
            4. Select **Customer-managed key** and choose a Cloud KMS key.
            5. Complete cluster creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud dataproc clusters create CLUSTER_NAME \
              --region=REGION \
              --gce-pd-kms-key=projects/PROJECT/locations/LOCATION/keyRings/RING/cryptoKeys/KEY
            ```
    refs:
      - url: https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption
        title: Customer-managed encryption keys for Dataproc
  - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.dataprocService.clusters().all(
        config.encryption['gcePdKmsKeyName'] != empty
      )
  - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_dataproc_cluster')
    mql: |
      terraform.resources('google_dataproc_cluster').all(
        blocks.where(type == 'cluster_config').all(
          blocks.where(type == 'encryption_config') != empty &&
          blocks.where(type == 'encryption_config').all(arguments.kms_key_name != empty)
        )
      )
  - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dataproc_cluster').all(
        change.after.cluster_config != empty &&
        change.after.cluster_config.all(_['encryption_config'] != empty)
      )
  - uid: mondoo-gcp-security-dataproc-cluster-encryption-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_dataproc_cluster').all(
        values.cluster_config != empty &&
        values.cluster_config.all(_['encryption_config'] != empty)
      )
  - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only
    title: Ensure Dataproc clusters use internal IP addresses only
    impact: 80
    variants:
      - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-gcp
      - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-hcl
      - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-plan
      - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-state
    docs:
      desc: |
        This check ensures that Dataproc clusters are configured with internal IP addresses only, preventing cluster nodes from being directly accessible from the public internet.

        **Why this matters**

        Dataproc clusters with public IP addresses expose cluster nodes to the internet:
          - Public IPs allow direct SSH access attempts and other network-based attacks against cluster nodes.
          - Data processing environments often handle sensitive data that should not be accessible from external networks.
          - Internal-only networking ensures cluster communication stays within the VPC, reducing the attack surface.
          - Private Google Access enables clusters to reach Google APIs without public IPs.

        If Dataproc clusters have public IP addresses, it can lead to:
          - Unauthorized access to cluster nodes and the data they process.
          - Data exfiltration through network-level access to cluster endpoints.
          - Increased exposure to brute-force and scanning attacks.

        **Risk mitigation:**
          - Enable internal IP only mode when creating clusters.
          - Ensure Private Google Access is enabled on the subnet for accessing Google APIs.
          - Use Cloud NAT for outbound internet access if needed.
          - Configure firewall rules to restrict internal access to authorized networks.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_dataproc_cluster" "example" {
              name   = "example-cluster"
              region = "us-central1"

              cluster_config {
                gce_cluster_config {
                  internal_ip_only = true
                  subnetwork       = google_compute_subnetwork.example.id
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Dataproc > Clusters** in the Google Cloud Console.
            2. Click **Create Cluster**.
            3. Under **Configure nodes**, expand **Network configuration**.
            4. Enable **Internal IP only**.
            5. Complete cluster creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud dataproc clusters create CLUSTER_NAME \
              --region=REGION \
              --no-address \
              --subnet=SUBNET_NAME
            ```
    refs:
      - url: https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network
        title: Dataproc cluster network configuration
  - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.dataprocService.clusters().all(
        config.gceCluster.internalIpOnly == true
      )
  - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_dataproc_cluster')
    mql: |
      terraform.resources('google_dataproc_cluster').all(
        blocks.where(type == 'cluster_config').all(
          blocks.where(type == 'gce_cluster_config').all(arguments.internal_ip_only == true)
        )
      )
  - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dataproc_cluster').all(
        change.after.cluster_config != empty &&
        change.after.cluster_config.all(_['gce_cluster_config'] != empty && _['gce_cluster_config'].all(_['internal_ip_only'] == true))
      )
  - uid: mondoo-gcp-security-dataproc-cluster-internal-ip-only-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_dataproc_cluster').all(
        values.cluster_config != empty &&
        values.cluster_config.all(_['gce_cluster_config'] != empty && _['gce_cluster_config'].all(_['internal_ip_only'] == true))
      )
  - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms
    title: Ensure Dataproc clusters have Shielded VM features enabled
    impact: 60
    variants:
      - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-gcp
      - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-hcl
      - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-plan
      - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-state
    docs:
      desc: |
        This check ensures that Dataproc clusters have Shielded VM features enabled, including Secure Boot, vTPM, and integrity monitoring. Shielded VMs provide verifiable integrity of cluster instances, protecting against rootkits and bootkits.

        **Why this matters**

        Shielded VM features protect the boot process and runtime integrity of cluster nodes:
          - Secure Boot ensures that only verified, signed software runs during the boot process.
          - vTPM (Virtual Trusted Platform Module) provides a virtual root of trust for measuring boot integrity.
          - Integrity monitoring detects changes to the boot sequence and raises alerts for unauthorized modifications.
          - Without these protections, attackers who gain node access could install persistent rootkits that survive reboots.

        **Risk mitigation:**
          - Enable all three Shielded VM features (Secure Boot, vTPM, integrity monitoring) when creating clusters.
          - Monitor integrity validation reports for signs of boot-level tampering.
          - Use Shielded VM images for cluster nodes.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_dataproc_cluster" "example" {
              name   = "example-cluster"
              region = "us-central1"

              cluster_config {
                gce_cluster_config {
                  shielded_instance_config {
                    enable_secure_boot          = true
                    enable_vtpm                 = true
                    enable_integrity_monitoring = true
                  }
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Dataproc > Clusters** in the Google Cloud Console.
            2. Click **Create Cluster**.
            3. Under **Manage security**, expand **Shielded VMs**.
            4. Enable **Secure Boot**, **vTPM**, and **Integrity Monitoring**.
            5. Complete cluster creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud dataproc clusters create CLUSTER_NAME \
              --region=REGION \
              --shielded-secure-boot \
              --shielded-vtpm \
              --shielded-integrity-monitoring
            ```
    refs:
      - url: https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/shielded-vms
        title: Shielded VMs in Dataproc
  - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.dataprocService.clusters().all(
        config.gceCluster.shieldedInstanceConfig.enableSecureBoot == true &&
        config.gceCluster.shieldedInstanceConfig.enableVtpm == true &&
        config.gceCluster.shieldedInstanceConfig.enableIntegrityMonitoring == true
      )
  - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_dataproc_cluster')
    mql: |
      terraform.resources('google_dataproc_cluster').all(
        blocks.where(type == 'cluster_config').all(
          blocks.where(type == 'gce_cluster_config').all(
            blocks.where(type == 'shielded_instance_config').all(
              arguments.enable_secure_boot == true &&
              arguments.enable_vtpm == true &&
              arguments.enable_integrity_monitoring == true
            )
          )
        )
      )
  - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dataproc_cluster').all(
        change.after.cluster_config != empty &&
        change.after.cluster_config.all(
          _['gce_cluster_config'] != empty &&
          _['gce_cluster_config'].all(
            _['shielded_instance_config'] != empty &&
            _['shielded_instance_config'].all(
              _['enable_secure_boot'] == true &&
              _['enable_vtpm'] == true &&
              _['enable_integrity_monitoring'] == true
            )
          )
        )
      )
  - uid: mondoo-gcp-security-dataproc-cluster-shielded-vms-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_dataproc_cluster')
    mql: |
      terraform.state.resources.where(type == 'google_dataproc_cluster').all(
        values.cluster_config != empty &&
        values.cluster_config.all(
          _['gce_cluster_config'] != empty &&
          _['gce_cluster_config'].all(
            _['shielded_instance_config'] != empty &&
            _['shielded_instance_config'].all(
              _['enable_secure_boot'] == true &&
              _['enable_vtpm'] == true &&
              _['enable_integrity_monitoring'] == true
            )
          )
        )
      )
  # ============================================================================
  # Binary Authorization Checks
  # ============================================================================
  - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all
    title: Ensure Binary Authorization default admission rule does not allow all images
    impact: 90
    variants:
      - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-gcp
      - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-hcl
      - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-plan
      - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-state
    docs:
      desc: |
        This check ensures that the Binary Authorization default admission rule is not set to ALWAYS_ALLOW. When set to ALWAYS_ALLOW, any container image can be deployed without attestation, completely bypassing the image verification controls that Binary Authorization is designed to enforce.

        **Why this matters**

        Binary Authorization is a deploy-time security control that ensures only trusted container images are deployed:
          - An ALWAYS_ALLOW default rule defeats the entire purpose of Binary Authorization, allowing any image including potentially malicious or vulnerable ones.
          - Attackers who gain access to deploy workloads can run arbitrary container images without any verification.
          - The default admission rule applies when no more specific cluster or namespace rule matches, making it the last line of defense.
          - Requiring attestation ensures that only images that have passed security scanning, code review, or other verification steps can be deployed.

        If the default rule allows all images, it can lead to:
          - Deployment of unverified, vulnerable, or malicious container images.
          - Supply chain attacks through compromised base images or dependencies.
          - Non-compliance with container security policies and regulatory requirements.
          - Complete bypass of image integrity verification.

        **Risk mitigation:**
          - Set the default admission rule to ALWAYS_DENY or REQUIRE_ATTESTATION.
          - Create attestors for your CI/CD pipeline to sign verified images.
          - Use per-cluster admission rules for environments with different security requirements.
          - Monitor Binary Authorization events for policy violations.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_binary_authorization_policy" "policy" {
              default_admission_rule {
                evaluation_mode  = "REQUIRE_ATTESTATION"
                enforcement_mode = "ENFORCED_BLOCK_AND_AUDIT_LOG"
                require_attestations_by = [
                  google_binary_authorization_attestor.attestor.name
                ]
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security > Binary Authorization** in the Google Cloud Console.
            2. Click **Edit Policy**.
            3. Under **Default rule**, change the evaluation mode from **Allow all images** to **Require attestations** or **Disallow all images**.
            4. If using attestations, configure the required attestors.
            5. Click **Save Policy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Export the current policy:

            ```bash
            gcloud container binauthz policy export > policy.yaml
            ```

            Edit `policy.yaml` to change the `defaultAdmissionRule.evaluationMode` from `ALWAYS_ALLOW` to `REQUIRE_ATTESTATION`, then import:

            ```bash
            gcloud container binauthz policy import policy.yaml
            ```
    refs:
      - url: https://cloud.google.com/binary-authorization/docs/overview
        title: Binary Authorization overview
      - url: https://cloud.google.com/binary-authorization/docs/configuring-policy-cli
        title: Configuring a Binary Authorization policy
  - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.binaryAuthorizationControl.policy.defaultAdmissionRule.evaluationMode != "ALWAYS_ALLOW"
  - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_binary_authorization_policy')
    mql: |
      terraform.resources('google_binary_authorization_policy').all(
        blocks.where(type == 'default_admission_rule').all(
          arguments.evaluation_mode != "ALWAYS_ALLOW"
        )
      )
  - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_binary_authorization_policy')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_binary_authorization_policy').all(
        change.after.default_admission_rule != empty &&
        change.after.default_admission_rule.all(_['evaluation_mode'] != "ALWAYS_ALLOW")
      )
  - uid: mondoo-gcp-security-binary-authorization-default-rule-not-allow-all-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_binary_authorization_policy')
    mql: |
      terraform.state.resources.where(type == 'google_binary_authorization_policy').all(
        values.default_admission_rule != empty &&
        values.default_admission_rule.all(_['evaluation_mode'] != "ALWAYS_ALLOW")
      )
  - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled
    title: Ensure Binary Authorization global policy evaluation is enabled
    impact: 70
    variants:
      - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-gcp
      - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-hcl
      - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-plan
      - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Binary Authorization global policy evaluation is enabled. Global policy evaluation applies Google-maintained system policies to evaluate common system-level images, providing a baseline level of trust verification without requiring explicit allowlisting of every system image.

        **Why this matters**

        Global policy evaluation provides an important layer of image verification:
          - Google-maintained system policies verify that common GKE system images (kube-proxy, metrics-server, etc.) are authentic and unmodified.
          - Without global evaluation, organizations must manually allowlist every system image, which is error-prone and can lead to overly broad allowlist patterns.
          - Disabling global evaluation may cause operational issues if system images are not explicitly allowlisted.

        **Risk mitigation:**
          - Enable global policy evaluation mode to benefit from Google-maintained system image verification.
          - Combine global evaluation with project-specific attestation policies for application images.
          - Monitor policy evaluation logs for unexpected denials or allowances.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_binary_authorization_policy" "policy" {
              global_policy_evaluation_mode = "ENABLE"

              default_admission_rule {
                evaluation_mode  = "REQUIRE_ATTESTATION"
                enforcement_mode = "ENFORCED_BLOCK_AND_AUDIT_LOG"
                require_attestations_by = [
                  google_binary_authorization_attestor.attestor.name
                ]
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security > Binary Authorization** in the Google Cloud Console.
            2. Click **Edit Policy**.
            3. Under **Google-maintained system policy**, enable the global policy evaluation.
            4. Click **Save Policy**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Export the current policy:

            ```bash
            gcloud container binauthz policy export > policy.yaml
            ```

            Edit `policy.yaml` to set `globalPolicyEvaluationMode: ENABLE`, then import:

            ```bash
            gcloud container binauthz policy import policy.yaml
            ```
    refs:
      - url: https://cloud.google.com/binary-authorization/docs/overview
        title: Binary Authorization overview
  - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.binaryAuthorizationControl.policy.globalPolicyEvaluationMode == "ENABLE"
  - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_binary_authorization_policy')
    mql: |
      terraform.resources('google_binary_authorization_policy').all(
        arguments.global_policy_evaluation_mode == "ENABLE"
      )
  - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_binary_authorization_policy')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_binary_authorization_policy').all(
        change.after.global_policy_evaluation_mode == "ENABLE"
      )
  - uid: mondoo-gcp-security-binary-authorization-global-policy-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_binary_authorization_policy')
    mql: |
      terraform.state.resources.where(type == 'google_binary_authorization_policy').all(
        values.global_policy_evaluation_mode == "ENABLE"
      )
  # ============================================================================
  # API Keys Checks
  # ============================================================================
  - uid: mondoo-gcp-security-api-keys-api-restrictions-configured
    title: Ensure API keys have API target restrictions configured
    impact: 80
    variants:
      - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-gcp
      - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-hcl
      - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-plan
      - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-state
    docs:
      desc: |
        This check ensures that API keys have API target restrictions configured, limiting which Google Cloud APIs the key can be used to call. Without API restrictions, a compromised key can be used to call any enabled API in the project.

        **Why this matters**

        API keys without target restrictions grant access to all enabled APIs in the project:
          - A compromised key can be used to access any Google Cloud service, significantly increasing the blast radius.
          - API restrictions limit the key to only the specific APIs it needs, following the principle of least privilege.
          - Unrestricted keys are a common finding in security audits and a known risk vector for cloud environments.
          - Restricting APIs reduces the potential damage from key leakage in source code, logs, or client applications.

        If API keys lack API restrictions, it can lead to:
          - Unauthorized use of project APIs through compromised keys.
          - Unexpected costs from API abuse.
          - Data access through APIs that the key was never intended to call.
          - Non-compliance with CIS GCP Foundations Benchmark requirements.

        **Risk mitigation:**
          - Configure API target restrictions on all API keys to limit them to only required APIs.
          - Regularly review API key usage to ensure restrictions are appropriate.
          - Consider using service accounts with OAuth 2.0 instead of API keys where possible.
          - Monitor API key usage for unexpected API calls.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_apikeys_key" "example" {
              name         = "example-key"
              display_name = "Example API Key"
              project      = var.project_id

              restrictions {
                api_targets {
                  service = "maps-backend.googleapis.com"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **APIs & Services > Credentials** in the Google Cloud Console.
            2. Select the API key to update.
            3. Under **API restrictions**, select **Restrict key**.
            4. Select the specific APIs the key should be able to call.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud services api-keys update KEY_ID \
              --api-target=service=maps-backend.googleapis.com
            ```
    refs:
      - url: https://cloud.google.com/docs/authentication/api-keys
        title: API keys overview
      - url: https://cloud.google.com/docs/authentication/api-keys#api_key_restrictions
        title: API key restrictions
  - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.apiKeys.all(
        restrictions.apiTargets.length > 0
      )
  - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_apikeys_key')
    mql: |
      terraform.resources('google_apikeys_key').all(
        blocks.where(type == 'restrictions').all(
          blocks.where(type == 'api_targets') != empty
        )
      )
  - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_apikeys_key')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_apikeys_key').all(
        change.after.restrictions != empty &&
        change.after.restrictions.all(_['api_targets'] != empty)
      )
  - uid: mondoo-gcp-security-api-keys-api-restrictions-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_apikeys_key')
    mql: |
      terraform.state.resources.where(type == 'google_apikeys_key').all(
        values.restrictions != empty &&
        values.restrictions.all(_['api_targets'] != empty)
      )
  - uid: mondoo-gcp-security-api-keys-application-restrictions-configured
    title: Ensure API keys have application restrictions configured
    impact: 80
    variants:
      - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-gcp
      - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-hcl
      - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-plan
      - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-state
    docs:
      desc: |
        This check ensures that API keys have at least one type of application restriction configured (HTTP referrer, IP address, Android app, or iOS app). Application restrictions limit where the key can be used from, preventing unauthorized use if the key is leaked.

        **Why this matters**

        API keys without application restrictions can be used from any source:
          - A leaked key without restrictions can be used by anyone from any location.
          - Application restrictions act as a second layer of defense, ensuring keys only work from authorized sources.
          - Different restriction types suit different use cases: browser keys use HTTP referrers, server keys use IP addresses, mobile keys use app identifiers.

        If API keys lack application restrictions, it can lead to:
          - Unauthorized use of keys from unexpected sources.
          - API quota exhaustion from abusive callers.
          - Cost overruns from unauthorized API usage.

        **Risk mitigation:**
          - Configure appropriate application restrictions based on key usage context.
          - Use IP restrictions for server-side keys.
          - Use HTTP referrer restrictions for browser-side keys.
          - Use app restrictions for mobile application keys.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_apikeys_key" "example" {
              name         = "example-key"
              display_name = "Example API Key"
              project      = var.project_id

              restrictions {
                server_key_restrictions {
                  allowed_ips = ["10.0.0.0/8"]
                }
                api_targets {
                  service = "maps-backend.googleapis.com"
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **APIs & Services > Credentials** in the Google Cloud Console.
            2. Select the API key to update.
            3. Under **Application restrictions**, select the appropriate restriction type:
               - **HTTP referrers** for browser applications
               - **IP addresses** for server applications
               - **Android apps** or **iOS apps** for mobile applications
            4. Configure the restriction values.
            5. Click **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Add IP restrictions:

            ```bash
            gcloud services api-keys update KEY_ID \
              --allowed-ips=10.0.0.0/8
            ```

            Add HTTP referrer restrictions:

            ```bash
            gcloud services api-keys update KEY_ID \
              --allowed-referrers=https://example.com/*
            ```
    refs:
      - url: https://cloud.google.com/docs/authentication/api-keys#api_key_restrictions
        title: API key restrictions
  - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.apiKeys.all(
        restrictions.browserKeyRestrictions != empty ||
        restrictions.serverKeyRestrictions != empty ||
        restrictions.androidKeyRestrictions != empty ||
        restrictions.iosKeyRestrictions != empty
      )
  - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_apikeys_key')
    mql: |
      terraform.resources('google_apikeys_key').all(
        blocks.where(type == 'restrictions').all(
          blocks.where(type == 'server_key_restrictions' || type == 'browser_key_restrictions' || type == 'android_key_restrictions' || type == 'ios_key_restrictions') != empty
        )
      )
  - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_apikeys_key')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_apikeys_key').all(
        change.after.restrictions != empty
      )
  - uid: mondoo-gcp-security-api-keys-application-restrictions-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_apikeys_key')
    mql: |
      terraform.state.resources.where(type == 'google_apikeys_key').all(
        values.restrictions != empty
      )
  - uid: mondoo-gcp-security-api-keys-not-stale
    title: Ensure API keys have been rotated within 90 days
    impact: 60
    variants:
      - uid: mondoo-gcp-security-api-keys-not-stale-gcp
    docs:
      desc: |
        This check ensures that API keys have been created or updated within the last 90 days. Stale API keys that have not been rotated increase the window of opportunity for credential misuse and should be regularly rotated or replaced.

        **Why this matters**

        API keys that are not regularly rotated pose increasing risk over time:
          - The longer a key exists unchanged, the more likely it is to have been exposed or compromised.
          - Regular rotation limits the useful lifetime of any compromised key.
          - Rotation ensures that decommissioned applications and former team members lose access through old keys.
          - Key rotation is a standard security practice required by many compliance frameworks.

        **Risk mitigation:**
          - Implement a key rotation schedule of 90 days or less.
          - Automate key rotation as part of your CI/CD or operations pipeline.
          - Monitor key age using Cloud Monitoring and alert when keys approach the rotation deadline.
          - Delete keys that are no longer needed rather than leaving them to age.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **APIs & Services > Credentials** in the Google Cloud Console.
            2. Identify API keys that have not been updated recently.
            3. For each stale key, create a new key with the same restrictions.
            4. Update all consumers to use the new key.
            5. Delete the old key.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            List API keys and their creation dates:

            ```bash
            gcloud services api-keys list --project=PROJECT_ID
            ```

            Create a new key:

            ```bash
            gcloud services api-keys create --display-name="Rotated Key" --project=PROJECT_ID
            ```

            Delete the old key after updating consumers:

            ```bash
            gcloud services api-keys delete KEY_ID --project=PROJECT_ID
            ```
    refs:
      - url: https://cloud.google.com/docs/authentication/api-keys
        title: API keys overview
  - uid: mondoo-gcp-security-api-keys-not-stale-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.apiKeys.all(
        updated > time.now - 90 * time.day || created > time.now - 90 * time.day
      )
  # ============================================================================
  # Expanded Compute Network Checks
  # ============================================================================
  - uid: mondoo-gcp-security-compute-network-default-deleted
    title: Ensure the default network does not exist in the project
    impact: 70
    variants:
      - uid: mondoo-gcp-security-compute-network-default-deleted-gcp
      - uid: mondoo-gcp-security-compute-network-default-deleted-terraform-hcl
    docs:
      desc: |
        This check ensures that the default VPC network has been deleted from the project. The default network is automatically created with permissive firewall rules that allow SSH and RDP from anywhere, and should be replaced with custom networks following least-privilege networking principles.

        **Why this matters**

        The default network comes preconfigured with overly permissive firewall rules:
          - The default-allow-ssh rule permits SSH (port 22) from any source (0.0.0.0/0).
          - The default-allow-rdp rule permits RDP (port 3389) from any source.
          - The default-allow-icmp rule permits ICMP from any source.
          - The default-allow-internal rule permits all traffic between instances in the default network.
          - These rules create an unnecessarily large attack surface for any resources deployed to the default network.

        If the default network exists, it can lead to:
          - Accidental deployment of resources to an insecure network with permissive firewall rules.
          - Unauthorized access to instances through the default SSH and RDP rules.
          - Reduced network segmentation and isolation between workloads.
          - Non-compliance with CIS GCP Foundations Benchmark and organizational network security policies.

        **Risk mitigation:**
          - Delete the default network and all its associated firewall rules.
          - Create custom VPC networks with explicitly defined subnets and firewall rules.
          - Use organization policies to prevent automatic creation of default networks in new projects.
          - Implement VPC Service Controls for additional network-level security.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Prevent default network creation and create a custom network:

            ```hcl
            resource "google_compute_network" "custom" {
              name                    = "custom-network"
              auto_create_subnetworks = false
            }

            # Use an org policy to prevent default network creation
            resource "google_project_organization_policy" "no_default_network" {
              project    = var.project_id
              constraint = "compute.skipDefaultNetworkCreation"

              boolean_policy {
                enforced = true
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **VPC network > VPC networks** in the Google Cloud Console.
            2. Select the **default** network.
            3. Click **Delete VPC network**.
            4. Confirm the deletion. This will also delete all associated firewall rules and subnets.
            5. Create a custom VPC network with explicit subnet and firewall configurations.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Delete the default network:

            ```bash
            gcloud compute networks delete default
            ```

            Create a custom network:

            ```bash
            gcloud compute networks create custom-network \
              --subnet-mode=custom
            ```
    refs:
      - url: https://cloud.google.com/vpc/docs/vpc#default-network
        title: Default network
      - url: https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
        title: Organization policy constraints
  - uid: mondoo-gcp-security-compute-network-default-deleted-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.computeService.networks.none(name == "default")
  - uid: mondoo-gcp-security-compute-network-default-deleted-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_compute_network')
    mql: |
      terraform.resources('google_compute_network').none(
        arguments.name == "default"
      )
  - uid: mondoo-gcp-security-compute-network-dns-logging-enabled
    title: Ensure DNS logging is enabled for VPC networks
    impact: 60
    variants:
      - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-gcp
      - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-hcl
      - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-plan
      - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that DNS logging is enabled through Cloud DNS policies for VPC networks. DNS logging captures DNS queries made by resources within a VPC, providing critical data for threat detection, forensic investigation, and monitoring for data exfiltration via DNS tunneling.

        **Why this matters**

        DNS query logs provide visibility into network communication patterns:
          - DNS queries reveal which external domains resources are communicating with, enabling detection of malicious communication.
          - DNS tunneling is a common technique for data exfiltration that can only be detected through DNS query analysis.
          - DNS logs are essential for incident response to understand the scope of a compromise.
          - Many threat intelligence feeds are DNS-based and require DNS logs for correlation.

        If DNS logging is not enabled, it can lead to:
          - Inability to detect DNS-based threats like tunneling, domain generation algorithms (DGAs), or communication with known malicious domains.
          - Gaps in forensic investigation during incident response.
          - Reduced effectiveness of DNS-based threat intelligence integration.

        **Risk mitigation:**
          - Create a Cloud DNS policy with logging enabled and apply it to all VPC networks.
          - Forward DNS logs to your SIEM or security monitoring platform.
          - Configure alerts for queries to known malicious domains or unusual DNS patterns.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_dns_policy" "logging" {
              name           = "dns-logging-policy"
              enable_logging = true

              networks {
                network_url = google_compute_network.example.id
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Network services > Cloud DNS** in the Google Cloud Console.
            2. Click **DNS Server Policies** tab.
            3. Click **Create Policy**.
            4. Enable **Logging**.
            5. Select the VPC networks to apply the policy to.
            6. Click **Create**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud dns policies create dns-logging-policy \
              --enable-logging \
              --networks=NETWORK_NAME
            ```
    refs:
      - url: https://cloud.google.com/dns/docs/monitoring
        title: Cloud DNS logging and monitoring
  - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.dnsService.policies().all(enableLogging == true)
  - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_dns_policy')
    mql: |
      terraform.resources('google_dns_policy').any(
        arguments.enable_logging == true
      )
  - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_dns_policy')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_dns_policy').any(
        change.after.enable_logging == true
      )
  - uid: mondoo-gcp-security-compute-network-dns-logging-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_dns_policy')
    mql: |
      terraform.state.resources.where(type == 'google_dns_policy').any(
        values.enable_logging == true
      )
  # ============================================================================
  # Expanded Compute Subnetwork Checks
  # ============================================================================
  - uid: mondoo-gcp-security-compute-subnetwork-not-overly-broad-cidr
    title: Ensure subnetworks do not use overly broad IP CIDR ranges
    impact: 50
    variants:
      - uid: mondoo-gcp-security-compute-subnetwork-not-overly-broad-cidr-gcp
    docs:
      desc: |
        This check ensures that VPC subnetworks do not use overly broad IP CIDR ranges (/15 or larger). Excessively large subnets reduce the effectiveness of network segmentation and make it harder to contain the blast radius of security incidents.

        **Why this matters**

        Subnet size directly impacts network segmentation and security:
          - Overly broad subnets (e.g., /8 or /16) place too many resources in the same network segment.
          - Micro-segmentation becomes difficult when large numbers of resources share a single subnet.
          - Firewall rules based on subnet ranges become less effective when subnets are too large.
          - Smaller, purpose-built subnets improve security isolation and reduce blast radius.

        **Risk mitigation:**
          - Design subnets with the smallest CIDR range that meets operational requirements.
          - Use separate subnets for different workload types, environments, and security zones.
          - Implement secondary IP ranges for pods and services in GKE clusters.
          - Review subnet utilization and split oversized subnets when possible.
      remediation:
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **VPC network > VPC networks** in the Google Cloud Console.
            2. Review each subnet's IP address range.
            3. For subnets with overly broad ranges, create new subnets with appropriately sized CIDR ranges.
            4. Migrate resources to the new subnets.
            5. Delete the oversized subnets.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            List subnets and their CIDR ranges:

            ```bash
            gcloud compute networks subnets list --format="table(name,region,ipCidrRange)"
            ```

            Create a properly sized subnet:

            ```bash
            gcloud compute networks subnets create NEW_SUBNET \
              --network=NETWORK \
              --region=REGION \
              --range=10.0.0.0/24
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Define subnets with appropriately sized CIDR ranges:

            ```hcl
            resource "google_compute_subnetwork" "example" {
              name          = "example-subnet"
              ip_cidr_range = "10.0.0.0/24"
              region        = "us-central1"
              network       = google_compute_network.example.id
            }
            ```

            Avoid using CIDR ranges larger than /16 for individual subnets. Use separate subnets for different workloads and environments to maintain proper network segmentation.
    refs:
      - url: https://cloud.google.com/vpc/docs/subnets
        title: Subnets overview
  - uid: mondoo-gcp-security-compute-subnetwork-not-overly-broad-cidr-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.computeService.subnetworks
        .where(purpose == "PRIVATE" || purpose == "")
        .all(ipCidrRange != /^\d+\.\d+\.\d+\.\d+\/(([0-9]|1[0-5]))$/)
  # ============================================================================
  # Expanded Cloud Redis Checks
  # ============================================================================
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled
    title: Ensure in-transit encryption is enabled for Cloud Memorystore for Redis
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-memorystore-redis
      - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-memorystore-rediscluster
      - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-hcl
      - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-plan
      - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-state
    docs:
      desc: |
        This check ensures that in-transit encryption (TLS) is enabled on Cloud Memorystore for Redis instances and clusters. In-transit encryption encrypts all data transmitted between the client application and the Redis instance, preventing eavesdropping and man-in-the-middle attacks.

        **Why this matters**

        Without in-transit encryption, data exchanged between clients and Redis travels in plaintext over the network:
          - Attackers with network access can intercept sensitive cached data, session tokens, or application secrets.
          - Man-in-the-middle attacks can modify data in transit, leading to cache poisoning or data corruption.
          - Regulatory frameworks such as PCI-DSS, HIPAA, and SOC 2 require encryption of data in transit for services handling sensitive information.

        Enabling in-transit encryption provides:
          - TLS encryption for all client-to-server communication, protecting data confidentiality.
          - Server authentication via certificates, ensuring clients connect to the legitimate Redis endpoint.
          - Compliance with security standards that mandate encryption of data in transit.
          - Defense-in-depth when combined with AUTH and VPC network isolation.

        **Risk mitigation:**
          - Enable in-transit encryption on all Cloud Memorystore for Redis instances and clusters.
          - Ensure client applications are configured to use TLS when connecting to Redis.
          - Combine in-transit encryption with AUTH and network-level access controls.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            For Cloud Memorystore for Redis instances:

            ```hcl
            resource "google_redis_instance" "cache" {
              name           = "my-redis-instance"
              tier           = "STANDARD_HA"
              memory_size_gb = 1
              region         = "us-central1"

              transit_encryption_mode = "SERVER_AUTHENTICATION"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            Note: In-transit encryption must be configured at instance creation time and cannot be changed on an existing instance.

            1. Go to the **Memorystore > Redis** page in the Google Cloud Console.
            2. Select **Create Instance**.
            3. In the **Security** section, select **Enable in-transit encryption**.
            4. Complete the instance creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Note: In-transit encryption must be configured at instance creation time.

            For Cloud Memorystore for Redis instances:

            ```bash
            gcloud redis instances create INSTANCE_NAME \
              --region=REGION \
              --transit-encryption-mode=SERVER_AUTHENTICATION
            ```
    refs:
      - title: Cloud Memorystore for Redis in-transit encryption documentation
        url: https://cloud.google.com/memorystore/docs/redis/in-transit-encryption
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-memorystore-redis
    filters: asset.platform == "gcp-memorystore-redis"
    mql: |
      gcp.project.redisService.instance.transitEncryptionMode == "SERVER_AUTHENTICATION"
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-memorystore-rediscluster
    filters: asset.platform == "gcp-memorystore-rediscluster"
    mql: |
      gcp.project.redisService.cluster.transitEncryptionMode == "TRANSIT_ENCRYPTION_MODE_SERVER_AUTHENTICATION"
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_redis_instance')
    mql: |
      terraform.resources('google_redis_instance').all(
        arguments.transit_encryption_mode == "SERVER_AUTHENTICATION"
      )
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_redis_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_redis_instance').all(
        change.after.transit_encryption_mode == "SERVER_AUTHENTICATION"
      )
  - uid: mondoo-gcp-security-cloud-redis-transit-encryption-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_redis_instance')
    mql: |
      terraform.state.resources.where(type == 'google_redis_instance').all(
        values.transit_encryption_mode == "SERVER_AUTHENTICATION"
      )
  - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier
    title: Ensure Cloud Redis instances use the Standard HA tier
    impact: 40
    variants:
      - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-gcp
      - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-hcl
      - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-plan
      - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-state
    docs:
      desc: |
        This check ensures that Cloud Memorystore for Redis instances are using the Standard HA tier, which provides automatic failover and replication for high availability and data durability.

        **Why this matters**

        The Basic tier does not provide data replication or automatic failover:
          - A Basic tier instance failure results in complete data loss since there is no replica.
          - Standard HA tier provides cross-zone replication with automatic failover, minimizing downtime.
          - Applications relying on Redis for caching, session management, or data storage need reliable availability.
          - Data loss from a Basic tier failure can impact application state, user sessions, and business operations.

        **Risk mitigation:**
          - Use Standard HA tier for all production Redis instances.
          - Reserve Basic tier only for development or testing environments where data loss is acceptable.
          - Monitor Redis instance health and configure alerts for failover events.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_redis_instance" "cache" {
              name           = "my-redis-instance"
              tier           = "STANDARD_HA"
              memory_size_gb = 1
              region         = "us-central1"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            Note: The tier cannot be changed after instance creation.

            1. Navigate to **Memorystore > Redis** in the Google Cloud Console.
            2. Click **Create Instance**.
            3. Under **Tier**, select **Standard**.
            4. Complete instance creation.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Note: The tier cannot be changed after instance creation.

            ```bash
            gcloud redis instances create INSTANCE_NAME \
              --region=REGION \
              --tier=STANDARD_HA \
              --size=1
            ```
    refs:
      - url: https://cloud.google.com/memorystore/docs/redis/redis-tiers
        title: Memorystore for Redis tiers
  - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.redisService.instances.all(tier == "STANDARD_HA")
  - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_redis_instance')
    mql: |
      terraform.resources('google_redis_instance').all(
        arguments.tier == "STANDARD_HA"
      )
  - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_redis_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_redis_instance').all(
        change.after.tier == "STANDARD_HA"
      )
  - uid: mondoo-gcp-security-cloud-redis-standard-ha-tier-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_redis_instance')
    mql: |
      terraform.state.resources.where(type == 'google_redis_instance').all(
        values.tier == "STANDARD_HA"
      )
  - uid: mondoo-gcp-security-cloud-redis-cluster-iam-auth-enabled
    title: Ensure IAM authentication is enabled for Cloud Memorystore for Redis Cluster
    impact: 80
    variants:
      - uid: mondoo-gcp-security-cloud-redis-cluster-iam-auth-enabled-memorystore-rediscluster
    docs:
      desc: |
        This check ensures that IAM authentication is enabled on Cloud Memorystore for Redis Cluster instances. IAM authentication integrates Redis Cluster with Google Cloud's Identity and Access Management, replacing open or password-based access with identity-based access control.

        **Why this matters**

        Without IAM authentication, Redis Cluster access relies on network-level controls alone, which increases risk:
          - Any workload with network access to the cluster can execute commands without identity verification.
          - There is no audit trail of which identity accessed or modified data in the cluster.
          - Compromised workloads within the same network can freely access cached data.

        Enabling IAM authentication provides:
          - Identity-based access control using Google Cloud IAM roles and policies.
          - Audit logging of authentication attempts, enabling security monitoring and incident response.
          - Fine-grained access management through IAM, allowing different permissions for different service accounts.
          - Alignment with the principle of least privilege by granting access only to authorized identities.

        **Risk mitigation:**
          - Enable IAM authentication on all Cloud Memorystore for Redis Cluster instances.
          - Assign the appropriate IAM roles to service accounts that need Redis access.
          - Monitor IAM authentication logs through Cloud Audit Logs.
          - Combine IAM authentication with in-transit encryption and VPC network isolation.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_redis_cluster" "cluster" {
              name        = "my-redis-cluster"
              region      = "us-central1"
              shard_count = 3

              authorization_mode = "AUTH_MODE_IAM_AUTH"
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Memorystore > Redis Cluster** page in the Google Cloud Console.
            2. Select **Create Cluster**.
            3. In the **Security** section, select **IAM Auth** as the authorization mode.
            4. Complete the cluster creation.

            For existing clusters, update the authorization mode in the cluster settings.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud redis clusters create CLUSTER_NAME \
              --region=REGION \
              --shard-count=3 \
              --authorization-mode=iam-auth
            ```
    refs:
      - title: Cloud Memorystore for Redis Cluster IAM authentication documentation
        url: https://cloud.google.com/memorystore/docs/cluster/about-iam-auth
  - uid: mondoo-gcp-security-cloud-redis-cluster-iam-auth-enabled-memorystore-rediscluster
    filters: asset.platform == "gcp-memorystore-rediscluster"
    mql: |
      gcp.project.redisService.cluster.authorizationMode == "AUTH_MODE_IAM_AUTH"
  - uid: mondoo-gcp-security-cloud-redis-cluster-deletion-protection-enabled
    title: Ensure deletion protection is enabled for Cloud Memorystore for Redis Cluster
    impact: 50
    variants:
      - uid: mondoo-gcp-security-cloud-redis-cluster-deletion-protection-enabled-memorystore-rediscluster
    docs:
      desc: |
        This check ensures that deletion protection is enabled on Cloud Memorystore for Redis Cluster instances. Deletion protection prevents accidental or malicious deletion of the cluster, safeguarding data availability and service continuity.

        **Why this matters**

        Without deletion protection, a Redis Cluster can be deleted by any user or service account with sufficient IAM permissions:
          - Accidental deletion by an administrator can cause immediate data loss and service outages.
          - A compromised service account could be used to destroy critical infrastructure.
          - Automated tooling or scripts with overly broad permissions could inadvertently delete production clusters.

        Enabling deletion protection provides:
          - A safeguard against accidental cluster deletion, requiring explicit disabling before deletion can proceed.
          - An additional layer of defense against malicious actors who gain administrative access.
          - Protection for production workloads that depend on the cluster for caching or session management.
          - Alignment with operational best practices for critical infrastructure protection.

        **Risk mitigation:**
          - Enable deletion protection on all production Cloud Memorystore for Redis Cluster instances.
          - Use IAM policies to restrict who can disable deletion protection.
          - Implement change management processes for any modifications to deletion protection settings.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            ```hcl
            resource "google_redis_cluster" "cluster" {
              name        = "my-redis-cluster"
              region      = "us-central1"
              shard_count = 3

              deletion_protection_enabled = true
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Go to the **Memorystore > Redis Cluster** page in the Google Cloud Console.
            2. Select the cluster you want to update.
            3. Select **Edit**.
            4. Enable **Deletion protection**.
            5. Select **Save**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            ```bash
            gcloud redis clusters update CLUSTER_NAME \
              --region=REGION \
              --deletion-protection-enabled
            ```
    refs:
      - title: Cloud Memorystore for Redis Cluster deletion protection documentation
        url: https://cloud.google.com/memorystore/docs/cluster/about-delete-protection
  - uid: mondoo-gcp-security-cloud-redis-cluster-deletion-protection-enabled-memorystore-rediscluster
    filters: asset.platform == "gcp-memorystore-rediscluster"
    mql: |
      gcp.project.redisService.cluster.deletionProtectionEnabled == true
  # ============================================================================
  # Secret Manager Checks
  # ============================================================================
  - uid: mondoo-gcp-security-secretmanager-cmek-encryption
    title: Ensure Secret Manager secrets are encrypted with customer-managed encryption keys (CMEK)
    impact: 60
    variants:
      - uid: mondoo-gcp-security-secretmanager-cmek-encryption-gcp
      - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-hcl
      - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-plan
      - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-state
    docs:
      desc: |
        This check ensures that Secret Manager secrets are encrypted using customer-managed encryption keys (CMEK) rather than default Google-managed keys. CMEK provides organizations with full control over the encryption key lifecycle for secret data at rest.

        **Why this matters**

        Secret Manager stores sensitive credentials, API keys, certificates, and other confidential data that may require enhanced encryption controls:
          - Google-managed encryption keys do not allow organizations to control key rotation, access, or revocation independently.
          - CMEK enables organizations to revoke access to encrypted secrets by disabling or destroying the encryption key, providing a cryptographic kill switch.
          - Compliance frameworks such as PCI DSS, HIPAA, FedRAMP, and SOC 2 may require customer-managed encryption for secrets and credentials at rest.
          - CMEK provides audit trails through Cloud KMS for all key usage operations, supporting security monitoring and compliance reporting.

        If Secret Manager secrets are not encrypted with CMEK, it can lead to:
          - Inability to independently manage the encryption key lifecycle for secret data.
          - Non-compliance with data protection requirements mandating customer-managed encryption.
          - No separation of duties between the cloud provider managing encryption and the customer controlling keys.
          - Limited auditability of encryption key operations for sensitive credential data.

        **Risk mitigation:**

          - **Key control:** Full control over key lifecycle including rotation and deletion.
          - **Access management:** Fine-grained access control through Cloud KMS key policies.
          - **Auditability:** All encryption operations are logged in Cloud Audit Logs.
          - **Crypto shredding:** Usage of a customer-managed key makes crypto shredding possible. Crypto shredding is a secure data destruction technique where the encryption key is deleted, making all data encrypted with that key permanently and irreversibly unrecoverable. This is required for compliance with data retention and deletion regulations.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure a Cloud KMS key and set it as the encryption key for the secret:

            ```hcl
            resource "google_kms_key_ring" "example" {
              name     = "example-keyring"
              location = "global"
            }

            resource "google_kms_crypto_key" "example" {
              name     = "example-key"
              key_ring = google_kms_key_ring.example.id
            }

            resource "google_secret_manager_secret" "example" {
              secret_id = "example-secret"

              replication {
                user_managed {
                  replicas {
                    location = "us-central1"
                    customer_managed_encryption {
                      kms_key_name = google_kms_crypto_key.example.id
                    }
                  }
                }
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security > Secret Manager** in the Google Cloud Console.
            2. Click **Create Secret** or select an existing secret.
            3. Under **Encryption**, select **Customer-managed encryption key (CMEK)**.
            4. Select or create a Cloud KMS key for each replication location.
            5. Click **Create Secret** or **Update**.

            Note: Encryption configuration is set at secret creation time. To change encryption on an existing secret, you must create a new secret with CMEK and migrate the secret versions.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Create a secret with CMEK encryption:

            ```bash
            gcloud secrets create SECRET_ID \
              --replication-policy=user-managed \
              --locations=LOCATION \
              --kms-key-name=projects/PROJECT/locations/LOCATION/keyRings/RING/cryptoKeys/KEY
            ```

            Note: CMEK must be configured at secret creation time. To migrate an existing secret, create a new CMEK-encrypted secret and add the secret data as a new version.
    refs:
      - url: https://cloud.google.com/secret-manager/docs/cmek
        title: Customer-managed encryption keys for Secret Manager
      - url: https://cloud.google.com/secret-manager/docs/creating-and-accessing-secrets
        title: Creating and accessing secrets
  - uid: mondoo-gcp-security-secretmanager-cmek-encryption-gcp
    filters: asset.platform == 'gcp-secretmanager-secret'
    mql: gcp.project.secretmanager.secret.customerManagedEncryption != empty
  - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_secret_manager_secret')
    mql: |
      terraform.resources('google_secret_manager_secret').all(
        blocks.one(type == 'replication') &&
        blocks.where(type == 'replication').all(
          blocks.one(type == 'user_managed') &&
          blocks.where(type == 'user_managed').all(
            blocks.where(type == 'replicas').all(
              blocks.one(type == 'customer_managed_encryption')
            )
          )
        )
      )
  - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_secret_manager_secret')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_secret_manager_secret').all(
        change.after['replication'] != empty &&
        change.after['replication']['user_managed'] != empty &&
        change.after['replication']['user_managed']['replicas'] != empty &&
        change.after['replication']['user_managed']['replicas'].all(
          _['customer_managed_encryption'] != empty
        )
      )
  - uid: mondoo-gcp-security-secretmanager-cmek-encryption-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_secret_manager_secret')
    mql: |
      terraform.state.resources.where(type == 'google_secret_manager_secret').all(
        values['replication'] != empty &&
        values['replication']['user_managed'] != empty &&
        values['replication']['user_managed']['replicas'] != empty &&
        values['replication']['user_managed']['replicas'].all(
          _['customer_managed_encryption'] != empty
        )
      )
  - uid: mondoo-gcp-security-secretmanager-rotation-configured
    title: Ensure Secret Manager secrets have rotation configured
    impact: 70
    variants:
      - uid: mondoo-gcp-security-secretmanager-rotation-configured-gcp
      - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-hcl
      - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-plan
      - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-state
    docs:
      desc: |
        This check ensures that Secret Manager secrets have a rotation policy configured. Secret rotation limits the window of exposure if a secret is compromised and ensures that credentials are regularly refreshed.

        **Why this matters**

        Secrets that are never rotated present a growing security risk over time:
          - Long-lived secrets increase the window of opportunity for attackers who may have obtained the secret through a breach, log exposure, or insider threat.
          - Without rotation, a compromised secret remains valid indefinitely until manually revoked, allowing persistent unauthorized access.
          - Rotation policies enforce credential hygiene and reduce the blast radius of credential exposure incidents.
          - Compliance frameworks such as PCI DSS, NIST 800-53, and SOC 2 require periodic rotation of cryptographic keys and credentials.

        If secrets do not have rotation configured, it can lead to:
          - Extended unauthorized access if a secret is leaked or compromised without detection.
          - Non-compliance with regulatory and industry security standards that mandate credential rotation.
          - Accumulation of stale credentials that are difficult to track and manage.
          - Increased difficulty in incident response, as there is no established rotation workflow to invoke during a breach.

        **Risk mitigation:**
          - Configure rotation policies on all Secret Manager secrets with a rotation period appropriate for the sensitivity of the data.
          - Use Cloud Functions or Pub/Sub topic triggers to automate the rotation process.
          - Monitor rotation events through Cloud Audit Logs to ensure rotation is occurring as scheduled.
          - Establish organizational policies requiring rotation configuration for all new secrets.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Configure rotation on a Secret Manager secret with a Pub/Sub topic for rotation notifications:

            ```hcl
            resource "google_pubsub_topic" "rotation" {
              name = "secret-rotation-topic"
            }

            resource "google_secret_manager_secret" "example" {
              secret_id = "example-secret"

              replication {
                auto {}
              }

              rotation {
                rotation_period    = "7776000s"  # 90 days
                next_rotation_time = "2024-12-01T00:00:00Z"
              }

              topics {
                name = google_pubsub_topic.rotation.id
              }
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security > Secret Manager** in the Google Cloud Console.
            2. Select the secret you want to configure.
            3. Click **Edit Secret**.
            4. Under **Rotation**, select **Set rotation period**.
            5. Configure the rotation period (for example, 90 days).
            6. Set the next rotation time.
            7. Configure a Pub/Sub topic to receive rotation notifications.
            8. Click **Update Secret**.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            Configure rotation on an existing secret:

            ```bash
            gcloud secrets update SECRET_ID \
              --next-rotation-time="2024-12-01T00:00:00Z" \
              --rotation-period="7776000s" \
              --add-topics=projects/PROJECT/topics/ROTATION_TOPIC
            ```

            Note: A Pub/Sub topic must be configured on the secret to receive rotation notifications. The rotation period is specified in seconds (for example, 7776000s for 90 days).
    refs:
      - url: https://cloud.google.com/secret-manager/docs/secret-rotation
        title: Secret rotation in Secret Manager
      - url: https://cloud.google.com/secret-manager/docs/creating-and-accessing-secrets
        title: Creating and accessing secrets
  - uid: mondoo-gcp-security-secretmanager-rotation-configured-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.secretmanagerService.secrets.all(
        rotation != empty
      )
  - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.resources.contains(nameLabel == 'google_secret_manager_secret')
    mql: |
      terraform.resources('google_secret_manager_secret').all(
        blocks.where(type == 'rotation') != empty &&
        blocks.where(type == 'rotation').all(
          arguments.rotation_period != empty
        )
      )
  - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type == 'google_secret_manager_secret')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_secret_manager_secret').all(
        change.after.rotation != empty
      )
  - uid: mondoo-gcp-security-secretmanager-rotation-configured-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_secret_manager_secret')
    mql: |
      terraform.state.resources.where(type == 'google_secret_manager_secret').all(
        values.rotation != empty
      )
  - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible
    title: Ensure Secret Manager secrets do not have overly permissive IAM policies
    impact: 80
    variants:
      - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-gcp
      - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-hcl
      - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-plan
      - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-state
    docs:
      desc: |
        This check ensures that Secret Manager secrets do not have IAM bindings that grant access to `allUsers` or `allAuthenticatedUsers`. These principals represent unauthenticated and broadly authenticated public access, which would expose sensitive credentials to the internet.

        **Why this matters**

        Secret Manager stores highly sensitive data including API keys, database credentials, certificates, and encryption keys. Granting public access to secrets is among the most critical misconfigurations possible:
          - The `allUsers` principal allows anyone on the internet to access the secret without any authentication.
          - The `allAuthenticatedUsers` principal allows any user with a Google account to access the secret, which includes personal Gmail accounts.
          - Public access to secrets can lead to immediate credential compromise, unauthorized access to downstream systems, and full infrastructure takeover.
          - Unlike other resources, secrets often contain the keys to access multiple other systems, making exposure a cascading risk.

        If secrets have overly permissive IAM policies, it can lead to:
          - Immediate exposure of credentials, API keys, and certificates to unauthorized parties.
          - Lateral movement and privilege escalation as attackers use exposed credentials to access additional systems.
          - Data breaches across connected services that rely on the exposed credentials.
          - Non-compliance with virtually all security frameworks including PCI DSS, HIPAA, SOC 2, and NIST 800-53.

        **Risk mitigation:**
          - Audit IAM policies on all secrets to detect bindings involving `allUsers` or `allAuthenticatedUsers`.
          - Remove public access principals and replace them with specific service accounts, groups, or individual users.
          - Use organization policies to restrict the use of `allUsers` and `allAuthenticatedUsers` across your projects.
          - Implement least privilege access by granting only the `secretmanager.secretAccessor` role to specific identities that require access.
      remediation:
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure that IAM policy resources for Secret Manager secrets do not include `allUsers` or `allAuthenticatedUsers` as members:

            ```hcl
            # Correct - specific service accounts only
            resource "google_secret_manager_secret_iam_binding" "binding" {
              secret_id = google_secret_manager_secret.example.secret_id
              role      = "roles/secretmanager.secretAccessor"

              members = [
                "serviceAccount:my-service@project.iam.gserviceaccount.com",
              ]
            }
            ```
        - id: console
          desc: |
            **Using Google Cloud Console**

            1. Navigate to **Security > Secret Manager** in the Google Cloud Console.
            2. Select the secret you want to review.
            3. Click the **Permissions** tab.
            4. Review all IAM bindings for the secret.
            5. For any binding that includes `allUsers` or `allAuthenticatedUsers`:
                - Click **Edit** for that binding.
                - Remove `allUsers` and/or `allAuthenticatedUsers` from the members list.
                - Click **Save** to apply the changes.
            6. Replace removed principals with specific identities that require access.
        - id: cli
          desc: |
            **Using Google Cloud CLI**

            1. List the IAM policy for a secret:

            ```bash
            gcloud secrets get-iam-policy SECRET_ID
            ```

            2. Remove public access bindings:

            ```bash
            gcloud secrets remove-iam-policy-binding SECRET_ID \
              --member='allUsers' \
              --role='ROLE'

            gcloud secrets remove-iam-policy-binding SECRET_ID \
              --member='allAuthenticatedUsers' \
              --role='ROLE'
            ```

            3. Grant access to specific identities instead:

            ```bash
            gcloud secrets add-iam-policy-binding SECRET_ID \
              --member='serviceAccount:SA_EMAIL' \
              --role='roles/secretmanager.secretAccessor'
            ```
    refs:
      - url: https://cloud.google.com/secret-manager/docs/access-control
        title: Secret Manager access control with IAM
      - url: https://cloud.google.com/secret-manager/docs/creating-and-accessing-secrets
        title: Creating and accessing secrets
  - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-gcp
    filters: asset.platform == 'gcp'
    mql: |
      gcp.project.secretmanagerService.secrets.all(
        iamPolicy().all(
          members.none(_ == "allUsers" || _ == "allAuthenticatedUsers")
        )
      )
  - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' &&
        terraform.resources.where(nameLabel.in(['google_secret_manager_secret_iam_policy', 'google_secret_manager_secret_iam_binding', 'google_secret_manager_secret_iam_member'])) != empty
    mql: |
      terraform.resources.where(nameLabel == 'google_secret_manager_secret_iam_policy' || nameLabel == 'google_secret_manager_secret_iam_binding')
        .all(
          arguments.members == empty || arguments.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
        )
      terraform.resources('google_secret_manager_secret_iam_member').all(
        arguments.member != 'allUsers' && arguments.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
      terraform.plan.resourceChanges.contains(type == 'google_secret_manager_secret_iam_policy') ||
      terraform.plan.resourceChanges.contains(type == 'google_secret_manager_secret_iam_binding') ||
      terraform.plan.resourceChanges.contains(type == 'google_secret_manager_secret_iam_member')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_secret_manager_secret_iam_policy' || type == 'google_secret_manager_secret_iam_binding').all(
        change.after.members == empty ||
          change.after.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
      terraform.plan.resourceChanges.where(type == 'google_secret_manager_secret_iam_member').all(
        change.after.member != 'allUsers' && change.after.member != 'allAuthenticatedUsers'
      )
  - uid: mondoo-gcp-security-secretmanager-not-publicly-accessible-terraform-state
    filters: |
      asset.platform == 'terraform-state'
      terraform.state.resources.contains(type == 'google_secret_manager_secret_iam_policy') ||
      terraform.state.resources.contains(type == 'google_secret_manager_secret_iam_binding') ||
      terraform.state.resources.contains(type == 'google_secret_manager_secret_iam_member')
    mql: |
      terraform.state.resources.where(type == 'google_secret_manager_secret_iam_policy' || type == 'google_secret_manager_secret_iam_binding').all(
        values.members == empty ||
          values.members.none(_ == 'allUsers' || _ == 'allAuthenticatedUsers')
      )
      terraform.state.resources.where(type == 'google_secret_manager_secret_iam_member').all(
        values.member != 'allUsers' && values.member != 'allAuthenticatedUsers'
      )
