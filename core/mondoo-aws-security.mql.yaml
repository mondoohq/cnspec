# Copyright (c) Mondoo, Inc.
# SPDX-License-Identifier: BUSL-1.1

policies:
  - uid: mondoo-aws-security
    name: Mondoo AWS Security
    version: 5.0.0
    license: BUSL-1.1
    tags:
      mondoo.com/category: security
      mondoo.com/platform: aws,cloud
    authors:
      - name: Mondoo, Inc
        email: hello@mondoo.com
    docs:
      desc: |
        The Mondoo AWS Security policy is designed to identify critical misconfigurations that could leave your AWS infrastructure vulnerable to attackers. This policy helps organizations detect and remediate security risks before they can be exploited, reducing the likelihood of unauthorized access, data breaches, privilege escalation, and operational disruptions.

        This policy provides security checks across key AWS services, uncovering misconfigurations that could put critical resources at risk, particularly those exposed to the public internet:

        - Identity and Access Management (IAM)
        - Lambda
        - Simple Storage Service (S3)
        - Virtual Private Cloud (VPCs)
        - DynamoDB
        - Relational Database Service (RDS) & Redshift
        - Elastic Compute Cloud (EC2) instances & storage
        - Elastic File System (EFS)
        - CloudWatch
        - Elastic Load Balancers (ELBs)
        - Elasticsearch (OpenSearch Service)
        - SageMaker
        - CloudTrail

        ## Join the community!

        Our goal is to build policies that are simple to deploy, accurate, and actionable. This policy is open-source and we welcome contributions from the community, whether it's adding new checks, refining existing ones, or providing feedback. If you have suggestions to improve this policy, visit our [cnspec-policies repository](https://github.com/mondoohq/cnspec-policies).
    groups:
      - title: AWS IAM
        checks:
          - uid: mondoo-aws-security-access-keys-rotated
          - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
          - uid: mondoo-aws-security-root-account-mfa-enabled
          - uid: mondoo-aws-security-iam-password-policy
          - uid: mondoo-aws-security-iam-root-access-key-check
          - uid: mondoo-aws-security-iam-users-only-one-access-key
          - uid: mondoo-aws-security-iam-group-has-users-check
          - uid: mondoo-aws-security-iam-user-no-inline-policies-check
      - title: AWS Lambda Function
        checks:
          - uid: mondoo-aws-security-lambda-concurrency-check
          - uid: mondoo-aws-security-lambda-function-public-access-prohibited
      - title: AWS S3 Bucket
        checks:
          - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
          - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
      - title: AWS Security Group
        checks:
          - uid: mondoo-aws-security-secgroup-restricted-ssh
          - uid: mondoo-aws-security-secgroup-restricted-vnc
          - uid: mondoo-aws-security-secgroup-restricted-rdp
          - uid: mondoo-aws-security-secgroup-restrict-traffic
      - title: AWS VPC
        checks:
          - uid: mondoo-aws-security-vpc-default-security-group-closed
          - uid: mondoo-aws-security-vpc-flow-logs-enabled
          - uid: mondoo-aws-security-vpc-bpa-enabled
      - title: AWS DynamoDB Table
        checks:
          - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
      - title: AWS RDS DB Instance
        checks:
          - uid: mondoo-aws-security-rds-instance-public-access-check
          - uid: mondoo-aws-security-rds-instance-encryption-at-rest
          - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades
      - title: AWS RDS DB Cluster
        checks:
          - uid: mondoo-aws-security-rds-cluster-public-access-check
          - uid: mondoo-aws-security-rds-cluster-encryption-at-rest
          - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades
          - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl
      - title: AWS Redshift Cluster
        checks:
          - uid: mondoo-aws-security-redshift-cluster-public-access-check
      - title: AWS EC2
        checks:
          - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
          - uid: mondoo-aws-security-ec2-imdsv2-check
          - uid: mondoo-aws-security-ec2-instance-no-public-ip
          - uid: mondoo-aws-security-ec2-volume-inuse-check
          - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
          - uid: mondoo-aws-security-ebs-snapshot-encrypted
          - uid: mondoo-aws-security-ec2-encrypted-volumes
      - title: AWS EFS Filesystem
        checks:
          - uid: mondoo-aws-security-efs-encrypted-check
      - title: AWS CloudWatch
        checks:
          - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
      - title: AWS ELB Load Balancer
        checks:
          - uid: mondoo-aws-security-elb-deletion-protection-enabled
          - uid: mondoo-aws-security-elb-logging-enabled
          - uid: mondoo-aws-security-elb-security-policy-enabled
          - uid: mondoo-aws-security-elb-ssl-listener
      - title: AWS Elasticsearch Domain
        checks:
          - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
      - title: AWS KMS Key
        checks:
          - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
      - title: AWS SageMaker Notebook Instance
        checks:
          - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
      - title: AWS CloudTrail Trail
        checks:
          - uid: mondoo-aws-security-cloud-trail-encryption-enabled
          - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled
    scoring_system: highest impact
queries:
  - uid: mondoo-aws-security-iam-root-access-key-check
    title: Ensure no root user account access key exists
    impact: 85
    variants:
      - uid: mondoo-aws-security-iam-root-access-key-check-api
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-hcl
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-plan
      - uid: mondoo-aws-security-iam-root-access-key-check-terraform-state
    docs:
      desc: |
        This check ensures that the AWS root user account does not have an active access key. The AWS root user has full administrative privileges over the AWS account, making it the most powerful identity in AWS. AWS best practices recommend that root user credentials should never be used for everyday operations, and instead, AWS Identity and Access Management (IAM) users or roles should be utilized for all administrative tasks.

        **Rationale:**

        Root user access keys pose a high security risk if compromised, as they provide unrestricted access to all AWS resources. If an attacker gains access to a root user's credentials, they can:

        - Delete or modify critical resources.
        - Access sensitive data across all AWS services.
        - Disable security controls, logging, and monitoring.

        By ensuring that no root user access keys exist, organizations can enforce security best practices and reduce the risk of unauthorized access.

        **Risk mitigation:**

        - **Prevents root key compromise:** Eliminates a major attack vector for AWS account takeovers.
        - **Ensures compliance:** Aligns with security frameworks like CIS AWS Foundations Benchmark, SOC 2, PCI DSS, and ISO 27001.
        - **Encourages least privilege:** Promotes the use of IAM users and roles for secure access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users → Root User.
            3.	Under Access Keys, verify that no access keys are listed.
            4.	If an access key exists, delete it immediately:
                - Select the Access Key ID.
                - Select Delete and confirm the action.
            5.	Ensure that MFA is enabled for the root user for additional security.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if the root user has an access key:

            ```bash
            aws iam get-account-summary --query "SummaryMap.RootAccessKeysPresent"
            ```

            If the output is greater than 0, a root access key exists.

            Delete the root access key (replace ACCESS_KEY_ID with the actual key ID):

            ```bash
            aws iam delete-access-key --access-key-id ACCESS_KEY_ID --user-name root
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            AWS does not allow direct management of the root user's access key via Terraform. However, you should enforce IAM policies that prevent the creation of root access keys:

            ```hcl
            resource "aws_iam_policy" "deny_root_access_keys" {
              name        = "DenyRootAccessKeys"
              description = "Prevents creation of root user access keys"

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect   = "Deny"
                    Action   = "iam:CreateAccessKey"
                    Resource = "arn:aws:iam::123456789012:root"
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**
            
            AWS does not allow direct management of the root user's access keys via CloudFormation. However, you can create a stack that implements preventative controls:
            ```yaml
            Resources:
              DenyRootAccessKeysPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: DenyRootAccessKeys
                  Description: Prevents creation of root user access keys
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action: 'iam:CreateAccessKey'
                        Resource: 'arn:aws:iam::123456789012:root'

            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html
        title: AWS Documentation - AWS account root user
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user_manage_delete-key.html
        title: AWS Documentation - Delete access keys for the root user
  - uid: mondoo-aws-security-iam-root-access-key-check-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(properties.user == "<root_account>").all(accessKey1Active == false)
      aws.iam.credentialReport.where(properties.user == "<root_account>").all(accessKey2Active == false)
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-hcl
    filters: asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(arguments.policy.any(Statement {Effect == "Deny" && Action == "iam:CreateAccessKey"} ) )
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-plan
    filters: asset.platform == "terraform-plan"
    mql: |
      policyPlan = terraform.plan.resourceChanges.where(type == "aws_iam_policy").map(change.after.policy).first
      policyPlan.contains('Action') && policyPlan.contains('iam:CreateAccessKey')
      policyPlan.contains('Effect') && policyPlan.contains('Deny')
  - uid: mondoo-aws-security-iam-root-access-key-check-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      policyState = terraform.state.resources.where(type == "aws_iam_policy").map(values.policy).first
      policyState.contains('Action') && policyState.contains('iam:CreateAccessKey')
      policyState.contains('Effect') && policyState.contains('Deny')



  - uid: mondoo-aws-security-root-account-mfa-enabled
    title: Ensure MFA is enabled for the "root user" account
    impact: 95
    variants:
      - uid: mondoo-aws-security-root-account-mfa-enabled-single
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-hcl
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-plan
      - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Multi-Factor Authentication (MFA) is enabled for the AWS root user account. The root user has full administrative privileges over an AWS account, making it the most critical identity. Enabling MFA significantly enhances security by requiring an additional authentication factor beyond just the password.

        **Rationale:**

        The root user account is the most powerful account in AWS, and if compromised, an attacker can gain full control over all AWS resources. Without MFA, an attacker who obtains the root password (via phishing, credential leaks, or brute-force attacks) can:

        - Delete or modify critical resources.
        - Disable security controls, logging, and monitoring.
        - Access and exfiltrate sensitive data.

        By enabling Multi-Factor Authentication (MFA), organizations prevent unauthorized access, even if root credentials are compromised. AWS supports hardware MFA tokens and virtual MFA devices (such as Authy or Google Authenticator) for added security.

        **Risk mitigation:**

        - **Prevents account takeovers:** Even if the root password is stolen, MFA blocks unauthorized logins.
        - **Ensures compliance:** Meets security standards such as CIS AWS Foundations Benchmark, SOC 2, ISO 27001, and PCI DSS.
        - **Strengthens account security:** Adds an extra layer of authentication beyond the password.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users → Root User.
            3.	Under Multi-Factor Authentication (MFA), check if an MFA device is assigned.
            4.	If no MFA is enabled, select Enable MFA and choose one of the following options:
              - Virtual MFA device: Use a mobile authenticator app (e.g., Google Authenticator, Authy).
              - Hardware MFA device: Use a FIDO2 security key or an AWS-supported MFA token.
            5.	Follow the on-screen steps to scan the QR code (for virtual MFA) or register a hardware MFA device.
            6.	Enter the two consecutive MFA codes generated by the device and select Enable MFA.

        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if MFA is enabled for the root user:

            ```bash
            aws iam get-account-summary --query "SummaryMap.AccountMFAEnabled"
            ```

            If the output is 0, MFA is not enabled.

            To enable MFA, first list existing MFA devices:

            ```bash
            aws iam list-mfa-devices --user-name root
            ```

            If no device is listed, assign a new MFA device (replace arn-of-mfa-device with the correct ARN):

            ```bash
            aws iam enable-mfa-device --user-name root --serial-number arn-of-mfa-device --authentication-code-1 123456 --authentication-code-2 654321
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            AWS does not allow managing root MFA directly through Terraform. However, you can enforce a security policy that blocks root logins unless MFA is enabled:

            ```hcl
            resource "aws_iam_policy" "require_root_mfa" {
              name        = "RequireRootMFA"
              description = "Blocks root logins without MFA"

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect   = "Deny"
                    Action   = "sts:AssumeRole"
                    Resource = "*"
                    Condition = {
                      BoolIfExists = {
                        "aws:MultiFactorAuthPresent": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**
            
            ```yaml
            Resources:
              RequireRootMFAPolicy:
                Type: "AWS::IAM::ManagedPolicy"
                Properties:
                  Description: "Blocks root logins without MFA"
                  ManagedPolicyName: "RequireRootMFA"
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Deny"
                        Action: "*"
                        Resource: "*"
                        Condition:
                          Bool:
                            "aws:MultiFactorAuthPresent": "false"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/enable-virt-mfa-for-root.html
        title: Enable a virtual MFA device for the root user (console)
  - uid: mondoo-aws-security-root-account-mfa-enabled-single
    filters: asset.platform == "aws"
    mql: aws.iam.credentialReport.where(properties.user == "<root_account>").all(mfaActive == true)
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy") {
        arguments.policy {
          Statement {
            Effect == "Deny"
            Action == "sts:AssumeRole"
            Resource == "*"
            Condition {BoolIfExists {_["aws:MultiFactorAuthPresent"] == false}}
          }
        }
      }
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_xxx" )
    mql: |
      policyPlan = terraform.plan.resourceChanges.where(type == "aws_iam_policy").map(change.after.policy).first
      policyPlan.contains('Action') && policyPlan.contains('sts:AssumeRole')
      policyPlan.contains('Effect') && policyPlan.contains('Deny')
      policyPlan.contains('Resource') && policyPlan.contains('"*"')
      policyPlan.contains('aws:MultiFactorAuthPresent') && policyPlan.contains('false')
  - uid: mondoo-aws-security-root-account-mfa-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_xxx" )
    mql: |
      policyState = terraform.state.resources.where(type == "aws_iam_policy").map(values.policy).first
      policyState.contains('Action') && policyState.contains('sts:AssumeRole')
      policyState.contains('Effect') && policyState.contains('Deny')
      policyState.contains('Resource') && policyState.contains('"*"')
      policyState.contains('aws:MultiFactorAuthPresent') && policyState.contains('false')



  - uid: mondoo-aws-security-iam-password-policy
    title: Ensure strong account password policy requirements are used
    impact: 60
    props:
      - uid: mondooAWSSecurityIamPasswordPolicyMaxPasswordAge
        title: Define the maximum number of days a password is allowed to exist before being rotated
        mql: "90"
      - uid: mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength
        title: Minimum password length
        mql: "14"
      - uid: mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention
        title: Number of passwords before allowing reuse
        mql: "24"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireLowercaseCharacters
        title: Denotes whether lowercase characters are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireNumbers
        title: Denotes whether numbers are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireSymbols
        title: Denotes whether symbols are required for passwords
        mql: "true"
      - uid: mondooAWSSecurityIamPasswordPolicyRequireUppercaseCharacters
        title: Denotes whether uppercase characters are required for passwords
        mql: "true"
    variants:
      - uid: mondoo-aws-security-iam-password-policy-api
      - uid: mondoo-aws-security-iam-password-policy-terraform-hcl
      - uid: mondoo-aws-security-iam-password-policy-terraform-plan
      - uid: mondoo-aws-security-iam-password-policy-terraform-state
    docs:
      desc: |
        This check ensures that AWS accounts enforce a strong IAM password policy to enhance security by preventing weak or easily guessable passwords. A well-defined password policy helps protect against brute-force attacks, credential stuffing, and unauthorized access.

        **Rationale:**

        Without a strong password policy, IAM users may use weak passwords, increasing the risk of compromised credentials. Implementing a strict password policy ensures that AWS accounts comply with security best practices and regulatory standards such as CIS AWS Foundations Benchmark, NIST, ISO 27001, PCI DSS, and SOC 2.

        A secure IAM password policy should enforce the following requirements:

        - At least one uppercase character
        - At least one lowercase character
        - At least one number
        - At least one symbol (e.g., !@#$%^&*)
        - A minimum password length of 14 characters
        - Prevention of password reuse for at least the last 24 passwords
        - Password expiration after 90 days

        **Risk mitigation:**

        - **Prevents brute-force attacks:** Ensures passwords are complex and difficult to guess.
        - **Reduces credential stuffing risks:** Enforces frequent password changes and prevents password reuse.
        - **Ensures compliance:** Meets security requirements for regulated industries.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Account settings in the left panel.
            3.	In the Password Policy section, ensure the following settings are enabled:
              - Require at least one uppercase letter
              - Require at least one lowercase letter
              - Require at least one number
              - Require at least one symbol
              - Require a minimum password length of 14 characters
              - Prevent password reuse for the last 24 passwords
              - Require password expiration every 90 days
            4.	Select Apply Password Policy to enforce these settings.

        - id: cli
          desc: |
            **Using AWS CLI:**

            Check the current password policy settings:

            ```bash
            aws iam get-account-password-policy
            ```

            If no password policy exists, apply a strong password policy:

            ```bash
            aws iam update-account-password-policy \
            --minimum-password-length 14 \
            --require-symbols true \
            --require-numbers true \
            --require-uppercase-characters true \
            --require-lowercase-characters true \
            --max-password-age 90 \
            --password-reuse-prevention 24 \
            --allow-users-to-change-password true
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Define a strict password policy using Terraform:

            ```hcl
            resource "aws_iam_account_password_policy" "strong_policy" {
              minimum_password_length        = 14
              require_uppercase_characters   = true
              require_lowercase_characters   = true
              require_numbers                = true
              require_symbols                = true
              max_password_age               = 90
              password_reuse_prevention      = 24
              allow_users_to_change_password = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation**

            CloudFormation can enforce a strong IAM password policy by creating an AWS::IAM::AccountPasswordPolicy resource with the necessary complexity requirements:

            ```yaml
            Resources:
              StrongIAMPasswordPolicy:
                Type: "AWS::IAM::AccountPasswordPolicy"
                Properties:
                  MinimumPasswordLength: 14
                  RequireUppercaseCharacters: true
                  RequireLowercaseCharacters: true
                  RequireNumbers: true
                  RequireSymbols: true
                  MaxPasswordAge: 90
                  PasswordReusePrevention: 24
                  AllowUsersToChangePassword: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords.html
        title: User passwords in AWS
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html
        title: Set an account password policy for IAM users
  - uid: mondoo-aws-security-iam-password-policy-api
    filters: asset.platform == "aws"
    mql: |
      // Ensure properties do exist.
      aws.iam.accountPasswordPolicy.RequireUppercaseCharacters != empty
      aws.iam.accountPasswordPolicy.RequireLowercaseCharacters != empty
      aws.iam.accountPasswordPolicy.RequireSymbols != empty
      aws.iam.accountPasswordPolicy.RequireNumbers != empty
      aws.iam.accountPasswordPolicy.MinimumPasswordLength != empty
      aws.iam.accountPasswordPolicy.PasswordReusePrevention != empty
      aws.iam.accountPasswordPolicy.MaxPasswordAge != empty
      // Validate each policy setting against props
      aws.iam.accountPasswordPolicy.where(RequireUppercaseCharacters != empty).all(RequireUppercaseCharacters == props.mondooAWSSecurityIamPasswordPolicyRequireUppercaseCharacters)
      aws.iam.accountPasswordPolicy.where(RequireLowercaseCharacters != empty).all(RequireLowercaseCharacters == props.mondooAWSSecurityIamPasswordPolicyRequireLowercaseCharacters)
      aws.iam.accountPasswordPolicy.where(RequireSymbols != empty).all(RequireSymbols == props.mondooAWSSecurityIamPasswordPolicyRequireSymbols)
      aws.iam.accountPasswordPolicy.where(RequireNumbers != empty).all(RequireNumbers == props.mondooAWSSecurityIamPasswordPolicyRequireNumbers)
      aws.iam.accountPasswordPolicy.where(MinimumPasswordLength != empty).all(MinimumPasswordLength >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength)
      aws.iam.accountPasswordPolicy.where(PasswordReusePrevention != empty).all(PasswordReusePrevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention)
      aws.iam.accountPasswordPolicy.where(MaxPasswordAge != empty).all(MaxPasswordAge <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge)
  - uid: mondoo-aws-security-iam-password-policy-terraform-hcl
    filters: asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_account_password_policy") {
        arguments.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength
        arguments.require_uppercase_characters == true
        arguments.require_lowercase_characters == true
        arguments.require_numbers == true
        arguments.require_symbols == true
        arguments.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge
        arguments.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention
        arguments.allow_users_to_change_password == true
      }
  - uid: mondoo-aws-security-iam-password-policy-terraform-plan
    filters: asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_account_password_policy") {
        change.after.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength
        change.after.require_uppercase_characters == true
        change.after.require_lowercase_characters == true
        change.after.require_numbers == true
        change.after.require_symbols == true
        change.after.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge
        change.after.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention
        change.after.allow_users_to_change_password == true
      }
  - uid: mondoo-aws-security-iam-password-policy-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "aws_iam_account_password_policy") {
        values.minimum_password_length >= props.mondooAWSSecurityIamPasswordPolicyMinimumPasswordLength
        values.require_uppercase_characters == true
        values.require_lowercase_characters == true
        values.require_numbers == true
        values.require_symbols == true
        values.max_password_age <= props.mondooAWSSecurityIamPasswordPolicyMaxPasswordAge
        values.password_reuse_prevention >= props.mondooAWSSecurityIamPasswordPolicyPasswordReusePrevention
        values.allow_users_to_change_password == true
      }



  - uid: mondoo-aws-security-access-keys-rotated
    title: Ensure IAM user access keys are rotated
    impact: 70
    props:
      - uid: mondooAWSSecurityMaxAccessKeyAge
        title: Define the maximum number of days an IAM key is allowed to exist before rotation
        mql: "90"
    variants:
      - uid: mondoo-aws-security-access-keys-rotated-api
      - uid: mondoo-aws-security-access-keys-rotated-state
    docs:
      desc: |
        This check ensures that AWS IAM user access keys are regularly rotated to reduce the risk of credential compromise. Access keys should be changed periodically to prevent long-term exposure and limit the impact of potential key leaks. AWS best practices recommend rotating IAM access keys every 90 days or less.

        **Rationale:**

        IAM access keys provide programmatic access to AWS services. If an access key is compromised, an attacker could gain unauthorized access to AWS resources. Regularly rotating access keys limits the window of opportunity for an attacker to use stolen credentials.

        A strong key rotation policy helps organizations comply with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2.

        **Risk mitigation:**

        - Reduces the risk of long-term key exposure
        - Ensures compliance with security and regulatory standards
        - Limits the impact of potential credential leaks
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users in the left panel.
            3.	Select an IAM user and go to the Security Credentials tab.
            4.	Under Access Keys, check the Last Used and Created Date columns.
            5.	If a key is older than 90 days, create a new access key:
              - Select Create access key
              - Update AWS applications and scripts to use the new key
              - Deactivate and delete the old access key
            6.	Repeat this process for all IAM users with access keys.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List all IAM users with active access keys:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check the age of access keys for each user:

            ```bash
            aws iam list-access-keys --user-name <username> --query "AccessKeyMetadata[*].{AccessKeyId:AccessKeyId, CreateDate:CreateDate}"
            ```

            If a key is older than 90 days, create a new key and delete the old one:

            ```bash
            aws iam create-access-key --user-name <username>
            aws iam delete-access-key --access-key-id <old-access-key-id> --user-name <username>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            AWS does not support automatic access key rotation in Terraform, but you can enforce IAM policies to require regular key rotation:

            ```hcl
            resource "aws_iam_policy" "enforce_key_rotation" {
              name        = "EnforceKeyRotation"
              description = "Requires IAM users to rotate access keys every 90 days"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = "iam:UpdateAccessKey",
                    Resource = "*",
                    Condition = {
                      NumericGreaterThan = {
                        "aws:MultiFactorAuthAge": 7776000  # 90 days in seconds
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              # IAM policy to enforce key rotation
              EnforceKeyRotationPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: EnforceKeyRotation
                  Description: Requires IAM users to rotate access keys every 90 days
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action: 'iam:UpdateAccessKey'
                        Resource: '*'
                        Condition:
                          NumericGreaterThan:
                            'aws:MultiFactorAuthAge': 7776000  # 90 days in seconds
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
        title: AWS Documentation - Manage access keys for IAM users
  - uid: mondoo-aws-security-access-keys-rotated-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(accessKey1Active == true && time.now - userCreationTime > props.mondooAWSSecurityMaxAccessKeyAge * time.day).all(time.now - accessKey1LastRotated < props.mondooAWSSecurityMaxAccessKeyAge * time.day)
      aws.iam.credentialReport.where(accessKey2Active == true && time.now - userCreationTime > props.mondooAWSSecurityMaxAccessKeyAge * time.day).all(time.now - accessKey2LastRotated < props.mondooAWSSecurityMaxAccessKeyAge * time.day)
  - uid: mondoo-aws-security-access-keys-rotated-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_access_key")
    mql: |
      creationDate = parse.date(terraform.state.resources.where(type == "aws_iam_access_key").map(values.create_date).first)
      time.now - creationDate


  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
    title: Ensure multi-factor authentication is enabled for all IAM users with console access
    impact: 90
    variants:
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-api
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-hcl
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-plan
      - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-state
    docs:
      desc: |
        This check ensures that all AWS IAM users with console access have Multi-Factor Authentication (MFA) enabled. MFA provides an additional layer of security beyond just a username and password, reducing the risk of unauthorized account access in case credentials are compromised.

        **Rationale:**

        IAM users with console access rely on password-based authentication, which is vulnerable to phishing, credential leaks, and brute-force attacks. Without MFA, an attacker who obtains an IAM user's password can gain unauthorized access to AWS resources. Enforcing MFA helps mitigate this risk by requiring a second factor, such as a one-time code from a mobile authenticator app or a hardware security key.

        AWS best practices and security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2 require MFA for all users with administrative or privileged access.

        **Risk mitigation:**

        - Prevents unauthorized access due to stolen or weak passwords
        - Enhances security posture by enforcing multi-layer authentication
        - Aligns with compliance and security best practices
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users in the left panel.
            3.	Identify users with Console Access enabled.
            4.	Select a user and go to the Security Credentials tab.
            5.	Under Multi-Factor Authentication (MFA), check if MFA is enabled.
            6.	If MFA is not enabled:
              - Select Assign MFA Device
              - Choose a method (Virtual MFA Device, FIDO Security Key, or Hardware MFA Token)
              - Follow the setup process and enter the required MFA codes
            7.	Repeat this process for all IAM users with console access.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List IAM users with console access and check their MFA status:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            For each user, check if MFA is enabled:

            ```bash
            aws iam list-mfa-devices --user-name <username>
            ```

            If no MFA device is listed, enforce MFA by setting up a virtual MFA device:

            ```bash
            aws iam enable-mfa-device --user-name <username> --serial-number "arn-of-mfa-device" --authentication-code-1 123456 --authentication-code-2 654321
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            AWS does not allow enforcing MFA directly via Terraform, but you can create an IAM policy that denies access unless MFA is enabled:

            ```hcl
            resource "aws_iam_policy" "enforce_mfa" {
              name        = "EnforceMFA"
              description = "Require MFA for all IAM users with console access"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = [
                      "ec2:*",
                      "s3:*",
                      "iam:*",
                      "lambda:*"
                    ],
                    Resource  = "*",
                    Condition = {
                      Bool = {
                        "aws:MultiFactorAuthPresent": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              EnforceMFAPolicy:
                Type: AWS::IAM::ManagedPolicy
                Properties:
                  ManagedPolicyName: EnforceMFA
                  Description: Require MFA for all IAM users with console access
                  PolicyDocument:
                    Version: '2012-10-17'
                    Statement:
                      - Effect: Deny
                        Action:
                          - 'ec2:*'
                          - 's3:*'
                          - 'iam:*'
                          - 'lambda:*'
                        Resource: '*'
                        Condition:
                          Bool:
                            'aws:MultiFactorAuthPresent': 'false'

            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html
        title: AWS Multi-factor authentication in IAM
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html
        title: Assign a virtual MFA device in the AWS Management Console
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-api
    filters: asset.platform == "aws"
    mql: |
      aws.iam.credentialReport.where(passwordEnabled == true).all(mfaActive == true)
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(
        arguments.policy.any(
          _['Statement'].any(
            _['Condition']['Bool']['aws:MultiFactorAuthPresent'] == false
              && _['Effect'] == "Deny"
              && _['Resource'] == "*"
          )
        )
      )
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-plan
    filters: asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_policy").any(
        change.after.policy.contains('Deny') &&
        change.after.policy.contains('aws:MultiFactorAuthPresent') &&
        change.after.policy.contains('false')
      )
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "aws_iam_policy").any(
        values.policy.contains('Deny') &&
        values.policy.contains('aws:MultiFactorAuthPresent') &&
        values.policy.contains('false')
      )



  - uid: mondoo-aws-security-iam-group-has-users-check
    title: Ensure IAM groups are utilized by assigning at least one user
    impact: 30
    variants:
      - uid: mondoo-aws-security-iam-group-has-users-check-single
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-hcl
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-plan
      - uid: mondoo-aws-security-iam-group-has-users-check-terraform-state
    docs:
      desc: |
        This check ensures that IAM groups in AWS have at least one assigned user. IAM groups help manage permissions efficiently by allowing administrators to assign policies at the group level instead of managing permissions for individual IAM users. If IAM groups exist without any users, it indicates potential misconfigurations or unused access controls.

        **Rationale:**

        IAM groups simplify access management by allowing permissions to be applied collectively to users rather than individually. This reduces administrative overhead, enforces consistency, and minimizes the risk of misconfigured permissions. If IAM groups exist but have no users assigned, it may indicate:

        - Poor permission management practices.
        - Orphaned groups that should be removed or repurposed.
        - A failure to follow the principle of least privilege, leading to excessive permissions being granted to individual users.

        By ensuring that IAM groups are properly utilized, organizations can improve security, maintain structured access controls, and reduce human errors in permission assignments.

        **Risk mitigation:**

        - Reduces the risk of misconfigured permissions by enforcing structured access control.
        - Simplifies permission management by grouping users with similar roles.
        - Aligns with security best practices and compliance frameworks such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and SOC 2.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Groups in the left panel.
            3.	Review IAM groups and check if they have at least one assigned user.
            4.	If a group has no users:
              - Select the group name.
              - Go to the Users tab and select Add Users to Group.
              - Select the appropriate users and select Add Users.
            5.	If an IAM group is not needed, consider deleting it to reduce clutter.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List all IAM groups:

            ```bash
            aws iam list-groups --query "Groups[*].GroupName"
            ```

            Check if an IAM group has users assigned:

            ```bash
            aws iam get-group --group-name <group-name> --query "Users[*].UserName"
            ```

            If a group has no users, add a user to the group:

            ```bash
            aws iam add-user-to-group --group-name <group-name> --user-name <user-name>
            ```

            If a group is unused and unnecessary, delete it:

            ```bash
            aws iam delete-group --group-name <group-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure IAM users are assigned to groups in Terraform:

            ```hcl
            resource "aws_iam_group" "admins" {
              name = "Admins"
            }

            resource "aws_iam_user" "user1" {
              name = "user1"
            }

            resource "aws_iam_group_membership" "admin_membership" {
              name  = "admin-membership"
              group = aws_iam_group.admins.name
              users = [aws_iam_user.user1.name]
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            CloudFormation can manage IAM groups and group memberships. To ensure IAM groups have at least one user:

            ```yaml
            Resources:
              # Create an IAM group
              AdminGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "Administrators"
                  Path: "/"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/AdministratorAccess"

              # Create an IAM user
              AdminUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "admin-user"
                  Path: "/"

              # Add user to the group
              GroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref AdminGroup
                  Users:
                    - !Ref AdminUser
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage.html
        title: AWS Documentation - IAM user groups
  - uid: mondoo-aws-security-iam-group-has-users-check-single
    filters: asset.platform == "aws-iam-group"
    mql: aws.iam.group.usernames != empty
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_group_membership").all(
        arguments.users != empty
      )
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_group_membership").all(
        change.after.users != empty
      )
  - uid: mondoo-aws-security-iam-group-has-users-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_group")
    mql: |
      terraform.state.resources.where(type == "aws_iam_group_membership").all(
        values.users != empty
      )



  - uid: mondoo-aws-security-iam-users-only-one-access-key
    title: Ensure there is only one active access key available for any single IAM user
    impact: 70
    variants:
      - uid: mondoo-aws-security-iam-users-only-one-access-key-single
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-hcl
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-plan
      - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-state
    docs:
      desc: |
        This check ensures that each AWS IAM user has no more than one active access key. IAM users can have up to two access keys, but maintaining multiple active keys increases the risk of credential leakage and unauthorized access if one of the keys is compromised. Best practices dictate that only one active key should exist per IAM user to reduce attack surfaces and ensure proper key management.

        **Rationale:**

        Access keys provide programmatic access to AWS services. If multiple active keys exist for a user:

        - The risk of credential exposure increases.
        - It becomes harder to track and rotate access keys securely.
        - Unused keys may remain active longer than necessary, violating least privilege principles.

        AWS best practices and security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, NIST, ISO 27001, and SOC 2 recommend that IAM users should have at most one active access key at any time.

        **Risk mitigation:**

        - Reduces exposure to key compromise by minimizing unused or unnecessary credentials.
        - Simplifies access key rotation by ensuring only one key is active at any given time.
        - Enhances security posture by enforcing least privilege access for IAM users.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users in the left panel.
            3.	Select a user and go to the Security Credentials tab.
            4.	Under Access Keys, check how many active keys exist.
            5.	If more than one active access key is present:

              - Determine which key is in use.
              - Disable and delete the extra key(s).
              - If a key is needed for rotation, create a new key before deleting the old one.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List all IAM users:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check access keys for a specific user:

            ```bash
            aws iam list-access-keys --user-name <username> --query "AccessKeyMetadata[*].{AccessKeyId:AccessKeyId, Status:Status}"
            ```

            If more than one Active (Status: Active) key exists, deactivate and delete extra keys:

            ```bash
            aws iam update-access-key --user-name <username> --access-key-id <access-key-id> --status Inactive
            aws iam delete-access-key --user-name <username> --access-key-id <access-key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            AWS does not support direct enforcement of single active access keys in Terraform, but you can enforce a security policy to limit IAM users to one active key:

            ```hcl
            resource "aws_iam_policy" "limit_access_keys" {
              name        = "LimitAccessKeys"
              description = "Ensure IAM users have at most one active access key"

              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect   = "Deny",
                    Action   = "iam:CreateAccessKey",
                    Resource = "*",
                    Condition = {
                      NumericGreaterThan = {
                        "iam:AccessKeysCount": 1
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              # Policy to deny creation of more than one access key per user
              LimitAccessKeysPolicy:
                Type: "AWS::IAM::ManagedPolicy"
                Properties:
                  ManagedPolicyName: "LimitAccessKeys"
                  Description: "Ensure IAM users have at most one active access key"
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Deny"
                        Action: "iam:CreateAccessKey"
                        Resource: "*"
                        Condition:
                          NumericGreaterThanEquals:
                            "iam:ActiveAccessKeys": "1"
            ```
  - uid: mondoo-aws-security-iam-users-only-one-access-key-single
    filters: asset.platform == "aws-iam-user"
    mql: |
      aws.iam.user.accessKeys.flat.where(Status == "Active").length <= 1
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_policy")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_policy").any(
        arguments.policy.any(
          _['Statement'].any(
            _['Effect'] == "Deny" &&
            _['Action'] == "iam:CreateAccessKey" &&
            _['Condition']['NumericGreaterThan']['iam:AccessKeysCount'] >= 1
          )
        )
      )
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_policy")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_iam_policy").any(
        change.after.policy.contains('iam:CreateAccessKey') &&
        change.after.policy.contains('Deny') &&
        change.after.policy.contains('NumericGreaterThan') &&
        change.after.policy.contains('iam:AccessKeysCount')
      )
  - uid: mondoo-aws-security-iam-users-only-one-access-key-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_policy")
    mql: |
      terraform.state.resources.where(type == "aws_iam_policy").any(
        values.policy.contains('iam:CreateAccessKey') &&
        values.policy.contains('Deny') &&
        values.policy.contains('NumericGreaterThan') &&
        values.policy.contains('iam:AccessKeysCount')
      )



  - uid: mondoo-aws-security-iam-user-no-inline-policies-check
    title: Ensure IAM users receive permissions only through groups
    impact: 70
    variants:
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-hcl
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-plan
      - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-state
    docs:
      desc: |
        This check ensures that AWS IAM users do not have directly attached policies and instead receive permissions exclusively through IAM groups. Assigning permissions via groups simplifies access management, enforces least privilege principles, and reduces the risk of misconfigured permissions at the individual user level.

        **Rationale:**

        IAM users should not have inline or managed policies attached directly to their accounts. Instead, permissions should be granted via IAM groups to:

        - Ensure consistent and scalable permission management
        - Reduce the risk of excessive privileges assigned to individual users
        - Improve auditability and compliance with security frameworks such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and SOC 2

        By enforcing group-based access control, administrators can efficiently manage role-based permissions and prevent overly permissive access for individual IAM users.

        **Risk mitigation:**

        - Reduces administrative overhead by managing permissions collectively
        - Prevents privilege creep by enforcing structured access control
        - Enhances security posture by ensuring users inherit only necessary permissions
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS IAM Console.
            2.	Select Users in the left panel.
            3.	Select a user and go to the Permissions tab.
            4.	Identify users with directly attached policies (either managed or inline policies).
            5.	If direct policies exist:
              - Detach managed policies from the user.
              - Delete inline policies assigned to the user.
              - Assign the user to an IAM group that grants the necessary permissions.

        - id: cli
          desc: |
            **Using AWS CLI:**

            List all IAM users and check if they have directly attached policies:

            ```bash
            aws iam list-users --query "Users[*].UserName"
            ```

            Check managed policies attached to a user:

            ```bash
            aws iam list-attached-user-policies --user-name <username>
            ```

            Detach any managed policies:

            ```bash
            aws iam detach-user-policy --user-name <username> --policy-arn <policy-arn>
            ```

            Check inline policies assigned to a user:

            ```bash
            aws iam list-user-policies --user-name <username>
            ```

            Delete any inline policies:

            ```bash
            aws iam delete-user-policy --user-name <username> --policy-name <policy-name>
            ```

            Assign the user to an IAM group instead:

            ```bash
            aws iam add-user-to-group --group-name <group-name> --user-name <username>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Enforce group-based permissions and prevent direct policy assignments:

            ```hcl
            resource "aws_iam_group" "developers" {
              name = "Developers"
            }

            resource "aws_iam_user" "user1" {
              name = "user1"
            }

            resource "aws_iam_group_membership" "dev_group_membership" {
              name  = "dev-membership"
              group = aws_iam_group.developers.name
              users = [aws_iam_user.user1.name]
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            CloudFormation can enforce that IAM users receive permissions through groups only:

            ```yaml
            Resources:
              # Create IAM groups with appropriate permissions
              ReadOnlyGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "ReadOnlyUsers"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/ReadOnlyAccess"

              AdminGroup:
                Type: "AWS::IAM::Group"
                Properties:
                  GroupName: "Administrators"
                  ManagedPolicyArns:
                    - "arn:aws:iam::aws:policy/AdministratorAccess"

              # Create IAM users without direct policies
              ReadOnlyUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "readonly-user"
                  Path: "/"
                  # No inline policies or managed policies attached directly

              AdminUser:
                Type: "AWS::IAM::User"
                Properties:
                  UserName: "admin-user"
                  Path: "/"
                  # No inline policies or managed policies attached directly

              # Add users to the appropriate groups
              ReadOnlyUserGroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref ReadOnlyGroup
                  Users:
                    - !Ref ReadOnlyUser

              AdminUserGroupMembership:
                Type: "AWS::IAM::UserToGroupAddition"
                Properties:
                  GroupName: !Ref AdminGroup
                  Users:
                    - !Ref AdminUser
            ```
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html
        title: Managed policies and inline policies
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single
    filters: asset.platform == "aws-iam-user"
    mql: |
      aws.iam.user.policies == empty
      aws.iam.user.attachedPolicies == empty
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_iam_user")
    mql: |
      terraform.resources.where(nameLabel == "aws_iam_user_policy_attachment" || nameLabel == "aws_iam_user_policy") == empty
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_iam_user")
    mql: |
      terraform.plan.resourceChanges.none(type == "aws_iam_user_policy" || type == "aws_iam_user_policy_attachment")
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_iam_user")
    mql: |
      terraform.state.resources.none(type == "aws_iam_user_policy" || type == "aws_iam_user_policy_attachment")



  - uid: mondoo-aws-security-vpc-default-security-group-closed
    title: Ensure the default security group of every VPC restricts all traffic
    impact: 80
    variants:
      - uid: mondoo-aws-security-vpc-default-security-group-closed-single
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-hcl
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-plan
      - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-state
    docs:
      desc: |
        This check ensures that the default security group (SG) for every AWS Virtual Private Cloud (VPC) is configured to restrict all inbound and outbound traffic. By default, AWS creates a default security group for each VPC, which allows unrestricted communication between instances associated with the group. This can pose a significant security risk if not properly restricted.

        **Rationale:**

        The default security group in a VPC automatically allows all inbound and outbound traffic between instances using the same security group, which can:

        - Allow unintended access between instances, increasing the risk of lateral movement.
        - Expose resources to potential unauthorized access if assigned inadvertently.
        - Violate security best practices and compliance standards such as CIS AWS Foundations Benchmark, NIST, ISO 27001, and PCI DSS.

        To mitigate this risk, the default security group should be modified to restrict all traffic by removing all inbound and outbound rules.

        **Risk mitigation:**

        - Prevents unintended access by eliminating unrestricted communication between instances.
        - Enforces least privilege by requiring explicit security group assignments.
        - Improves network security posture by reducing exposure to internal threats.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS VPC Console.
            2.	Select Security Groups from the left panel.
            3.	Filter by “default” security groups under the VPC ID column.
            4.	For each default security group:
              - Remove all inbound rules by selecting Edit inbound rules and deleting all existing entries.
              - Remove all outbound rules by selecting Edit outbound rules and deleting all existing entries.
            5.	Save the changes to ensure that the default security group does not allow any traffic.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List all default security groups:

            ```bash
            aws ec2 describe-security-groups --filters Name=group-name,Values=default --query "SecurityGroups[*].GroupId"
            ```
            For each default security group, remove all inbound rules:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <sg-id> --protocol all --port -1 --cidr 0.0.0.0/0
            ```
            Remove all outbound rules:

            ```bash
            aws ec2 revoke-security-group-egress --group-id <sg-id> --protocol all --port -1 --cidr 0.0.0.0/0
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure the default security group restricts all traffic:

            ```hcl
            resource "aws_default_security_group" "default_sg" {
              vpc_id = aws_vpc.main.id

              ingress = []  # No inbound rules
              egress  = []  # No outbound rules

              tags = {
                Name = "Restricted Default SG"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            CloudFormation can help you manage the default security group to ensure it has no inbound or outbound rules:

            ```yaml
            Resources:
              DefaultSecurityGroup:
                Type: AWS::EC2::SecurityGroupIngress
                Properties:
                  GroupId: !GetAtt MainVPC.DefaultSecurityGroup
                  # Empty list for no inbound rules

              DefaultSecurityGroupEgress:
                Type: AWS::EC2::SecurityGroupEgress
                Properties:
                  GroupId: !GetAtt MainVPC.DefaultSecurityGroup
                  # Empty list for no outbound rules

              DefaultSecurityGroupTagging:
                Type: AWS::EC2::Tags
                Properties:
                  ResourceId: !GetAtt MainVPC.DefaultSecurityGroup
                  Tags:
                    - Key: Name
                      Value: Restricted Default SG
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Reference - EC2
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-vpc-default-security-group-closed-single
    filters: asset.platform == "aws-security-group" && aws.ec2.securitygroup.name == "default"
    mql: |
      aws.ec2.securitygroup.ipPermissions == empty
      aws.ec2.securitygroup.ipPermissionsEgress == empty
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_default_security_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_default_security_group").all(
        arguments.ingress == empty && arguments.egress == empty
      )
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_default_security_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_default_security_group").all(
        change.after.ingress == empty && change.after.egress == empty
      )
  - uid: mondoo-aws-security-vpc-default-security-group-closed-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_default_security_group")
    mql: |
      terraform.state.resources.where(type == "aws_default_security_group").all(
        values.ingress == empty && values.egress == empty
      )


  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
    title: Ensure EBS volume encryption is enabled by default
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-api
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-hcl
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-plan
      - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volume encryption is enabled by default in an AWS account. Enabling default encryption ensures that all newly created EBS volumes are encrypted automatically using AWS Key Management Service (KMS) keys. This eliminates the risk of unencrypted volumes being created inadvertently.

        **Rationale:**

        By default, EBS volumes are not encrypted unless specified during creation. Without default encryption, users may create unencrypted EBS volumes, exposing sensitive data to unauthorized access if the volume is compromised. Enabling default EBS encryption ensures:

        - Consistent enforcement of encryption across all new volumes.
        - Improved security by protecting data at rest.
        - Simplified compliance with regulations such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        **Risk mitigation:**

        - Prevents accidental creation of unencrypted volumes by enforcing encryption automatically.
        - Ensures compliance with data protection standards that require encryption at rest.
        - Reduces the risk of data breaches by protecting data stored on AWS-managed disks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select EC2 Dashboard > EBS > Settings.
            3.	Locate the Always encrypt new EBS volumes option.
            4.	If encryption is disabled, select Edit and check Enable encryption by default.
            5.	Select the KMS key to use (either the default AWS-managed key or a customer-managed key).
            6.	Select Save changes to enforce encryption by default.

        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if EBS encryption is enabled by default:

            ```bash
            aws ec2 get-ebs-encryption-by-default
            ```

            If the output is false, enable default encryption:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```

            To specify a custom KMS key for encryption:

            ```bash
            aws ec2 modify-ebs-default-kms-key-id --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```

        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure EBS encryption is enabled by default:

            ```hcl
            resource "aws_ebs_encryption_by_default" "default_encryption" {}
            ```

            To use a specific KMS key for encryption:

            ```hcl
            resource "aws_ebs_default_kms_key" "default" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            CloudFormation can enable EBS encryption by default for your AWS account:

            ```yaml
            Resources:
              DefaultEBSEncryption:
                Type: AWS::EC2::EBSEncryptionByDefault
                Properties:
                  Enabled: true

              DefaultEBSKMSKey:
                Type: AWS::EC2::EBSDefaultKMSKey
                Properties:
                  KmsKeyId: !GetAtt EBSEncryptionKey.Arn
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default
        title: AWS Documentation - Encryption by default
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-api
    filters: asset.platform == "aws"
    mql: aws.ec2.ebsEncryptionByDefault.values.all(_ == true)
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_encryption_by_default")
    mql: |
      terraform.resources.where(nameLabel == "aws_ebs_encryption_by_default").all(
        arguments.enabled == true
      )
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_encryption_by_default")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_encryption_by_default").all(
        change.after.enabled == true
      )
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_encryption_by_default")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_encryption_by_default").all(
        values.enabled == true
      )


  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
    title: Ensure public access to S3 buckets is blocked at the account level
    impact: 95
    variants:
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-single
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-hcl
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-plan
      - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-state
    docs:
      desc: |
        This check ensures that Amazon S3 Public Access Block settings are enabled at the account level to prevent accidental or intentional exposure of data stored in S3 buckets. Enforcing this setting at the account level ensures that no S3 bucket or object can be made public, even if bucket policies or ACLs attempt to allow public access.

        **Rationale:**

        By default, S3 allows granular control over access policies, but misconfigurations in bucket policies, access control lists (ACLs), or object permissions can lead to data leaks. Enforcing S3 Public Access Block settings at the account level ensures that:

        - All buckets are protected from accidental public exposure.
        - Individual users cannot override security policies by changing bucket-level settings.
        - Compliance requirements for data protection and privacy regulations (such as CIS AWS Foundations Benchmark, GDPR, PCI DSS, and ISO 27001) are met.

        **Risk mitigation:**

        - Prevents accidental public data exposure by blocking public access to all S3 resources.
        - Enhances security posture by enforcing organization-wide security policies.
        - Ensures compliance with regulatory frameworks that require strict data access controls.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS S3 Console.
            2.	Select Block Public Access Settings for this Account.
            3.	Ensure the following options are enabled:
              - Block public access to buckets and objects granted through new access control lists (ACLs)
              - Block public access to buckets and objects granted through any access control lists (ACLs)
              - Block public access to buckets and objects granted through new public bucket policies
              - Block public and cross-account access to buckets that have public policies
            4.	Select Save Changes to enforce these settings at the account level.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if public access is blocked at the account level:

            ```bash
            aws s3control get-public-access-block --account-id <account-id>
            ```

            If any of the settings are missing or set to false, enable full public access block:

            ```bash
            aws s3control put-public-access-block \
            --account-id <account-id> \
            --public-access-block-configuration '{
                "BlockPublicAcls": true,
                "IgnorePublicAcls": true,
                "BlockPublicPolicy": true,
                "RestrictPublicBuckets": true
            }'
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure account-level S3 public access block settings are enforced:

            ```hcl
            resource "aws_s3_account_public_access_block" "account_block" {
              block_public_acls       = true
              ignore_public_acls      = true
              block_public_policy     = true
              restrict_public_buckets = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            CloudFormation can enable S3 Block Public Access at the account level:

            ```yaml
            Resources:
              # Enable S3 Block Public Access at the account level
                S3AccountPublicAccessBlock:
                Type: AWS::S3::AccountPublicAccessBlock
                Properties:
                  BlockPublicAcls: true
                  IgnorePublicAcls: true
                  BlockPublicPolicy: true
                  RestrictPublicBuckets: true
            ```

    refs:
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/configuring-block-public-access-account.html
        title: Configuring block public access settings for your account
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-single
    filters: asset.platform == "aws"
    mql: |
      aws.s3control.accountPublicAccessBlock != empty
      aws.s3control.accountPublicAccessBlock.values.all(_ == true)
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_s3_account_public_access_block")
    mql: |
      terraform.resources.where(nameLabel == "aws_s3_account_public_access_block").all(
        arguments.block_public_acls == true &&
        arguments.ignore_public_acls == true &&
        arguments.block_public_policy == true &&
        arguments.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_s3_account_public_access_block")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_s3_account_public_access_block").all(
        change.after.block_public_acls == true &&
        change.after.ignore_public_acls == true &&
        change.after.block_public_policy == true &&
        change.after.restrict_public_buckets == true
      )
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_s3_account_public_access_block")
    mql: |
      terraform.state.resources.where(type == "aws_s3_account_public_access_block").all(
        values.block_public_acls == true &&
        values.ignore_public_acls == true &&
        values.block_public_policy == true &&
        values.restrict_public_buckets == true
      )



  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
    title: Ensure Amazon S3 buckets have public access restrictions enforced
    impact: 100
    variants:
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-bucket
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-hcl
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-plan
      - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that each Amazon S3 bucket has public access restrictions enforced to prevent unauthorized exposure of sensitive data. While account-level public access block settings provide a broad safeguard, bucket-level controls ensure that no individual bucket is unintentionally exposed due to misconfigurations in bucket policies, ACLs, or object permissions.

        **Rationale:**

        Amazon S3 buckets can be made publicly accessible through:

        - Bucket policies that allow public s3:GetObject or s3:ListBucket permissions.
        - Access Control Lists (ACLs) that grant READ or WRITE permissions to AllUsers (0.0.0.0/0) or AuthenticatedUsers.
        - Cross-account access where a bucket is unintentionally exposed via an overly permissive policy.

        Unrestricted public access to S3 buckets can result in:

        - Data breaches exposing sensitive files to unauthorized users.
        - Compliance violations under frameworks such as CIS AWS Foundations Benchmark, GDPR, PCI DSS, and ISO 27001.
        - Malicious exploitation, including data theft, ransomware attacks, or unauthorized data modifications.

        By enforcing bucket-level public access restrictions, organizations can prevent unintended data exposure while maintaining granular control over access permissions.

        **Risk mitigation:**

        - Prevents accidental or intentional data leaks due to misconfigured bucket policies or ACLs.
        - Strengthens security posture by enforcing explicit access control at the bucket level.
        - Ensures regulatory compliance with industry data protection standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS S3 Console.
            2.	Select a bucket and go to the Permissions tab.
            3.	Under Block public access (bucket settings), ensure the following options are enabled:
              - Block public access to buckets and objects granted through new access control lists (ACLs)
              - Block public access to buckets and objects granted through any access control lists (ACLs)
              - Block public access to buckets and objects granted through new public bucket policies
              - Block public and cross-account access to buckets that have public policies
            4.	Under Bucket policy, review the policy and ensure it does not allow `Principal: "*"` or overly permissive access rules.
            5.	Under Access Control List (ACLs), verify that no objects or buckets have `READ` or `WRITE` permissions assigned to Everyone `(public)` or `Authenticated Users`.
            6.	Save changes and confirm that public access is fully restricted.

        - id: cli
          desc: |
            **Using AWS CLI:**

            Check the public access block settings for a specific bucket:

            ```bash
            aws s3api get-public-access-block --bucket <bucket-name>
            ```

            If public access is not fully blocked, apply the following settings:

            ```bash
            aws s3api put-public-access-block --bucket <bucket-name> --public-access-block-configuration '{
                "BlockPublicAcls": true,
                "IgnorePublicAcls": true,
                "BlockPublicPolicy": true,
                "RestrictPublicBuckets": true
            }'
            ```

            Check if the bucket policy allows public access:

            ```bash
            aws s3api get-bucket-policy --bucket <bucket-name> --query "Policy"
            ```

            If a policy allows public access (Principal: "*", "Effect": "Allow", and "Action": "s3:*"), remove or modify it:

            ```bash
            aws s3api delete-bucket-policy --bucket <bucket-name>
            ```

            Check if ACLs allow public or cross-account access:

            ```bash
            aws s3api get-bucket-acl --bucket <bucket-name>
            ```

            If ACLs allow public access ("Grantee": { "URI": "http://acs.amazonaws.com/groups/global/AllUsers" }), remove the ACL:

            ```bash
            aws s3api put-bucket-acl --bucket <bucket-name> --acl private
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure S3 public access block settings are enforced at the bucket level:

            ```hcl
            resource "aws_s3_bucket_public_access_block" "secure_bucket" {
              bucket = aws_s3_bucket.my_bucket.id

              block_public_acls       = true
              ignore_public_acls      = true
              block_public_policy     = true
              restrict_public_buckets = true
            }
            ```

            Ensure S3 bucket policies do not allow public access:

            ```hcl
            resource "aws_s3_bucket_policy" "secure_policy" {
              bucket = aws_s3_bucket.my_bucket.id
              policy = jsonencode({
                Version = "2012-10-17",
                Statement = [
                  {
                    Effect    = "Deny",
                    Principal = "*",
                    Action    = "s3:*",
                    Resource  = [
                      "arn:aws:s3:::${aws_s3_bucket.my_bucket.id}",
                      "arn:aws:s3:::${aws_s3_bucket.my_bucket.id}/*"
                    ],
                    Condition = {
                      Bool = {
                        "aws:SecureTransport": "false"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation:**

            ```
            Resources:
            SecureBucketPublicAccessBlock:
              Type: AWS::S3::BucketPublicAccessBlock
              Properties:
                Bucket: !Ref MyBucket
                BlockPublicAcls: true
                IgnorePublicAcls: true
                BlockPublicPolicy: true
                RestrictPublicBuckets: true

            SecureBucketPolicy:
              Type: AWS::S3::BucketPolicy
              Properties:
                Bucket: !Ref MyBucket
                PolicyDocument:
                  Version: '2012-10-17'
                  Statement:
                    - Effect: Deny
                      Principal: '*'
                      Action: 's3:*'
                      Resource:
                        - !Sub 'arn:aws:s3:::${MyBucket}'
                        - !Sub 'arn:aws:s3:::${MyBucket}/*'
                      Condition:
                        Bool:
                          'aws:SecureTransport': 'false'
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS Documentation - Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS CLI Command Reference - aws s3api put-public-access-block
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block
        title: Terraform Documentation - AWS Provider - aws_s3_bucket_public_access_block
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-bucket
    filters: asset.platform == "aws-s3-bucket"
    mql: |
      aws.s3.bucket.publicAccessBlock != empty
      aws.s3.bucket.publicAccessBlock.BlockPublicAcls == true
      aws.s3.bucket.publicAccessBlock.BlockPublicPolicy == true
      aws.s3.bucket.publicAccessBlock.IgnorePublicAcls == true
      aws.s3.bucket.publicAccessBlock.RestrictPublicBuckets == true
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_s3_bucket" )
    mql: |
      terraform.resources.where( nameLabel == "aws_s3_bucket_public_access_block" ).all( arguments.block_public_acls == true )
      terraform.resources.where( nameLabel == "aws_s3_bucket_public_access_block" ).all( arguments.block_public_policy == true )
      terraform.resources.where( nameLabel == "aws_s3_bucket_public_access_block" ).all( arguments.ignore_public_acls == true )
      terraform.resources.where( nameLabel == "aws_s3_bucket_public_access_block" ).all( arguments.restrict_public_buckets == true )
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_s3_bucket" )
    mql: |
      terraform.plan.resourceChanges.where( type == "aws_s3_bucket_public_access_block" ).all( change.after.block_public_acls == true )
      terraform.plan.resourceChanges.where( type == "aws_s3_bucket_public_access_block" ).all( change.after.block_public_policy == true )
      terraform.plan.resourceChanges.where( type == "aws_s3_bucket_public_access_block" ).all( change.after.ignore_public_acls == true )
      terraform.plan.resourceChanges.where( type == "aws_s3_bucket_public_access_block" ).all( change.after.restrict_public_buckets == true )
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_s3_bucket" )
    mql: |
      terraform.state.resources.where( type == "aws_s3_bucket_public_access_block" ).all( values.block_public_acls == true )
      terraform.state.resources.where( type == "aws_s3_bucket_public_access_block" ).all( values.block_public_policy == true )
      terraform.state.resources.where( type == "aws_s3_bucket_public_access_block" ).all( values.ignore_public_acls == true )
      terraform.state.resources.where( type == "aws_s3_bucket_public_access_block" ).all( values.restrict_public_buckets == true )



  - uid: mondoo-aws-security-ec2-instance-no-public-ip
    title: Ensure no public IPs are associated with EC2 instances
    impact: 80
    variants:
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-api
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-hcl
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-plan
      - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EC2 instances do not have public IP addresses to prevent unintended exposure of cloud resources to the internet. Instances with public IPs can be directly accessed from the internet, increasing the risk of security breaches, unauthorized access, and potential data exfiltration.

        **Rationale:**

        By default, EC2 instances launched in a public subnet may receive an auto-assigned public IP unless explicitly disabled. Additionally, Elastic IPs (EIPs) can be manually associated with instances. Direct public access to EC2 instances poses serious security risks, including:

        - Increased attack surface for brute-force, DDoS, or credential stuffing attacks.
        - Unauthorized access if security groups, ACLs, or instance configurations are misconfigured.
        - Regulatory non-compliance with standards such as CIS AWS Foundations Benchmark, PCI DSS, and ISO 27001.

        To mitigate these risks, EC2 instances should be placed in private subnets and accessed securely using bastion hosts, AWS Systems Manager Session Manager, or VPNs instead of exposing them directly to the internet.

        **Risk mitigation:**

        - Reduces exposure to external threats by eliminating direct public access.
        - Improves security posture by enforcing network segmentation best practices.
        - Ensures compliance with cloud security frameworks and industry standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select Instances in the left panel.
            3.	Check the Public IPv4 Address column for any assigned public IPs.
            4.	If an instance has a public IP:
              - Select the instance and select Networking > Manage IP Addresses.
              - If using an Elastic IP (EIP), disassociate it from the instance.
              - Modify the instance's subnet settings to disable auto-assign public IPs.
            5.	If public access is necessary, use a bastion host, VPN, or AWS Systems Manager Session Manager instead of directly exposing the instance.
        - id: cli
          desc: |
            **Using AWS CLI:**

            List EC2 instances with public IP addresses:

            ```bash
            aws ec2 describe-instances --query "Reservations[*].Instances[*].[InstanceId, PublicIpAddress]" --output table
            ```

            If any instances have a Public IP, remove manually assigned Elastic IPs:

            ```bash
            aws ec2 disassociate-address --public-ip <public-ip-address>
            ```

            Modify an instance's network interface to remove the public IP (requires instance stop/start):

            ```bash
            aws ec2 modify-instance-attribute --instance-id <instance-id> --no-associate-public-ip-address
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure that EC2 instances are launched without public IPs:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami             = "ami-12345678"
              instance_type   = "t3.micro"
              subnet_id       = aws_subnet.private_subnet.id
              associate_public_ip_address = false  # Ensure no public IP is assigned

              tags = {
                Name = "PrivateInstance"
              }
            }
            ```

            Ensure that default VPC subnets do not auto-assign public IPs:

            ```hcl
            resource "aws_subnet" "private_subnet" {
              vpc_id            = aws_vpc.main.id
              cidr_block        = "10.0.1.0/24"
              map_public_ip_on_launch = false  # Disable auto-assigned public IPs
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure that EC2 instances do not receive public IPs in CloudFormation templates:

            ```yaml
            Resources:
              PrivateInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  SubnetId: !Ref PrivateSubnet
                  NetworkInterfaces:
                    - AssociatePublicIpAddress: false
                      DeviceIndex: 0
              PrivateSubnet:
                Type: "AWS::EC2::Subnet"
                Properties:
                  VpcId: !Ref VPC
                  CidrBlock: "10.0.1.0/24"
                  MapPublicIpOnLaunch: false
            ```
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-ip-addressing.html
        title: AWS Documentation - IP addressing for your VPCs and subnets
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance
        title: Terraform Registry - aws_instance
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-api
    filters: asset.platform == "aws"
    mql: aws.ec2.instances.all(publicIp == empty)
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_instance" )
    mql: terraform.resources.where( nameLabel == "aws_instance" ).none( arguments.associate_public_ip_address == true )
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_instance" )
    mql: terraform.plan.resourceChanges.where( type == "aws_instance" ).none( change.after.associate_public_ip_address == true )
  - uid: mondoo-aws-security-ec2-instance-no-public-ip-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_instance" )
    mql: terraform.state.resources.where( type == "aws_instance" ).none( values.associate_public_ip_address == true )



  - uid: mondoo-aws-security-ec2-imdsv2-check
    title: Ensure EC2 instances use IMDSv2 for metadata access
    impact: 90
    variants:
      - uid: mondoo-aws-security-ec2-imdsv2-check-api
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-hcl
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-plan
      - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon EC2 instances are configured to use Instance Metadata Service Version 2 (IMDSv2) instead of IMDSv1. IMDSv2 provides enhanced security by requiring session-based authentication using a token, reducing the risk of metadata theft and credential exposure.

        **Rationale:**


        IMDSv1 allows unauthenticated HTTP requests to retrieve instance metadata, making it vulnerable to server-side request forgery (SSRF) attacks, credential theft, and container breakout scenarios. IMDSv2 mitigates these risks by:

        - Requiring session-based authentication with a limited-time token.
        - Protecting against open WAF bypasses and SSRF exploitation.
        - Enforcing request headers to prevent unauthorized access.

        AWS security best practices, as well as CIS AWS Foundations Benchmark, PCI DSS, ISO 27001, and NIST, recommend enforcing IMDSv2-only for all EC2 instances.

        **Risk mitigation:**

        - Prevents unauthorized metadata access by enforcing authenticated API requests.
        - Mitigates SSRF vulnerabilities that could expose instance credentials.
        - Aligns with compliance requirements for secure cloud environments.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select Instances in the left panel.
            3.	Select an instance and go to the Details tab.
            4.	Under Metadata version, check if it is set to V2 only.
            5.	If IMDSv1 is allowed, update the settings:

              - Select Actions > Modify instance metadata options.
              - Set Metadata version to IMDSv2 only.
              - Set Hop limit to at least 1 (for containerized workloads).
              - Select Save to apply the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check the IMDS version for all EC2 instances:

            ```bash
            aws ec2 describe-instances --query "Reservations[*].Instances[*].{Instance:InstanceId, MetadataOptions:MetadataOptions}" --output table
            ```

            Update an instance to enforce IMDSv2 only:

            ```bash
            aws ec2 modify-instance-metadata-options --instance-id <instance-id> --http-tokens required --http-put-response-hop-limit 1
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure IMDSv2-only is enforced in Terraform:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              metadata_options {
                http_tokens                 = "required"  # Enforce IMDSv2
                http_put_response_hop_limit = 1
                http_endpoint               = "enabled"
              }

              tags = {
                Name = "SecureInstance"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Configure IMDSv2-only in a CloudFormation template:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  MetadataOptions:
                    HttpTokens: "required"
                    HttpPutResponseHopLimit: 1
                    HttpEndpoint: "enabled"
            ```
  - uid: mondoo-aws-security-ec2-imdsv2-check-api
    filters: |
      asset.platform == "aws"
    mql: |
      aws.ec2.instances.where(
        state != /terminated|shutting-down/
          && httpEndpoint == "enabled"
        ).all(
          httpTokens == "required"
        )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_instance")
    mql: terraform.resources.where( nameLabel == "aws_instance" ).all( blocks.where( type == "metadata_options" ) { arguments.http_endpoint == "disabled" || arguments.http_tokens == "required" } )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_instance")
    mql: terraform.plan.resourceChanges.where( type == "aws_instance" ).all( change.after.metadata_options[0].http_endpoint == "disabled" || change.after.metadata_options[0].http_tokens == "required" )
  - uid: mondoo-aws-security-ec2-imdsv2-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_instance")
    mql: terraform.state.resources.where( type == "aws_instance" ).all( values.metadata_options[0].http_endpoint == "disabled" || values.metadata_options[0].http_tokens == "required" )



  - uid: mondoo-aws-security-vpc-bpa-enabled
    title: Ensure VPC Block Public Access (BPA) is enabled
    impact: 90
    variants:
      - uid: mondoo-aws-security-vpc-bpa-enabled-single
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-hcl
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-plan
      - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Virtual Private Cloud (VPC) Block Public Access (BPA) is enabled on all VPCs to prevent accidental exposure of resources to the internet. VPC BPA provides a centralized control to block the creation of Internet Gateways, public route table entries, and public security group rules, thereby preventing resources within the VPC from becoming publicly accessible.

        **Rationale:**

        Without VPC Block Public Access enabled:

        - Resources may be inadvertently exposed to the internet through misconfigured network settings.
        - Human error during configuration changes could lead to unintended public access to sensitive workloads.
        - Compliance frameworks such as CIS AWS Foundations Benchmark, PCI DSS, and SOC 2 recommendations for network isolation may be compromised.

        VPC Block Public Access serves as a guardrail that prevents accidental exposure while still allowing for intentional public-facing workloads when properly configured.

        **Risk mitigation:**

        - **Defense Against Misconfiguration:** Prevents accidental public exposure of resources through configuration errors.
        - **Consistent Security Posture:** Maintains network isolation across the organization even during rapid development.
        - **Reduced Attack Surface:** Minimizes the risk of resources being unintentionally exposed to internet-based threats.

        **Important caveats:**

        - VPC BPA will block all new public access, which may disrupt legitimate public-facing workloads like web applications unless exceptions are properly configured.
        - Enabling BPA does not retroactively remove existing public access; existing Internet Gateways and public routes remain functional.
        - Service-linked resources managed by AWS (such as those for ELB or NAT Gateways) require explicit exemptions to continue functioning properly.
        - There may be organizational impacts requiring coordination across teams before implementation to avoid disrupting business operations.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS VPC Console.
            2. Select Your VPCs from the left panel.
            3. Select the target VPC.
            4. Under Actions, select Edit VPC settings.
            5. In the Block Public Access settings section, select Enable block public access.
            6. Configure appropriate exclusions for resources that need public access, if needed.
            7. Select Save changes to apply the settings.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Enable VPC Block Public Access for a specific VPC:

            ```bash
            aws ec2 enable-vpc-block-public-access-v2 --vpc-ids vpc-12345678
            ```

            Create an exclusion for specific resources (if necessary):

            ```bash
            aws ec2 create-vpc-block-public-access-exclusion --vpc-id vpc-12345678 --internet-gateway-exclusion-mode "allow-egress" --subnet-id subnet-12345678
            ```

            Verify the status of VPC BPA:

            ```bash
            aws ec2 describe-vpc-block-public-access --vpc-ids vpc-12345678
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            resource "aws_vpc" "main" {
              cidr_block = "10.0.0.0/16"
              tags = {
                Name = "main-vpc"
              }
            }

            resource "aws_vpc_block_public_access" "example" {
              vpc_id = aws_vpc.main.id
            }

            # Optional: If you need exclusions for specific resources
            resource "aws_vpc_block_public_access_exclusion" "example" {
              vpc_id                         = aws_vpc.main.id
              subnet_id                      = aws_subnet.public.id
              internet_gateway_exclusion_mode = "allow-egress"
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              MainVPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  Tags:
                    - Key: "Name"
                      Value: "main-vpc"

              VPCBlockPublicAccess:
                Type: "AWS::EC2::VPCBlockPublicAccess"
                Properties:
                  VpcId: !Ref MainVPC

              # Optional: If you need exclusions for specific resources
              VPCBlockPublicAccessExclusion:
                Type: "AWS::EC2::VPCBlockPublicAccessExclusion"
                Properties:
                  VpcId: !Ref MainVPC
                  SubnetId: !Ref PublicSubnet
                  InternetGatewayExclusionMode: "allow-egress"
            ```
  - uid: mondoo-aws-security-vpc-bpa-enabled-single
    filters: asset.platform == "aws-vpc"
    mql: aws.vpc.internetGatewayBlockMode != "off"
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_vpc")
    mql: |
      bpaBlock = terraform.resources.where( nameLabel == "aws_vpc_block_public_access_exclusion" )
      bpaBlock.any(arguments.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/)
      bpaBlock.any(related.where(labels.contains("aws_subnet")))
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_vpc")
    mql: |
      bpaPlan = terraform.plan.resourceChanges.where( type == "aws_vpc_block_public_access_exclusion" )
      bpaPlan.any(change.after.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/)
  - uid: mondoo-aws-security-vpc-bpa-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_vpc")
    mql: |
      bpaState = terraform.state.resources.where( type == "aws_vpc_block_public_access_exclusion" )
      bpaState.any(values.internet_gateway_exclusion_mode == /allow-egress|allow-bidirectional/)



  - uid: mondoo-aws-security-vpc-flow-logs-enabled
    title: Ensure VPC flow logging is enabled in all VPCs
    impact: 70
    variants:
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-single
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-hcl
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-plan
      - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Virtual Private Cloud (VPC) flow logs are enabled for all VPCs to capture network traffic metadata. VPC Flow Logs provide visibility into network traffic patterns, allowing security teams to monitor, detect anomalies, and investigate incidents such as unauthorized access, data exfiltration, and security breaches.

        **Rationale:**

        Without VPC Flow Logs, organizations lack visibility into ingress and egress network traffic within their AWS environment. This can lead to:

        - Difficulty in detecting security incidents, such as unauthorized connections or data leaks.
        - Lack of compliance with industry standards (e.g., CIS AWS Foundations Benchmark, NIST, PCI DSS, ISO 27001).
        - Inability to audit network activity, which is crucial for forensic investigations.

        Enabling VPC Flow Logs ensures that network traffic metadata is continuously collected, aiding in threat detection, security analytics, and compliance reporting.

        **Risk mitigation:**

        - Enhances network visibility by capturing VPC-level traffic metadata.
        - Improves threat detection by monitoring suspicious or unauthorized traffic.
        - Supports compliance requirements for security monitoring and audit logging.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS VPC Console.
            2.	Select Your VPCs from the left panel.
            3.	For each VPC:
              - Select the VPC name.
              - Go to the Flow Logs tab.
              - Select Create Flow Log and configure:
              - Filter: Choose All Traffic to capture both accepted and rejected packets.
              - Destination: Select Amazon CloudWatch Logs or Amazon S3.
              - IAM Role: Ensure an IAM role with appropriate permissions is used.
              - Log Format: Use default or a custom log format if required.
              - Select Create to enable flow logging.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if VPC Flow Logs are enabled for all VPCs:

            ```bash
            aws ec2 describe-flow-logs --query "FlowLogs[*].{VPC:ResourceId,LogGroup:LogGroupName}"
            ```

            If a VPC does not have flow logs enabled, create one:

            ```bash
            aws ec2 create-flow-logs \
            --resource-type VPC \
            --resource-ids <vpc-id> \
            --traffic-type ALL \
            --log-destination-type cloud-watch-logs \
            --log-group-name vpc-flow-logs \
            --deliver-logs-permission-arn arn:aws:iam::<account-id>:role/vpc-flow-logs-role
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure that VPC Flow Logs are enabled in Terraform:

            ```hcl
            resource "aws_flow_log" "vpc_flow_log" {
              vpc_id          = aws_vpc.main.id
              traffic_type    = "ALL"
              log_destination = aws_cloudwatch_log_group.vpc_logs.arn
            }

            resource "aws_cloudwatch_log_group" "vpc_logs" {
              name = "vpc-flow-logs"
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable VPC Flow Logs in CloudFormation:

            ```yaml
            Resources:
              VPCFlowLog:
                Type: "AWS::EC2::FlowLog"
                Properties:
                  ResourceType: "VPC"
                  ResourceId: !Ref MyVPC
                  TrafficType: "ALL"
                  LogDestinationType: "cloud-watch-logs"
                  LogGroupName: "/aws/vpc/flow-logs"
                  DeliverLogsPermissionArn: !Sub "arn:aws:iam::${AWS::AccountId}:role/vpc-flow-logs-role"
              MyVPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/index.html
        title: AWS Documentation - AWS CLI Command Reference - logs
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Command Reference - ec2
      - url: https://registry.terraform.io/providers/cloudposse/awsutils/latest/docs
        title: Terraform registry - Cloud Posse AWS Utils Provider
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-single
    filters: asset.platform == "aws-vpc"
    mql: |
      aws.vpc.flowLogs.any(
        status == "ACTIVE" &&
        destination != empty &&
        destinationType == "cloud-watch-logs" &&
        deliverLogsStatus == "SUCCESS" &&
        trafficType == "REJECT" || trafficType == "ALL"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_vpc")
    mql: |
      terraform.resources.where(nameLabel == "aws_flow_log").any(
        arguments.traffic_type == "ALL" || arguments.traffic_type == "REJECT" && arguments.log_destination_type == "cloud-watch-logs"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_vpc")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_flow_log").any(
        change.after.traffic_type == "ALL" || change.after.traffic_type == "REJECT" && change.after.log_destination_type == "cloud-watch-logs"
      )
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_vpc")
    mql: |
      terraform.state.resources.where(type == "aws_flow_log").any(
        values.traffic_type == "ALL" || values.traffic_type == "REJECT" && values.log_destination_type ==  "cloud-watch-logs"
      )



  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
    title: Ensure DynamoDB tables are encrypted with AWS Key Management Service (KMS)
    impact: 30
    variants:
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-single
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-hcl
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-plan
      - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-state
    docs:
      desc: |
        This check ensures that Amazon DynamoDB tables are encrypted using AWS Key Management Service (KMS) to protect sensitive data at rest. DynamoDB encryption at rest ensures that data is automatically encrypted before being written to disk and decrypted when read, preventing unauthorized access to stored information.

        **Rationale:**

        By default, AWS encrypts DynamoDB tables using an AWS-owned key, but customer-managed keys (CMKs) provide additional security benefits such as:

        - Access control via AWS Identity and Access Management (IAM) policies.
        - Key rotation for enhanced security and compliance.
        - Auditability with CloudTrail logging of key usage.

        Encrypting DynamoDB tables using AWS KMS CMKs aligns with security best practices and compliance standards such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.

        **Risk mitigation:**

        - Prevents unauthorized access to sensitive data by enforcing encryption at rest.
        - Enhances security by leveraging customer-managed KMS keys (CMKs) instead of default AWS-managed keys.
        - Ensures compliance with industry security and regulatory requirements.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS DynamoDB Console.
            2.	Select Tables from the left panel.
            3.	Select a table name and navigate to the Encryption section under Table Details.
            4.	Verify the KMS key type:
              - If it is AWS-owned key, change it to a Customer-managed KMS key (CMK).
              - Note that this requires creating a new table and migrating data, as encryption settings cannot be modified after table creation.
            5.	Create a new table with KMS encryption:
              - Select Create Table.
              - Under Encryption at rest, select AWS KMS and choose a Customer-Managed Key (CMK).
              - Migrate data from the old table and delete the unencrypted table.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if a DynamoDB table is encrypted with AWS KMS CMKs:

            ```bash
            aws dynamodb describe-table --table-name <table-name> --query "Table.SSEDescription"
            ```

            If KMSMasterKeyArn is missing or the SSEType is not "KMS", you need to create a new encrypted table and migrate data:

            ```bash
            aws dynamodb create-table \
            --table-name <new-table-name> \
            --attribute-definitions AttributeName=Id,AttributeType=S \
            --key-schema AttributeName=Id,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST \
            --sse-specification Enabled=true,SSEType=KMS,KMSMasterKeyId="arn:aws:kms:region:account-id:key/key-id"
            ```

            Migrate data from the old table and delete the unencrypted table:

            ```bash
            aws dynamodb delete-table --table-name <old-table-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure DynamoDB tables use KMS CMKs for encryption:

            ```hcl
            resource "aws_kms_key" "dynamodb_encryption" {
              description = "KMS key for DynamoDB encryption"
            }

            resource "aws_dynamodb_table" "secure_dynamodb" {
              name           = "secure-table"
              billing_mode   = "PAY_PER_REQUEST"
              hash_key       = "id"

              attribute {
                name = "id"
                type = "S"
              }

              server_side_encryption {
                enabled     = true
                kms_key_arn = aws_kms_key.dynamodb_encryption.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable KMS encryption for DynamoDB tables in CloudFormation:

            ```yaml
            Resources:
              SecureDynamoDBTable:
                Type: "AWS::DynamoDB::Table"
                Properties:
                  TableName: "secure-table"
                  BillingMode: "PAY_PER_REQUEST"
                  AttributeDefinitions:
                    - AttributeName: "Id"
                      AttributeType: "S"
                  KeySchema:
                    - AttributeName: "Id"
                      KeyType: "HASH"
                  SSESpecification:
                    SSEEnabled: true
                    SSEType: "KMS"
                    KMSMasterKeyId: !Ref DynamoDBKMSKey

              DynamoDBKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for DynamoDB encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: "*"
                        Action: "kms:*"
                        Resource: "*"
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/index.html
        title: AWS Documentation - AWS CLI Command Reference - DynamoDB
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
      - url: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html
        title: AWS Documentation - DynamoDB encryption at rest
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-single
    filters: asset.platform == "aws-dynamodb-table"
    mql: |
      aws.dynamodb.table.sseDescription.SSEType == "KMS"
      aws.dynamodb.table.sseDescription.Status == "ENABLED"
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_dynamodb_table")
    mql: |
      terraform.resources.where(nameLabel == "aws_dynamodb_table").any(
        blocks.where(type == "server_side_encryption").all(
          arguments.enabled == true && arguments.kms_key_arn != empty
        )
      )
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_dynamodb_table")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_dynamodb_table").all(
        change.after.server_side_encryption.any(enabled == true)
      )
      terraform.plan.resourceChanges.where(type == "aws_dynamodb_table").all(
        change.afterUnknown.server_side_encryption.any(kms_key_arn == true)
      )
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_dynamodb_table")
    mql: |
      terraform.state.resources.where(type == "aws_dynamodb_table").all(
        values.server_side_encryption.any(enabled == true)
      )
      terraform.state.resources.where(type == "aws_dynamodb_table").all(
        values.server_side_encryption.any(kms_key_arn != empty)
      )



  - uid: mondoo-aws-security-lambda-concurrency-check
    title: Ensure Lambda functions are configured with function-level concurrent execution limits
    impact: 60
    variants:
      - uid: mondoo-aws-security-lambda-concurrency-check-single
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-hcl
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-plan
      - uid: mondoo-aws-security-lambda-concurrency-check-terraform-state
    docs:
      desc: |
        This check ensures that AWS Lambda functions are configured with function-level concurrent execution limits to prevent excessive resource consumption and throttle protection at the account level. By default, Lambda functions share the account-level concurrency limit, which can lead to resource exhaustion, affecting other critical workloads if a single function consumes too many concurrent executions.

        **Rationale:**

        Without function-level concurrency limits:

        - A single function with high invocation rates can consume all available concurrency for an AWS account, causing throttling for other functions.
        - Unintentional denial-of-service (DoS) scenarios may occur due to unbounded parallel executions.
        - Compliance frameworks such as CIS AWS Foundations Benchmark, PCI DSS, and ISO 27001 recommend enforcing concurrency controls to mitigate resource exhaustion risks.

        Enforcing function-level concurrency limits ensures fair resource distribution and prevents overuse of compute resources by a single Lambda function.

        **Risk mitigation:**

        - Prevents resource starvation by limiting the number of concurrent executions per function.
        - Improves application stability by preventing accidental or intentional excessive execution.
        - Enhances security and compliance by enforcing workload isolation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS Lambda Console.
            2.	Select Functions from the left panel.
            3.	Select a Lambda function and go to the Configuration tab.
            4.	Under Concurrency, select Edit.
            5.	Enable Reserved Concurrency and set an appropriate concurrent execution limit.
            6.	Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check the current concurrency setting for a Lambda function:

            ```bash
            aws lambda get-function-concurrency --function-name <function-name>
            ```

            If no reserved concurrency is set, configure a limit:

            ```bash
            aws lambda put-function-concurrency --function-name <function-name> --reserved-concurrent-executions <limit>
            ```

            To remove a concurrency limit if needed:

            ```bash
            aws lambda delete-function-concurrency --function-name <function-name>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure Lambda functions have a reserved concurrency limit:

            ```yaml
            resource "aws_lambda_function" "secure_lambda" {
              function_name    = "SecureLambda"
              role            = aws_iam_role.lambda_role.arn
              handler         = "index.handler"
              runtime         = "python3.8"
              filename        = "lambda.zip"

              reserved_concurrent_executions = 10  # Set function-level concurrency limit
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Define reserved concurrency settings for a Lambda function in CloudFormation:

            ```yaml
            Resources:
              SecureLambdaFunction:
                Type: AWS::Lambda::Function
                Properties:
                  FunctionName: SecureLambda
                  Description: Example Lambda function with reserved concurrency.
                  Role: arn:aws:iam::123456789012:role/YourLambdaExecutionRole
                  Handler: index.handler
                  Runtime: python3.8
                  Code:
                    S3Bucket: your-s3-bucket-name
                    S3Key: lambda.zip
                  ReservedConcurrentExecutions: 10
            ```
  - uid: mondoo-aws-security-lambda-concurrency-check-single
    filters: asset.platform == "aws-lambda-function"
    mql: |
      aws.lambda.function.concurrency > 0
      aws.lambda.function.concurrency <= 100
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lambda_function")
    mql: |
      terraform.resources.where(nameLabel == "aws_lambda_function").all(
        arguments.reserved_concurrent_executions > 0 &&
        arguments.reserved_concurrent_executions <= 100
      )
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lambda_function")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lambda_function").all(
        change.after.reserved_concurrent_executions > 0 &&
        change.after.reserved_concurrent_executions <= 100
      )
  - uid: mondoo-aws-security-lambda-concurrency-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lambda_function")
    mql: |
      terraform.state.resources.where(type == "aws_lambda_function").all(
        values.reserved_concurrent_executions > 0 &&
        values.reserved_concurrent_executions <= 100
      )



  - uid: mondoo-aws-security-lambda-function-public-access-prohibited
    title: Ensure the attached policy attached to the lambda function prohibits public access
    impact: 95
    variants:
      - uid: mondoo-aws-lambda-function-public-access-prohibited-single
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-hcl
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-plan
      - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-state
    docs:
      desc: |
        This check ensures that AWS Lambda functions have resource-based policies that explicitly prohibit public access. Resource-based policies control who can invoke or access Lambda functions, and improperly configured policies may inadvertently allow unauthorized users to trigger functions or access sensitive functionality and data.

        **Rationale:**

        Without proper access controls on Lambda functions:

        - Unauthorized users may be able to invoke functions that process sensitive data or perform privileged operations.
        - Malicious actors could potentially trigger resource-intensive functions as part of a denial-of-service attack.
        - Public exposure of Lambda functions may violate compliance requirements such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and SOC 2, which mandate strict access controls for compute resources.

        Lambda functions should follow the principle of least privilege, ensuring that only explicitly authorized identities can invoke or access the function.

        **Risk mitigation:**

        - Prevents unauthorized invocation of Lambda functions by restricting access to trusted entities only.
        - Reduces the attack surface by eliminating public exposure of serverless compute resources.
        - Ensures compliance with security frameworks that require controlled access to computing resources.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS Lambda Console.
            2. Select Functions in the left panel.
            3. Select the Lambda function that has public access.
            4. Go to the Configuration tab and select Permissions.
            5. Under Resource-based policy, check for any policy statements with "Principal": "*" or "Principal": {"AWS": "*"}.
            6. Select Edit to modify the resource-based policy.
            7. Remove or update any policy statements that allow public access, restricting access to specific AWS accounts or services.
            8. Select Save to apply the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Get the current policy for a Lambda function:

            ```bash
            aws lambda get-policy --function-name <function-name>
            ```

            Remove the existing policy if it contains public access:

            ```bash
            aws lambda remove-permission --function-name <function-name> --statement-id <sid>
            ```

            Add a more restrictive policy:

            ```bash
            aws lambda add-permission \
              --function-name <function-name> \
              --statement-id AllowExecutionFromSpecificAccount \
              --action lambda:InvokeFunction \
              --principal <trusted-aws-account-id> \
              --source-account <source-account-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            resource "aws_lambda_function" "secure_function" {
              function_name = "secure-function"
              role          = aws_iam_role.lambda_role.arn
              handler       = "index.handler"
              runtime       = "nodejs18.x"
              filename      = "lambda.zip"
            }

            # Use a proper permission policy without public access
            resource "aws_lambda_permission" "secure_permission" {
              statement_id  = "AllowExecutionFromSpecificAccount"
              action        = "lambda:InvokeFunction"
              function_name = aws_lambda_function.secure_function.function_name
              principal     = "123456789012" # Specific AWS account ID, not "*"

              # Optional: Add additional restrictions
              source_account = "123456789012"
              source_arn     = "arn:aws:s3:::example-bucket"
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              SecureFunction:
                Type: AWS::Lambda::Function
                Properties:
                  FunctionName: secure-function
                  Role: !GetAtt LambdaRole.Arn
                  Handler: index.handler
                  Runtime: nodejs18.x
                  Code:
                    ZipFile: !Ref LambdaZipFile  # Or use S3Bucket/S3Key if stored in S3

              SecureFunctionPermission:
                Type: AWS::Lambda::Permission
                Properties:
                  FunctionName: !Ref SecureFunction
                  Action: lambda:InvokeFunction
                  Principal: '123456789012'  # Specific AWS account ID, not "*"
                  SourceAccount: '123456789012'
                  SourceArn: 'arn:aws:s3:::example-bucket'
                  StatementId: AllowExecutionFromSpecificAccount
            ```
  - uid: mondoo-aws-lambda-function-public-access-prohibited-single
    filters: |
      asset.platform == "aws-lambda-function"
    mql: |
      aws.lambda.function.policy.Statement.where(Effect == "Allow").all(Principal {AWS {_ != "*"}})
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lambda_permission")
    mql: |
      terraform.resources.where(nameLabel == "aws_lambda_permission").none(
        arguments.principal == "*"
      )
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lambda_permission")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lambda_permission").none(
        change.after.principal == "*"
      )
  - uid: mondoo-aws-lambda-function-public-access-prohibited-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lambda_permission")
    mql: |
      terraform.state.resources.where(type == "aws_lambda_permission").none(
        values.principal == "*"
      )



  - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades
    title: Ensure no pending OS upgrades are available for RDS instances
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades-single
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) instances have the latest operating system patches applied and no pending OS upgrades are available. Operating system patches include critical security updates, bug fixes, and performance improvements that help maintain the security posture and stability of database instances.

        **Rationale:**

        Without regular application of OS patches on RDS instances:

        - Known vulnerabilities in the underlying operating system may remain unaddressed, potentially allowing attackers to exploit these weaknesses.
        - Database instances may miss important performance improvements and stability fixes that could impact application reliability.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for timely security patch management may not be satisfied.

        While AWS manages the underlying infrastructure, customers are responsible for scheduling and applying OS patches to their RDS instances during defined maintenance windows. Postponing these upgrades increases the risk exposure window for known vulnerabilities.

        **Risk mitigation:**

        - **Security Posture:** Reduces vulnerability exposure by ensuring the latest security patches are applied.
        - **Operational Stability:** Incorporates bug fixes and performance improvements that enhance database reliability.
        - **Compliance Management:** Helps meet regulatory requirements for timely security patch management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Select the RDS instance with pending OS upgrades.
            4. Under Maintenance & backups tab, check for pending maintenance.
            5. If maintenance is pending, select Actions, then Upgrade operating system.
            6. Choose whether to apply immediately or during the next maintenance window.
            7. Select Upgrade operating system to apply the pending patches.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check for RDS instances with pending OS upgrades:

            ```bash
            aws rds describe-pending-maintenance-actions
            ```

            Apply pending upgrades immediately:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:db:instance-id \
              --apply-action system-update \
              --opt-in-type immediate
            ```

            Or schedule for next maintenance window:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:db:instance-id \
              --apply-action system-update \
              --opt-in-type next-maintenance
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # You can use auto minor version upgrades to reduce manual management
            resource "aws_db_instance" "secure_rds" {
              identifier                  = "secure-rds-instance"
              engine                      = "mysql"
              engine_version              = "8.0"
              auto_minor_version_upgrade  = true
              maintenance_window          = "Mon:03:00-Mon:04:00"

              # Other configuration parameters
              instance_class              = "db.t3.micro"
              allocated_storage           = 20
              storage_type                = "gp2"
              username                    = "admin"
              password                    = "YourSecurePassword123"
              skip_final_snapshot         = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              SecureRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "secure-rds-instance"
                  Engine: "mysql"
                  EngineVersion: "8.0"
                  AutoMinorVersionUpgrade: true
                  PreferredMaintenanceWindow: "Mon:03:00-Mon:04:00"

                  # Other configuration parameters
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  StorageType: "gp2"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  SkipFinalSnapshot: true
            ```
  - uid: mondoo-aws-security-rds-instance-no-pending-os-upgrades-single
    filters: asset.platform == "aws-rds-dbinstance"
    mql: aws.rds.dbinstance.pendingMaintenanceActions == empty



  - uid: mondoo-aws-security-rds-instance-encryption-at-rest
    title: Ensure all RDS instances are enabled for encryption-at-rest
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-single
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-hcl
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-plan
      - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-state
    docs:
      desc: |
        Amazon RDS utilizes the widely adopted AES-256 encryption algorithm, a standard in the industry, to safeguard the data stored within your DB instances. This encryption secures your information directly on the server infrastructure where your Amazon RDS DB instance resides. After encryption is enabled, Amazon RDS automatically manages access authentication and data decryption without requiring manual intervention, ensuring a minimal effect on database performance.

        **Rationale:**

        Since databases frequently contain confidential and essential data, enabling encryption is a crucial security measure. It acts as a vital layer of defense against unauthorized access or exposure of sensitive information. By activating RDS encryption, you ensure comprehensive protection, as the encryption covers the data on the instance's underlying storage, along with its automated backups, any read replicas, and all created snapshots.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Note: Encryption cannot be enabled on an existing unencrypted DB instance. Instead, create a new encrypted instance:
               - Select Create database.
               - Configure the database with the same settings as the unencrypted instance.
               - Under Encryption, enable "Turn on encryption".
               - Choose an AWS KMS key (default or custom).
               - Complete the database creation.
            4. Migrate data from the unencrypted instance to the encrypted one.
               - For MySQL/MariaDB: Use mysqldump or AWS Database Migration Service.
               - For PostgreSQL: Use pg_dump/pg_restore or AWS DMS.
               - For Oracle: Use Oracle Data Pump or AWS DMS.
               - For SQL Server: Use native backup/restore or AWS DMS.
            5. Once migration is complete, decommission the unencrypted instance.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Create a snapshot of the unencrypted instance:

            ```bash
            aws rds create-db-snapshot \
              --db-instance-identifier unencrypted-instance \
              --db-snapshot-identifier unencrypted-snapshot
            ```

            Create an encrypted copy of the snapshot:

            ```bash
            aws rds copy-db-snapshot \
              --source-db-snapshot-identifier unencrypted-snapshot \
              --target-db-snapshot-identifier encrypted-snapshot \
              --kms-key-id arn:aws:kms:region:account-id:key/key-id
            ```

            Restore a new instance from the encrypted snapshot:

            ```bash
            aws rds restore-db-instance-from-db-snapshot \
              --db-instance-identifier new-encrypted-instance \
              --db-snapshot-identifier encrypted-snapshot
            ```

            After verification, delete the unencrypted instance:

            ```bash
            aws rds delete-db-instance \
              --db-instance-identifier unencrypted-instance \
              --skip-final-snapshot
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Create a KMS key for RDS encryption
            resource "aws_kms_key" "rds_encryption_key" {
              description         = "KMS key for RDS encryption"
              enable_key_rotation = true
            }

            # Create an encrypted RDS instance
            resource "aws_db_instance" "encrypted_instance" {
              identifier           = "encrypted-rds-instance"
              engine               = "mysql"
              engine_version       = "8.0"
              instance_class       = "db.t3.micro"
              allocated_storage    = 20
              storage_type         = "gp2"
              username             = "admin"
              password             = "YourSecurePassword123"

              # Enable encryption
              storage_encrypted    = true
              kms_key_id           = aws_kms_key.rds_encryption_key.arn

              # Other configuration
              multi_az             = true
              skip_final_snapshot  = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              RDSEncryptionKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for RDS encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"

              EncryptedRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "encrypted-rds-instance"
                  Engine: "mysql"
                  EngineVersion: "8.0"
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  StorageType: "gp2"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"

                  # Enable encryption
                  StorageEncrypted: true
                  KmsKeyId: !Ref RDSEncryptionKey

                  # Other configuration
                  MultiAZ: true
                  SkipFinalSnapshot: true
            ```
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-single
    filters: asset.platform == "aws-rds-dbinstance"
    mql: aws.rds.dbinstance.storageEncrypted == true
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_db_instance")
    mql: terraform.resources.where(nameLabel == "aws_db_instance").all(arguments['storage_encrypted'] == true)
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_db_instance")
    mql: terraform.plan.resourceChanges.where(type == "aws_db_instance").all( change.after.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-instance-encryption-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_db_instance" )
    mql: terraform.state.resources.where( type == "aws_db_instance" ).all( values.storage_encrypted == true )



  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl
    title: Ensure that encryption in transit is enabled for all RDS Clusters via cluster parameter groups
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-single
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-hcl
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-plan
      - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-state
    docs:
      desc: |
        This check ensures that Amazon RDS database clusters have encryption in transit enforced through the appropriate cluster parameter group settings. Specifically, this verifies that the parameter`ssl` is set to "1" which mandates TLS/SSL connections for all database communications, preventing any unencrypted connections to the instances of the cluster.

        **Rationale:**

        Without proper parameter group configuration enforcing encryption in transit:

        - Database administrators or applications may be able to establish unencrypted connections to the cluster, even if TLS is available.
        - There is no uniform enforcement of secure connections across all instances in the cluster, potentially creating security inconsistencies.
        - Compliance frameworks such as PCI DSS, HIPAA, GDPR, and SOC 2 requirements for mandatory encryption of data in transit may not be satisfied.

        Using cluster parameter groups to enforce encryption provides a centralized and consistent approach to securing all instances within the cluster. Unlike instance-level or application-level settings, parameter groups ensure that secure connection requirements cannot be bypassed or misconfigured on individual instances.

        **Risk mitigation:**

        - **Consistent Security Policy:** Ensures uniform encryption requirements across all instances in the cluster.
        - **Prevent Configuration Drift:** Eliminates the risk of individual instances having different security settings.
        - **Compliance Enforcement:** Provides an auditable mechanism to demonstrate mandatory encryption for all database connections.

        **Note:**

        In general cluster parameter groups can be overridden by instance parameter groups, but there is no equivalent setting on instance group level to `ssl`.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS RDS Console.
            2. In the left navigation panel, select Parameter groups.
            3. Identify the cluster parameter group associated with your RDS cluster.
            4. Select the parameter group and choose Edit parameters.
            5. In the parameter search field, search for "ssl".
            6. Change the value of the ssl parameter from "0" to "1" to enforce SSL connections.
            7. Select Save changes to apply the modified parameter.
            8. If this is a new parameter group, you need to associate it with your RDS cluster:
               - Navigate to Databases in the left panel.
               - Select your RDS cluster.
               - Select Modify.
               - Under Additional configuration, select the parameter group with SSL enabled.
               - Select Continue and Apply immediately to apply the changes.
            9. After applying the changes, monitor the cluster status until it shows "Available" again.
            10. Note that the cluster may require a reboot to apply the parameter change.
        - id: cli
          desc: |
            **Using AWS CLI:**

            First, check if the cluster parameter group has SSL enabled:

            ```bash
            aws rds describe-db-cluster-parameters \
              --db-cluster-parameter-group-name <parameter-group-name> \
              --query "Parameters[?ParameterName=='ssl']"
            ```

            If SSL is not enabled (value is "0"), create a modified parameter group:

            ```bash
            # First, create a new parameter group (if needed)
            aws rds create-db-cluster-parameter-group \
              --db-cluster-parameter-group-name secure-cluster-params \
              --db-parameter-group-family aurora-mysql5.7 \
              --description "Cluster parameter group with SSL enabled"

            # Modify the SSL parameter to enforce SSL connections
            aws rds modify-db-cluster-parameter-group \
              --db-cluster-parameter-group-name secure-cluster-params \
              --parameters "ParameterName=ssl,ParameterValue=1,ApplyMethod=immediate"
            ```

            Apply the parameter group to your RDS cluster:

            ```bash
            aws rds modify-db-cluster \
              --db-cluster-identifier <cluster-identifier> \
              --db-cluster-parameter-group-name secure-cluster-params \
              --apply-immediately
            ```

            Verify the parameter group is associated and the SSL parameter is set correctly:

            ```bash
            aws rds describe-db-clusters \
              --db-cluster-identifier <cluster-identifier> \
              --query "DBClusters[*].DBClusterParameterGroup"

            aws rds describe-db-cluster-parameters \
              --db-cluster-parameter-group-name secure-cluster-params \
              --query "Parameters[?ParameterName=='ssl']"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Create a MySQL cluster parameter group with SSL enabled
            resource "aws_rds_cluster_parameter_group" "secure_cluster_params" {
              name        = "secure-cluster-params-mysql5.7"
              family      = "aurora-mysql5.7"
              description = "Cluster parameter group with SSL enabled"

              parameter {
                name  = "require_secure_transport"
                value = "ON"
              }
            }

            # Create a Postgresql cluster parameter group with SSL enabled
            resource "aws_rds_cluster_parameter_group" "secure_cluster_params" {
              name        = "secure-cluster-params-pg10"
              family      = "aurora-postgresql10"
              description = "Cluster parameter group with SSL enabled"

              parameter {
                name  = "ssl"
                value = "1"
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              # Create a cluster parameter group with SSL enabled
              SecureClusterParameterGroupMysql57:
                Type: "AWS::RDS::DBClusterParameterGroup"
                Properties:
                  Description: "Cluster parameter group with SSL enabled"
                  Family: "aurora-mysql5.7"
                  Parameters:
                    require_secure_transport: "ON"
                  Tags:
                    - Key: "Name"
                      Value: "secure-cluster-params"

              # Create a cluster parameter group with SSL enabled
              SecureClusterParameterGroupPG10:
                Type: "AWS::RDS::DBClusterParameterGroup"
                Properties:
                  Description: "Cluster parameter group with SSL enabled"
                  Family: "aurora-postgresql10"
                  Parameters:
                    ssl: 1
                  Tags:
                    - Key: "Name"
                      Value: "secure-cluster-params-pg10"
            ```
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-single
    filters: asset.platform == "aws-rds-dbcluster"
    mql: |
      clusterParameterGroup = aws.rds.dbcluster.parameterGroupName
      aws.rds.clusterParameterGroups.where(name == clusterParameterGroup)
        .all(
          parameters.where(name == 'ssl').any(value == 1)
            || parameters.where(name == 'require_secure_transport').any(value == "ON")
        )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_rds_cluster_parameter_group")
    mql: |
      awsRdsClusterParameterGroupsMySql = terraform.resources.where(nameLabel == "aws_rds_cluster_parameter_group" && arguments.family == /mysql/)
      awsRdsClusterParameterGroupsPostgresql = terraform.resources.where(nameLabel == "aws_rds_cluster_parameter_group" && arguments.family == /postgres/)

      awsRdsClusterParameterGroupsMySql.all(blocks.any(attributes {_['name']['value'] == "require_secure_transport" && _['value']['value'] == "ON" }  ) )
      awsRdsClusterParameterGroupsPostgresql.all(blocks.any(attributes {_['name']['value'] == "ssl" && _['value']['value'] == 1 }  ) )
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_rds_cluster_parameter_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_rds_cluster_parameter_group").where(change.after.family == /postgres/) {change.after.parameter.where(name == 'ssl') {value == 1} }
      terraform.plan.resourceChanges.where(type == "aws_rds_cluster_parameter_group").where(change.after.family == /mysql/) {change.after.parameter.where(name == 'require_secure_transport') {value == "ON"} }
  - uid: mondoo-aws-security-rds-cluster-parameter-group-ssl-terraform-state
    filters: asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "aws_rds_cluster_parameter_group").where(values.family == /mysql/) {values.parameter.where(name == 'require_secure_transport') {value == "ON"} values.arn}
      terraform.state.resources.where(type == "aws_rds_cluster_parameter_group").where(values.family == /postgres/) {values.parameter.where(name == 'ssl') {value == 1} values.arn}




  - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades
    title: Ensure no pending OS upgrades are available for RDS clusters
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades-single
    docs:
      desc: |
        This check ensures that Amazon RDS database clusters, including Aurora clusters, have the latest operating system patches applied and no pending OS upgrades are available. Operating system patches include critical security updates, bug fixes, and performance improvements that help maintain the security posture and stability of database clusters.

        **Rationale:**

        Without regular application of OS patches on RDS clusters:

        - Known vulnerabilities in the underlying operating system may remain unaddressed, potentially allowing attackers to exploit these weaknesses across multiple database instances.
        - Database clusters may miss important performance improvements and stability fixes that could impact application reliability and high availability.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for timely security patch management may not be satisfied.

        While AWS manages the underlying infrastructure, customers are responsible for scheduling and applying OS patches to their RDS clusters during defined maintenance windows. Postponing these upgrades increases the risk exposure window for known vulnerabilities.

        **Risk mitigation:**

        - **Security Posture:** Reduces vulnerability exposure by ensuring the latest security patches are applied across all instances in the cluster.
        - **Operational Stability:** Incorporates bug fixes and performance improvements that enhance database reliability and consistency.
        - **Compliance Management:** Helps meet regulatory requirements for timely security patch management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Look for the RDS cluster (such as an Aurora cluster) with pending OS upgrades.
            4. Under Maintenance & backups tab, check for pending maintenance.
            5. If maintenance is pending, select Actions, then Upgrade operating system.
            6. Choose whether to apply immediately or during the next maintenance window.
            7. If there are multiple instances in the cluster, you can choose to apply to all or specific instances.
            8. Select Upgrade operating system to apply the pending patches.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check for pending maintenance actions on RDS clusters:

            ```bash
            aws rds describe-pending-maintenance-actions
            ```

            Apply pending OS upgrades immediately to a cluster:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:cluster:cluster-id \
              --apply-action system-update \
              --opt-in-type immediate
            ```

            Schedule the upgrade for the next maintenance window:

            ```bash
            aws rds apply-pending-maintenance-action \
              --resource-identifier arn:aws:rds:region:account-id:cluster:cluster-id \
              --apply-action system-update \
              --opt-in-type next-maintenance
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Ensure auto minor version upgrades are enabled to reduce manual management of OS patches
            resource "aws_rds_cluster" "secure_cluster" {
              cluster_identifier      = "secure-aurora-cluster"
              engine                  = "aurora-mysql"
              engine_version          = "5.7.mysql_aurora.2.10.2"
              availability_zones      = ["us-west-2a", "us-west-2b", "us-west-2c"]
              database_name           = "production"
              master_username         = "admin"
              master_password         = "YourSecurePassword123"
              backup_retention_period = 7
              preferred_maintenance_window = "sun:05:00-sun:06:00"
              skip_final_snapshot     = true
            }

            resource "aws_rds_cluster_instance" "cluster_instances" {
              count               = 2
              identifier          = "secure-aurora-cluster-${count.index}"
              cluster_identifier  = aws_rds_cluster.secure_cluster.id
              instance_class      = "db.r5.large"
              engine              = aws_rds_cluster.secure_cluster.engine
              engine_version      = aws_rds_cluster.secure_cluster.engine_version
              auto_minor_version_upgrade = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              SecureAuroraCluster:
                Type: "AWS::RDS::DBCluster"
                Properties:
                  DBClusterIdentifier: "secure-aurora-cluster"
                  Engine: "aurora-mysql"
                  EngineVersion: "5.7.mysql_aurora.2.10.2"
                  AvailabilityZones:
                    - !Select [0, !GetAZs ""]
                    - !Select [1, !GetAZs ""]
                    - !Select [2, !GetAZs ""]
                  DatabaseName: "production"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  BackupRetentionPeriod: 7
                  PreferredMaintenanceWindow: "sun:05:00-sun:06:00"
                  DeletionProtection: true

              InstanceOne:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref SecureAuroraCluster
                  DBInstanceIdentifier: "secure-aurora-cluster-0"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
                  AutoMinorVersionUpgrade: true

              InstanceTwo:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref SecureAuroraCluster
                  DBInstanceIdentifier: "secure-aurora-cluster-1"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
                  AutoMinorVersionUpgrade: true
            ```
  - uid: mondoo-aws-security-rds-cluster-no-pending-os-upgrades-single
    filters: asset.platform == "aws-rds-dbinstance"
    mql: |
      rdsArn = asset.ids.where(_ == /^arn/).first
      aws.rds.allPendingMaintenanceActions.where(resourceArn == rdsArn) == empty



  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest
    title: Ensure all RDS clusters are set to be encrypted-at-rest
    impact: 90
    variants:
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-single
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-hcl
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-plan
      - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-state
    docs:
      desc: |
        Amazon RDS utilizes the industry-standard AES-256 encryption algorithm to safeguard the data stored within your DB clusters. This encryption secures your information directly across the cluster's underlying storage volume. Once encryption is enabled for the cluster, Amazon RDS automatically manages access authentication and data decryption transparently, designed to ensure a minimal impact on overall cluster performance.

        **Rationale:**

        Database clusters often consolidate significant amounts of sensitive or critical data. Implementing encryption is therefore a highly recommended security practice to protect this data against unauthorized access or potential disclosure. By activating RDS encryption on your cluster, you ensure comprehensive data-at-rest protection, covering the data within the shared cluster storage, as well as associated components like automated backups, cluster snapshots, and any read replicas within the cluster environment.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS RDS Console.
            2. Select Databases in the left panel.
            3. Note: Encryption cannot be enabled on an existing unencrypted DB cluster. Instead, create a new encrypted cluster:
               - Select Create database.
               - Choose Amazon Aurora.
               - Configure the cluster with the same settings as the unencrypted cluster.
               - Under Encryption, enable "Turn on encryption".
               - Choose an AWS KMS key (default or custom).
               - Complete the cluster creation.
            4. Migrate data from the unencrypted cluster to the encrypted one using one of these methods:
               - For Aurora MySQL: Use mysqldump, AWS Database Migration Service, or native Aurora backup/restore.
               - For Aurora PostgreSQL: Use pg_dump/pg_restore, logical replication, or AWS DMS.
            5. Once migration is complete, decommission the unencrypted cluster.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Export data from unencrypted cluster (for MySQL):

            ```bash
            # Use the RDS export feature to S3
            aws rds start-export-task \
              --export-task-identifier "export-unencrypted-cluster" \
              --source-arn "arn:aws:rds:region:account-id:cluster:unencrypted-cluster" \
              --s3-bucket-name "your-export-bucket" \
              --iam-role-arn "arn:aws:iam::account-id:role/rds-s3-export-role" \
              --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```

            Create a new encrypted cluster:

            ```bash
            aws rds create-db-cluster \
              --db-cluster-identifier encrypted-cluster \
              --engine aurora-mysql \
              --engine-version 5.7.mysql_aurora.2.10.2 \
              --master-username admin \
              --master-user-password YourSecurePassword123 \
              --storage-encrypted \
              --kms-key-id arn:aws:kms:region:account-id:key/key-id
            ```

            Create DB instances for the new cluster:

            ```bash
            aws rds create-db-instance \
              --db-instance-identifier encrypted-instance-1 \
              --db-cluster-identifier encrypted-cluster \
              --engine aurora-mysql \
              --db-instance-class db.r5.large
            ```

            After migration and verification, delete the unencrypted cluster:

            ```bash
            aws rds delete-db-cluster \
              --db-cluster-identifier unencrypted-cluster \
              --skip-final-snapshot
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Create a KMS key for RDS cluster encryption
            resource "aws_kms_key" "aurora_encryption_key" {
              description         = "KMS key for Aurora cluster encryption"
              enable_key_rotation = true
            }

            # Create an encrypted Aurora cluster
            resource "aws_rds_cluster" "encrypted_cluster" {
              cluster_identifier      = "encrypted-aurora-cluster"
              engine                  = "aurora-mysql"
              engine_version          = "5.7.mysql_aurora.2.10.2"
              availability_zones      = ["us-west-2a", "us-west-2b", "us-west-2c"]
              database_name           = "production"
              master_username         = "admin"
              master_password         = "YourSecurePassword123"
              backup_retention_period = 7
              preferred_backup_window = "07:00-09:00"

              # Enable encryption
              storage_encrypted       = true
              kms_key_id              = aws_kms_key.aurora_encryption_key.arn

              skip_final_snapshot     = true
            }

            # Create cluster instances
            resource "aws_rds_cluster_instance" "cluster_instances" {
              count               = 2
              identifier          = "encrypted-aurora-cluster-${count.index}"
              cluster_identifier  = aws_rds_cluster.encrypted_cluster.id
              instance_class      = "db.r5.large"
              engine              = aws_rds_cluster.encrypted_cluster.engine
              engine_version      = aws_rds_cluster.encrypted_cluster.engine_version
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              AuroraEncryptionKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for Aurora cluster encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"

              EncryptedAuroraCluster:
                Type: "AWS::RDS::DBCluster"
                Properties:
                  DBClusterIdentifier: "encrypted-aurora-cluster"
                  Engine: "aurora-mysql"
                  EngineVersion: "5.7.mysql_aurora.2.10.2"
                  AvailabilityZones:
                    - !Select [0, !GetAZs ""]
                    - !Select [1, !GetAZs ""]
                    - !Select [2, !GetAZs ""]
                  DatabaseName: "production"
                  MasterUsername: "admin"
                  MasterUserPassword: "YourSecurePassword123"
                  BackupRetentionPeriod: 7
                  PreferredBackupWindow: "07:00-09:00"

                  # Enable encryption
                  StorageEncrypted: true
                  KmsKeyId: !Ref AuroraEncryptionKey

                  DeletionProtection: true

              InstanceOne:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref EncryptedAuroraCluster
                  DBInstanceIdentifier: "encrypted-aurora-cluster-0"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"

              InstanceTwo:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBClusterIdentifier: !Ref EncryptedAuroraCluster
                  DBInstanceIdentifier: "encrypted-aurora-cluster-1"
                  DBInstanceClass: "db.r5.large"
                  Engine: "aurora-mysql"
            ```
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-single
    filters: |
      asset.platform == "aws-rds-dbcluster"
    mql: |
      aws.rds.dbcluster.storageEncrypted == true
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_rds_cluster")
    mql: terraform.resources.where(nameLabel == "aws_rds_cluster").all(arguments['storage_encrypted'] == true)
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_rds_cluster")
    mql: terraform.plan.resourceChanges.where(type == "aws_rds_cluster").all( change.after.storage_encrypted == true )
  - uid: mondoo-aws-security-rds-cluster-encryption-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_rds_cluster" )
    mql: terraform.state.resources.where( type == "aws_rds_cluster" ).all( values.storage_encrypted == true )



  - uid: mondoo-aws-security-rds-cluster-public-access-check
    title: Ensure all RDS clusters are not publicly accessible
    impact: 100
    variants:
      - uid: mondoo-aws-security-rds-cluster-public-access-check-single
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) clusters and cluster instances are not publicly accessible to prevent unauthorized access to sensitive databases. By default, RDS instances can be configured to allow public access, which exposes them to the internet, increasing the risk of security breaches, unauthorized data access, and potential data exfiltration.

        **Rationale:**

        Publicly accessible RDS clusters pose significant security risks, including:

        - Unauthorized access if credentials or security configurations are weak.
        - Brute-force attacks on database authentication.
        - Non-compliance with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        To mitigate these risks, RDS clusters should be deployed in private subnets and accessible only through bastion hosts, VPNs, or AWS PrivateLink instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting direct exposure to the internet.
        - Enhances database security by enforcing private networking best practices.
        - Ensures compliance with regulatory and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS RDS Console.
            2.	In the left panel, select Databases.
            3.	Locate and select the RDS Cluster (e.g., Aurora) you want to update.
            4.	Under the Connectivity & security tab, check the Publicly accessible setting for both:
              - The cluster itself
              - Each DB instance in the cluster (shown below the cluster details)
            5.	If the cluster or any of its instances are publicly accessible:
              - For the cluster:
              - Choose Modify cluster.
              - Under Connectivity, set Public access to No.
              - Select Continue, then choose Apply immediately or schedule for the next maintenance window.
              - For each instance:
              - Choose the instance name to open its details.
              - Select Modify.
              - Under Connectivity, set Public access to No.
              - Select Continue, then Apply immediately or schedule as needed.
            6.	Ensure the DB subnet group used by the cluster points to private subnets (i.e., subnets with MapPublicIpOnLaunch set to false).
            7.	Confirm the security group allows access only from trusted sources—e.g., your app servers, bastion hosts, or VPN.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an RDS Cluster is publicly accessible:

            ```bash
            aws rds describe-db-clusters --query "DBClusters[*].{DBClusterIdentifier:DBClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
              ```

            Check if RDS Cluster instances are publicly accessible:

            ```bash
              aws rds describe-db-instances --query "DBInstances[*].{DBInstanceIdentifier:DBInstanceIdentifier, DBClusterIdentifier:DBClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If the cluster or any of its instances are public, modify them:

            ```bash
            aws rds modify-db-cluster --db-cluster-identifier <db-cluster-id> --publicly-accessible false --apply-immediately
            ```

            ```bash
            aws rds modify-db-instance --db-instance-identifier <db-instance-id> --publicly-accessible false --apply-immediately
            ```

            Ensure your RDS cluster is deployed in private subnets:

            ```bash

            Ensure that RDS is in a private subnet:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].{SubnetId:SubnetId, MapPublicIpOnLaunch:MapPublicIpOnLaunch}"
            ```

            If any subnet used by the DB subnet group has MapPublicIpOnLaunch: true, consider moving the cluster to a private subnet group.
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure RDS clusters are not publicly accessible:

            ```hcl
              resource "aws_rds_cluster" "secure_cluster" {
                cluster_identifier      = "secure-rds-cluster"
                engine                  = "aurora-mysql"
                master_username         = "admin"
                master_password         = "yourpassword"
                vpc_security_group_ids  = [aws_security_group.private_sg.id]
                db_subnet_group_name    = aws_db_subnet_group.private_db_subnet.name
              }

              resource "aws_rds_cluster_instance" "secure_cluster_instances" {
                count                   = 2
                identifier              = "secure-rds-cluster-instance-${count.index}"
                cluster_identifier      = aws_rds_cluster.secure_cluster.id
                instance_class          = "db.r5.large"
                publicly_accessible     = false  # Can only be set on individual instances
                db_subnet_group_name    = aws_db_subnet_group.private_db_subnet.name
                engine                  = aws_rds_cluster.secure_cluster.engine
              }

              resource "aws_db_subnet_group" "private_db_subnet" {
                name       = "private-db-subnet"
                subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
              }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure RDS clusters are not publicly accessible:

            ```yaml
              Resources:
                SecureRDSCluster:
                  Type: "AWS::RDS::DBCluster"
                  Properties:
                    Engine: "aurora-mysql"
                    DBClusterIdentifier: "secure-rds-cluster"
                    MasterUsername: "admin"
                    MasterUserPassword: "YourSecurePassword123"
                    VpcSecurityGroupIds:
                      - !Ref PrivateSecurityGroup
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                SecureRDSClusterInstance1:
                  Type: "AWS::RDS::DBInstance"
                  Properties:
                    DBInstanceIdentifier: "secure-rds-cluster-instance-1"
                    DBClusterIdentifier: !Ref SecureRDSCluster
                    Engine: "aurora-mysql"
                    DBInstanceClass: "db.r5.large"
                    PubliclyAccessible: false  # Ensure the instance is private
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                SecureRDSClusterInstance2:
                  Type: "AWS::RDS::DBInstance"
                  Properties:
                    DBInstanceIdentifier: "secure-rds-cluster-instance-2"
                    DBClusterIdentifier: !Ref SecureRDSCluster
                    Engine: "aurora-mysql"
                    DBInstanceClass: "db.r5.large"
                    PubliclyAccessible: false
                    DBSubnetGroupName: !Ref PrivateDBSubnetGroup

                PrivateDBSubnetGroup:
                  Type: "AWS::RDS::DBSubnetGroup"
                  Properties:
                    DBSubnetGroupName: "private-db-subnet"
                    SubnetIds:
                      - !Ref PrivateSubnet1
                      - !Ref PrivateSubnet2
                    DBSubnetGroupDescription: "Private subnets for RDS cluster"
            ```
    refs:
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-cluster.html
        title: AWS CLI Command Reference - create-db-cluster
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-cluster.html
        title: AWS CLI Command Reference - modify-db-cluster
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster_instance#publicly_accessible-1
        title: Terraform Registry - rds_cluster_instance
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-rds-cluster-public-access-check-single
    filters: |
      asset.platform == "aws-rds-dbcluster"
    mql: |
      aws.rds.dbcluster.securityGroups.none(
        vpc.routeTables.where(
          routes.any(GatewayId == /igw-/ && DestinationCidrBlock == "0.0.0.0/0")
        )
      )



  - uid: mondoo-aws-security-rds-instance-public-access-check
    title: Ensure all RDS instances are not publicly accessible
    impact: 100
    variants:
      - uid: mondoo-aws-security-rds-instance-public-access-check-single
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-hcl
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-plan
      - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Relational Database Service (RDS) instances are not publicly accessible to prevent unauthorized access to sensitive databases. By default, RDS instances can be configured to allow public access, which exposes them to the internet, increasing the risk of security breaches, unauthorized data access, and potential data exfiltration.

        **Rationale:**

        Publicly accessible RDS instances pose significant security risks, including:

        - Unauthorized access if credentials or security configurations are weak.
        - Brute-force attacks on database authentication.
        - Non-compliance with security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.

        To mitigate these risks, RDS instances should be deployed in private subnets and accessible only through bastion hosts, VPNs, or AWS PrivateLink instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting direct exposure to the internet.
        - Enhances database security by enforcing private networking best practices.
        - Ensures compliance with regulatory and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

              1.	Navigate to the AWS RDS Console.
              2.	Select Databases in the left panel.
              3.	Select an RDS instance and go to the Connectivity & security tab.
              4.	Check the Publicly accessible setting.
              5.	If the instance is publicly accessible, modify it:
                - Select Modify.
                - Under Connectivity, set Public access to No.
                - Select Continue, and then Apply immediately or schedule the change during the next maintenance window.
              6.	Ensure the instance is placed in a private subnet with security group rules allowing access only from authorized sources.

        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an RDS instance is publicly accessible:

            ```bash
            aws rds describe-db-instances --query "DBInstances[*].{DBInstanceIdentifier:DBInstanceIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If an instance is publicly accessible, modify it:

            ```bash
            aws rds modify-db-instance --db-instance-identifier <db-instance-id> --publicly-accessible false --apply-immediately
            ```

            Ensure that RDS is in a private subnet:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].MapPublicIpOnLaunch"
            ```

            If `MapPublicIpOnLaunch` is `true`, move the RDS instance to a private subnet.
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure RDS instances are not publicly accessible:

            ```hcl
            resource "aws_db_instance" "secure_rds" {
              identifier              = "secure-rds-instance"
              engine                 = "mysql"
              instance_class         = "db.t3.micro"
              allocated_storage      = 20
              publicly_accessible    = false  # Ensure RDS is private
              vpc_security_group_ids = [aws_security_group.private_sg.id]
              db_subnet_group_name   = aws_db_subnet_group.private_db_subnet.name
            }

            resource "aws_db_subnet_group" "private_db_subnet" {
              name       = "private-db-subnet"
              subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure RDS instances are not publicly accessible:

            ```yaml
            Resources:
              SecureRDSInstance:
                Type: "AWS::RDS::DBInstance"
                Properties:
                  DBInstanceIdentifier: "secure-rds-instance"
                  Engine: "mysql"
                  DBInstanceClass: "db.t3.micro"
                  AllocatedStorage: 20
                  PubliclyAccessible: false
                  DBSubnetGroupName: !Ref PrivateDBSubnetGroup

              PrivateDBSubnetGroup:
                Type: "AWS::RDS::DBSubnetGroup"
                Properties:
                  DBSubnetGroupName: "private-db-subnet"
                  SubnetIds:
                    - !Ref PrivateSubnet1
                    - !Ref PrivateSubnet2
            ```
    refs:
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-instance.html
        title: AWS CLI Command Reference - create-db-instance
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html
        title: AWS CLI Command Reference - modify-db-instance
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#publicly_accessible-1
        title: Terraform Registry - aws_db_instance
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-rds-instance-public-access-check-single
    filters: |
      asset.platform == "aws-rds-dbinstance"
    mql: |
      aws.rds.dbinstance.publiclyAccessible == false
      aws.rds.dbinstance.securityGroups.none(
        vpc.routeTables.where(
          routes.any(GatewayId == /igw-/ && DestinationCidrBlock == "0.0.0.0/0")
        )
      )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_db_instance" )
    mql: terraform.resources.where( nameLabel == "aws_db_instance" ).all( arguments.publicly_accessible != true )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_db_instance" )
    mql: terraform.plan.resourceChanges.where( type == "aws_db_instance" ).all( change.after.publicly_accessible != true )
  - uid: mondoo-aws-security-rds-instance-public-access-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_db_instance" )
    mql: terraform.state.resources.where( type == "aws_db_instance" ).all( values.publicly_accessible != true )



  - uid: mondoo-aws-security-redshift-cluster-public-access-check
    title: Ensure Redshift clusters are not publicly accessible
    impact: 95
    variants:
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-single
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-hcl
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-plan
      - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Redshift clusters are not publicly accessible to prevent unauthorized access and potential data breaches. A publicly accessible Redshift cluster can be reached from the internet, exposing it to security threats, including brute-force attacks and data exfiltration.

        **Rationale:**

        Amazon Redshift is used for data warehousing and analytics, often storing sensitive business intelligence and customer data. If a Redshift cluster is publicly accessible:

        - Anyone on the internet could attempt to access it if misconfigured.
        - Brute-force attacks could compromise database credentials.
        - Compliance violations may occur under frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and SOC 2.

        To mitigate these risks, Redshift clusters should be placed in private subnets and accessed securely using VPNs, VPC peering, AWS PrivateLink, or AWS IAM authentication instead of direct internet exposure.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting internet exposure.
        - Enhances security by ensuring database traffic remains private.
        - Ensures compliance with industry security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS Redshift Console.
            2.	Select Clusters in the left panel.
            3.	Select the cluster and go to the Properties tab.
            4.	Under Network and security, check Publicly accessible.
            5.	If the cluster is publicly accessible, modify the settings:
              - Select Edit publicly accessible setting.
              - Set Publicly accessible to No.
              - Select Save changes.
            6.	Ensure that the cluster is placed in a private subnet and that security groups restrict access to trusted sources only.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if a Redshift cluster is publicly accessible:

            ```bash
            aws redshift describe-clusters --query "Clusters[*].{Cluster:ClusterIdentifier, PubliclyAccessible:PubliclyAccessible}"
            ```

            If a cluster is publicly accessible, modify it:

            ```bash
            aws redshift modify-cluster --cluster-identifier <cluster-id> --publicly-accessible false
            ```

            Ensure the cluster is placed in a private subnet:

            ```bash
            aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query "Subnets[*].MapPublicIpOnLaunch"
            ```

            If `MapPublicIpOnLaunch` is `true`, move the Redshift cluster to a private subnet.
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure Redshift clusters are not publicly accessible:

            ```hcl
            resource "aws_redshift_cluster" "secure_redshift" {
              cluster_identifier  = "secure-redshift-cluster"
              node_type           = "dc2.large"
              master_username     = "admin"
              master_password     = "securepassword"
              publicly_accessible = false  # Ensure Redshift is private
              cluster_subnet_group_name = aws_redshift_subnet_group.private_redshift_subnet.name
            }

            resource "aws_redshift_subnet_group" "private_redshift_subnet" {
              name       = "private-redshift-subnet"
              subnet_ids = [aws_subnet.private1.id, aws_subnet.private2.id]
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure Redshift clusters are not publicly accessible:

            ```yaml
            Resources:
              SecureRedshiftCluster:
                Type: "AWS::Redshift::Cluster"
                Properties:
                  ClusterIdentifier: "secure-redshift-cluster"
                  NodeType: "dc2.large"
                  MasterUsername: "admin"
                  MasterUserPassword: "securepassword"
                  PubliclyAccessible: false
                  ClusterSubnetGroupName: !Ref PrivateRedshiftSubnetGroup

              PrivateRedshiftSubnetGroup:
                Type: "AWS::Redshift::ClusterSubnetGroup"
                Properties:
                  Description: "Private Redshift Subnet Group"
                  SubnetIds:
                    - !Ref PrivateSubnet1
                    - !Ref PrivateSubnet2
            ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/redshift/index.html
        title: AWS Documentation - AWS CLI Command Reference - Redshift
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-single
    filters: asset.platform == "aws-redshift-cluster"
    mql: aws.redshift.cluster.publiclyAccessible == false
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_redshift_cluster" )
    mql: terraform.resources.where( nameLabel == "aws_redshift_cluster" ).all( arguments.publicly_accessible != true )
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_redshift_cluster" )
    mql: terraform.plan.resourceChanges.where( type == "aws_redshift_cluster" ).all( change.after.publicly_accessible != true )
  - uid: mondoo-aws-security-redshift-cluster-public-access-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_redshift_cluster" )
    mql: terraform.state.resources.where( type == "aws_redshift_cluster" ).all( values.publicly_accessible != true )



  - uid: mondoo-aws-security-ec2-volume-inuse-check
    title: Ensure EBS volumes attached to EC2 instances are configured for deletion on instance termination
    impact: 60
    props:
      - uid: mondooAWSSecurityEbsVolumeDeleteOnTermination
        title: Defines whether instances should be configured to delete volumes on termination
        mql: "true"
    variants:
      - uid: mondoo-aws-security-ec2-volume-inuse-check-single
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-hcl
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-plan
      - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volumes attached to EC2 instances are configured to be automatically deleted when the instance is terminated. When an EBS volume is created and attached to an instance, the `DeleteOnTermination` attribute determines whether the volume persists after instance termination.

        **Rationale**

        By default, EBS volumes persist even after the associated EC2 instance is terminated, which can lead to orphaned volumes accumulating over time. These orphaned volumes not only increase storage costs but can also pose a security risk if they contain sensitive data and are left unmonitored.

        Setting the `DeleteOnTermination` flag ensures that unused EBS volumes do not persist beyond the lifecycle of the EC2 instance, reducing the risk of unauthorized access, data leaks, and unnecessary storage costs. This is particularly important in dynamic cloud environments where instances are frequently created and terminated.

        **Risk Mitigation**

        - **Cost Optimization:** Prevents unnecessary storage costs by ensuring that unused volumes do not persist.
        - **Security and Compliance:** Reduces the risk of orphaned volumes containing sensitive data.
        - **Operational Efficiency:** Prevents clutter and improves resource management in AWS environments.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select Instances in the left panel.
            3.	Select an instance and go to the Storage tab.
            4.	Check if the Delete on Termination flag is enabled for all EBS volumes.
            5.	If not enabled:
              - Select Modify Instance (for root volumes) or Detach Volume and reattach with Delete on Termination enabled.
            6.	Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an EBS volume is set to delete on termination:

            ```bash
            aws ec2 describe-instances --query "Reservations[].Instances[].BlockDeviceMappings[?Ebs.DeleteOnTermination==`false`]" --output table
            ```

            Enable delete on termination for a specific volume:

            ```bash
            aws ec2 modify-instance-attribute --instance-id <instance-id> --block-device-mappings "[{\"DeviceName\":\"/dev/sdf\",\"Ebs\":{\"DeleteOnTermination\":true}}]"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure EBS volumes delete on termination:

            ```hcl
            resource "aws_instance" "secure_instance" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              root_block_device {
                delete_on_termination = true
              }

              ebs_block_device {
                device_name           = "/dev/sdf"
                volume_size           = 20
                delete_on_termination = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure EBS volumes are deleted on termination:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  BlockDeviceMappings:
                    - DeviceName: "/dev/sda1"
                      Ebs:
                        VolumeSize: 20
                        DeleteOnTermination: true
                    - DeviceName: "/dev/sdf"
                      Ebs:
                        VolumeSize: 50
                        DeleteOnTermination: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html
        title: AWS Documentation - Delete an Amazon EBS volume
  - uid: mondoo-aws-security-ec2-volume-inuse-check-single
    filters: asset.platform == "aws-ebs-volume" && aws.ec2.volume.attachments != empty
    mql: |
      aws.ec2.volume.attachments.any(DeleteOnTermination == true)
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_instance").all(
        blocks.where(type == "root_block_device").any(arguments.delete_on_termination == true) &&
        blocks.where(type == "ebs_block_device").any(arguments.delete_on_termination == true)
      )
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_instance").all(
        change.after.root_block_device.any(
          delete_on_termination == true
        )
      )
      terraform.plan.resourceChanges.where(type == "aws_instance").all(
        change.after.ebs_block_device.any(
          delete_on_termination == true
        )
      )
  - uid: mondoo-aws-security-ec2-volume-inuse-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_instance")
    mql: |
      terraform.state.resources.where(type == "aws_instance").all(
        values.root_block_device.any(
          delete_on_termination == true
        )
      )
      terraform.state.resources.where(type == "aws_instance").all(
        values.ebs_block_device.any(
          delete_on_termination == false
        )
      )



  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
    title: Ensure EBS snapshots are not publicly restorable
    impact: 80
    variants:
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-single
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-hcl
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-plan
      - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) snapshots are not configured to be publicly restorable. A public snapshot can be accessed by anyone, potentially exposing sensitive data. AWS provides fine-grained access controls for EBS snapshots, and by default, snapshots are private unless explicitly shared.

        **Rationale:**

        Publicly accessible EBS snapshots pose a significant security risk, as they can contain sensitive data such as personally identifiable information (PII), credentials, or proprietary application data. If a snapshot is mistakenly made public, it can be accessed by unauthorized parties, leading to data breaches, regulatory compliance violations, and reputational damage.

        Ensuring that snapshots remain private unless intentionally shared with specific AWS accounts mitigates the risk of data exposure while allowing controlled data sharing when necessary.

        **Risk mitigation:**

        - **Data Security:** Prevents unauthorized access to potentially sensitive EBS snapshot data.
        - **Compliance:** Helps maintain compliance with security frameworks such as GDPR, HIPAA, and SOC 2.
        - **Operational Control:** Ensures that data is shared only with intended AWS accounts or users.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select Snapshots in the left panel.
            3.	Check the Permissions column for any snapshots listed as Public.
            4.	If a snapshot is public, update its permissions:
              - Select the snapshot.
              - Go to Modify Permissions under the Actions menu.
              - Ensure that Public access is not selected.
              - If needed, specify the AWS account IDs that require access.
              - Select Save Changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if any snapshots are publicly accessible:

            ```bash
            aws ec2 describe-snapshots --owner-id <account-id> --query "Snapshots[?Public].SnapshotId"
            ```

            Modify a snapshot to remove public access:

            ```bash
            aws ec2 modify-snapshot-attribute --snapshot-id <snapshot-id> --attribute createVolumePermission --operation-type remove --group-names all
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Note: It's not possible to set this on snapshot level via terraform, but you can use a global setting:

            ```hcl
            resource "aws_ebs_snapshot_block_public_access" "secure_snapshot" {
              state = "block-all-sharing"
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure that EBS snapshots are private in CloudFormation:

            ```yaml
            Resources:
              SecureSnapshot:
                Type: AWS::EC2::SnapshotBlockPublicAccess
                Properties:
                  State: block-all-sharing
            ```
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-single
    filters: asset.platform == "aws-ebs-snapshot"
    mql: |
      aws.ec2.snapshot.createVolumePermission.none(Group == "all")
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_snapshot")
    mql: |
      terraform.resources.any(nameLabel == "aws_ebs_snapshot_block_public_access" && arguments.state == "block-all-sharing")
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.plan.resourceChanges.any(
        type == "aws_ebs_snapshot_block_public_access"
          && change.after.state == "block-all-sharing"
      )
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.state.resources.any(
        type == "aws_ebs_snapshot_block_public_access"
          && values.state == "block-all-sharing"
      )



  - uid: mondoo-aws-security-ebs-snapshot-encrypted
    title: Ensure EBS Snapshots are configured to be encrypted at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-single
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-plan
      - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) snapshots are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that snapshot contents are stored securely. AWS KMS provides centralized key management and integrates with EBS snapshots to automatically encrypt and decrypt data transparently.

        **Rationale:**

        EBS snapshots inherit the encryption status of their source volumes. If a snapshot is created from an encrypted volume, the snapshot will be encrypted automatically using the same KMS key. However, snapshots from unencrypted volumes will remain unencrypted unless explicitly configured for encryption during the copy operation. Organizations should verify that all snapshots, including those shared or copied across accounts, maintain proper encryption settings.

        AWS KMS encryption ensures that snapshot data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects backup data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Snapshots under the Elastic Block Store section.
            3. For unencrypted snapshots, you can create an encrypted copy:
               - Select the unencrypted snapshot.
               - Select Actions, then Copy.
               - In the Copy Snapshot dialog, check Encrypt this snapshot.
               - Choose a KMS key (AWS managed or customer managed).
               - Provide a description and click Copy Snapshot.
            4. After verifying the encrypted copy, consider deleting the unencrypted original.

            To ensure future snapshots are encrypted:
            1. Navigate to EC2 Dashboard > EBS settings.
            2. Enable EBS encryption by default.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check for unencrypted snapshots:

            ```bash
            aws ec2 describe-snapshots --owner-ids self --query "Snapshots[?Encrypted==`false`].SnapshotId"
            ```

            Create an encrypted copy of an unencrypted snapshot:

            ```bash
            aws ec2 copy-snapshot \
              --source-region us-east-1 \
              --source-snapshot-id snap-1234567890abcdef0 \
              --description "Encrypted copy of snapshot" \
              --encrypted \
              --kms-key-id arn:aws:kms:us-east-1:account-id:key/key-id
            ```

            Enable EBS encryption by default for all future volumes and snapshots:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Enable default EBS encryption for the account
            resource "aws_ebs_encryption_by_default" "example" {
              enabled = true
            }

            # Create a KMS key for EBS encryption
            resource "aws_kms_key" "ebs_encryption" {
              description             = "KMS key for EBS encryption"
              deletion_window_in_days = 10
              enable_key_rotation     = true
            }

            # Set the default KMS key for EBS encryption
            resource "aws_ebs_default_kms_key" "example" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }

            # Create an encrypted snapshot
            resource "aws_ebs_snapshot" "example" {
              volume_id   = aws_ebs_volume.example.id
              description = "Encrypted snapshot"

              # Snapshots will be encrypted if the volume is encrypted
              # or if encryption by default is enabled
            }

            # Create an encrypted volume
            resource "aws_ebs_volume" "example" {
              availability_zone = "us-west-2a"
              size              = 50
              encrypted         = true
              kms_key_id        = aws_kms_key.ebs_encryption.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure that EBS snapshots are encrypted in CloudFormation:

            ```yaml
            Resources:
              SecureEBSVolume:
                Type: "AWS::EC2::Volume"
                Properties:
                  Size: 20
                  AvailabilityZone: "us-east-1a"
                  Encrypted: true
                  KmsKeyId: !Ref MyKMSKey  # Optional - references a KMS key you define
                  Tags:
                    - Key: "Name"
                      Value: "Secure Volume"

              SecureEBSSnapshot:
                Type: "AWS::EC2::Snapshot"
                Properties:
                  VolumeId: !Ref SecureEBSVolume
                  Description: "Encrypted EBS snapshot"
                  Tags:
                    - Key: "Name"
                      Value: "Secure Snapshot"

              # Optional: Define your own KMS key for encryption
              MyKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for EBS volume encryption"
                  EnableKeyRotation: true
                  KeyPolicy:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "kms:*"
                        Resource: "*"
            ```
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-single
    filters: asset.platform == "aws-ebs-snapshot"
    mql: |
      aws.ec2.snapshot.encrypted == true
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_snapshot").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-ebs-snapshot-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_snapshot")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_snapshot").all(
        values.encrypted == true
      )



  - uid: mondoo-aws-security-ec2-encrypted-volumes
    title: Ensure attached EBS volumes are configured to be encrypted at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-ec2-encrypted-volumes-single
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-hcl
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-plan
      - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic Block Store (EBS) volumes are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that volume contents are stored securely. AWS KMS provides centralized key management and integrates with EBS to automatically encrypt and decrypt data transparently.

        **Rationale:**

        As of May 2019, AWS enables encryption by default for newly created EBS volumes in supported regions. However, organizations should still verify this setting, as encryption settings can be modified and older volumes created before this change may remain unencrypted. Additionally, organizations may want to use specific KMS keys rather than the default AWS-managed keys.

        AWS KMS encryption ensures that volume data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Volumes under the Elastic Block Store section.
            3. For unencrypted volumes, create encrypted replacements:
               a. First, create a snapshot of the unencrypted volume:
                  - Select the unencrypted volume.
                  - Choose Actions > Create Snapshot.
                  - Add a description and tags, then click Create Snapshot.
               b. Create an encrypted copy of the snapshot:
                  - Go to Snapshots, select the newly created snapshot.
                  - Choose Actions > Copy.
                  - Check Encrypt this snapshot.
                  - Select a KMS key.
                  - Click Copy Snapshot.
               c. Create a new encrypted volume from the encrypted snapshot:
                  - Select the encrypted snapshot.
                  - Choose Actions > Create Volume.
                  - Configure the volume size and type.
                  - Verify Encryption is enabled.
                  - Click Create Volume.
               d. Attach the new encrypted volume:
                  - Stop the EC2 instance.
                  - Detach the original unencrypted volume.
                  - Attach the new encrypted volume.
                  - Start the instance.

            4. For future volumes, enable EBS encryption by default:
               - Go to EC2 Dashboard > EBS settings.
               - Select Manage under EBS encryption.
               - Check Always encrypt new EBS volumes.
               - Click Update.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check for unencrypted volumes:

            ```bash
            aws ec2 describe-volumes --query "Volumes[?Encrypted==`false`].VolumeId"
            ```

            Create a snapshot of an unencrypted volume:

            ```bash
            aws ec2 create-snapshot \
              --volume-id vol-1234567890abcdef0 \
              --description "Snapshot of unencrypted volume"
            ```

            Create an encrypted copy of the snapshot:

            ```bash
            aws ec2 copy-snapshot \
              --source-region us-east-1 \
              --source-snapshot-id snap-1234567890abcdef0 \
              --description "Encrypted copy of snapshot" \
              --encrypted \
              --kms-key-id arn:aws:kms:us-east-1:account-id:key/key-id
            ```

            Create a new encrypted volume from the encrypted snapshot:

            ```bash
            aws ec2 create-volume \
              --availability-zone us-east-1a \
              --snapshot-id snap-0abcdef1234567890 \
              --volume-type gp3
            ```

            Stop the instance, detach the old volume, and attach the new volume:

            ```bash
            aws ec2 stop-instances --instance-ids i-1234567890abcdef0

            aws ec2 detach-volume --volume-id vol-1234567890abcdef0

            aws ec2 attach-volume \
              --volume-id vol-0abcdef1234567890 \
              --instance-id i-1234567890abcdef0 \
              --device /dev/sda1

            aws ec2 start-instances --instance-ids i-1234567890abcdef0
            ```

            Enable EBS encryption by default:

            ```bash
            aws ec2 enable-ebs-encryption-by-default
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Enable default EBS encryption for the account
            resource "aws_ebs_encryption_by_default" "example" {
              enabled = true
            }

            # Create a KMS key for EBS encryption
            resource "aws_kms_key" "ebs_encryption" {
              description             = "KMS key for EBS encryption"
              deletion_window_in_days = 10
              enable_key_rotation     = true
            }

            # Set the default KMS key for EBS encryption
            resource "aws_ebs_default_kms_key" "example" {
              key_arn = aws_kms_key.ebs_encryption.arn
            }

            # Create an encrypted volume
            resource "aws_ebs_volume" "encrypted_volume" {
              availability_zone = "us-west-2a"
              size              = 50
              encrypted         = true
              kms_key_id        = aws_kms_key.ebs_encryption.arn

              tags = {
                Name = "encrypted-volume"
              }
            }

            # EC2 instance with encrypted root and additional volumes
            resource "aws_instance" "example" {
              ami           = "ami-12345678"
              instance_type = "t3.micro"

              root_block_device {
                volume_size = 20
                volume_type = "gp3"
                encrypted   = true
                kms_key_id  = aws_kms_key.ebs_encryption.arn
              }

              ebs_block_device {
                device_name = "/dev/sdf"
                volume_size = 50
                volume_type = "gp3"
                encrypted   = true
                kms_key_id  = aws_kms_key.ebs_encryption.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure EBS volumes are deleted on termination:

            ```yaml
            Resources:
              SecureInstance:
                Type: "AWS::EC2::Instance"
                Properties:
                  ImageId: "ami-12345678"
                  InstanceType: "t3.micro"
                  BlockDeviceMappings:
                    - DeviceName: "/dev/sda1"
                      Ebs:
                        VolumeSize: 20
                        Encrypted: true
                        KmsKeyId: !Ref "AWS::NoValue"  # Uses AWS-managed key by default
                    - DeviceName: "/dev/sdf"
                      Ebs:
                        VolumeSize: 50
                        Encrypted: true
                        KmsKeyId: !Ref "AWS::NoValue"  # Uses AWS-managed key by default
            ```
  - uid: mondoo-aws-security-ec2-encrypted-volumes-single
    filters: |
      asset.platform == "aws-ebs-volume" &&
      aws.ec2.volume.state != /deleting|deleted|error/
    mql: aws.ec2.volume.encrypted == true
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_ebs_volume")
    mql: |
      terraform.resources.where(nameLabel == "aws_ebs_volume").all(
        arguments.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_ebs_volume")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_ebs_volume").all(
        change.after.encrypted == true
      )
  - uid: mondoo-aws-security-ec2-encrypted-volumes-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_ebs_volume")
    mql: |
      terraform.state.resources.where(type == "aws_ebs_volume").all(
        values.encrypted == true
      )



  - uid: mondoo-aws-security-efs-encrypted-check
    title: Ensure EFS is configured to encrypt file data using KMS
    impact: 75
    variants:
      - uid: mondoo-aws-security-efs-encrypted-check-single
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-hcl
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-plan
      - uid: mondoo-aws-security-efs-encrypted-check-terraform-state
    docs:
      desc: |
        This check ensures that Amazon Elastic File System (EFS) is configured to encrypt file data at rest using AWS Key Management Service (KMS). Encryption helps protect sensitive data from unauthorized access by ensuring that files are stored securely. AWS KMS provides centralized key management and integrates with EFS to automatically encrypt and decrypt data transparently.

        **Rationale:**

        By default, EFS does not enable encryption unless explicitly configured. Without encryption, data stored in EFS volumes remains in plaintext, making it vulnerable to unauthorized access if an attacker gains access to the storage system.
        AWS KMS encryption ensures that file data is protected at rest, preventing unauthorized users or malicious actors from accessing sensitive information. This is particularly important for compliance with security frameworks such as GDPR, HIPAA, PCI DSS, and SOC 2.

        **Risk mitigation:**

        - **Data Security:** Protects data at rest from unauthorized access.
        - **Regulatory Compliance:** Helps meet compliance requirements for data protection and privacy.
        - **Centralized Key Management:** Uses AWS KMS for key lifecycle management, auditing, and fine-grained access control.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EFS Console.
            2.	Select File Systems from the left panel.
            3.	Identify file systems that do not have encryption enabled.
            4.	If an EFS file system is not encrypted, encryption cannot be enabled on an existing file system. You must:
              - Create a new EFS file system with encryption enabled.
              - Migrate data from the old unencrypted file system to the new encrypted one.
            5.	While creating a new file system:
              - Under General settings, check Enable encryption.
              - Select AWS KMS as the encryption provider.
              - Choose a customer-managed KMS key (CMK) if required.
            6.	Once data migration is complete, delete the old unencrypted file system.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an EFS file system is encrypted:

            ```bash
            aws efs describe-file-systems --query "FileSystems[*].{FileSystemId:FileSystemId, Encrypted:Encrypted}"
            ```

            Create an encrypted EFS file system using a KMS key:

            ```bash
            aws efs create-file-system --creation-token "secure-efs" --encrypted --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure EFS encryption is enabled with an AWS KMS key:

            ```hcl
            resource "aws_kms_key" "efs_encryption_key" {
              description             = "KMS key for EFS encryption"
              enable_key_rotation     = true
            }

            resource "aws_efs_file_system" "secure_efs" {
              encrypted  = true
              kms_key_id = aws_kms_key.efs_encryption_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure EFS file systems are encrypted using AWS KMS:

            ```yaml
            Resources:
              SecureEFS:
                Type: "AWS::EFS::FileSystem"
                Properties:
                  Encrypted: true
                  KmsKeyId: !Ref EFSKMSKey

              EFSKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for EFS encryption"
                  EnableKeyRotation: true
            ```
    refs:
      - url: https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html
        title: AWS Documentation - Security in Amazon EFS
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system
        title: Terraform Registry - aws_efs_file_system resource
      - url: https://docs.aws.amazon.com/efs/latest/ug/creating-using-create-fs.html#creating-using-fs-part1-cli
        title: AWS Documentation - Creating a file system using the AWS CLI
  - uid: mondoo-aws-security-efs-encrypted-check-single
    filters: asset.platform == "aws-efs-filesystem"
    mql: |
      aws.efs.filesystem.encrypted == true
      aws.efs.filesystem.kmsKey != empty
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_efs_file_system")
    mql: |
      terraform.resources.where(nameLabel == "aws_efs_file_system").all(
        arguments.encrypted == true
          && arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_efs_file_system")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_efs_file_system").all(
        change.after.encrypted == true
      )
      terraform.plan.resourceChanges.where(type == "aws_efs_file_system").all(
        change.after.kms_key_id != empty
      )
  - uid: mondoo-aws-security-efs-encrypted-check-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_efs_file_system")
    mql: |
      terraform.state.resources.where(type == "aws_efs_file_system").all(
        values.encrypted == true
      )
      terraform.state.resources.where(type == "aws_efs_file_system").all(
        values.kms_key_id != empty
      )



  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
    title: Ensure CloudWatch Logs are encrypted at rest using KMS CMKs
    impact: 70
    variants:
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-api
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-hcl
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-plan
      - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-state
    docs:
      desc: |
        This check ensures that Amazon CloudWatch log groups are configured to encrypt log data at rest using AWS Key Management Service (KMS) Customer-Managed Keys (CMKs). CloudWatch Logs store critical operational and security data, and encrypting them using CMKs enhances security by providing better control over key management and access policies.

        **Rationale:**

        CloudWatch Logs often store critical system logs, security logs, and application logs, which may contain sensitive data. Without KMS CMK encryption:

        - Logs are encrypted using default AWS-managed keys, which lack fine-grained access control.
        - Compliance requirements under CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001 may not be met.
        - Security risks increase, as logs could be exposed to unauthorized access.

        Using customer-managed KMS CMKs allows organizations to control key permissions, enable key rotation, and track encryption events via AWS CloudTrail.

        **Risk mitigation:**

        - **Data Security:** Ensures sensitive log data is encrypted at rest.
        - **Regulatory Compliance:** Helps meet security and compliance standards (e.g., GDPR, HIPAA, PCI DSS, SOC 2).
        - **Access Control:** Provides better control over encryption keys, including key rotation and access permissions.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS CloudWatch Console.
            2.	Select Log Groups from the left panel.
            3.	Select a log group and go to the Log Group Settings.
            4.	Under Data Protection, check if KMS encryption is enabled.
            5.	If KMS is not configured:
              - Select Edit and enable Use a KMS key to encrypt log data.
              - Choose a Customer-Managed KMS Key (CMK) instead of the AWS-managed key.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if a CloudWatch log group is encrypted with a KMS CMK:

            ```bash
            aws logs describe-log-groups --query "logGroups[*].{LogGroupName:logGroupName, KmsKeyId:kmsKeyId}"
            ```

            If a log group does not have a KMS key, assign one:

            ```bash
            aws logs associate-kms-key --log-group-name <log-group-name> --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure CloudWatch Logs use KMS encryption:

            ```hcl
            resource "aws_kms_key" "cloudwatch_kms_key" {
              description         = "KMS key for CloudWatch Log encryption"
              enable_key_rotation = true
            }

            resource "aws_cloudwatch_log_group" "secure_log_group" {
              name       = "secure-log-group"
              kms_key_id = aws_kms_key.cloudwatch_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure CloudWatch Logs are encrypted using AWS KMS:

            ```yaml
            Resources:
              SecureCloudWatchLogs:
                Type: "AWS::Logs::LogGroup"
                Properties:
                  LogGroupName: "secure-log-group"
                  KmsKeyId: !Ref CloudWatchKMSKey

              CloudWatchKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for CloudWatch Log encryption"
                  EnableKeyRotation: true
            ```
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-api
    filters: asset.platform == "aws-cloudwatch-loggroup"
    mql: |
      aws.cloudwatch.loggroup.kmsKey != empty
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudwatch_log_group")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudwatch_log_group").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudwatch_log_group").all(
        change.after.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudwatch_log_group")
    mql: |
      terraform.state.resources.where(type == "aws_cloudwatch_log_group").all(
        values.kms_key_id != empty
      )



  - uid: mondoo-aws-security-elb-security-policy-enabled
    title: Ensure Application Load Balancers have configured with a secure TLS security policy
    impact: 70
    props:
      - uid: allowedTlsPoliciesAlb
        title: Defines a list of allowed TLS policies that can be used with ALBs
        mql: |
          return [
            "ELBSecurityPolicy-TLS13-1-2-2021-06",
            "ELBSecurityPolicy-TLS13-1-3-2021-06",
            "ELBSecurityPolicy-TLS13-1-2-Res-2021-06",
            "ELBSecurityPolicy-FS-1-2-Res-2020-10"
          ]
    variants:
      - uid: mondoo-aws-security-elb-security-policy-enabled-single
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with secure Transport Layer Security (TLS) policies that enforce strong encryption protocols and cipher suites. TLS security policies define which protocols and ciphers are supported when establishing secure connections between clients and the load balancer, protecting data in transit from interception and tampering.

        **Rationale:**

        Without secure TLS policies on Application Load Balancers:

        - Outdated or vulnerable cryptographic protocols (such as TLS 1.0, TLS 1.1, or SSL 3.0) may be used, exposing communications to known security vulnerabilities.
        - Weak cipher suites might be enabled, reducing the strength of encryption and potentially allowing attackers to decrypt intercepted traffic.
        - Compliance requirements for data protection in transit, including PCI DSS, HIPAA, GDPR, and SOC 2, may not be satisfied.

        Modern TLS security policies (such as ELBSecurityPolicy-TLS-1-2-2017-01 or newer) ensure that only strong encryption methods are used, protecting sensitive information transmitted between clients and your applications.

        **Risk mitigation:**

        - **Data Protection:** Ensures sensitive data is properly encrypted in transit using strong protocols and ciphers.
        - **Security Posture:** Prevents exploitation of known vulnerabilities in outdated TLS versions and weak cipher suites.
        - **Regulatory Compliance:** Helps meet requirements for secure data transmission in various compliance frameworks.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer you want to update.
            4. Select the Listeners tab.
            5. For the HTTPS listener, select Edit.
            6. Under Security policy, select a more secure policy:
               - ELBSecurityPolicy-TLS13-1-2-2021-06 (recommended)
               - ELBSecurityPolicy-TLS13-1-3-2021-06 (if you need TLS 1.3 only)
               - ELBSecurityPolicy-FS-1-2-Res-2020-10 (for FIPS compliance)
            7. Select Save changes to apply the updated security policy.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Identify listeners for your load balancer:

            ```bash
            aws elbv2 describe-listeners --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef
            ```

            Update the security policy for an HTTPS listener:

            ```bash
            aws elbv2 modify-listener \
              --listener-arn arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06
            ```

            Verify the updated security policy:

            ```bash
            aws elbv2 describe-listeners \
              --listener-arns arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --query "Listeners[0].SslPolicy"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]
            }

            resource "aws_lb_listener" "https" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "443"
              protocol          = "HTTPS"
              ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06" # Secure TLS policy
              certificate_arn   = aws_acm_certificate.cert.arn

              default_action {
                type             = "forward"
                target_group_arn = aws_lb_target_group.app.arn
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB

              SecureHttpsListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 443
                  Protocol: "HTTPS"
                  SslPolicy: "ELBSecurityPolicy-TLS13-1-2-2021-06"
                  Certificates:
                    - CertificateArn: !Ref SSLCertificate
                  DefaultActions:
                    - Type: "forward"
                      TargetGroupArn: !Ref DefaultTargetGroup

              DefaultTargetGroup:
                Type: "AWS::ElasticLoadBalancingV2::TargetGroup"
                Properties:
                  VpcId: !Ref VPC
                  Port: 80
                  Protocol: "HTTP"
            ```
  - uid: mondoo-aws-security-elb-security-policy-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.listenerDescriptions.all(
        SslPolicy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb_listener")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb_listener").all(
        arguments.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb_listener")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb_listener").all(
        change.after.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )
  - uid: mondoo-aws-security-elb-security-policy-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb_listener")
    mql: |
      terraform.state.resources.where(type == "aws_lb_listener").all(
        values.ssl_policy.in(props.allowedTlsPoliciesAlb)
      )



  - uid: mondoo-aws-security-elb-ssl-listener
    title: Ensure Application Load Balancers are configured with HTTPS listeners
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-ssl-listener-single
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-hcl
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-plan
      - uid: mondoo-aws-security-elb-ssl-listener-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with HTTPS listeners to encrypt traffic between clients and the load balancer. HTTPS listeners use TLS/SSL certificates to establish secure encrypted connections, protecting sensitive data transmitted over the network from eavesdropping and man-in-the-middle attacks.

        **Rationale:**

        Without HTTPS listeners on Application Load Balancers:

        - Data transmitted between clients and applications remains unencrypted and vulnerable to interception by malicious actors.
        - Authentication credentials, session tokens, personal information, and other sensitive data could be exposed in plaintext.
        - Organizations may fail to meet compliance requirements such as PCI DSS, HIPAA, GDPR, and SOC 2, which mandate encryption for data in transit.

        Using HTTP-only listeners poses significant security risks, especially when transmitting sensitive information. Modern security best practices require encryption for all web traffic, regardless of the sensitivity level.

        **Risk mitigation:**

        - **Data Confidentiality:** Encrypts communications to prevent unauthorized access to sensitive information.
        - **Authentication Protection:** Secures user credentials and session information from being intercepted.
        - **Trust and Compliance:** Builds user trust and satisfies regulatory requirements for protecting data in transit.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer that needs HTTPS configuration.
            4. Select the Listeners tab.
            5. If there isn't an HTTPS listener (port 443):
               - Select Add listener.
               - Set Protocol:Port to HTTPS:443.
               - Under Security policy, select a secure policy like ELBSecurityPolicy-TLS13-1-2-2021-06.
               - Under Default SSL certificate, choose one of:
                 * Choose from ACM (recommended)
                 * Choose from IAM
                 * Import a certificate
               - Configure the default action (typically forwarding to a target group).
            6. Select Add to create the HTTPS listener.

            7. For existing HTTP listeners, consider implementing a redirect to HTTPS:
               - Select the HTTP listener and choose Edit.
               - Change the default action to Redirect.
               - Set Protocol to HTTPS, Port to 443, and Status code to 301 (Permanently moved).
            8. Select Save changes to apply the updated configuration.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Create an HTTPS listener:

            ```bash
            aws elbv2 create-listener \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --protocol HTTPS \
              --port 443 \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06 \
              --certificates CertificateArn=arn:aws:acm:region:account-id:certificate/certificate-id \
              --default-actions Type=forward,TargetGroupArn=arn:aws:elasticloadbalancing:region:account-id:targetgroup/my-target-group/1234567890abcdef
            ```

            Update an existing HTTP listener to redirect to HTTPS:

            ```bash
            aws elbv2 modify-listener \
              --listener-arn arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890abcdef/listener-id \
              --port 80 \
              --protocol HTTP \
              --default-actions Type=redirect,RedirectConfig="{Protocol=HTTPS,Port=443,StatusCode=HTTP_301}"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]
            }

            # HTTPS listener
            resource "aws_lb_listener" "https" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "443"
              protocol          = "HTTPS"
              ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06"
              certificate_arn   = aws_acm_certificate.cert.arn

              default_action {
                type             = "forward"
                target_group_arn = aws_lb_target_group.app.arn
              }
            }

            # HTTP listener redirecting to HTTPS
            resource "aws_lb_listener" "http" {
              load_balancer_arn = aws_lb.secure_alb.arn
              port              = "80"
              protocol          = "HTTP"

              default_action {
                type = "redirect"

                redirect {
                  port        = "443"
                  protocol    = "HTTPS"
                  status_code = "HTTP_301"
                }
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB

              # HTTPS Listener
              HttpsListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 443
                  Protocol: "HTTPS"
                  SslPolicy: "ELBSecurityPolicy-TLS13-1-2-2021-06"
                  Certificates:
                    - CertificateArn: !Ref SSLCertificate
                  DefaultActions:
                    - Type: "forward"
                      TargetGroupArn: !Ref DefaultTargetGroup

              # HTTP Listener with redirect to HTTPS
              HttpListener:
                Type: "AWS::ElasticLoadBalancingV2::Listener"
                Properties:
                  LoadBalancerArn: !Ref SecureLoadBalancer
                  Port: 80
                  Protocol: "HTTP"
                  DefaultActions:
                    - Type: "redirect"
                      RedirectConfig:
                        Protocol: "HTTPS"
                        Port: "443"
                        StatusCode: "HTTP_301"
            ```
  - uid: mondoo-aws-security-elb-ssl-listener-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.listenerDescriptions.all(Protocol == "HTTPS")
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb_listener")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb_listener").all(
        arguments.protocol == "HTTPS"
      )
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb_listener")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb_listener").all(
        change.after.protocol == "HTTPS"
      )
  - uid: mondoo-aws-security-elb-ssl-listener-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb_listener")
    mql: |
      terraform.state.resources.where(type == "aws_lb_listener").all(
        values.protocol == "HTTPS"
      )



  - uid: mondoo-aws-security-elb-logging-enabled
    title: Ensure Application Load Balancers have logging enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-logging-enabled-single
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-logging-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) are configured with access logging enabled to capture detailed information about requests sent to the load balancer. Access logs provide comprehensive data including client IP addresses, request paths, latencies, response codes, and more, which are delivered to an Amazon S3 bucket for storage and analysis.

        **Rationale:**

        Without access logging enabled on Application Load Balancers:

        - Security teams lack visibility into traffic patterns and potential security incidents targeting web applications.
        - Troubleshooting application issues becomes more difficult without historical request data.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for maintaining audit trails of system access may not be satisfied.

        Access logs are critical for security monitoring, compliance auditing, operational troubleshooting, and traffic analysis. These logs help identify suspicious patterns that may indicate security threats or application issues.

        **Risk mitigation:**

        - **Security Monitoring:** Provides visibility into potential attacks, such as SQL injection attempts or cross-site scripting.
        - **Compliance Documentation:** Helps meet regulatory requirements for maintaining audit trails of system access.
        - **Operational Intelligence:** Allows analysis of traffic patterns, error rates, and client behaviors to improve application performance.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select the Application Load Balancer you want to enable logging for.
            4. Select the Attributes tab.
            5. Select Edit.
            6. Under Access logs, check Enable.
            7. Specify an existing S3 bucket or create a new one.
            8. Optionally, specify a prefix to organize the logs within the bucket.
            9. Select Save changes to enable access logging.

            Note: Ensure the S3 bucket has the appropriate permissions to allow the ELB to write logs.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Enable access logs for a load balancer:

            ```bash
            aws elbv2 modify-load-balancer-attributes \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --attributes Key=access_logs.s3.enabled,Value=true Key=access_logs.s3.bucket,Value=my-log-bucket Key=access_logs.s3.prefix,Value=my-app-logs
            ```

            Verify that logging is enabled:

            ```bash
            aws elbv2 describe-load-balancer-attributes \
              --load-balancer-arn arn:aws:elasticloadbalancing:region:account-id:loadbalancer/app/my-load-balancer/1234567890abcdef \
              --query "Attributes[?Key=='access_logs.s3.enabled' || Key=='access_logs.s3.bucket']"
            ```

            Create an S3 bucket policy to allow ELB to write logs:

            ```bash
            aws s3api put-bucket-policy \
              --bucket my-log-bucket \
              --policy '{
                "Version": "2012-10-17",
                "Statement": [
                  {
                    "Effect": "Allow",
                    "Principal": {
                      "AWS": "arn:aws:iam::elb-account-id:root"
                    },
                    "Action": "s3:PutObject",
                    "Resource": "arn:aws:s3:::my-log-bucket/my-app-logs/AWSLogs/account-id/*"
                  }
                ]
              }'
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # S3 bucket for ALB access logs
            resource "aws_s3_bucket" "alb_logs" {
              bucket = "my-alb-logs-bucket"
              force_destroy = true
            }

            # S3 bucket policy to allow ALB to write logs
            resource "aws_s3_bucket_policy" "alb_logs_policy" {
              bucket = aws_s3_bucket.alb_logs.id

              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Effect = "Allow"
                    Principal = {
                      AWS = "arn:aws:iam::${data.aws_elb_service_account.main.id}:root"
                    }
                    Action = "s3:PutObject"
                    Resource = "${aws_s3_bucket.alb_logs.arn}/alb-logs/AWSLogs/${data.aws_caller_identity.current.account_id}/*"
                  }
                ]
              })
            }

            # Get AWS ELB service account ID
            data "aws_elb_service_account" "main" {}

            # Get current AWS account ID
            data "aws_caller_identity" "current" {}

            # Create ALB with logging enabled
            resource "aws_lb" "secure_alb" {
              name               = "secure-alb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.lb_sg.id]
              subnets            = [aws_subnet.public_a.id, aws_subnet.public_b.id]

              access_logs {
                bucket  = aws_s3_bucket.alb_logs.id
                prefix  = "alb-logs"
                enabled = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              LogBucket:
                Type: "AWS::S3::Bucket"
                Properties:
                  BucketName: "my-alb-logs-bucket"

              LogBucketPolicy:
                Type: "AWS::S3::BucketPolicy"
                Properties:
                  Bucket: !Ref LogBucket
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Effect: "Allow"
                        Principal:
                          AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
                        Action: "s3:PutObject"
                        Resource: !Sub "${LogBucket.Arn}/alb-logs/AWSLogs/${AWS::AccountId}/*"

              SecureLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-alb"
                  Scheme: "internet-facing"
                  Type: "application"
                  SecurityGroups:
                    - !Ref LoadBalancerSecurityGroup
                  Subnets:
                    - !Ref PublicSubnetA
                    - !Ref PublicSubnetB
                  LoadBalancerAttributes:
                    - Key: "access_logs.s3.enabled"
                      Value: "true"
                    - Key: "access_logs.s3.bucket"
                      Value: !Ref LogBucket
                    - Key: "access_logs.s3.prefix"
                      Value: "alb-logs"
            ```
  - uid: mondoo-aws-security-elb-logging-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.attributes.any(Key == "access_logs.s3.enabled")
      aws.elb.loadbalancer.attributes.where(Key == "access_logs.s3.enabled").all(Value == true)
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb").one(
        blocks.where(type == "access_logs").contains(
          arguments.enabled == true
        )
      )
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb").all(
        change.after.access_logs.any(
          enabled == true
        )
      )
  - uid: mondoo-aws-security-elb-logging-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb")
    mql: |
      terraform.state.resources.where(type == "aws_lb").all(
        values.access_logs.any(
          enabled == true
        )
      )



  - uid: mondoo-aws-security-elb-deletion-protection-enabled
    title: Ensure Application Load Balancers are configured with deletion protection enabled
    impact: 70
    variants:
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-single
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-hcl
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-plan
      - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Application Load Balancers (ALBs) have deletion protection enabled to prevent accidental or unauthorized deletion. Deleting a load balancer without proper authorization or by mistake can result in application downtime, traffic disruption, and loss of critical configurations.

        **Rationale:**

        By default, deletion protection is disabled for Application Load Balancers, making them susceptible to accidental removal. If an ALB is deleted:

        - All traffic routing is disrupted, causing application downtime.
        - Reconfiguration is required, leading to potential misconfigurations or longer recovery times.
        - Security policies and access control settings are lost, which may expose applications to threats.

        Enabling deletion protection ensures that ALBs cannot be deleted without explicitly disabling this setting first, providing an additional layer of protection against human errors and misconfigurations.

        **Risk mitigation:**

        - Prevents accidental deletions that could cause service outages.
        - Ensures operational stability by enforcing change control processes.
        - Reduces misconfigurations and security risks associated with unintended deletions.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS EC2 Console.
            2. Select Load Balancers under the Load Balancing section.
            3. Select an Application Load Balancer (ALB).
            4. Select the Description tab.
            5. Under Deletion Protection, check if it is enabled.
            6. If it is disabled, modify the setting:
              - Select Edit attributes.
              - Enable Deletion protection.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an ALB has deletion protection enabled:

            ```bash
            aws elbv2 describe-load-balancers --query "LoadBalancers[*].{Name:LoadBalancerName, DeletionProtectionEnabled:Attributes[?Key=='deletion_protection.enabled'].Value | [0]}"
            ```

            Enable deletion protection for a specific ALB:

            ```bash
            aws elbv2 modify-load-balancer-attributes \
            --load-balancer-arn <load-balancer-arn> \
            --attributes Key=deletion_protection.enabled,Value=true
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure ALBs have deletion protection enabled:

            ```hcl
            resource "aws_lb" "secure_alb" {
              name               = "secure-application-lb"
              internal           = false
              load_balancer_type = "application"
              security_groups    = [aws_security_group.alb_sg.id]
              subnets            = [aws_subnet.public1.id, aws_subnet.public2.id]

              enable_deletion_protection = true  # Ensures deletion protection is enabled
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable deletion protection for ALBs:

            ```yaml
            Resources:
              SecureApplicationLoadBalancer:
                Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
                Properties:
                  Name: "secure-application-lb"
                  Type: "application"
                  Scheme: "internet-facing"
                  Subnets:
                    - !Ref PublicSubnet1
                    - !Ref PublicSubnet2
                  SecurityGroups:
                    - !Ref ALBSecurityGroup
                  LoadBalancerAttributes:
                    - Key: "deletion_protection.enabled"
                      Value: "true"
            ```
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-single
    filters: asset.platform == "aws-elb-loadbalancer"
    mql: |
      aws.elb.loadbalancer.attributes.any(Key == "deletion_protection.enabled")
      aws.elb.loadbalancer.attributes.where(Key == "deletion_protection.enabled").all(Value == true)
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_lb")
    mql: |
      terraform.resources.where(nameLabel == "aws_lb").all(
        arguments.enable_deletion_protection == true
      )
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_lb")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_lb").all(
        change.after.enable_deletion_protection == true
      )
  - uid: mondoo-aws-security-elb-deletion-protection-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_lb")
    mql: |
      terraform.state.resources.where(type == "aws_lb").all(
        values.enable_deletion_protection == true
      )



  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
    title: Ensure Amazon OpenSearch Service domains are configured with encryption-at-rest
    impact: 70
    variants:
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-api
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-hcl
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-plan
      - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-state
    docs:
      desc: |
        This check ensures that Amazon OpenSearch Service domains are configured to encrypt data at rest using AWS Key Management Service (KMS). Encryption at rest protects sensitive search and analytics data from unauthorized access, ensuring that stored data is automatically encrypted before being written to disk.

        **Rationale:**

        By default, OpenSearch Service does not encrypt data at rest unless explicitly enabled. Without encryption:

        - Sensitive data remains in plaintext, making it vulnerable to unauthorized access.
        - Security and compliance risks increase under regulations such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, and ISO 27001.
        - Data exposure risks exist if an OpenSearch domain is compromised.

        To mitigate these risks, OpenSearch domains should be encrypted using AWS KMS, which provides centralized key management, access control, and audit logging.

        **Risk mitigation:**

        - Prevents unauthorized access by ensuring all stored data is encrypted.
        - Enhances compliance with industry security frameworks requiring encryption at rest.
        - Improves security posture by integrating AWS KMS for key management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS OpenSearch Service Console.
            2.	Select Domains in the left panel.
            3.	Select an OpenSearch domain and go to the Security tab.
            4.	Under Encryption at rest, check if encryption is enabled.
            5.	If encryption is not enabled, create a new OpenSearch domain with encryption:
              - Select Create domain.
              - Under Encryption at rest, enable encrypt data at rest.
              - Choose a customer-managed KMS key (CMK) if required.
              - Complete the domain creation process.
            6.	Migrate data from the unencrypted domain to the new encrypted domain, then delete the unencrypted domain.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if an OpenSearch domain is encrypted:

            ```bash
            aws opensearch describe-domain --domain-name <domain-name> --query "DomainStatus.EncryptionAtRestOptions"
            ```

            If encryption is not enabled, create a new encrypted OpenSearch domain:

            ```bash
            aws opensearch create-domain \
            --domain-name "secure-opensearch-domain" \
            --encryption-at-rest-options Enabled=true,KmsKeyId="arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure OpenSearch Service encryption is enabled using AWS KMS:

            ```hcl
            resource "aws_kms_key" "opensearch_kms_key" {
              description         = "KMS key for OpenSearch encryption"
              enable_key_rotation = true
            }

            resource "aws_opensearch_domain" "secure_opensearch" {
              domain_name = "secure-opensearch-domain"

              encrypt_at_rest {
                enabled    = true
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable encryption at rest for OpenSearch domains:

            ```yaml
            Resources:
              SecureOpenSearchDomain:
                Type: "AWS::OpenSearchService::Domain"
                Properties:
                  DomainName: "secure-opensearch-domain"
                  EncryptionAtRestOptions:
                    Enabled: true
                    KmsKeyId: !Ref OpenSearchKMSKey

              OpenSearchKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for OpenSearch encryption"
                  EnableKeyRotation: true
            ```
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-api
    filters: asset.platform == "aws"
    mql: aws.es.domains.all(encryptionAtRestEnabled == true)
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_opensearch_domain")
    mql: |
      terraform.resources.where(nameLabel == "aws_opensearch_domain").one(
        blocks.where(type == "encrypt_at_rest" ).contains(
          arguments.enabled == true
        )
      )
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_opensearch_domain").any(
        change.after.encrypt_at_rest.contains(
          enabled == true
        )
      )
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_opensearch_domain")
    mql: |
      terraform.state.resources.where(type == "aws_opensearch_domain").any(
        values.encrypt_at_rest.contains(
          enabled == true
        )
      )



  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
    title: Ensure rotation for customer-managed keys (CMKs) is enabled
    impact: 80
    variants:
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-single
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-hcl
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-plan
      - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS Key Management Service (KMS) customer-managed keys (CMKs) have automatic key rotation enabled. Enabling key rotation ensures that cryptographic keys are periodically refreshed, reducing the risk of long-term key compromise and enhancing overall security.

        **Rationale:**

        By default, AWS does not enable automatic rotation for CMKs, leaving encryption keys unchanged unless manually rotated. Without key rotation:

        - Keys remain in use indefinitely, increasing the impact of potential key compromise.
        - Compliance issues may arise under security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.
        - Security best practices require periodic key changes to limit exposure.

        AWS allows automatic key rotation for symmetric CMKs every 365 days, ensuring that keys remain secure over time.

        **Risk mitigation:**

        - Reduces key compromise risk by ensuring keys are periodically refreshed.
        - Ensures compliance with security frameworks that mandate key rotation.
        - Improves cryptographic security by limiting key lifespan.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS KMS Console.
            2.	Select Customer managed keys in the left panel.
            3.	Select a CMK to review its settings.
            4.	Under Key rotation, check if Automatic rotation is enabled.
            5.	If rotation is disabled, select Edit key settings:
              - Enable Automatic key rotation.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if key rotation is enabled for all customer-managed CMKs:

            ```bash
            aws kms list-keys --query "Keys[*].KeyId" | while read -r key_id; do
                aws kms get-key-rotation-status --key-id "$key_id" --query "KeyRotationEnabled"
            done
            ```

            If rotation is not enabled, activate it:

            ```bash
            aws kms enable-key-rotation --key-id <key-id>
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure KMS key rotation is enabled:

            ```hcl
            resource "aws_kms_key" "secure_kms_key" {
              description         = "Customer-managed KMS key with automatic rotation"
              enable_key_rotation = true
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable KMS key rotation for CMKs:

            ```yaml
            Resources:
              SecureKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "Customer-managed KMS key with automatic rotation"
                  EnableKeyRotation: true
            ```
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-single
    filters: asset.platform == "aws-kms-key" && aws.kms.key.metadata.KeyState == "Enabled" && aws.kms.key.metadata.KeySpec == "SYMMETRIC_DEFAULT"
    mql: |
      aws.kms.key.keyRotationEnabled == true
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_kms_key")
    mql: |
      terraform.resources.where(nameLabel == "aws_kms_key").all(
        arguments.enable_key_rotation == true
      )
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_kms_key")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_kms_key").all(
        change.after.enable_key_rotation == true
      )
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_kms_key")
    mql: |
      terraform.state.resources.where(type == "aws_kms_key").all(
        values.enable_key_rotation == true
      )



  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
    title: Ensure SageMaker notebook instances are configured to use KMS
    impact: 50
    variants:
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-single
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-hcl
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-plan
      - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-state
    docs:
      desc: |
        This check ensures that Amazon SageMaker notebook instances are configured to encrypt data at rest using AWS Key Management Service (KMS). Enabling KMS encryption enhances security by protecting sensitive machine learning (ML) data stored in SageMaker notebook instances from unauthorized access.

        **Rationale:**

        By default, SageMaker notebook instances may store training datasets, model artifacts, and proprietary code in Amazon EBS volumes. Without KMS encryption:

        - Data is stored in plaintext, making it vulnerable to unauthorized access.
        - Security and compliance risks increase, especially for organizations under PCI DSS, HIPAA, ISO 27001, and CIS AWS Foundations Benchmark.
        - No centralized control over encryption keys, preventing fine-grained access control and auditing.

        To mitigate these risks, SageMaker notebook instances should be encrypted using AWS KMS, allowing secure key management, key rotation, and logging of key usage.

        **Risk mitigation:**

        - Prevents unauthorized access to sensitive machine learning data.
        - Ensures compliance with security frameworks that mandate encryption.
        - Improves security posture by leveraging AWS KMS for centralized key management.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS SageMaker Console.
            2.	Select Notebook instances in the left panel.
            3.	Select a notebook instance and go to the Storage volume settings.
            4.	Check if the Encryption key is set to an AWS KMS key.
            5.	If no KMS key is assigned, update the instance by creating a new SageMaker notebook instance with encryption enabled:
              - Select Create Notebook Instance.
              - Under Encryption key, select a customer-managed KMS key (CMK).
              - Launch the new instance and migrate existing data.
            6.	Delete the unencrypted notebook instance once migration is complete.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if SageMaker notebook instances are encrypted with KMS:

            ```bash
            aws sagemaker list-notebook-instances --query "NotebookInstances[*].{Name:NotebookInstanceName, KmsKeyId:KmsKeyId}"
            ```

            If an instance does not have a KMS key, create a new encrypted notebook instance:

            ```bash
            aws sagemaker create-notebook-instance \
            --notebook-instance-name "secure-sagemaker-instance" \
            --instance-type "ml.t3.medium" \
            --role-arn "arn:aws:iam::<account-id>:role/SageMakerRole" \
            --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure SageMaker notebook instances are encrypted using a KMS key:

            ```hcl
            resource "aws_kms_key" "sagemaker_kms_key" {
              description         = "KMS key for SageMaker notebook encryption"
              enable_key_rotation = true
            }

            resource "aws_sagemaker_notebook_instance" "secure_notebook" {
              name               = "secure-sagemaker-instance"
              instance_type      = "ml.t3.medium"
              role_arn          = aws_iam_role.sagemaker_role.arn
              kms_key_id        = aws_kms_key.sagemaker_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            ```yaml
            Resources:
              SecureSageMakerNotebook:
                Type: "AWS::SageMaker::NotebookInstance"
                Properties:
                  NotebookInstanceName: "secure-sagemaker-instance"
                  InstanceType: "ml.t3.medium"
                  RoleArn: !GetAtt SageMakerRole.Arn
                  KmsKeyId: !Ref SageMakerKMSKey

              SageMakerKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for SageMaker encryption"
                  EnableKeyRotation: true
            ```
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-single
    filters: asset.platform == "aws-sagemaker-notebookinstance"
    mql: |
      aws.sagemaker.notebookinstance.details.kmsKey != empty
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.resources.where(nameLabel == "aws_sagemaker_notebook_instance").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_sagemaker_notebook_instance").all(
        change.after.kms_key_id != empty ||
        change.afterUnknown.kms_key_id == true
      )
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_sagemaker_notebook_instance")
    mql: |
      terraform.state.resources.where(type == "aws_sagemaker_notebook_instance").all(
        values.kms_key_id != empty
      )



  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled
    title: Ensure CloudTrail log file validation is enabled
    impact: 60
    variants:
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-single
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-plan
      - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS CloudTrail has log file validation enabled to verify the integrity of logged events. Log file validation generates a digitally signed digest file containing a hash of each log that CloudTrail delivers, allowing you to determine whether a log file was modified, deleted, or unchanged after CloudTrail delivered it.

        **Rationale:**

        Without log file validation enabled in CloudTrail:

        - Unauthorized modifications to log files may go undetected, compromising the reliability of audit trails.
        - Attackers could potentially alter or delete log records to cover their tracks after gaining unauthorized access.
        - Compliance frameworks such as PCI DSS, HIPAA, and SOC 2 requirements for maintaining tamper-proof audit logs may not be satisfied.

        Log file validation is crucial for maintaining the chain of custody for security events and ensuring the authenticity of CloudTrail logs during security investigations, compliance audits, and forensic analysis of security incidents.

        **Risk mitigation:**

        - **Log Integrity:** Provides cryptographic assurance that logs have not been modified since they were delivered by CloudTrail.
        - **Forensic Readiness:** Ensures reliable evidence for security incident investigations and dispute resolution.
        - **Compliance Validation:** Helps meet regulatory requirements for tamper-evident logging mechanisms.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1. Navigate to the AWS CloudTrail Console.
            2. Select Trails in the left panel.
            3. Select the CloudTrail trail you want to update.
            4. Select Edit.
            5. Scroll down to the Additional settings section.
            6. Check the Enable log file validation checkbox.
            7. Select Save changes to update the trail.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if log file validation is enabled for a specific trail:

            ```bash
            aws cloudtrail describe-trails \
              --trail-name-list my-trail \
              --query "trailList[*].{Name:Name,LogFileValidation:LogFileValidationEnabled}"
            ```

            Enable log file validation for a trail:

            ```bash
            aws cloudtrail update-trail \
              --name my-trail \
              --enable-log-file-validation
            ```

            Verify that log file validation is now enabled:

            ```bash
            aws cloudtrail describe-trails \
              --trail-name-list my-trail \
              --query "trailList[*].{Name:Name,LogFileValidation:LogFileValidationEnabled}"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            ```hcl
            # Create a secure CloudTrail trail with log file validation enabled
            resource "aws_cloudtrail" "secure_trail" {
              name                          = "secure-cloudtrail"
              s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
              is_multi_region_trail         = true
              include_global_service_events = true
              enable_logging                = true
              enable_log_file_validation    = true  # Ensure log file validation is enabled
            }

            # S3 bucket for CloudTrail logs
            resource "aws_s3_bucket" "cloudtrail_logs" {
              bucket        = "cloudtrail-logs-bucket"
              force_destroy = true
            }

            # S3 bucket policy for CloudTrail
            resource "aws_s3_bucket_policy" "cloudtrail" {
              bucket = aws_s3_bucket.cloudtrail_logs.id
              policy = jsonencode({
                Version = "2012-10-17"
                Statement = [
                  {
                    Sid    = "AWSCloudTrailAclCheck"
                    Effect = "Allow"
                    Principal = {
                      Service = "cloudtrail.amazonaws.com"
                    }
                    Action   = "s3:GetBucketAcl"
                    Resource = aws_s3_bucket.cloudtrail_logs.arn
                  },
                  {
                    Sid    = "AWSCloudTrailWrite"
                    Effect = "Allow"
                    Principal = {
                      Service = "cloudtrail.amazonaws.com"
                    }
                    Action   = "s3:PutObject"
                    Resource = "${aws_s3_bucket.cloudtrail_logs.arn}/AWSLogs/*"
                    Condition = {
                      StringEquals = {
                        "s3:x-amz-acl" = "bucket-owner-full-control"
                      }
                    }
                  }
                ]
              })
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            ```yaml
            Resources:
              CloudTrailLogsBucket:
                Type: "AWS::S3::Bucket"
                Properties:
                  BucketName: !Sub "cloudtrail-logs-${AWS::AccountId}"
                  VersioningConfiguration:
                    Status: Enabled

              CloudTrailBucketPolicy:
                Type: "AWS::S3::BucketPolicy"
                Properties:
                  Bucket: !Ref CloudTrailLogsBucket
                  PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Sid: "AWSCloudTrailAclCheck"
                        Effect: "Allow"
                        Principal:
                          Service: "cloudtrail.amazonaws.com"
                        Action: "s3:GetBucketAcl"
                        Resource: !GetAtt CloudTrailLogsBucket.Arn
                      - Sid: "AWSCloudTrailWrite"
                        Effect: "Allow"
                        Principal:
                          Service: "cloudtrail.amazonaws.com"
                        Action: "s3:PutObject"
                        Resource: !Sub "${CloudTrailLogsBucket.Arn}/AWSLogs/${AWS::AccountId}/*"
                        Condition:
                          StringEquals:
                            "s3:x-amz-acl": "bucket-owner-full-control"

              SecureCloudTrail:
                Type: "AWS::CloudTrail::Trail"
                DependsOn:
                  - CloudTrailBucketPolicy
                Properties:
                  TrailName: "secure-cloudtrail"
                  S3BucketName: !Ref CloudTrailLogsBucket
                  IsMultiRegionTrail: true
                  EnableLogFileValidation: true  # Enable log file validation
                  IncludeGlobalServiceEvents: true
            ```
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-single
    filters: asset.platform == "aws-cloudtrail-trail"
    mql: aws.cloudtrail.trail.logFileValidationEnabled == true
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudtrail")
    mql: terraform.resources.where(nameLabel == "aws_cloudtrail").all(arguments.enable_log_file_validation == true)
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudtrail")
    mql: terraform.plan.resourceChanges.where(type == "aws_cloudtrail").all(change.after.enable_log_file_validation == true)
  - uid: mondoo-aws-security-cloud-trail-log-file-validation-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudtrail")
    mql: terraform.state.resources.where(type == "aws_cloudtrail").all(values.enable_log_file_validation == true)



  - uid: mondoo-aws-security-cloud-trail-encryption-enabled
    title: Ensure CloudTrail trails are configured to use the server-side encryption KMS
    impact: 70
    variants:
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-single
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-hcl
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-plan
      - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-state
    docs:
      desc: |
        This check ensures that AWS CloudTrail trails are configured to use AWS Key Management Service (KMS) for server-side encryption (SSE). Using KMS encryption protects log data from unauthorized access and enhances the security of audit logs.

        **Rationale:**

        By default, CloudTrail logs are not encrypted using a customer-managed KMS key (CMK) unless explicitly configured. Without KMS encryption:

        - CloudTrail logs may be accessed or modified if security policies are misconfigured.
        - Sensitive log data is stored in plaintext, increasing security risks.
        - Compliance requirements under CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST may not be met.

        Using KMS CMKs provides fine-grained access control, automatic key rotation, and detailed audit logging via AWS CloudTrail.

        **Risk mitigation:**

        - Prevents unauthorized access to audit logs by enforcing encryption.
        - Enhances security posture by integrating AWS KMS for key management.
        - Ensures compliance with industry security frameworks requiring encryption at rest.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS CloudTrail Console.
            2.	Select Trails in the left panel.
            3.	Select a CloudTrail trail and go to the Storage Location section.
            4.	Under Log file SSE-KMS encryption, check if encryption is enabled.
            5.	If KMS encryption is not enabled, modify the trail:
              - Select Edit.
              - Under Log file encryption, select Use a custom AWS KMS key.
              - Choose an existing Customer-Managed KMS Key (CMK) or create a new one.
              - Select Save changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check if a CloudTrail trail is using KMS encryption:

            ```bash
            aws cloudtrail describe-trails --query "trailList[*].{TrailName:Name, KmsKeyId:KmsKeyId}"
            ```

            If KMS encryption is not configured, update the trail:

            ```bash
            aws cloudtrail update-trail --name <trail-name> --kms-key-id "arn:aws:kms:region:account-id:key/key-id"
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure CloudTrail is encrypted with KMS:

            ```hcl
            resource "aws_kms_key" "cloudtrail_kms_key" {
              description         = "KMS key for CloudTrail encryption"
              enable_key_rotation = true
            }

            resource "aws_cloudtrail" "secure_trail" {
              name                          = "secure-cloudtrail"
              s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
              is_multi_region_trail         = true
              kms_key_id                    = aws_kms_key.cloudtrail_kms_key.arn
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Enable CloudTrail encryption using KMS:

            ```yaml
            Resources:
              SecureCloudTrail:
                Type: "AWS::CloudTrail::Trail"
                Properties:
                  TrailName: "secure-cloudtrail"
                  S3BucketName: !Ref CloudTrailLogsBucket
                  IsMultiRegionTrail: true
                  KMSKeyId: !Ref CloudTrailKMSKey

              CloudTrailKMSKey:
                Type: "AWS::KMS::Key"
                Properties:
                  Description: "KMS key for CloudTrail encryption"
                  EnableKeyRotation: true
            ```
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-single
    filters: asset.platform == "aws-cloudtrail-trail"
    mql: |
      aws.cloudtrail.trail.kmsKey != empty
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains(nameLabel == "aws_cloudtrail")
    mql: |
      terraform.resources.where(nameLabel == "aws_cloudtrail").all(
        arguments.kms_key_id != empty
      )
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains(type == "aws_cloudtrail")
    mql: |
      terraform.plan.resourceChanges.where(type == "aws_cloudtrail").all(
        change.after.kms_key_id != empty ||
        change.afterUnknown.kms_key_id == true
      )
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains(type == "aws_cloudtrail")
    mql: |
      terraform.state.resources.where(type == "aws_cloudtrail").all(
        values.kms_key_id != empty
      )



  - uid: mondoo-aws-security-secgroup-restricted-ssh
    title: Ensure security groups restrict incoming SSH traffic
    impact: 90
    docs:
      desc: |
        This check ensures that AWS security groups are configured to restrict incoming SSH `(port 22)` traffic. Allowing unrestricted SSH access `(0.0.0.0/0 or ::/0)` poses a significant security risk by exposing instances to unauthorized access attempts, brute-force attacks, and potential exploitation by malicious actors.

        **Rationale:**

        By default, AWS allows full control over inbound and outbound traffic through security groups. However, allowing unrestricted SSH access increases the risk of unauthorized logins, credential theft, and automated attacks. Instead, SSH access should be restricted to specific IP addresses, such as known administrative networks, bastion hosts, or VPN subnets.

        **Restricting SSH access helps mitigate:**

        - **Brute-force attacks:** Reduces exposure to automated SSH login attempts.
        - **Unauthorized access:** Limits access to only trusted networks.
        - **Compliance risks:** Aligns with best practices in security frameworks like PCI DSS, NIST, and CIS benchmarks.

        **Risk mitigation:**

        - **Minimize attack surface:** Reduces the number of exposed SSH endpoints.
        - **Ensure least privilege access:** Restricts access to only authorized IP ranges.
        - **Improve network security:** Protects EC2 instances from unauthorized access.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the Amazon EC2 Console.
            2.	Select Security Groups from the left navigation panel.
            3.	Identify security groups that have inbound rules allowing port 22 (SSH) from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.	Edit the security group's inbound rules and replace 0.0.0.0/0 with a trusted IP range (e.g., your office network or VPN).
            5.	Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check security groups with unrestricted SSH access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?FromPort==`22` && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0')]].GroupId"
            ```

            Revoke unrestricted SSH access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 22 --cidr 0.0.0.0/0
            ```

            Add a more restrictive SSH rule (replace x.x.x.x/x with a trusted IP range):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 22 --cidr x.x.x.x/x
            ```
        - id: terraform
          desc: |
            **Using Terraform**

            Ensure SSH access is restricted to a specific IP range:

            ```hcl
            resource "aws_security_group" "secure_sg" {
              name        = "secure-sg"
              description = "Restricts SSH access"

              ingress {
                from_port   = 22
                to_port     = 22
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with trusted IP range
              }
              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using CloudFormation**

            This template ensures that SSH access (port 22) is only allowed from a specific IP range (e.g., a corporate VPN or a bastion host):

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted SSH access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 22
                      ToPort: 22
                      CidrIp: "192.168.1.0/24"  # Replace with your trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedSSHSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-ssh-single
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-state
  - uid: mondoo-aws-security-secgroup-restricted-ssh-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 22 && toPort >= 22 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == 22 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == 22 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-ssh-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == 22 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))



  - uid: mondoo-aws-security-secgroup-restricted-vnc
    title: Ensure security groups restrict incoming VNC traffic
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-vnc-single
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups do not allow unrestricted incoming Virtual Network Computing (VNC) traffic, which operates on ports 5900-5903. Allowing unrestricted VNC access (0.0.0.0/0 or ::/0) exposes instances to unauthorized access attempts, brute-force attacks, and remote exploitation.

        **Rationale:**

        VNC is a widely used remote desktop protocol that, if exposed to the internet, can be exploited by attackers for unauthorized access, credential theft, or lateral movement within the network. Attackers frequently scan for open VNC ports, and leaving them unrestricted significantly increases the risk of compromise.

        To mitigate risks, VNC access should be restricted to trusted IP addresses, such as an internal corporate network, a VPN, or a bastion host.

        **Risks of unrestricted VNC access:**

        - **Brute-force attacks:** Attackers can repeatedly attempt to guess VNC passwords.
        - **Unencrypted connections:** Many VNC implementations do not encrypt traffic by default.
        - **Unauthorized remote access:** Unrestricted access allows attackers to control the remote system.

        **Risk mitigation:**

        - **Limit exposure:** Restrict VNC access to known IP addresses (e.g., office VPN or bastion host).
        - **Use encrypted alternatives:** Consider replacing VNC with more secure alternatives like SSH tunneling or AWS Session Manager.
        - **Enhance authentication:** Use strong passwords, multi-factor authentication (MFA), and network segmentation.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the Amazon EC2 Console.
            2.	Select Security Groups from the left navigation panel.
            3.	Identify security groups that have inbound rules allowing traffic on ports 5900-5903 from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.	Edit the security group's inbound rules and remove any rule that allows unrestricted VNC access.
            5.	If necessary, replace 0.0.0.0/0 with a trusted IP range (e.g., your office VPN or bastion host).
            6.	Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check security groups with unrestricted VNC access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?((FromPort==`5900` || FromPort==`5901` || FromPort==`5902` || FromPort==`5903`) && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0'))]].GroupId"
            ```

            Revoke unrestricted VNC access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 5900-5903 --cidr 0.0.0.0/0
            ```

            Allow VNC access only from a trusted IP range (replace x.x.x.x/x with your specific IP range):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 5900-5903 --cidr x.x.x.x/x
            ```

        - id: terraform
          desc: |
            **Ensure security groups restrict VNC access to a specific IP range:**

            ```hcl
            resource "aws_security_group" "restricted_vnc" {
              name        = "restricted-vnc"
              description = "Restricts VNC access"

              ingress {
                from_port   = 5900
                to_port     = 5903
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with trusted IP range
              }

                egress {
                  from_port   = 0
                  to_port     = 0
                  protocol    = "-1"
                  cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
                }
            }
        - id: cloudformation
          desc: |
            **Ensure security groups restrict VNC access to a specific IP range:**

            Resources:
              RestrictedVNC:
                Type: AWS::EC2::SecurityGroup
                Properties:
                  GroupName: restricted-vnc
                  GroupDescription: Restricts VNC access
                  SecurityGroupIngress:
                    - IpProtocol: tcp
                      FromPort: 5900
                      ToPort: 5903
                      CidrIp: 203.0.113.0/24  # Replace with trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: -1
                      FromPort: 0
                      ToPort: 0
                      CidrIp: 0.0.0.0/0  # Allow all outbound traffic
            ```
  - uid: mondoo-aws-security-secgroup-restricted-vnc-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 5900 && toPort >= 5900 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
        )
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == 5900 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == 5900 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-vnc-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == 5900 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))



  - uid: mondoo-aws-security-secgroup-restricted-rdp
    title: Ensure security groups restrict incoming RDP traffic
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restricted-rdp-single
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-plan
      - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups are not configured to allow unrestricted inbound Remote Desktop Protocol (RDP) traffic, which operates on port 3389. Allowing unrestricted RDP access (0.0.0.0/0 or ::/0) significantly increases the risk of brute-force attacks, unauthorized remote access, and exploitation by malicious actors.

        **Rationale:**

        RDP is a widely used protocol for remote administration of Windows-based instances in AWS. However, exposing port 3389 to the internet without restrictions creates a high-security risk. Attackers continuously scan for open RDP ports and attempt brute-force login attacks using credential stuffing or password spraying techniques.

        Instead of allowing open RDP access, organizations should:

        - Restrict RDP access to trusted IP addresses (e.g., corporate networks, VPNs, or bastion hosts).
        - Use AWS Systems Manager Session Manager as a secure alternative to direct RDP access.
        - Enable multi-factor authentication (MFA) and strong authentication mechanisms.

        **Risk mitigation:**

        - **Prevent brute-force attacks:** Limits exposure to automated credential-guessing attacks.
        - **Ensure least privilege access:** Only trusted IPs can establish RDP sessions.
        - **Improve security posture:** Protects Windows servers from unauthorized access and exploits.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the Amazon EC2 Console.
            2.	Select Security Groups from the left navigation panel.
            3.	Identify security groups that allow inbound rules on port 3389 (RDP) from 0.0.0.0/0 (IPv4) or ::/0 (IPv6).
            4.	Select Edit inbound rules and remove any rule that allows unrestricted RDP access.
            5.	If necessary, replace 0.0.0.0/0 with a trusted IP range (e.g., a VPN or bastion host).
            6.	Save the changes.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check for security groups with unrestricted RDP access:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[?IpPermissions[?FromPort==`3389` && (IpRanges[].CidrIp=='0.0.0.0/0' || Ipv6Ranges[].CidrIpv6=='::/0')]].GroupId"
            ```

            Revoke unrestricted RDP access:

            ```bash
            aws ec2 revoke-security-group-ingress --group-id <security-group-id> --protocol tcp --port 3389 --cidr 0.0.0.0/0
            ```

            Allow RDP access only from a trusted IP range (replace x.x.x.x/x with your corporate/VPN subnet):

            ```bash
            aws ec2 authorize-security-group-ingress --group-id <security-group-id> --protocol tcp --port 3389 --cidr x.x.x.x/x
            ```

        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure security groups restrict RDP access to a specific IP range:

            ```hcl
            resource "aws_security_group" "restricted_rdp" {
              name        = "restricted-rdp"
              description = "Restricts RDP access"

              ingress {
                from_port   = 3389
                to_port     = 3389
                protocol    = "tcp"
                cidr_blocks = ["203.0.113.0/24"] # Replace with a trusted IP range
              }

                egress {
                  from_port   = 0
                  to_port     = 0
                  protocol    = "-1"
                  cidr_blocks = ["0.0.0.0/0"]  # Allow outbound traffic
                }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure security groups do not allow unrestricted RDP access:

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted RDP access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 3389
                      ToPort: 3389
                      CidrIp: "192.168.1.0/24"  # Restrict to a trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedRDPSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
  - uid: mondoo-aws-security-secgroup-restricted-rdp-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort <= 3389 && toPort >= 3389 && toPort != 0).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == 3389 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == 3389 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restricted-rdp-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == 3389 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))



  - uid: mondoo-aws-security-secgroup-restrict-traffic
    title: Ensure security groups restrict access to specific IPs and ports
    impact: 90
    variants:
      - uid: mondoo-aws-security-secgroup-restrict-traffic-single
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-hcl
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-plan
      - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-state
    docs:
      desc: |
        This check ensures that AWS security groups do not allow unrestricted access to all IPs (0.0.0.0/0 or ::/0) on any port. Allowing open access to security groups exposes AWS resources to unauthorized access, increasing the risk of security breaches, brute-force attacks, and data exfiltration.

        **Rationale:**

        AWS security groups act as virtual firewalls that control inbound and outbound traffic. When a security group allows access from all IPs (0.0.0.0/0 for IPv4 or ::/0 for IPv6) on all ports, it poses significant risks:

        - Unrestricted access to sensitive services (e.g., SSH on port 22, RDP on port 3389, or databases like MySQL on port 3306).
        - Increased exposure to brute-force attacks, credential stuffing, and other cyber threats.
        - Compliance violations under security frameworks such as CIS AWS Foundations Benchmark, PCI DSS, HIPAA, ISO 27001, and NIST.

        To mitigate these risks, security groups should be configured with the principle of least privilege, allowing access only to specific IP ranges and necessary ports.

        **Risk mitigation:**

        - Prevents unauthorized access by restricting inbound and outbound traffic.
        - Reduces exposure to external attacks (e.g., brute force, malware injections).
        - Ensures compliance with industry best practices and cloud security standards.
      remediation:
        - id: console
          desc: |
            **Using AWS Console:**

            1.	Navigate to the AWS EC2 Console.
            2.	Select Security Groups in the left panel.
            3.	Identify security groups with inbound rules allowing 0.0.0.0/0 or ::/0.
            4.	If a rule allows unrestricted access, modify it:
              - Select Edit inbound rules.
              - Restrict the source IP range to trusted networks (e.g., corporate VPN, private subnets, specific IPs).
              - Select Save changes.
            5.	Repeat for outbound rules, ensuring traffic is limited to necessary destinations.
        - id: cli
          desc: |
            **Using AWS CLI:**

            Check security groups for unrestricted inbound rules:

            ```bash
            aws ec2 describe-security-groups --query "SecurityGroups[*].{ID:GroupId, Name:GroupName, Ingress:IpPermissions[*]}"
            ```

            Revoke a rule that allows open access:

            ```bash
            aws ec2 revoke-security-group-ingress \
            --group-id <security-group-id> \
            --protocol tcp \
            --port 22 \
            --cidr 0.0.0.0/0
            ```

            Add a restricted rule (e.g., allow SSH only from a trusted IP range):

            ```bash
            aws ec2 authorize-security-group-ingress \
            --group-id <security-group-id> \
            --protocol tcp \
            --port 22 \
            --cidr 192.168.1.0/24
            ```
        - id: terraform
          desc: |
            **Using Terraform:**

            Ensure security groups do not allow open access:

            ```hcl
            resource "aws_security_group" "restricted_sg" {
              name        = "restricted-security-group"
              description = "Security group with restricted access"
              vpc_id      = aws_vpc.main.id

              ingress {
                description = "Allow SSH from a trusted IP range"
                from_port   = 22
                to_port     = 22
                protocol    = "tcp"
                cidr_blocks = ["192.168.1.0/24"]  # Restrict to a known IP range
              }

              egress {
                from_port   = 0
                to_port     = 0
                protocol    = "-1"
                cidr_blocks = ["0.0.0.0/0"]  # Allow all outbound traffic (if necessary)
              }
            }
            ```
        - id: cloudformation
          desc: |
            **Using AWS CloudFormation:**

            Ensure security groups do not allow unrestricted access:

            ```yaml
            Resources:
              SecureSecurityGroup:
                Type: "AWS::EC2::SecurityGroup"
                Properties:
                  GroupDescription: "Security group with restricted access"
                  VpcId: !Ref VPC
                  SecurityGroupIngress:
                    - IpProtocol: "tcp"
                      FromPort: 22
                      ToPort: 22
                      CidrIp: "192.168.1.0/24"  # Restrict to a trusted IP range
                  SecurityGroupEgress:
                    - IpProtocol: "-1"
                      FromPort: -1
                      ToPort: -1
                      CidrIp: "0.0.0.0/0"  # Allow outbound traffic
                  Tags:
                    - Key: "Name"
                      Value: "RestrictedSecurityGroup"

              VPC:
                Type: "AWS::EC2::VPC"
                Properties:
                  CidrBlock: "10.0.0.0/16"
                  EnableDnsSupport: true
                  EnableDnsHostnames: true
                  Tags:
                    - Key: "Name"
                      Value: "SecureVPC"
            ```
  - uid: mondoo-aws-security-secgroup-restrict-traffic-single
    filters: asset.platform == "aws-security-group"
    mql: |
      aws.ec2.securitygroup.ipPermissions.where(
        fromPort == -1 && toPort == -1).none(
          ipRanges.contains("0.0.0.0/0") || ipRanges.contains("::/0")
          )
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-hcl
    filters: asset.platform == "terraform-hcl" && terraform.resources.contains( nameLabel == "aws_security_group")
    mql: terraform.resources.where( nameLabel == "aws_security_group" && blocks.where( type == "ingress").contains( arguments.to_port == -1 )).none( blocks.where( type == "ingress" ) { arguments.cidr_blocks.contains("0.0.0.0/0") || arguments.cidr_blocks.contains("::/0") })
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-plan
    filters: asset.platform == "terraform-plan" && terraform.plan.resourceChanges.contains( type == "aws_security_group")
    mql: terraform.plan.resourceChanges.where( type == "aws_security_group" && change.after.ingress.contains( to_port == -1 )).none( change.after.ingress[0].cidr_blocks.contains("0.0.0.0/0") || change.after.ingress[0].cidr_blocks.contains("::/0"))
  - uid: mondoo-aws-security-secgroup-restrict-traffic-terraform-state
    filters: asset.platform == "terraform-state" && terraform.state.resources.contains( type == "aws_security_group")
    mql: terraform.state.resources.where( type == "aws_security_group" && values.ingress.contains( to_port == -1 ) ).none( values.ingress[0].cidr_blocks.contains("0.0.0.0/0") || values.ingress[0].cidr_blocks.contains("::/0"))
