policies:
  - uid: mondoo-aws-security
    name: AWS Security
    version: 1.0.0
    license: MPL-2.0
    tags:
      mondoo.com/category: security
      mondoo.com/platform: aws,cloud
    authors:
      - name: Mondoo, Inc
        email: hello@mondoo.com
    docs:
      desc: "## Overview\n\nAWS Security by Mondoo provides guidance for establishing minimum recommended security and operational best practices for Amazon Web Services (AWS). The controls in this policy bundle are based on AWS's Operational Best Practices recommendations as part of the [AWS Config conformance packs](https://docs.aws.amazon.com/config/latest/developerguide/conformance-packs.html).\n\n## Remote scan\n\nRemote scans use native transports in `cnspec` to provide on-demand scan results without installing any agents or integrations.\n\nFor a complete list of native transports run:\n\n```bash\ncnspec scan --help\n``` \n\n### Prerequisites\n\nRemote scanning of AWS accounts with `cnspec` relies on the access key ID and secret access key configured for the AWS CLI. For more information on configuring these keys in the AWS CLI, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n\n### Scan an AWS account\n\nThe following command will perform a scan of all enabled regions in an AWS account:\n\n```bash\ncnspec scan aws\n```\n\n### Scan a single AWS region\n\nTo specify a single region to scan with cnspec, use the `--region` flag with the AWS region code:\n\n```bash\ncnspec scan aws --region us-west-2\n```\n\nFor a complete list of AWS region codes, see [Regions and Zones](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html).\n\n### Scan an AWS account using a specific profile\n\nIf multiple AWS profiles are configured for the AWS CLI, `cnspec` can target a specific profile by setting the `AWS_PROFILE` environment variable or the `--profile` command line flag.\n\n```bash\nexport AWS_PROFILE=my-profile\ncnspec scan aws \n```\n\n```bash\ncnspec scan aws --profile my-profile\n```\n\n## Join the community!\n\nOur goal is to build policies that are simple to deploy, accurate, and actionable. \n\nIf you have any suggestions on improving this policy or need support, [join the community](https://github.com/orgs/mondoohq/discussions) in GitHub Discussions. "
    groups:
      - title: AWS Core
        filters: |
          platform.name == "aws"
          platform.kind == "api"
        checks:
          - uid: mondoo-aws-security-access-keys-rotated
          - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
          - uid: mondoo-aws-security-ec2-imdsv2-check
          - uid: mondoo-aws-security-ec2-instance-no-public-ip
          - uid: mondoo-aws-security-iam-group-has-users-check
          - uid: mondoo-aws-security-iam-password-policy
          - uid: mondoo-aws-security-iam-root-access-key-check
          - uid: mondoo-aws-security-iam-user-no-inline-policies-check
          - uid: mondoo-aws-security-iam-users-only-one-access-key
          - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
          - uid: mondoo-aws-security-root-account-mfa-enabled
          - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
          - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
          - uid: mondoo-aws-security-vpc-default-security-group-closed
          - uid: mondoo-aws-security-vpc-flow-logs-enabled
      - title: AWS Account
        filters: |
          platform.name == "aws-account"
          platform.kind == "api"
        checks:
          - uid: mondoo-aws-security-access-keys-rotated
          - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
          - uid: mondoo-aws-security-ec2-imdsv2-check
          - uid: mondoo-aws-security-ec2-instance-no-public-ip
          - uid: mondoo-aws-security-iam-password-policy
          - uid: mondoo-aws-security-iam-root-access-key-check
          - uid: mondoo-aws-security-iam-users-only-one-access-key
          - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
          - uid: mondoo-aws-security-root-account-mfa-enabled
          - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
      - title: AWS Lambda Function
        filters: |
          platform.name == "aws-lambda-function"
        checks:
          - uid: mondoo-aws-security-lambda-concurrency-check
      - title: AWS S3 Bucket
        filters: |
          platform.name == "aws-s3-bucket"
        checks:
          - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-single-bucket
      - title: AWS Security Group
        filters: |
          platform.name == "aws-security-group"
        checks:
          - uid: mondoo-aws-security-secgroup-restricted-ssh
          - uid: mondoo-aws-security-vpc-default-security-group-closed-single-secgroup
      - title: AWS VPC
        filters: |
          platform.name == "aws-vpc"
        checks:
          - uid: mondoo-aws-security-vpc-flow-logs-enabled-single-vpc
      - title: AWS DynamoDB Table
        filters: |
          platform.name == "aws-dynamodb-table"
        checks:
          - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
      - title: AWS RDS DBInstance
        filters: |
          platform.name == "aws-rds-dbinstance"
        checks:
          - uid: mondoo-aws-security-rds-instance-public-access-check
      - title: AWS Redshift Cluster
        filters: |
          platform.name == "aws-redshift-cluster"
        checks:
          - uid: mondoo-aws-security-redshift-cluster-public-access-check
      - title: AWS EC2 Volume
        filters: |
          platform.name == "aws-ec2-volume"
        checks:
          - uid: mondoo-aws-security-ec2-volume-inuse-check
      - title: AWS EC2 Snapshot
        filters: |
          platform.name == "aws-ec2-snapshot"
        checks:
          - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
      - title: AWS Gateway RestAPI
        filters: |
          platform.name == "aws-gateway-restapi"
        checks:
          - uid: mondoo-aws-security-api-gw-cache-encrypted
      - title: AWS IAM User
        filters: |
          platform.name == "aws-iam-user"
        checks:
          - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single-user
      - title: AWS EFS Filesystem
        filters: |
          platform.name == "aws-efs-filesystem"
        checks:
          - uid: mondoo-aws-security-efs-encrypted-check
      - title: AWS IAM Group
        filters: |
          platform.name == "aws-iam-group"
        checks:
          - uid: mondoo-aws-security-iam-group-has-users-check-single-group
      - title: AWS CloudWatch LogGroup
        filters: |
          platform.name == "aws-cloudwatch-loggroup"
        checks:
          - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
      - title: AWS ELB LoadBalancer
        filters: |
          platform.name == "aws-elb-loadbalancer"
        checks:
          - uid: mondoo-aws-security-elb-deletion-protection-enabled
      - title: AWS ES Domain
        filters: |
          platform.name == "aws-es-domain"
        checks:
          - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
      - title: AWS KMS Key
        filters: |
          platform.name == "aws-kms-key"
        checks:
          - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
      - title: AWS SageMaker NotebookInstance
        filters: |
          platform.name == "aws-sagemaker-notebookinstance"
        checks:
          - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
      - title: AWS CloudTrail Trail
        filters: |
          platform.name == "aws-cloudtrail-trail"
        checks:
          - uid: mondoo-aws-security-cloud-trail-encryption-enabled
    scoring_system: 2
props:
  - uid: maxAccessKeyAge
    title: Define the maximum number of days an IAM key is allowed to exist before rotation
    mql: "90"
  - uid: maxCredentialUsageAge
    title: Define the maximum number of days a credential can go unused
    mql: "90"
  - uid: iamPasswordPolicyMaxPasswordAge
    title: Define the maximum number of days a password is allowed to exist before being rotated
    mql: "90"
  - uid: iamPasswordPolicyMinimumPasswordLength
    title: Minimum password length
    mql: "14"
  - uid: iamPasswordPolicyPasswordReusePrevention
    title: Number of passwords before allowing reuse
    mql: "24"
  - uid: iamPasswordPolicyRequireLowercaseCharacters
    title: Denotes whether lowercase characters are required for passwords
    mql: "true"
  - uid: iamPasswordPolicyRequireNumbers
    title: Denotes whether numbers are required for passwords
    mql: "true"
  - uid: iamPasswordPolicyRequireSymbols
    title: Denotes whether symbols are required for passwords
    mql: "true"
  - uid: iamPasswordPolicyRequireUppercaseCharacters
    title: Denotes whether uppercase characters are required for passwords
    mql: "true"
  - uid: restrictedIncomingTrafficBlockedPort1
    title: Defines a blocked TCP port
    mql: "20"
  - uid: restrictedIncomingTrafficBlockedPort2
    title: Defines a blocked TCP port
    mql: "21"
  - uid: restrictedIncomingTrafficBlockedPort3
    title: Defines a blocked TCP port
    mql: "3389"
  - uid: restrictedIncomingTrafficBlockedPort4
    title: Defines a blocked TCP port
    mql: "3306"
  - uid: restrictedIncomingTrafficBlockedPort5
    title: Defines a blocked TCP port
    mql: "4333"
  - uid: s3AccountLevelPublicAccessBlocksBlockPublicAcls
    title: Denotes whether public ACLs should be blocked
    mql: "true"
  - uid: s3AccountLevelPublicAccessBlocksBlockPublicPolicy
    title: Denotes whether public policies should be blocked
    mql: "true"
  - uid: s3AccountLevelPublicAccessBlocksIgnorePublicAcls
    title: Denotes whether public ACLs should be ignored
    mql: "true"
  - uid: s3AccountLevelPublicAccessBlocksRestrictPublicBuckets
    title: Denotes whether public buckets should be blocked
    mql: "true"
  - uid: guarddutyNonArchivedFindingsDaysHighSev
    title: Count of days a high severity finding is allowed to exist in a non-archived state
    mql: "1"
  - uid: guarddutyNonArchivedFindingsDaysLowSev
    title: Count of days a low severity finding is allowed to exist in a non-archived state
    mql: "30"
  - uid: guarddutyNonArchivedFindingsDaysMediumSev
    title: Count of days a medium severity finding is allowed to exist in a non-archived state
    mql: "7"
  - uid: acmCertificateExpirationCheckDaysToExpiration
    title: Specify the number of days a certificate is allowed to exist before expiration
    mql: "90"
  - uid: numRegionsSecHubEnabled
    title: Define the number of regions that should have Security Hub enabled
    mql: "16"
  - uid: ebsVolumeDeleteOnTermination
    title: Defines whether instances should be configured to delete volumes on termination
    mql: "true"
queries:
  - uid: mondoo-aws-security-iam-root-access-key-check
    title: Ensure no root user account access key exists
    mql: "aws.iam.credentialReport.where( properties[\"user\"] == \"<root_account>\") {\n  accessKey1Active == false \n  accessKey2Active == false \n}\n"
    docs:
      desc: |
        AWS strongly recommends that you not use the root user for your everyday tasks, even administrative ones. Instead, adhere to the best practice of using the root user only to create your first IAM user. Then securely lock away the root user credentials and use them to perform only a few account and service management tasks. Anyone with root user credentials for your AWS account has unrestricted access to all the resources in your account, including billing information.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.credentialReport.where( properties[\"user\"] == \"<root_account>\") { accessKey1Active accessKey2Active }\n   ```\n\n  Example output\n\n  ```mql\n  aws.iam.credentialReport.where: [\n    0: {\n      accessKey1Active: false\n      accessKey2Active: false\n    }\n  ]\n  ```\n"
      remediation: |
        If any access keys exist for the root user, see [Deleting access keys for the root user](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_delete-key) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html
        title: AWS Documentation - AWS account root user
  - uid: mondoo-aws-security-root-account-mfa-enabled
    title: Ensure MFA is enabled for the "root user" account
    impact: 95
    mql: |
      aws.iam.credentialReport.where(
        properties["user"] == "<root_account>"
      ) { mfaActive == true }
    docs:
      desc: |
        AWS highly recommends that you follow the security best practice to enable multi-factor authentication (MFA) for your root account. Because your root user can perform sensitive operations in your account, adding an additional layer of authentication helps you to better secure your account. Multiple types of MFA are available.
      audit: |
        __cnspec shell__

        1. Open a Terminal.
        2. Connect cnspec shell to your AWS environment `cnspec shell aws`
        3. Run the following query:

           ```mql
           aws.iam.credentialReport.where( properties["user"] == "<root_account>") { mfaActive passwordLastChanged passwordLastUsed }
           ```

          Example output:

          ```mql
          aws.iam.credentialReport.where: [
            0: {
              mfaActive: true
            }
          ]
          ```
      remediation: "Note: This check uses the AWS Credential Report, which has a grace period of 4 hours before changes to credentials take effect.\n\n__Terraform__\n\nThe following snippet demonstrates creating a virtual device for the root user and returning the QRCode.\nAfter creating the virtual MFA device, the root user can follow the procedure described under the AWS Console section.\n\n```hcl\nresource \"aws_iam_virtual_mfa_device\" \"root_mfa\" {\n  virtual_mfa_device_name = \"root\"\n}\noutput \"root_qr_code\" {\n  value = tomap({\n    (aws_iam_virtual_mfa_device.root_mfa.virtual_mfa_device_name) = aws_iam_virtual_mfa_device.root_mfa.qr_code_png\n  })\n}\n```\n__AWS Console__\n\nMFA devices in AWS can be either hardware-based or virtual. To enable an MFA device for the root user, choose one of the following:\n\n1. [Enable a virtual MFA device for your AWS account root user (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html#enable-virt-mfa-for-root)\n2. [Enable a hardware MFA device for the AWS account root user (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_physical.html#enable-hw-mfa-for-root)\n\n__AWS CLI__\n\nSimilarly to non-root users, you can use the AWS CLI to: \n\nCreate a virtual MFA device:\n\n```bash\naws iam create-virtual-mfa-device \\\n  --virtual-mfa-device-name \"root\" \\\n  --outfile ./QRCode.png \\\n  --bootstrap-method QRCodePNG\n```\n\nActivate MFA device\n\n```bash\naws iam enable-mfa-device \\\n  --user-name \"root\" \\\n  --serial-number \"arn:aws:iam::123456976749:mfa/root\" \\\n  --authentication-code1 123456 \\\n  --authentication-code2 654321\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa
        title: Enable a virtual MFA device for your AWS account root user (console)
  - uid: mondoo-aws-security-iam-password-policy
    title: Checks whether the account password policy for IAM users meets the specified requirements
    impact: 30
    props:
      - uid: iamPasswordPolicyRequireUppercaseCharacters
        title: Denotes whether uppercase characters are required for passwords
        mql: "true"
      - uid: iamPasswordPolicyRequireLowercaseCharacters
        title: Denotes whether lowercase characters are required for passwords
        mql: "true"
      - uid: iamPasswordPolicyRequireSymbols
        title: Denotes whether symbols are required for passwords
        mql: "true"
      - uid: iamPasswordPolicyRequireNumbers
        title: Denotes whether numbers are required for passwords
        mql: "true"
      - uid: iamPasswordPolicyMinimumPasswordLength
        title: Minimum password length
        mql: "14"
      - uid: iamPasswordPolicyPasswordReusePrevention
        title: Number of passwords before allowing reuse
        mql: "24"
      - uid: iamPasswordPolicyMaxPasswordAge
        title: Define the maximum number of days a password is allowed to exist before being rotated
        mql: "90"
    mql: |
      aws.iam.accountPasswordPolicy['RequireUppercaseCharacters'] == props.iamPasswordPolicyRequireUppercaseCharacters
      aws.iam.accountPasswordPolicy['RequireLowercaseCharacters'] == props.iamPasswordPolicyRequireLowercaseCharacters
      aws.iam.accountPasswordPolicy['RequireSymbols'] == props.iamPasswordPolicyRequireSymbols
      aws.iam.accountPasswordPolicy['RequireNumbers'] == props.iamPasswordPolicyRequireNumbers
      aws.iam.accountPasswordPolicy['MinimumPasswordLength'] >= props.iamPasswordPolicyMinimumPasswordLength
      aws.iam.accountPasswordPolicy['PasswordReusePrevention'] == props.iamPasswordPolicyPasswordReusePrevention
      aws.iam.accountPasswordPolicy['MaxPasswordAge'] <= props.iamPasswordPolicyMaxPasswordAge
    docs:
      desc: |
        AWS allows for custom password policies on your AWS account to specify complexity requirements and mandatory rotation periods for your IAM users' passwords. IAM user passwords must meet the default AWS password policy if you don't set a custom password policy. AWS security best practices recommends the following password complexity requirements:

        - Require at least one uppercase character in passwords.
        - Require at least one lowercase character in passwords.
        - Require at least one symbol in passwords.
        - Require at least one number in passwords.
        - Require a minimum password length of at least 14 characters.
        - Require at least 24 passwords before allowing reuse.
        - Require at least 90 before password expiration.
        This check ensures all of the specified password policy requirements.
      audit: |
        __cnspec shell__

        1. Open a Terminal.
        2. Connect cnspec shell to your AWS environment `cnspec shell aws`
        3. Run the following query:

           ```mql
           aws.iam.accountPasswordPolicy
           ```

          Example output:

          ```mql
          aws.iam.accountPasswordPolicy: {
            AllowUsersToChangePassword: true
            ExpirePasswords: true
            HardExpiry: false
            MaxPasswordAge: "180"
            MinimumPasswordLength: "14"
            PasswordReusePrevention: "24"
            RequireLowercaseCharacters: true
            RequireNumbers: true
            RequireSymbols: true
            RequireUppercaseCharacters: true
          }
          ```
      remediation: "\n__Terraform__\n\n```hcl\nresource \"aws_iam_account_password_policy\" \"strict\" {\n  allow_users_to_change_password = true\n  require_uppercase_characters   = true\n  require_lowercase_characters   = true\n  require_symbols                = true\n  require_numbers                = true\n  minimum_password_length        = 14\n  password_reuse_prevention      = 24\n  max_password_age               = 90\n}\n```\n\n__AWS Console__\n\nTo create a custom password policy: \n\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose Account settings.\n3. In the Password policy section, choose Change password policy.\n4. Select the options you want to apply to your password policy and choose Save changes.\n\nTo change a custom password policy: \n\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose Account settings.\n3. In the Password policy section, choose Change.\n4. Select the options you want to apply to your password policy and choose Save changes.\n\n__AWS CLI__\n\n```bash\naws iam update-account-password-policy \\\n--allow-users-to-change-password \\\n--require-uppercase-characters \\\n--require-lowercase-characters \\\n--require-symbols \\\n--require-numbers \\\n--minimum-password-length 14 \\\n--password-reuse-prevention 24 \\\n--max-password-age 90\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords.html
        title: Managing user passwords in AWS
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html
        title: Setting an account password policy for IAM users
  - uid: mondoo-aws-security-access-keys-rotated
    title: Checks whether the active access keys are rotated within the number of days specified in maxAccessKeyAge (default 90)
    impact: 30
    mql: |
      aws.iam.credentialReport.where( accessKey1Active == true ) { time.now - accessKey1LastRotated < 90 * time.day }

      aws.iam.credentialReport.where( accessKey2Active == true ) { time.now - accessKey2LastRotated < 90 * time.day }
    docs:
      desc: |
        It is highly recommended that you regularly rotate (change) IAM user access keys to reduce the risk of unwanted access to your account.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.credentialReport.where( accessKey1Active == true || accessKey2Active == true ) { properties['user'] accessKey1Active accessKey2Active accessKey1LastRotated accessKey2LastRotated }\n   ```\n  \n  Example output\n\n  ```mql\n  aws.iam.credentialReport.where: [\n    0: {\n      accessKey1LastRotated: 2021-09-01 01:32:29 +0000 +0000\n      accessKey2LastRotated: Never\n      accessKey1Active: true\n      accessKey2Active: false\n      properties[user]: \"jimmy\"\n    }\n    1: {\n      accessKey1LastRotated: 2021-09-09 19:16:35 +0000 +0000\n      accessKey2LastRotated: Never\n      accessKey1Active: true\n      accessKey2Active: false\n      properties[user]: \"robert\"\n    }\n    2: {\n      accessKey1LastRotated: 2021-06-15 07:18:34 +0000 +0000\n      accessKey2LastRotated: Never\n      accessKey1Active: true\n      accessKey2Active: false\n      properties[user]: \"johnpaul\"\n    }\n    3: {\n      accessKey1LastRotated: 2021-09-29 21:53:04 +0000 +0000\n      accessKey2LastRotated: Never\n      accessKey1Active: true\n      accessKey2Active: false\n      properties[user]: \"bonzo\"\n    }\n  ]\n  ```\n"
      remediation: |
        To learn how to rotate AWS access keys, see [Rotating access keys](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_RotateAccessKey) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
        title: AWS Documentation - Managing access keys for IAM users
  - uid: mondoo-aws-security-mfa-enabled-for-iam-console-access
    title: Checks whether the AWS IAM users have multi-factor authentication (MFA) enabled
    impact: 95
    mql: |
      aws.iam.credentialReport.all(
        mfaActive == true
      )
    docs:
      desc: |
        Multi-factor authentication (MFA) is a best practice that adds an extra layer of protection on top of user names and passwords. With MFA, when a user signs in to the AWS Management Console, they are required to provide a time-sensitive authentication code provided by a registered virtual or physical device.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Run the command `cnspec shell aws`.\n3. Run the following query: \n\n  ```mql\n  aws.iam.credentialReport.where(\n    mfaActive != true\n  ) {arn properties[\"user\"]}\n  ```\n  Example output:\n\n  ```mql\n  aws.iam.credentialReport.where: [\n    0: {\n      properties[user]: \"test-iam-user\"\n      arn: \"arn:aws:iam::053121068929:user/users/test-iam-user\"\n    }\n  ]\n  ```\n"
      remediation: "Note: This check uses the AWS Credential Report, which has a grace period of 4 hours before changes to credentials take effect.\n\n__Terraform__\n\nWhen it comes to Terraform, there are a few options to remediate the absence of MFA devices. You probably already have a sensible structure for organizing your users into groups and restrictive policies.\n\nThe following example shows how to:\n1. Create users.\n2. Create users' login profiles with a PGP public key.\n3. Create a group and group policy that allows self-management of IAM profiles.\n4. Attach users to a group.\n5. Create Virtual MFA devices for users.\n6. Provide each user with the output QR Code and password.\n\n```hcl\nvariable \"users\" {\n  type = set(string)\n  default = [\n    \"mondoo-test@mondoo.com\",\n    \"mondoo-test2@mondoo.com\"\n  ]\n}\n\nresource \"aws_iam_user\" \"mondoo_test_users\" {\n  for_each = toset(var.users)\n  name     = each.key\n}\n\nresource \"aws_iam_user_login_profile\" \"mondoo_test_users_profile\" {\n  for_each                = var.users\n  user                    = each.key\n  # Key pair created using GnuPG. This is the public key\n  pgp_key = file(\"path/to/gpg_pub_key_base64.pem\")\n  password_reset_required = true\n  lifecycle {\n    ignore_changes = [\n      password_length,\n      password_reset_required,\n      pgp_key,\n    ]\n  }\n}\n\nresource \"aws_iam_virtual_mfa_device\" \"mondoo_test_mfa\" {\n  for_each                = toset(var.users)\n  virtual_mfa_device_name = each.key\n}\n\nresource \"aws_iam_group\" \"enforce_mfa_group\" {\n  name = \"EnforceMFAGroup\"\n}\n\nresource \"aws_iam_group_membership\" \"enforce_mfa_group_membership\" {\n  name  = \"EnforceMFAGroupMembership\"\n  group = aws_iam_group.enforce_mfa_group.name\n  users = [for k in aws_iam_user.mondoo_test_users : k.name]\n}\n\nresource \"aws_iam_group_policy\" \"enforce_mfa_policy\" {\n  name   = \"EnforceMFAGroupPolicy\"\n  group  = aws_iam_group.enforce_mfa_group.id\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n        \"Sid\": \"AllowViewAccountInfo\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:GetAccountPasswordPolicy\",\n            \"iam:ListVirtualMFADevices\"\n        ],\n        \"Resource\": \"*\"\n    },       \n    {\n        \"Sid\": \"AllowManageOwnPasswords\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:ChangePassword\",\n            \"iam:GetUser\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnAccessKeys\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:CreateAccessKey\",\n            \"iam:DeleteAccessKey\",\n            \"iam:ListAccessKeys\",\n            \"iam:UpdateAccessKey\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnSigningCertificates\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:DeleteSigningCertificate\",\n            \"iam:ListSigningCertificates\",\n            \"iam:UpdateSigningCertificate\",\n            \"iam:UploadSigningCertificate\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnSSHPublicKeys\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:DeleteSSHPublicKey\",\n            \"iam:GetSSHPublicKey\",\n            \"iam:ListSSHPublicKeys\",\n            \"iam:UpdateSSHPublicKey\",\n            \"iam:UploadSSHPublicKey\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnGitCredentials\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:CreateServiceSpecificCredential\",\n            \"iam:DeleteServiceSpecificCredential\",\n            \"iam:ListServiceSpecificCredentials\",\n            \"iam:ResetServiceSpecificCredential\",\n            \"iam:UpdateServiceSpecificCredential\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnVirtualMFADevice\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:CreateVirtualMFADevice\",\n            \"iam:DeleteVirtualMFADevice\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:mfa/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"AllowManageOwnUserMFA\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"iam:DeactivateMFADevice\",\n            \"iam:EnableMFADevice\",\n            \"iam:ListMFADevices\",\n            \"iam:ResyncMFADevice\"\n        ],\n        \"Resource\": \"arn:aws:iam::*:user/$${aws:username}\"\n    },\n    {\n        \"Sid\": \"DenyAllExceptListedIfNoMFA\",\n        \"Effect\": \"Deny\",\n        \"NotAction\": [\n            \"iam:CreateVirtualMFADevice\",\n            \"iam:EnableMFADevice\",\n            \"iam:GetUser\",\n            \"iam:ListMFADevices\",\n            \"iam:ListVirtualMFADevices\",\n            \"iam:ResyncMFADevice\",\n            \"sts:GetSessionToken\"\n        ],\n        \"Resource\": \"*\",\n        \"Condition\": {\n            \"BoolIfExists\": {\n                \"aws:MultiFactorAuthPresent\": \"false\"\n            }\n        }\n    }\n  ]\n}\nPOLICY\n}\n\noutput \"user_password_map\" {\n  # Outputs a map in the format {\"mondoo-test@mondoo.com\": <PGPEncryptedPassword>, \"mondoo-test2@mondoo.com\": <PGPEncryptedPassword>}\n  value = { for k, v in aws_iam_user_login_profile.mondoo_test_users_profile : k => v.password }\n}\n\noutput \"user_qr_map\" {\n  # Outputs a map in the format {\"mondoo-test@mondoo.com\": <QRCode>, \"mondoo-test2@mondoo.com\": <QRCode>}\n  value = { for k, v in aws_iam_virtual_mfa_device.mondoo_test_mfa : k => v.qr_code_png }\n}\n\n__AWS Console__\n\nTo enable MFA for any user accounts with AWS console access, see [Enabling a virtual multi-factor authentication (MFA) device (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html) in the AWS documentation.\n\n**To enable a virtual MFA device for an IAM user (console)**\n\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose Users.\n3. In the User Name list, choose the name of the intended MFA user.\n4. Choose the Security credentials tab. Next to Assigned MFA device, choose Manage.\n5. In the Manage MFA Device wizard, choose Virtual MFA device and then choose Continue.\n6. IAM generates and displays configuration information for the virtual MFA device, including a QR code graphic. The graphic represents the \"secret configuration key\" available for manual entry on devices that do not support QR codes.\n7. Open your virtual MFA app. For a list of apps you can use to host virtual MFA devices, see [Multi-Factor Authentication](https://aws.amazon.com/iam/features/mfa/).\n8. If the virtual MFA app supports multiple virtual MFA devices or accounts, choose the option to create a new virtual MFA device or account.\n9. Determine whether the MFA app supports QR codes, and then do one of the following:\n\n  * From the wizard, choose Show QR code, and then use the app to scan the QR code. For example, you might choose the camera icon or choose an option similar to Scan code, and then use the device's camera to scan the code.\n  * In the Manage MFA Device wizard, choose Show secret key, and then type the secret key into your MFA app.\n\n10. When you finish, the virtual MFA device generates one-time passwords.\n11. In the Manage MFA Device wizard, in the MFA code 1 box, type the one-time password that currently appears in the virtual MFA device. Wait up to 30 seconds for the device to generate a new one-time password. Then type the second one-time password into the MFA code 2 box. \n12. Choose Assign MFA.\n\n__AWS CLI__\n\nCreate an MFA device: \n\n```bash\naws iam create-virtual-mfa-device \\\n  --virtual-mfa-device-name \"mondoo.test@mondoo.com\" \\\n  --outfile ./QRCode.png \\\n  --bootstrap-method QRCodePNG\n```\n\nEnable MFA device for existing user:\n\n```bash\naws iam enable-mfa-device \\\n  --user-name \"mondoo.test@mondoo.com\" \\\n  --serial-number \"arn:aws:iam::123456976749:mfa/mondoo.test@mondoo.com\" \\\n  --authentication-code1 123456 \\\n  --authentication-code2 654321\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html
        title: Using multi-factor authentication (MFA) in AWS
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html
        title: Enabling a virtual multi-factor authentication (MFA) device (console)
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-iam-group-has-users-check
    title: Checks whether IAM groups have at least one IAM user
    mql: |
      aws.iam.groups.all(usernames.length > 0)
    docs:
      desc: |
        AWS Identity and Access Management (IAM) can help you incorporate the principles of least privilege and separation of duties with access permissions and authorizations by ensuring that IAM groups have at least one IAM user. Placing IAM users in groups based on their associated permissions or job function is one way to incorporate least privilege.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.groups.where( usernames.length == 0 ) {*}\n   ```\n\n  Example output\n\n  ```mql\n  aws.iam.groups.where: [\n    0: {\n      name: \"MyUserGroup\"\n      id: \"AGPASSOFBMF7OMHVGHACB\"\n      createDate: 2022-01-11 18:19:26 +0000 UTC\n      usernames: []\n      arn: \"arn:aws:iam::177043759486:group/MyUserGroup\"\n    }\n  ]\n  ```\n"
      remediation: |
        To delete empty IAM groups, see [Deleting an IAM user group](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage_delete.html) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage.html
        title: AWS Documentation -Managing IAM user groups
  - uid: mondoo-aws-security-iam-users-only-one-access-key
    title: Ensure there is only one active access key available for any single IAM user
    mql: aws.iam.credentialReport.none( accessKey1Active == true && accessKey2Active == true )
    docs:
      desc: |
        This check ensures for the existence of more than one access key for each user within an AWS account. Each AWS key within an account is something that must be protected, and rotated regularly. Since AWS access keys are long-term credentials, one of the best ways to protect your account is to not allow users to have multiple access keys, which reduces the overall number of keys, reducing the risk of exposure.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query:\n   \n   ```mql\n   aws.iam.users.where(accessKeys[0].length >= 1) \n   ```\n"
      remediation: |
        __From Console:__

        1. Sign in to the AWS Management Console and navigate to IAM dashboard at https://console.aws.amazon.com/iam/.
        2. In the left navigation panel, choose **Users**.
        3. Select the IAM user name that you want to examine.
        4. On the IAM user configuration page, select **Security Credentials** tab.
        5. In the Access Keys section, choose one access key that is less than 90 days old. This should be the only active key used by this IAM user to access AWS resources programmatically. Test your application(s) to make sure that the chosen access key is working.
        6. In the same Access Keys section, identify your non-operational access keys (other than the chosen one) and deactivate it by selecting the Make Inactive link.

        If you receive the Change Key Status confirmation box, select **Deactivate** to switch off the selected key.

        Repeat steps no. 3 - 7 for each IAM user in your AWS account.

        __From Command Line:__

        Using the IAM user and access key information provided in the Audit CLI, choose one access key that is less than 90 days old. This should be the only active key used by this IAM user to access AWS resources programmatically. Test your application(s) to make sure that the chosen access key is working.

        Run the `update-access-key`` command below using the IAM user name and the non-operational access key IDs to deactivate the unnecessary key(s). Refer to the Audit section to identify the unnecessary access key ID for the selected IAM user

        **Note:** The following command does not return any output:

        ```bash
        aws iam update-access-key --access-key-id <access-key-id> --status Inactive --user-name <user-name>
        ```

        To confirm that the selected access key pair has been successfully deactivated run the list-access-keys audit command again for that IAM User:

        ```bash
        aws iam list-access-keys --user-name <user-name>
        ```

        The command output should expose the metadata for each access key associated with the IAM user. If the non-operational key pair(s) Status is set to Inactive, the key has been successfully deactivated and the IAM user access configuration adheres now to this recommendation.

        Repeat steps no. 1 - 3 for each IAM user in your AWS account.
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check
    title: Ensure IAM Users Receive Permissions Only Through Groups
    mql: |
      aws.iam.users.all( attachedPolicies.length == 0 )

      aws.iam.users.all( policies.length == 0 )
    docs:
      desc: |
        AWS that IAM users must inherit permissions from IAM groups or roles. This policy checks that none of your IAM users have policies attached directly to the user. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.users.where( policies.length != 0 || attachedPolicies.length != 0 ) { name arn policies attachedPolicies }\n   ```\n\n  Example output\n\n  ```mql\n  aws.iam.users.where: [\n    0: {\n      arn: \"arn:aws:iam::1234567890987:user/1234567890987-alice\"\n      name: \"1234567890987-alice\"\n      attachedPolicies: []\n      policies: [\n        0: \"excess_policy\"\n      ]\n    }\n    1: {\n      arn: \"arn:aws:iam::1234567890987:user/maria\"\n      name: \"maria\"\n      attachedPolicies: [\n        0: aws.iam.policy id = arn:aws:iam::1234567890987:policy/ec2-instance-connect-sendssh\n      ]\n      policies: []\n    }\n    2: {\n      arn: \"arn:aws:iam::1234567890987:user/bobby\"\n      name: \"bobby\"\n      attachedPolicies: [\n        0: aws.iam.policy id = arn:aws:iam::1234567890987:policy/terraform20210901011436036200000004\n      ]\n      policies: []\n    }\n  ]\n  ```\n"
      remediation: |
        To learn how to remove inline policies from IAM users, see [Removing a permissions policy from a user (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_change-permissions.html#users_change_permissions-remove-policy-console) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html
        title: Managed policies and inline policies
  - uid: mondoo-aws-security-vpc-default-security-group-closed
    title: Ensure the default security group of every VPC restricts all traffic
    impact: 80
    mql: |
      aws.ec2.securityGroups.where(name == "default").all(
        ipPermissions.length == 0
        && ipPermissionsEgress.length == 0
      )
    docs:
      desc: |
        The rules for a default security group allow all ingress and egress traffic. To keep users from using the default security group (which cannot be deleted) of a VPC, delete all ingress and egress rules to block all traffic.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query: \n\n  ```mql\n  aws.ec2.securityGroups.where(\n    name == \"default\"\n  ).where(\n    ipPermissions.length != 0\n    || ipPermissionsEgress.length != 0\n  ){id name region ipPermissions{*} ipPermissionsEgress{*}}\n  ```\n\n  Example output:\n\n  ```mql\n  aws.ec2.securityGroups.where.where: [\n    0: {\n      ipPermissions: [\n        0: {\n          id: \"sg-0bd4b1ef47132d3de-0\"\n          fromPort: 0\n          toPort: 0\n          ipProtocol: \"-1\"\n          ipv6Ranges: []\n          ipRanges: []\n        }\n      ]\n      ipPermissionsEgress: []\n      name: \"default\"\n      region: \"eu-north-1\"\n      id: \"sg-0bd4b1ef47132d3de\"\n    }\n  ]\n  ```\n"
      remediation: "__Terraform__\n\nTerraform provides the resource `aws_default_security_group`, which differently from other Terraform resources, has the following effects in the state of the infrastructure.\n\n1. \"Adopts\" the default security group for the provided `vpc_id`.\n2. Removes all inbound (ingress) and outbound (egress) rules for the security group.\n\nIn order to remediate this check using Terraform, apply the following logic for every region the account has access to by aliasing the providers. \n\n**Notice:** it is necessary to create a new security group for all VPCs in order to reassign any resources created and previously using the default security groups.\n\n```hcl\nprovider \"aws\" {\n  alias  = \"us_east_1\"\n  region = \"us-east-1\"\n}\n\ndata \"aws_vpcs\" \"us_east_1\" {\n  provider = aws.us_east_1\n}\n\nresource \"aws_security_group\" \"replacement_for_default\" {\n  name     = \"AllowOrDenySomething\"\n  for_each = toset(data.aws_vpcs.us_east_1.ids)\n  vpc_id   = each.value\n  ingress {\n    # ... other configuration ...\n  }\n  egress {\n    # ... other configuration ...\n  }\n}\n\nresource \"aws_default_security_group\" \"us_east_1\" {\n  for_each = toset(data.aws_vpcs.us_east_1.ids)\n  vpc_id   = each.value\n  provider = aws.us_east_1\n}\n```\n\n__AWS Console__\n\nTo remediate this issue, create new security groups and assign those security groups to your resources (if needed). To prevent the default security groups from being used, remove their inbound and outbound rules.\nTo create new security groups and assign them to your resources:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose Security groups. View the default security groups details to see the resources that are assigned to them.\n3. Create a set of least-privilege security groups for the resources. For details on how to create security groups, see [Creating a security group](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#CreatingSecurityGroups) in the Amazon VPC User Guide.\n4. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n5. On the Amazon EC2 console, change the security group for the resources that use the default security groups to the least-privilege security group you created. See [Changing an instance's security groups](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SG_Changing_Group_Membership) in the Amazon VPC User Guide.\n\nAfter you assign the new security groups to the resources, remove the inbound and outbound rules from the default security groups. This ensures that the default security groups are not used.\n\nTo remove the rules from the default security group:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose Security groups.\n3. Select a default security group and choose the Inbound rules tab. Choose Edit inbound rules. Then delete all inbound rules. Choose Save rules.\n4. Repeat the previous step for each default security group.\n5. Select a default security group and choose the Outbound rule tab. Choose Edit outbound rules. Then delete all outbound rules. Choose Save rules.\n6. Repeat the previous step for each default security group.\nFor more information, see [Working with security groups](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#WorkingWithSecurityGroups) in the Amazon VPC User Guide.\n\n__AWS CLI__\n\nApply the same logic to the AWS CLI to remediate this check.\n\n**Notice:** Run this against all regions your account has access to.\n\n1. Get the security groups in the region.\n```bash\naws ec2 describe-security-groups\n```\n2. Create a new security group to replace the default in every VPC (if needed).\n```bash\naws ec2 create-security-group \\\n  --description \"AllowOrDenySomething\" \\\n  --group-name \"AllowOrDenySomething\" \\\n  --vpc-id <value>\n```\n3. Modify security group to provide inbound and outbound rules.\n```bash\naws ec2 modify-security-group-rules \\\n  --group-id <value> \\\n  --security-group-rules <rules>\n```\n4. Revoke security group rules from default security groups\n```bash\naws ec2 revoke-security-group-egress \\\n  --group-id <id_default_sg>\naws ec2 revoke-security-group-ingress \\\n  --group-id <id_default_sg>\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Reference - EC2
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-s3-buckets-account-level-block-public-access
    title: Checks if the required S3 public access block settings are configured from the account level
    impact: 30
    mql: |
      aws.s3control.accountPublicAccessBlock.values.all( _ == true )
    docs:
      desc: |
        Amazon S3 Block Public Access provides settings for access points, buckets, and accounts to help you manage public access to Amazon S3 resources. By default, new buckets, access points, and objects do not allow public access.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query: \n\n```mql\naws.s3control.accountPublicAccessBlock\n```\n\nExample output:\n\n```mql\naws.s3control.accountPublicAccessBlock: null\n```\n"
      remediation: |
        __Terraform__

        The following Terraform resource configures account level access to S3:

        ```hcl
        resource "aws_s3_account_public_access_block" "s3_control" {
          block_public_acls       = true
          block_public_policy     = true
          ignore_public_acls      = true
          restrict_public_buckets = true
        }
        ```

        __AWS Console__

        To edit block public access settings for all the S3 buckets in an AWS account.

        1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.
        2. Choose Block Public Access settings for this account.
        3. Choose Edit to change the block public access settings for all the buckets in your AWS account.
        4. Choose the settings you want to change, then choose Save changes.
        5. When you're asked for confirmation, enter confirm. Then choose Confirm to save your changes.

        __AWS CLI__

        ```bash
        aws s3control put-public-access-block \
        --account-id <value> \
        --public-access-block-configuration '{"BlockPublicAcls": true, "BlockPublicPolicy": true, "IgnorePublicAcls": true, "RestrictPublicBuckets": true}'
        ```
    refs:
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/configuring-block-public-access-account.html
        title: Configuring block public access settings for your account
  - uid: mondoo-aws-security-ec2-ebs-encryption-by-default
    title: Ensure EBS volume encryption is enabled by default
    impact: 30
    mql: |
      aws.ec2.ebsEncryptionByDefault.values.all(_ == true)
    docs:
      desc: |
        New Amazon EBS volumes aren't encrypted by default. However, there is a setting in the Amazon Elastic Compute Cloud (Amazon EC2) console that turns on encryption by default for all new Amazon EBS volumes and snapshot copies created within a specified Region.
      audit: |
        __cnspec shell__

        1. Open a Terminal.
        2. Connect cnspec shell to your AWS environment `cnspec shell aws`
        3. Run the following query:

          ```mql
          aws.ec2.ebsEncryptionByDefault
          ```

          Example output:

          ```mql
          aws.ec2.ebsEncryptionByDefault
            aws.ec2.ebsEncryptionByDefault: {
              ap-northeast-1: false
              ap-northeast-2: false
              ap-northeast-3: false
              ap-south-1: false
              ap-southeast-1: false
              ap-southeast-2: false
              ca-central-1: false
              eu-central-1: false
              eu-north-1: false
              eu-west-1: false
              eu-west-2: false
              eu-west-3: false
              sa-east-1: false
              us-east-1: true
              us-east-2: true
              us-west-1: false
              us-west-2: false
            }
          ```
      remediation: |
        __Terraform__

        The `aws_ebs_encryption_by_default` resource can be used to enable EBS encryption by default. This must be applied to each region.

        ```hcl
        provider "aws" {
          region = var.region
        }

        resource "aws_ebs_encryption_by_default" "example" {
          enabled = true
        }
        ```
        __AWS Console__

        1. Open the [Amazon EC2 console](https://console.aws.amazon.com/ec2/).
        2. Select the **Region** from the drop-down menu.
        3. On the **EC2 Dashboard**, under **Account Attributes**, select **Settings**.
        4. Under **EBS Storage**, select **Always encrypt new EBS volumes**.
        5. Select **Change the default key** and choose any of your keys ([default/KMS Keys](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#kms_keys)) as the **Default encryption key**.
        6. Select **Save Settings**.

        __AWS CLI__

        The following `enable-ebs-encryption-by-default` example enables EBS encryption for your AWS account in the current region by default.

        ```bash
        aws ec2 enable-ebs-encryption-by-default
        ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default
        title: AWS Documentation - Encryption by default
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited
    title: Checks if Amazon Simple Storage Service (S3) has bucket-level public access restrictions at the bucket level
    impact: 80
    mql: "aws.s3.buckets.all( \n  publicAccessBlock != null \n  && publicAccessBlock.values.all(_ == true)\n)\n"
    docs:
      desc: |
        This check ensures S3 buckets have bucket-level public access blocks applied. This check fails if any of the following settings are set to false:

        1. ignorePublicAcls
        2. blockPublicPolicy
        3. blockPublicAcls
        4. restrictPublicBuckets

        Block Public Access at the S3 bucket level provides controls to ensure that objects never have public access. Public access is granted to buckets and objects through access control lists (ACLs), bucket policies, or both.
        Unless you intend to have your S3 buckets publicly accessible, you should configure the bucket-level Amazon S3 Block Public Access feature.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.s3.buckets.all( \n    publicAccessBlock != null \n    && publicAccessBlock.values.all(_ == true)\n  )\n  ```\n\n  Example output\n\n  ```mql\n  [failed] [].all()\n    actual:   [\n      0: aws.s3.bucket id = arn:aws:s3:::mondoo-test2.policies.test-ui\n    ]\n  ```\n"
      remediation: |
        __Terraform__

        The following resource will create a Public Access Block resource and apply it to the specific bucket.

        ```hcl
        resource "aws_s3_bucket_public_access_block" "example" {
          bucket   = aws_s3.bucket.example.id
          block_public_acls       = true
          block_public_policy     = true
          ignore_public_acls      = true
          restrict_public_buckets = true
        }
        ```

        __AWS Console__

        To understand how to use the AWS Console to block public access on a bucket level, see:
        * [Blocking public access to your Amazon S3 storage](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html)

        __AWS CLI__

        ```bash
        aws s3api put-public-access-block \
          --bucket <value>
          --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS Documentation - Blocking public access to your Amazon S3 storage
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS CLI Command Reference - aws s3api put-public-access-block
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block
        title: Terraform Documentation - AWS Provider - aws_s3_bucket_public_access_block
  - uid: mondoo-aws-security-ec2-instance-no-public-ip
    title: Ensures no instances have a public IP
    impact: 80
    mql: "aws.ec2.instances.all( \n  publicIp.length == 0 \n)\n"
    docs:
      desc: 'EC2 instances with a public IP address are at an increased risk of compromise. It is recommended that EC2 instances not be configured with a public IP address. '
      audit: "\n__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query to return a list of all running EC2 instances across all enabled regions that along with the `instanceId`, `region`, and the configured `publicIp`\n\n  ```mql\n  aws.ec2.instances.where( state = \"running\" && publicIp != \"\" ) { instanceId region tags publicIp }   \n  ```\n  \n  Example output\n\n  ```mql\n  aws.ec2.instances.where: [\n  0: {\n    instanceId: \"i-0070af411a515f14a\"\n    tags: {\n      Environment: \"windows-development-vpc\"\n      Name: \"win19-dev-workstation-106e1f1c\"\n      Terraform: \"true\"\n    }\n    publicIp: \"54.55.222.9\"\n    region: \"us-east-1\"\n  }\n  ]\n  ```"
      remediation: "__Terraform__\n\nUse the `associate_public_ip_address = false` argument with the `aws_instance` resource to ensure EC2 instances are provisioned without a public IP address\n\n```hcl \nresource \"aws_instance\" \"no_public_ip\" {\n  ...\n  associate_public_ip_address = false\n}\n```\n__AWS Console__\n\nBy default, non-default subnets have the IPv4 public addressing attribute set to false, and default subnets have this attribute set to true. An exception is a non-default subnet created by the Amazon EC2 launch instance wizard  the wizard sets the attribute to true. You can modify this attribute using the Amazon VPC console.\n\nTo modify your subnet's public IPv4 addressing behavior:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose **Subnets**.\n3. Select your subnet and choose **Actions, Edit subnet settings**.\n4. The **Enable auto-assign public IPv4 address** check box, if selected, requests a public IPv4 address for all instances launched into the selected subnet. Select or clear the check box as required, and then choose **Save**.\n\n__AWS CLI__\n\nThe following command runs an EC2 Instance in a default subnet without associating a public IP address to it.\n\n```bash\naws ec2 run-instances \\\n--image-id <ami_id> \\\n--instance-type <instance_flavor> \\\n--no-associate-public-ip-address \\\n--key-name MyKeyPair\n```"
    refs:
      - url: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-ip-addressing.html
        title: AWS Documentation - IP addressing for your VPCs and subnets
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance
        title: Terraform Registry - aws_instance
  - uid: mondoo-aws-security-ec2-imdsv2-check
    title: Checks whether the instance metadata version is configured with IMDSv2 (http tokens required)
    impact: 80
    mql: |
      aws.ec2.instances.all(
        httpTokens == "required"
      )
    docs:
      desc: |
        EC2 instances should be configured to use IMDSv2 to prevent unauthorized access to instance metadata from application vulnerabilities such as Server Side Request Forgery (SSRF). IMDSv1 has been involved in security exploits.

        By default, you can use either IMDSv1 or IMDSv2, or both. The instance metadata service distinguishes between IMDSv1 and IMDSv2 requests based on whether, for any given request, either the PUT or GET headers, which are unique to IMDSv2, are present in that request. For more information, see [Add defense in depth against open firewalls, reverse proxies, and SSRF vulnerabilities with enhancements to the EC2 Instance Metadata Service](https://aws.amazon.com/blogs/security/defense-in-depth-open-firewalls-reverse-proxies-ssrf-vulnerabilities-ec2-instance-metadata-service/).
      audit: |
        __cnspec shell__

        1. Open a Terminal.
        2. Connect cnspec shell to your AWS environment `cnspec shell aws`
        3. Run the following query

          ```bash
          aws.ec2.instances.where( httpTokens != "required" ) { arn instanceId region tags httpTokens }
          ```

          Example Output

          ```mql
          aws.ec2.instances.where: [
            0: {
              instanceId: "i-0070af411a515f14a"
              region: "us-east-1"
              arn: "arn:aws:ec2:us-east-1:1234375555:instance/i-0070af411a515f14a"
              httpTokens: "optional"
              tags: {
                Environment: "windows-development-vpc"
                Name: "win19-dev-workstation-106e1f1c"
                Terraform: "true"
              }
            }
          ]
          ```
      remediation: |
        In order to remediate this check, there are a series of steps necessary to transition to IMDSv2. The steps include both configuring existing instances (such as changing your Terraform EC2 resources), and updating CLIs, SDKs, and software that uses role credentials.

        If your existing EC2 instance uses IMDSv1, you can reconfigure it to use IMDSv2. To learn how, see: [Transition to using Instance Metadata Service Version 2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html#instance-metadata-transition-to-version-2)

        __Terraform__

        Use the `metadata_options` block to configure `http_tokens = "required"`

        ```hcl
        resource "aws_instance" "web_host" {
          metadata_options {
            http_tokens   = "required"
          }
        }
        ```

        __AWS Console__

        To configure your new EC2 instance with IMDSv2 from the console
        1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
        2. Choose Launch instance and then choose Launch instance.
        3. In the Configure Instance Details step, under Advanced Details, for Metadata version, choose V2 (token required).
        4. Choose Review and Launch.

        __AWS CLI__

        In order to modify a running instance

        ```bash
        aws ec2 modify-instance-metadata-options \
        --instance-id <value>
        --http-tokens required \
        --http-endpoint enabled
        ```

        In order to create a new instance

        ```bash
        aws ec2 run-instances \
        --image-id <ami_id> \
        --instance-type <instance_flavor> \
        --metadata-options "HttpEndpoint=enabled,HttpTokens=required"
        ```
  - uid: mondoo-aws-security-vpc-flow-logs-enabled
    title: Ensure VPC flow logging is enabled in all VPCs
    impact: 30
    mql: |
      aws.vpcs.all(
        flowLogs.any(
          status == "ACTIVE"
        )
      )
    docs:
      desc: |
        This check ensures Amazon VPC Flow Logs are found and enabled for all VPCs. Default VPCs should always fail this check as they do not come with flow logs activated.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect cnspec Shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.vpcs.where(\n    flowLogs.length == 0\n  ){id arn region state isDefault flowLogs tags}\n  ```\n\n  Example output: only showing 1 VPC, but default VPCs in all regions will fail this check.\n\n  ```mql\n  aws.vpcs.where: [\n    0: {\n      arn: \"arn:aws:vpc:eu-north-1:053121068929:id/vpc-0c3955e3d04d2e09a\"\n      flowLogs: []\n      id: \"vpc-0c3955e3d04d2e09a\"\n      isDefault: true\n      region: \"eu-north-1\"\n      state: \"available\"\n      tags: {}\n    }\n    ...\n  ]\n  ```\n"
      remediation: "There are a few considerations while remediating this check:\n\n1. Default VPCs should not be used, therefore they should be deleted to avoid enabling flow logs for them.\n2. Any default or non-default VPC must have flow logs activated.\n3. Therefore the best way to remediate this check is to: \n  \n  * Migrate resources from default to non-default VPCs.\n  * Delete default VPCs.\n  * Enable flow logs for the non-default VPCs.\n\nWe recommend using either Terraform or the AWS console as there is automation to delete VPC and its dependencies in place.\n\n__Terraform__\n\nOpen source Terraform modules can help us obtain this result by providing ways to delete VPCs and children dependencies.\n\n**Notice:** The following example is destructive and irreversible. It destroys all child dependencies of default VPCs, including:\n\n1. Subnets\n2. Route tables\n3. NACLs\n4. Internet Gateways\n\nThis module execution will fail for VPCs containing resources attached to the network interfaces. In this case, review the resources and redeploy them to a non-default VPC.\n\n```hcl\nterraform {\n  required_providers {\n    awsutils = {\n      source = \"cloudposse/awsutils\"\n    }\n  }\n}\n\n# Create one for each region\nprovider \"awsutils\" {\n  alias  = \"ap_northeast_1\"\n  region = \"ap-northeast-1\"\n}\n\n# Create one for each region - the creation of this resource will delete the default resources\nresource \"awsutils_default_vpc_deletion\" \"us_east_1\" {\n  provider = awsutils.us_east_1\n}\n```\n\nTo enable Flow logs for VPCs with customer-managed KMS keys:\n\n```hcl\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_kms_key\" \"vpc_flowlog\" {\n  description         = \"Key to provide encryption to VPC Flow Logs\"\n  enable_key_rotation = true\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Encrypt*\",\n          \"kms:Decrypt*\",\n          \"kms:ReEncrypt*\",\n          \"kms:GenerateDataKey*\",\n          \"kms:Describe*\"\n        ]\n        Principal = {\n          Service = \"logs.<region>.amazonaws.com\"\n        }\n        Resource = \"arn:aws:kms:*:${data.aws_caller_identity.current.account_id}:key/*\"\n      },\n      {\n        Sid    = \"Enable IAM User Permissions\"\n        Effect = \"Allow\"\n        Principal = {\n          \"AWS\" : \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\nresource \"aws_cloudwatch_log_group\" \"vpc_flowlog\" {\n  name              = \"VPCFlowLog\"\n  kms_key_id        = aws_kms_key.vpc_flowlog.arn\n  retention_in_days = <value>\n}\n\nresource \"aws_iam_role\" \"vpc_flowlog\" {\n  name = \"VPCFlowLog\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"VPCFlowLog\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"vpc-flow-logs.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"vpc_flowlog\" {\n  name = \"VpcFlowLog\"\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\",\n          \"logs:DescribeLogGroups\",\n          \"logs:DescribeLogStreams\",\n        ],\n        Effect   = \"Allow\",\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_policy_attachment\" \"vpc_flowlog\" {\n  name       = \"${aws_iam_policy.vpc_flowlog.name}Attachment\"\n  roles      = [aws_iam_role.vpc_flowlog.id]\n  policy_arn = aws_iam_policy.vpc_flowlog.arn\n}\n\nresource \"aws_flow_log\" \"example\" {\n  iam_role_arn    = aws_iam_role.vpc_flowlog.arn\n  log_destination = aws_cloudwatch_log_group.vpc_flowlog.arn\n  traffic_type    = \"ALL\"\n  vpc_id          = aws_vpc.example.id\n}\n```\n\n__AWS Console__\n\nTo delete the default VPCs:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. Under Resources by Region, VPCs, choose See all regions.\n3. For each region with a default VPC, choose the region to open the VPC home page for that region in another tab.\n4. Under Your VPCs, check the default VPC.\n5. Under Actions, choose Delete VPC.\n6. In the Delete VPC form, acknowledge that you want to delete the default VPC.\n7. Choose Delete VPC.\n8. In case there are resources deployed to that VPC, an error will be sent back. In that case:\n  \n  * Create a VPC to hold the resources in the default VPC.\n  * Redeploy your resources to the non-default VPC.\n  * Try deleting the VPC again.\n\nTo enable VPC flow logging:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. Under Virtual Private Cloud, choose Your VPCs.\n3. Select a VPC to update.\n4. At the bottom of the page, choose Flow Logs.\n5. Choose Create flow log.\n6. For Filter, choose Reject.\n7. For Destination log group, choose the log group to use.\n8. For IAM role, choose the IAM role to use.\n9. Choose Create.\n\n__AWS CLI__\n\nDeleting default VPCs using the CLI is discouraged. In order to maintain the idempotency of commands, there is no automated deletion of children resources in place.\n\nWe advise that AWS customers delete default VPCs using either Terraform or the AWS Console (see above).\n\nTo create flow logs for non-default VPCs and send them to CloudWatch (recommended), proceed as follows:\n\n1. Create a policy (`key-policy.json`) to allow the CloudWatch principal access to KMS keys, replace `<account_id>`\n\n```javascript\n{\n  \"Version\": \"2012-10-17\"\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\"\n      \"Action\": [\n        \"kms:Encrypt*\",\n        \"kms:Decrypt*\",\n        \"kms:ReEncrypt*\",\n        \"kms:GenerateDataKey*\",\n        \"kms:Describe*\"\n      ]\n      \"Principal\": {\n        \"Service\": \"logs.us-east-1.amazonaws.com\"\n      }\n      \"Resource\": \"arn:aws:kms:*:<account_id>:key/*\"\n    },\n    {\n      \"Sid\": \"Enable IAM User Permissions\"\n      \"Effect\": \"Allow\"\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::<account_id>:root\"\n      }\n      \"Action\": \"kms:*\"\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n```bash\naws kms create-key \\\n  --description \"Key to provide encryption to VPC Flow Logs\" \\\n  --policy file://key-policy.json\n```\n\n2. Enable key rotation\n\n```bash\naws kms enable-key-rotation \\\n  --key-id <value>\n```\n\n3. Create a policy (`role-policy.json`) to allow CloudWatch to manage log groups\n\n```javascript\n{\n  \"Version\": \"2012-10-17\"\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\",\n        \"logs:DescribeLogGroups\",\n        \"logs:DescribeLogStreams\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n4. Create a role\n\n```bash\naws iam create-role \\\n  --path \"/\" \\\n  --role-name \"VPCFlowLog\"\n```\n\n5. Attach the policy to the role\n\n```bash\naws iam attach-role-policy \\\n  --role-name <value> \\\n  --policy-arn <value>\n```\n\n6. Create a CloudWatch log group\n\n```bash\naws logs create-log-group \\\n  --log-group-name <value> \\\n  --kms-key-id <value>\n```\n\n7. Create a CloudWatch log flow\n\n```bash\naws ec2 create-flow-logs \\\n  --deliver-logs-permission-arn <iam_role_arn> \\\n  --traffic-type \"ALL\" \\\n  --resource-ids \"<list>\" \"<vpcs>\" \"<ids>\" \\\n  --resource-type \"VPC\" \\\n  --log-destination-type \"cloud-watch-logs\" \\\n  --log-destination <arn_cloudwatch_log_group>\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/index.html
        title: AWS Documentation - AWS CLI Command Reference - logs
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Command Reference - ec2
      - url: https://registry.terraform.io/providers/cloudposse/awsutils/latest/docs
        title: Terraform registry - Cloud Posse AWS Utils Provider
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-iam-user-no-inline-policies-check-single-user
    title: Ensure IAM Users Receive Permissions Only Through Groups
    mql: |
      aws.iam.user { attachedPolicies.length == 0 }

      aws.iam.user { policies.length == 0 }
    docs:
      desc: |
        AWS that IAM users must inherit permissions from IAM groups or roles. This policy checks that none of your IAM users have policies attached directly to the user. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.users.where( policies.length != 0 || attachedPolicies.length != 0 ) { name arn policies attachedPolicies }\n   ```\n\n  Example output\n\n  ```mql\n  aws.iam.users.where: [\n    0: {\n      arn: \"arn:aws:iam::1234567890987:user/1234567890987-alice\"\n      name: \"1234567890987-alice\"\n      attachedPolicies: []\n      policies: [\n        0: \"excess_policy\"\n      ]\n    }\n    1: {\n      arn: \"arn:aws:iam::1234567890987:user/maria\"\n      name: \"maria\"\n      attachedPolicies: [\n        0: aws.iam.policy id = arn:aws:iam::1234567890987:policy/ec2-instance-connect-sendssh\n      ]\n      policies: []\n    }\n    2: {\n      arn: \"arn:aws:iam::1234567890987:user/bobby\"\n      name: \"bobby\"\n      attachedPolicies: [\n        0: aws.iam.policy id = arn:aws:iam::1234567890987:policy/terraform20210901011436036200000004\n      ]\n      policies: []\n    }\n  ]\n  ```\n"
      remediation: |
        To learn how to remove inline policies from IAM users, see [Removing a permissions policy from a user (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_change-permissions.html#users_change_permissions-remove-policy-console) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html
        title: Managed policies and inline policies
  - uid: mondoo-aws-security-iam-group-has-users-check-single-group
    title: Checks whether IAM groups have at least one IAM user
    mql: |
      aws.iam.group { usernames.length > 0 }
    docs:
      desc: |
        AWS Identity and Access Management (IAM) can help you incorporate the principles of least privilege and separation of duties with access permissions and authorizations by ensuring that IAM groups have at least one IAM user. Placing IAM users in groups based on their associated permissions or job function is one way to incorporate least privilege.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.iam.groups.where( usernames.length == 0 ) {*}\n   ```\n\n  Example output\n\n  ```mql\n  aws.iam.groups.where: [\n    0: {\n      name: \"MyUserGroup\"\n      id: \"AGPASSOFBMF7OMHVGHACB\"\n      createDate: 2022-01-11 18:19:26 +0000 UTC\n      usernames: []\n      arn: \"arn:aws:iam::177043759486:group/MyUserGroup\"\n    }\n  ]\n  ```\n"
      remediation: |
        To delete empty IAM groups, see [Deleting an IAM user group](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage_delete.html) in the AWS documentation.
    refs:
      - url: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage.html
        title: AWS Documentation - Managing IAM user groups
  - uid: mondoo-aws-security-vpc-default-security-group-closed-single-secgroup
    title: Ensure the default security group of every VPC restricts all traffic
    impact: 80
    mql: |
      aws.ec2.securitygroup { if (name == "default") {
        ipPermissions.length == 0
        && ipPermissionsEgress.length == 0
      }}
    docs:
      desc: |
        The rules for a default security group allow all ingress and egress traffic. To keep users from using the default security group (which cannot be deleted) of a VPC, delete all ingress and egress rules to block all traffic.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query: \n\n  ```mql\n  aws.ec2.securityGroups.where(\n    name == \"default\"\n  ).where(\n    ipPermissions.length != 0\n    || ipPermissionsEgress.length != 0\n  ){id name region ipPermissions{*} ipPermissionsEgress{*}}\n  ```\n\n  Example output:\n\n  ```mql\n  aws.ec2.securityGroups.where.where: [\n    0: {\n      ipPermissions: [\n        0: {\n          id: \"sg-0bd4b1ef47132d3de-0\"\n          fromPort: 0\n          toPort: 0\n          ipProtocol: \"-1\"\n          ipv6Ranges: []\n          ipRanges: []\n        }\n      ]\n      ipPermissionsEgress: []\n      name: \"default\"\n      region: \"eu-north-1\"\n      id: \"sg-0bd4b1ef47132d3de\"\n    }\n  ]\n  ```\n"
      remediation: "__Terraform__\n\nTerraform provides the resource `aws_default_security_group`, which differently from other Terraform resources, has the following effects in the state of the infrastructure.\n\n1. \"Adopts\" the default security group for the provided `vpc_id`.\n2. Removes all inbound (ingress) and outbound (egress) rules for the security group.\n\nIn order to remediate this check using Terraform, please apply the following for every region the account has access to by aliasing the providers. \n\n**Notice:** it is necessary to create a new security group for all VPCs in order to reassign any resources created and previously using the default security groups.\n\n```hcl\nprovider \"aws\" {\n  alias  = \"us_east_1\"\n  region = \"us-east-1\"\n}\n\ndata \"aws_vpcs\" \"us_east_1\" {\n  provider = aws.us_east_1\n}\n\nresource \"aws_security_group\" \"replacement_for_default\" {\n  name     = \"AllowOrDenySomething\"\n  for_each = toset(data.aws_vpcs.us_east_1.ids)\n  vpc_id   = each.value\n  ingress {\n    # ... other configuration ...\n  }\n  egress {\n    # ... other configuration ...\n  }\n}\n\nresource \"aws_default_security_group\" \"us_east_1\" {\n  for_each = toset(data.aws_vpcs.us_east_1.ids)\n  vpc_id   = each.value\n  provider = aws.us_east_1\n}\n```\n\n__AWS Console__\n\nTo remediate this issue, create new security groups and assign those security groups to your resources (if needed). To prevent the default security groups from being used, remove their inbound and outbound rules.\nTo create new security groups and assign them to your resources:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose Security groups. View the default security groups details to see the resources that are assigned to them.\n3. Create a set of least-privilege security groups for the resources. For details on how to create security groups, see [Creating a security group](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#CreatingSecurityGroups) in the Amazon VPC User Guide.\n4. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n5. On the Amazon EC2 console, change the security group for the resources that use the default security groups to the least-privilege security group you created. See [Changing an instance's security groups](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SG_Changing_Group_Membership) in the Amazon VPC User Guide.\n\nAfter you assign the new security groups to the resources, remove the inbound and outbound rules from the default security groups. This ensures that the default security groups are not used.\n\nTo remove the rules from the default security group:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose Security groups.\n3. Select a default security group and choose the Inbound rules tab. Choose Edit inbound rules. Then delete all inbound rules. Choose Save rules.\n4. Repeat the previous step for each default security group.\n5. Select a default security group and choose the Outbound rule tab. Choose Edit outbound rules. Then delete all outbound rules. Choose Save rules.\n6. Repeat the previous step for each default security group.\nFor more information, see [Working with security groups](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#WorkingWithSecurityGroups) in the Amazon VPC User Guide.\n\n__AWS CLI__\n\nApply the same logic to the AWS CLI to remediate this check.\n\n**Notice:** Run this against all regions your account has access to.\n\n1. Get the security groups in the region.\n```bash\naws ec2 describe-security-groups\n```\n2. Create a new security group to replace the default in every VPC (if needed).\n```bash\naws ec2 create-security-group \\\n  --description \"AllowOrDenySomething\" \\\n  --group-name \"AllowOrDenySomething\" \\\n  --vpc-id <value>\n```\n3. Modify security group to provide inbound and outbound rules.\n```bash\naws ec2 modify-security-group-rules \\\n  --group-id <value> \\\n  --security-group-rules <rules>\n```\n4. Revoke security group rules from default security groups\n```bash\naws ec2 revoke-security-group-egress \\\n  --group-id <id_default_sg>\naws ec2 revoke-security-group-ingress \\\n  --group-id <id_default_sg>\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Reference - EC2
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-s3-bucket-level-public-access-prohibited-single-bucket
    title: Checks if Amazon Simple Storage Service (S3) has bucket-level public access restrictions at the bucket level
    impact: 80
    mql: "aws.s3.bucket { \n  publicAccessBlock != null \n  && publicAccessBlock.values.all(_ == true)\n}\n"
    docs:
      desc: |
        This check ensures S3 buckets have bucket-level public access blocks applied. this check fails if any of the following settings are set to false:

        1. ignorePublicAcls
        2. blockPublicPolicy
        3. blockPublicAcls
        4. restrictPublicBuckets

        Block Public Access at the S3 bucket level provides controls to ensure that objects never have public access. Public access is granted to buckets and objects through access control lists (ACLs), bucket policies, or both.
        Unless you intend to have your S3 buckets publicly accessible, you should configure the bucket-level Amazon S3 Block Public Access feature.
      audit: "__cnspec shell__\n\n1. Open a Terminal.\n2. Connect cnspec shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.s3.buckets.all( \n    publicAccessBlock != null \n    && publicAccessBlock.values.all(_ == true)\n  )\n  ```\n\n  Example output\n\n  ```mql\n  [failed] [].all()\n    actual:   [\n      0: aws.s3.bucket id = arn:aws:s3:::mondoo-test2.policies.test-ui\n    ]\n  ```\n"
      remediation: |
        __Terraform__

        The following resource will create a Public Access Block resource and apply it to the specific bucket.

        ```hcl
        resource "aws_s3_bucket_public_access_block" "example" {
          bucket   = aws_s3.bucket.example.id
          block_public_acls       = true
          block_public_policy     = true
          ignore_public_acls      = true
          restrict_public_buckets = true
        }
        ```

        __AWS Console__

        To understand how to use the AWS Console to block public access on a bucket level, see:
        * [Blocking public access to your Amazon S3 storage](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html)

        __AWS CLI__

        ```bash
        aws s3api put-public-access-block \
          --bucket <value>
          --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html
        title: AWS Documentation - Blocking public access to your Amazon S3 storage
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-public-access-block.html
        title: AWS CLI Command Reference - aws s3api put-public-access-block
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block
        title: Terraform Documentation - AWS Provider - aws_s3_bucket_public_access_block
  - uid: mondoo-aws-security-vpc-flow-logs-enabled-single-vpc
    title: Ensure VPC flow logging is enabled in all VPCs
    impact: 30
    mql: |
      aws.vpc {
        flowLogs.any(
          status == "ACTIVE"
        )
      }
    docs:
      desc: |
        This check ensures Amazon VPC Flow Logs are found and enabled for all VPCs. Default VPCs should always fail this check as they do not come with flow logs activated.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect cnspec Shell to your AWS environment `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.vpcs.where(\n    flowLogs.length == 0\n  ){id arn region state isDefault flowLogs tags}\n  ```\n\n  Example output: only showing 1 VPC, but default VPCs in all regions will fail this check.\n\n  ```mql\n  aws.vpcs.where: [\n    0: {\n      arn: \"arn:aws:vpc:eu-north-1:053121068929:id/vpc-0c3955e3d04d2e09a\"\n      flowLogs: []\n      id: \"vpc-0c3955e3d04d2e09a\"\n      isDefault: true\n      region: \"eu-north-1\"\n      state: \"available\"\n      tags: {}\n    }\n    ...\n  ]\n  ```\n"
      remediation: "There are a few considerations while remediating this check:\n\n1. Default VPCs should not be used, therefore they should be deleted to avoid enabling flow logs for them.\n2. Any default or non-default VPC must have flow logs activated.\n3. Therefore the best way to remediate this check is to: \n  \n  * Migrate resources from default to non-default VPCs.\n  * Delete default VPCs.\n  * Enable flow logs for the non-default VPCs.\n\nWe recommend using either Terraform or the AWS console as there is automation to delete VPC and its dependencies in place.\n\n__Terraform__\n\nOpen source Terraform modules can help us obtain this result by providing ways to delete VPCs and children dependencies.\n\n**Notice:** The following example is destructive and irreversible. It destroys all child dependencies of default VPCs, including:\n\n1. Subnets\n2. Route tables\n3. NACLs\n4. Internet Gateways\n\nThis module execution will fail for VPCs containing resources attached to the network interfaces. In this case, review the resources and redeploy them to a non-default VPC.\n\n```hcl\nterraform {\n  required_providers {\n    awsutils = {\n      source = \"cloudposse/awsutils\"\n    }\n  }\n}\n\n# Create one for each region\nprovider \"awsutils\" {\n  alias  = \"ap_northeast_1\"\n  region = \"ap-northeast-1\"\n}\n\n# Create one for each region - the creation of this resource will delete the default resources\nresource \"awsutils_default_vpc_deletion\" \"us_east_1\" {\n  provider = awsutils.us_east_1\n}\n```\n\nTo enable Flow logs for VPCs with customer-managed KMS keys:\n\n```hcl\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_kms_key\" \"vpc_flowlog\" {\n  description         = \"Key to provide encryption to VPC Flow Logs\"\n  enable_key_rotation = true\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Encrypt*\",\n          \"kms:Decrypt*\",\n          \"kms:ReEncrypt*\",\n          \"kms:GenerateDataKey*\",\n          \"kms:Describe*\"\n        ]\n        Principal = {\n          Service = \"logs.<region>.amazonaws.com\"\n        }\n        Resource = \"arn:aws:kms:*:${data.aws_caller_identity.current.account_id}:key/*\"\n      },\n      {\n        Sid    = \"Enable IAM User Permissions\"\n        Effect = \"Allow\"\n        Principal = {\n          \"AWS\" : \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\nresource \"aws_cloudwatch_log_group\" \"vpc_flowlog\" {\n  name              = \"VPCFlowLog\"\n  kms_key_id        = aws_kms_key.vpc_flowlog.arn\n  retention_in_days = <value>\n}\n\nresource \"aws_iam_role\" \"vpc_flowlog\" {\n  name = \"VPCFlowLog\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"VPCFlowLog\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"vpc-flow-logs.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"vpc_flowlog\" {\n  name = \"VpcFlowLog\"\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\",\n          \"logs:DescribeLogGroups\",\n          \"logs:DescribeLogStreams\",\n        ],\n        Effect   = \"Allow\",\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_policy_attachment\" \"vpc_flowlog\" {\n  name       = \"${aws_iam_policy.vpc_flowlog.name}Attachment\"\n  roles      = [aws_iam_role.vpc_flowlog.id]\n  policy_arn = aws_iam_policy.vpc_flowlog.arn\n}\n\nresource \"aws_flow_log\" \"example\" {\n  iam_role_arn    = aws_iam_role.vpc_flowlog.arn\n  log_destination = aws_cloudwatch_log_group.vpc_flowlog.arn\n  traffic_type    = \"ALL\"\n  vpc_id          = aws_vpc.example.id\n}\n```\n\n__AWS Console__\n\nTo delete the default VPCs:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. Under Resources by Region, VPCs, choose See all regions.\n3. For each region with a default VPC, choose the region to open the VPC home page for that region in another tab.\n4. Under Your VPCs, check the default VPC.\n5. Under Actions, choose Delete VPC.\n6. In the Delete VPC form, acknowledge that you want to delete the default VPC.\n7. Choose Delete VPC.\n8. In case there are resources deployed to that VPC, an error will be sent back. In that case:\n  \n  * Create a VPC to hold the resources in the default VPC.\n  * Redeploy your resources to the non-default VPC.\n  * Try deleting the VPC again.\n\nTo enable VPC flow logging:\n\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. Under Virtual Private Cloud, choose Your VPCs.\n3. Select a VPC to update.\n4. At the bottom of the page, choose Flow Logs.\n5. Choose Create flow log.\n6. For Filter, choose Reject.\n7. For Destination log group, choose the log group to use.\n8. For IAM role, choose the IAM role to use.\n9. Choose Create.\n\n__AWS CLI__\n\nDeleting default VPCs using the CLI is discouraged. In order to maintain the idempotency of commands, there is no automated deletion of children resources in place.\n\nWe advise that AWS customers delete default VPCs using either Terraform or the AWS Console (see above).\n\nTo create flow logs for non-default VPCs and send them to CloudWatch (recommended), proceed as follows:\n\n1. Create a policy (`key-policy.json`) to allow the CloudWatch principal access to KMS keys, replace `<account_id>`\n\n```javascript\n{\n  \"Version\": \"2012-10-17\"\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\"\n      \"Action\": [\n        \"kms:Encrypt*\",\n        \"kms:Decrypt*\",\n        \"kms:ReEncrypt*\",\n        \"kms:GenerateDataKey*\",\n        \"kms:Describe*\"\n      ]\n      \"Principal\": {\n        \"Service\": \"logs.us-east-1.amazonaws.com\"\n      }\n      \"Resource\": \"arn:aws:kms:*:<account_id>:key/*\"\n    },\n    {\n      \"Sid\": \"Enable IAM User Permissions\"\n      \"Effect\": \"Allow\"\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::<account_id>:root\"\n      }\n      \"Action\": \"kms:*\"\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n```bash\naws kms create-key \\\n  --description \"Key to provide encryption to VPC Flow Logs\" \\\n  --policy file://key-policy.json\n```\n\n2. Enable key rotation\n\n```bash\naws kms enable-key-rotation \\\n  --key-id <value>\n```\n\n3. Create a policy (`role-policy.json`) to allow CloudWatch to manage log groups\n\n```javascript\n{\n  \"Version\": \"2012-10-17\"\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\",\n        \"logs:DescribeLogGroups\",\n        \"logs:DescribeLogStreams\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n4. Create a role\n\n```bash\naws iam create-role \\\n  --path \"/\" \\\n  --role-name \"VPCFlowLog\"\n```\n\n5. Attach the policy to the role\n\n```bash\naws iam attach-role-policy \\\n  --role-name <value> \\\n  --policy-arn <value>\n```\n\n6. Create a CloudWatch log group\n\n```bash\naws logs create-log-group \\\n  --log-group-name <value> \\\n  --kms-key-id <value>\n```\n\n7. Create a CloudWatch log flow\n\n```bash\naws ec2 create-flow-logs \\\n  --deliver-logs-permission-arn <iam_role_arn> \\\n  --traffic-type \"ALL\" \\\n  --resource-ids \"<list>\" \"<vpcs>\" \"<ids>\" \\\n  --resource-type \"VPC\" \\\n  --log-destination-type \"cloud-watch-logs\" \\\n  --log-destination <arn_cloudwatch_log_group>\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/index.html
        title: AWS Documentation - AWS CLI Command Reference - logs
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html
        title: AWS Documentation - AWS CLI Command Reference - ec2
      - url: https://registry.terraform.io/providers/cloudposse/awsutils/latest/docs
        title: Terraform registry - Cloud Posse AWS Utils Provider
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-dynamodb-table-encrypted-kms
    title: Checks that all DynamoDB tables are encrypted with AWS Key Management Service (KMS)
    impact: 30
    mql: "# @msg Found ${length} DynamoDB tables not using KMS encryption.\n#\n# ${{name arn region sseDescription}}\naws.dynamodb.table {\n  sseDescription[\"SSEType\"] == \"KMS\" \n  && sseDescription[\"Status\"] == \"ENABLED\"\n}\n"
    docs:
      desc: |
        Checks whether all DynamoDB tables are encrypted with a customer managed KMS key (non-default).
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.dynamodb.tables.where(\n    sseDescription.length == 0\n  ){*}\n  ```\n\n  Example output\n\n  ```mql\n  aws.dynamodb.tables.where: [\n    0: {\n      tags: {}\n      backups: []\n      arn: \"arn:aws:dynamodb:us-east-1:053121068929:table/GameScoresAutoscale\"\n      region: \"us-east-1\"\n      continuousBackups: {\n        ContinuousBackupsStatus: \"ENABLED\"\n        PointInTimeRecoveryDescription: {\n          EarliestRestorableDateTime: \"2022-08-02T18:54:51Z\"\n          LatestRestorableDateTime: \"2022-08-03T15:38:43.954Z\"\n          PointInTimeRecoveryStatus: \"ENABLED\"\n        }\n      }\n      sseDescription: {}\n      name: \"GameScoresAutoscale\"\n      provisionedThroughput: {\n        LastDecreaseDateTime: null\n        LastIncreaseDateTime: null\n        NumberOfDecreasesToday: 0.000000\n        ReadCapacityUnits: 1.000000\n        WriteCapacityUnits: 1.000000\n      }\n    }\n  ]\n  ```\n"
      remediation: |
        __Terraform__

        To remediate this check, create an AWS KMS Key and use it to encrypt the violating DynamoDB resource.

        ```hcl
        resource "aws_kms_key" "dynamodb_encryption" {
          description         = "Used for DynamoDB encryption configuration"
          enable_key_rotation = true
        }

        resource "aws_dynamodb_table" "example" {
          # ... other configuration ...
          server_side_encryption {
            enabled     = true
            kms_key_arn = aws_kms_key.dynamodb_encryption.arn
          }
        }
        ```

        __AWS Console__

        Assuming there is an existing AWS KMS key available to encrypt DynamoDB.

        To change a DynamoDB table encryption to a customer managed and owned KMS key.

        1. Open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.
        2. Choose the table that you want to work with, and then choose Additional settings.
        3. Under Encryption, choose Manage encryption.
        4. For Encryption at rest, choose Stored in your account, and owned and managed by you.
        5. Select the AWS Key to use. Save changes.

        __AWS CLI__

        ```bash
        aws dynamodb update-table \
          --table-name <value> \
          --sse-specification "Enabled=true,SSEType=KMS,KMSMasterKeyId=<kms_key_arn>"
        ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/index.html
        title: AWS Documentation - AWS CLI Command Reference - DynamoDB
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
      - url: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html
        title: AWS Documentation - DynamoDB encryption at rest
  - uid: mondoo-aws-security-lambda-concurrency-check
    title: Checks whether lambda functions are configured with function-level concurrent execution limit
    mql: aws.lambda.function { concurrency > 0 }
  - uid: mondoo-aws-security-rds-instance-public-access-check
    title: Checks that all RDS instances are not publicly accessible
    impact: 95
    mql: "# @msg Found ${length} RDS instance(s) that are publicly accessible:\n# \n# ${{arn name region dbInstanceIdentifier tags}}\naws.rds.dbinstance { publiclyAccessible == false }\n"
    docs:
      desc: |
        Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item.

        The default behavior varies depending on whether `DBSubnetGroupName` is specified.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n   ```mql\n   aws.rds.dbInstances.where(publiclyAccessible == true) {arn name region dbInstanceIdentifier tags}\n   ```\n\n  Example output\n\n  ```mql\n  aws.rds.dbInstances.where: [\n    0: {\n      arn: \"arn:aws:rds:us-moonbase-2:12345:db:rds-12345-mondoo-demo\"\n      tags: {\n        Environment: \"12345-mondoo-demo\"\n        Name: \"12345-mondoo-demo-rds\"\n        git_file: \"terraform/aws/db-app.tf\"\n        git_repo: \"mondoo-demo-environment\"\n      }\n      region: \"us-moonbase-2\"\n      dbInstanceIdentifier: \"rds-12345-mondoo-demo\"\n      name: \"db1\"\n    }\n  ]\n  ```\n"
      remediation: "__Terraform__\n\nUse the `aws_db_instance` resource to explicitly state that publicly_accessible = false. \n\n```hcl\nresource \"aws_db_instance\" \"pass_public_accessible\" {\n  allocated_storage    = 10\n  engine               = \"mysql\"\n  engine_version       = \"5.7\"\n  instance_class       = \"db.t3.micro\"\n  name                 = \"mydb\"\n  username             = \"foo\"\n  password             = \"foobarbaz\"\n  parameter_group_name = \"default.mysql5.7\"\n  skip_final_snapshot  = true\n  publicly_accessible  = false\n}\n```\n\n__AWS Console__\n\nTo remediate this issue, update your RDS DB instances to remove public access.\n\n**To remove public access from RDS DB instances**\n\n1. Open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. Navigate to Databases and then choose your public database.\n3. Choose Modify.\n4. Under Connectivity, expand Additional connectivity configuration.\n5. Under Public access, choose Not publicly accessible.\n6. Choose Continue.\n7. Under Scheduling of modifications, choose Apply immediately.\n8. Choose Modify DB Instance.\n\n__AWS CLI__\n\nThe following example demonstrates how to remediate publicly accessible RDS instances. Running this command can render your instance unassessable if you rely on the public access for your operations. Make sure you review your architecture before applying this remediation.\n\n**In order to modify an existing RDS instance**\n\n```bash\naws rds modify-db-instance \\\n  --db-instance-identifier <rds_instance_id> \\\n  --no-publicly-accessible\n```\n\n**In order to create a new RDS instance without public access**\n\n```bash\naws rds create-db-instance \\\n  --db-name \"production\" \\\n  --db-instance-identifier \"production-mysql-5-7\" \\\n  --db-instance-class \"db.t3.micro\" \\\n  --db-parameter-group-name \"default.mysql5.7\" \\\n  --engine \"mysql\" \\\n  --engine-version \"5.7\" \\\n  --allocated-storage 10 \\\n  --master-username \"mymasteruser\" \\\n  --master-user-password \"mysupersecretpasswordforthemasteruser\"\n```\n"
    refs:
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-cluster.html
        title: AWS CLI Command Reference - create-db-cluster
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html
        title: AWS CLI Command Reference - modify-db-instance
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#publicly_accessible
        title: Terraform Registry - aws_db_instance
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-redshift-cluster-public-access-check
    title: Checks whether Redshift clusters are publicly accessible
    impact: 95
    mql: |
      # @msg Found ${length} publicly accessible Redshift clusters.
      #
      # ${{name arn region publiclyAccessible}}
      aws.redshift.cluster {
        publiclyAccessible == false
      }
    docs:
      desc: |
        The PubliclyAccessible attribute of the Amazon Redshift cluster configuration indicates whether the cluster is publicly accessible. When the cluster is configured with PubliclyAccessible set to true, it is an Internet-facing instance that has a publicly resolvable DNS name, which resolves to a public IP address.

        When the cluster is not publicly accessible, it is an internal instance with a DNS name that resolves to a private IP address. Unless you intend for your cluster to be publicly accessible, the cluster should not be configured with PubliclyAccessible set to true.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.redshift.clusters.where(\n    publiclyAccessible != false\n  ){name arn region publiclyAccessible}\n  ```\n\n  Example output\n\n  ```mql\n  aws.redshift.clusters.where: [\n    0: {\n      region: \"us-east-1\"\n      publiclyAccessible: true\n      name: \"test-redshift-cluster\"\n      arn: \"arn:aws:redshift:us-east-1:053121068929:cluster/test-redshift-cluster\"\n    }\n  ]\n  ```\n"
      remediation: |
        __Terraform__

        To remediate this check, it is necessary to modify the redshift cluster resource and set `publicly_accessible` to `false`, the default value is `true`.

        ```hcl
        resource "aws_redshift_cluster" "example" {
          # ... other configuration ...
          publicly_accessible = false
        }
        ```

        __AWS Console__

        To disable public access to an Amazon Redshift cluster

        1. Open the Amazon Redshift console at https://console.aws.amazon.com/redshift/.
        2. In the navigation menu, choose Clusters, then choose the name of the cluster with the security group to modify.
        3. Choose Actions, then choose Modify publicly accessible setting.
        4. Under Allow instances and devices outside the VPC to connect to your database through the cluster endpoint, choose No.
        5. Choose Confirm.

        __AWS CLI__

        Use the `modify-cluster` command to set `--no-publicly-accessible`.

        ```bash
        aws redshift modify-cluster \
          --cluster-identifier "test-redshift-cluster" \
          --no-publicly-accessible
        ```
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
      - url: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/redshift/index.html
        title: AWS Documentation - AWS CLI Command Reference - Redshift
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
        title: Terraform Documentation - AWS Provider
  - uid: mondoo-aws-security-ec2-volume-inuse-check
    title: Checks whether EBS volumes are attached to EC2 instances and configured for deletion on instance termination
    impact: 30
    props:
      - uid: ebsVolumeDeleteOnTermination
        title: Defines whether instances should be configured to delete volumes on termination
        mql: "true"
    mql: "# @msg Found ${length} EBS volumes not attached to an instance:\n# \n# ${{ arn id volumeType availabilityZone tags }}    \naws.ec2.volume { attachments.length > 0 }\n\n# @msg Found ${length} EC2 instances that are not configured to delete volume on termination:\n# \n# ${{ arn instanceId region tags }} \nif (props.ebsVolumeDeleteOnTermination) {\n  aws.ec2.instances.all(deviceMappings.all(deleteOnTermination == true ))\n}\n"
    docs:
      desc: "Identifying and removing unattached (unused) Elastic Block Store (EBS) volumes in your AWS account can lower the cost of your monthly AWS bill. Deleting unused EBS volumes also reduces the risk of confidential or sensitive data leaving your premises. This check ensures there are no EBS volumes that are not attached to an instance. Additionally, it checks whether archived EC2 instances are configured to delete volumes on termination.\n\nBy default, EC2 instances are configured to delete the data in any EBS volumes associated with the instance, and to delete the root EBS volume of the instance. However, any non-root EBS volumes attached to the instance, at launch or during execution, get persisted after termination by default. \n"
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.ec2.volumes.where( attachments.length == 0 ) {*}\n  ```\n\n  Example output\n\n  ```mql\n  mondoo> aws.ec2.volumes.where( attachments.length == 0 ) {*}\n  aws.ec2.volumes.where: [\n    0: {\n      volumeType: \"gp2\"\n      attachments: []\n      availabilityZone: \"us-west-2a\"\n      encrypted: false\n      id: \"vol-0f5661d9f9db6dd3a\"\n      arn: \"arn:aws:ec2:us-west-2:187043755555:volume/vol-0f5661d9f9db6dd3a\"\n      state: \"available\"\n      tags: {\n        Name: \"Unattached Test\"\n      }\n    }\n  ]        \n  ```\n"
      remediation: |
        __Terraform__

        In order to prevent this scenario using Terraform, create EC2 instances with embedded EBS blocks. This ensures that any EBS blocks associated with the instance (not only the root) will be deleted on instance termination by having the attribute `ebs_block_device.delete_on_termination` defaulted to `true`.

        ```hcl
        resource "aws_instance" "web" {
            ami                    = <ami_id>
            instance_type          = <instance_flavor>
            ebs_block_device {
              delete_on_termination = true # Default
              device_name           = "/dev/sdh"
            }
        ```

        __AWS Console__

        To delete an EBS volume using the console

        1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
        2. In the navigation pane, choose **Volumes**.
        3. Select the volume to delete and choose **Actions, Delete volume**.
        4. Note: If Delete volume is greyed out, the volume is attached to an instance. You must detach the volume from the instance before it can be deleted.
        5. In the confirmation dialog box, choose **Delete**.

        __AWS CLI__

        This example command deletes an available volume with the volume ID of vol-049df61146c4d7901. If the command succeeds, no output is returned.

        ```bash
        aws ec2 delete-volume --volume-id vol-049df61146c4d7901
        ```
    refs:
      - url: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html
        title: AWS Documentation - Delete an Amazon EBS volume
  - uid: mondoo-aws-security-ebs-snapshot-public-restorable-check
    title: Checks that all EBS snapshots are not publicly restorable
    mql: aws.ec2.snapshot { createVolumePermission.none(_['Group'] == "all" ) }
  - uid: mondoo-aws-security-api-gw-cache-encrypted
    title: Checks that all methods in Amazon API Gateway have caching enabled and encrypted
    impact: 30
    mql: "# @msg Found ${length} API Gateway(s) containing stage(s) with cache encryption disabled:\n#\n# ${{ arn name }}\naws.apigateway.restapi {\n  stages.all(\n    methodSettings.values.all(\n      _[\"CachingEnabled\"] == false\n      ||\n      _[\"CachingEnabled\"] == true\n      &&\n      _[\"CacheDataEncrypted\"] == true\n    ) \n  )\n}\n"
    docs:
      desc: |
        This check ensures all methods in API Gateway REST API stages that have cache enabled are encrypted. The control fails if any method in an API Gateway REST API stage is configured to cache and the cache is not encrypted.

        API Gateway REST API caches should be encrypted at rest for an added layer of security.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.apigateway.restApis.all(\n    stages.all(\n      methodSettings.values.all(\n        _[\"CachingEnabled\"] == false\n        ||\n        _[\"CachingEnabled\"] == true\n        &&\n        _[\"CacheDataEncrypted\"] == true\n      ) \n    )\n  )\n  ```\n\n  Example output\n\n  ```mql\n  [failed] [].all()\n    actual:   [\n      0: aws.apigateway.restapi id = arn:aws:apigateway:us-east-1:053121068929::/apis/dvs21vajtg\n    ]\n  ```\n"
      remediation: |
        __Terraform__

        ```hcl
        # ... other configuration ...

        resource "aws_api_gateway_method_settings" "example" {
          rest_api_id = aws_api_gateway_rest_api.example.id
          stage_name  = aws_api_gateway_stage.example.stage_name
          method_path = "*/*"

          settings {
            cache_data_encrypted = true
            caching_enabled = true
          }
        }
        ```

        __AWS Console__

        To configure API caching for a given stage

        1. Open the API Gateway console at https://console.aws.amazon.com/apigateway/.
        2. Choose the API.
        3. Choose Stages.
        4. In the Stages list for the API, choose the stage to add caching to.
        5. Choose Settings.
        6. Choose Enable API cache.
        7. Update the desired settings, then select Encrypt cache data.
        8. Choose Save Changes.
    refs:
      - url: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-controls-reference.html
        title: AWS Documentation - Security Hub controls reference
  - uid: mondoo-aws-security-efs-encrypted-check
    title: Checks whether EFS is configured to encrypt file data using KMS
    impact: 30
    mql: "# @msg Found ${length} EFS file systems that are not encrypted:\n# \n# ${{ name arn id region tags }}  \naws.efs.filesystem {\n  encrypted == true && kmsKey != null \n}\n"
    docs:
      desc: |
        Amazon EFS supports two forms of encryption for file systems, encryption of data in transit and encryption at rest. This check ensures that all EFS file systems are configured with encryption at rest across all enabled regions in the account.
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.efs.filesystems.where( encrypted == false ) {*}\n  ```\n\n  Example output\n\n  ```mql\n  aws.efs.filesystems.where: [\n    0: {\n      tags: {\n        Name: \"12344375555-mondoo-demo-efs\"\n        git_file: \"terraform/aws/efs.tf\"\n        git_org: \"mondoolabs\"\n        git_repo: \"mondoo-demo-environment\"\n      }\n      id: \"fs-0a73947e541509f0e\"\n      region: \"us-west-2\"\n      name: \"12344375555-mondoo-demo-efs\"\n      kmsKey: null\n      encrypted: false\n      arn: \"arn:aws:elasticfilesystem:us-west-2:12344375555:file-system/fs-0a73947e541509f0e\"\n    }\n  ]       \n  ```\n"
      remediation: "__Terraform__\n\nThe following code snippet can be used to create a KMS encrypted EFS (Note: `kms_key_id` attribute is optional, and a key will be created if no kms key id is passed)\n\n```hcl\nresource \"aws_efs_file_system\" \"encrypted-efs\" {\n  creation_token = \"my-kms-encrypted-efs\"\n  encrypted      = true\n  kms_key_id     = \"arn:aws:kms:us-west-2:12344375555:key/16393ebd-3348-483f-b162-99b6648azz23\"\n\n  tags = {\n    Name = \"MyProduct\"\n  }\n}\n```   \n\n__AWS Console__\n\nTo configure EFS with encryption using the AWS console, see [Encrypting a file system at rest using the console](https://docs.aws.amazon.com/efs/latest/ug/encryption-at-rest.html).\n\n__AWS CLI__\n\nIt is important to notice that while creating EFS from the console enables encryption at rest by default, that is not true for EFS created using the CLI, API or SDK. The following example allows you to create an encrypted file system in your infrastructure.\n\n```bash\naws efs create-file-system \\\n--backup \\\n--encrypted \\\n--region us-east-1 \\\n```\n"
    refs:
      - url: https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html
        title: AWS Documentation - Security in Amazon EFS
      - url: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system
        title: Terraform Registry - aws_efs_file_system resource
      - url: https://docs.aws.amazon.com/efs/latest/ug/creating-using-create-fs.html#creating-using-fs-part1-cli
        title: AWS Documentation - Creating a file system using the AWS CLI
  - uid: mondoo-aws-security-cloudwatch-log-group-encrypted
    title: Checks that all log groups in Amazon CloudWatch Logs are encrypted with KMS
    mql: aws.cloudwatch.loggroup { kmsKey != null }
  - uid: mondoo-aws-security-elb-deletion-protection-enabled
    title: Checks whether elastic load balancing has deletion protection enabled
    mql: "aws.elb.loadbalancer { attributes \n  {  _['Key'] == \"deletion_protection.enabled\" && _['Value'] == true} \n}\n"
  - uid: mondoo-aws-security-elasticsearch-encrypted-at-rest
    title: Checks that all ES domains have encryption at rest configuration enabled
    mql: aws.es.domain { encryptionAtRestEnabled == true }
  - uid: mondoo-aws-security-rotation-customer-created-cmks-enabled
    title: Ensure rotation for customer created CMKs is enabled
    mql: aws.kms.key { if (metadata['KeyState'] == "Enabled") { keyRotationEnabled == true } }
  - uid: mondoo-aws-security-sagemaker-notebook-instance-kms-key-configured
    title: Checks that all SageMaker notebook instances are configured to use KMS
    mql: aws.sagemaker.notebookinstance { details.kmsKey != null }
  - uid: mondoo-aws-security-cloud-trail-encryption-enabled
    title: Checks that all CloudTrail trails are configured to use the server side encryption KMS
    impact: 30
    mql: |
      # @msg Found ${length} CloudTrail trail(s) with kms encryption disabled:
      #
      # ${{ arn name }}
      aws.cloudtrail.trail {
        kmsKey != null
      }
    docs:
      desc: |
        This check ensures CloudTrail is configured to use the server-side encryption (SSE) AWS KMS key encryption. The check passes if the KmsKeyId is defined.

        For more information on CloudTrail encryption at rest, please see:

          1. [Server Side Encryption with AWS KMS-managed key (SSE-KMS)](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html)
          2. [Amazon Server Side Encryption with Amazon S3-managed encryption keys (SSE-S3)](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html)
      audit: "__cnspec Shell__\n\n1. Open a Terminal.\n2. Connect to your AWS environment with cnspec shell: `cnspec shell aws`\n3. Run the following query \n\n  ```mql\n  aws.cloudtrail.trails.all(\n    kmsKey != null\n  )\n  ```\n\n  Example output\n\n  ```mql\n  [failed] [].all()\n    actual:   [\n      0: aws.cloudtrail.trail id = arn:aws:cloudtrail:us-east-1:053121068929:trail/s3-data-events\n    ]\n  ```\n"
      remediation: "__Terraform__\n\n```hcl\nTODO\n```\n\n__AWS Console__\n\nTo enable encryption for CloudTrail logs\n\n  1. Open the CloudTrail console at https://console.aws.amazon.com/cloudtrail/.\n  2. Choose Trails.\n  3. Choose the trail to update.\n  4. Under General details, choose Edit.\n  5. For Log file SSE-KMS encryption, select Enabled.\n  6. For Create a new KMS key, do one of the following:\n  \n    * To create a key, choose New. Then in AWS KMS alias, enter an alias for the key. The key is created in the same Region as the S3 bucket.\n    * To use an existing key, choose Existing, then from AWS KMS alias, choose the key.\n    * The AWS KMS key and S3 bucket must be in the same Region.\n\n  7. Choose Save.\n\n__AWS CLI__\n\n```bash\nTODO\n```\n"
  - uid: mondoo-aws-security-secgroup-restricted-ssh
    title: Checks that all incoming SSH traffic for the security groups is restricted
    mql: aws.ec2.securitygroup { ipPermissions.all(ipRanges.length == 0 && fromPort == 0 && toPort == 0)}
